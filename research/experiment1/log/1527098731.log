Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.118718, Accuracy: 0.960000, Test accuracy: 0.967500
Starting training epoch 1
Epoch : 2, Loss : 0.062083, Accuracy: 0.976000, Test accuracy: 0.979900
Starting training epoch 2
Epoch : 3, Loss : 0.063099, Accuracy: 0.984000, Test accuracy: 0.984600
Starting training epoch 3
Epoch : 4, Loss : 0.014971, Accuracy: 0.996000, Test accuracy: 0.986900
Starting training epoch 4
Epoch : 5, Loss : 0.021449, Accuracy: 0.992000, Test accuracy: 0.987600
Starting training epoch 5
Epoch : 6, Loss : 0.027148, Accuracy: 0.988000, Test accuracy: 0.990000
Starting training epoch 6
Epoch : 7, Loss : 0.037073, Accuracy: 0.988000, Test accuracy: 0.990900
Starting training epoch 7
Epoch : 8, Loss : 0.005053, Accuracy: 1.000000, Test accuracy: 0.989900
Starting training epoch 8
Epoch : 9, Loss : 0.041001, Accuracy: 0.992000, Test accuracy: 0.990200
Starting training epoch 9
Epoch : 10, Loss : 0.000925, Accuracy: 1.000000, Test accuracy: 0.991200
Starting training epoch 10
Epoch : 11, Loss : 0.002766, Accuracy: 1.000000, Test accuracy: 0.991300
Starting training epoch 11
Epoch : 12, Loss : 0.010086, Accuracy: 0.996000, Test accuracy: 0.991300
Starting training epoch 12
Epoch : 13, Loss : 0.002222, Accuracy: 1.000000, Test accuracy: 0.991400
Starting training epoch 13
Epoch : 14, Loss : 0.003234, Accuracy: 1.000000, Test accuracy: 0.991600
Starting training epoch 14
Epoch : 15, Loss : 0.001416, Accuracy: 1.000000, Test accuracy: 0.991500
Starting training epoch 15
Epoch : 16, Loss : 0.002805, Accuracy: 1.000000, Test accuracy: 0.991800
Starting training epoch 16
Epoch : 17, Loss : 0.003398, Accuracy: 1.000000, Test accuracy: 0.992200
Starting training epoch 17
Epoch : 18, Loss : 0.000915, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 18
Epoch : 19, Loss : 0.000868, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 19
Epoch : 20, Loss : 0.001995, Accuracy: 1.000000, Test accuracy: 0.990900
Starting training epoch 20
Epoch : 21, Loss : 0.009090, Accuracy: 0.996000, Test accuracy: 0.991900
Starting training epoch 21
Epoch : 22, Loss : 0.000141, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 22
Epoch : 23, Loss : 0.004649, Accuracy: 0.996000, Test accuracy: 0.991000
Starting training epoch 23
Epoch : 24, Loss : 0.000862, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 24
Epoch : 25, Loss : 0.002965, Accuracy: 1.000000, Test accuracy: 0.991400
Starting training epoch 25
Epoch : 26, Loss : 0.000302, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 26
Epoch : 27, Loss : 0.000106, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 27
Epoch : 28, Loss : 0.000043, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 28
Epoch : 29, Loss : 0.000710, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 29
Epoch : 30, Loss : 0.000202, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 30
Epoch : 31, Loss : 0.000754, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 31
Epoch : 32, Loss : 0.000146, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 32
Epoch : 33, Loss : 0.000272, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 33
Epoch : 34, Loss : 0.000034, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 34
Epoch : 35, Loss : 0.000399, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 35
Epoch : 36, Loss : 0.000020, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 36
Epoch : 37, Loss : 0.000199, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 37
Epoch : 38, Loss : 0.000014, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 38
Epoch : 39, Loss : 0.000023, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 39
Epoch : 40, Loss : 0.000102, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 40
Epoch : 41, Loss : 0.000037, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 41
Epoch : 42, Loss : 0.000454, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 42
Epoch : 43, Loss : 0.000006, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 43
Epoch : 44, Loss : 0.000016, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 44
Epoch : 45, Loss : 0.000131, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 45
Epoch : 46, Loss : 0.000245, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 46
Epoch : 47, Loss : 0.000007, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 47
Epoch : 48, Loss : 0.000033, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 48
Epoch : 49, Loss : 0.000032, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 49
Epoch : 50, Loss : 0.000015, Accuracy: 1.000000, Test accuracy: 0.993200
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 0.639424, Accuracy: 0.856000, Test accuracy: 0.838000
Starting training epoch 1
Epoch : 2, Loss : 0.411238, Accuracy: 0.880000, Test accuracy: 0.897300
Starting training epoch 2
Epoch : 3, Loss : 0.258092, Accuracy: 0.920000, Test accuracy: 0.911900
Starting training epoch 3
Epoch : 4, Loss : 0.400943, Accuracy: 0.876000, Test accuracy: 0.920600
Starting training epoch 4
Epoch : 5, Loss : 0.268156, Accuracy: 0.936000, Test accuracy: 0.925700
Starting training epoch 5
Epoch : 6, Loss : 0.183308, Accuracy: 0.952000, Test accuracy: 0.929400
Starting training epoch 6
Epoch : 7, Loss : 0.234603, Accuracy: 0.900000, Test accuracy: 0.932900
Starting training epoch 7
Epoch : 8, Loss : 0.321476, Accuracy: 0.912000, Test accuracy: 0.937500
Starting training epoch 8
Epoch : 9, Loss : 0.189236, Accuracy: 0.948000, Test accuracy: 0.940100
Starting training epoch 9
Epoch : 10, Loss : 0.225068, Accuracy: 0.924000, Test accuracy: 0.943900
Starting training epoch 10
Epoch : 11, Loss : 0.083364, Accuracy: 0.976000, Test accuracy: 0.947000
Starting training epoch 11
Epoch : 12, Loss : 0.291179, Accuracy: 0.932000, Test accuracy: 0.947600
Starting training epoch 12
Epoch : 13, Loss : 0.166910, Accuracy: 0.940000, Test accuracy: 0.951600
Starting training epoch 13
Epoch : 14, Loss : 0.166587, Accuracy: 0.952000, Test accuracy: 0.952300
Starting training epoch 14
Epoch : 15, Loss : 0.148742, Accuracy: 0.948000, Test accuracy: 0.954200
Starting training epoch 15
Epoch : 16, Loss : 0.160824, Accuracy: 0.952000, Test accuracy: 0.955500
Starting training epoch 16
Epoch : 17, Loss : 0.185019, Accuracy: 0.936000, Test accuracy: 0.957700
Starting training epoch 17
Epoch : 18, Loss : 0.166919, Accuracy: 0.952000, Test accuracy: 0.957900
Starting training epoch 18
Epoch : 19, Loss : 0.163187, Accuracy: 0.944000, Test accuracy: 0.959000
Starting training epoch 19
Epoch : 20, Loss : 0.115424, Accuracy: 0.964000, Test accuracy: 0.959200
Starting training epoch 20
Epoch : 21, Loss : 0.100015, Accuracy: 0.968000, Test accuracy: 0.961000
Starting training epoch 21
Epoch : 22, Loss : 0.131991, Accuracy: 0.956000, Test accuracy: 0.960700
Starting training epoch 22
Epoch : 23, Loss : 0.138224, Accuracy: 0.948000, Test accuracy: 0.962200
Starting training epoch 23
Epoch : 24, Loss : 0.130837, Accuracy: 0.960000, Test accuracy: 0.961800
Starting training epoch 24
Epoch : 25, Loss : 0.114843, Accuracy: 0.972000, Test accuracy: 0.961800
Starting training epoch 25
Epoch : 26, Loss : 0.061204, Accuracy: 0.984000, Test accuracy: 0.963600
Starting training epoch 26
Epoch : 27, Loss : 0.077884, Accuracy: 0.984000, Test accuracy: 0.961700
Starting training epoch 27
Epoch : 28, Loss : 0.108242, Accuracy: 0.980000, Test accuracy: 0.963600
Starting training epoch 28
Epoch : 29, Loss : 0.113052, Accuracy: 0.956000, Test accuracy: 0.963300
Starting training epoch 29
Epoch : 30, Loss : 0.096262, Accuracy: 0.968000, Test accuracy: 0.964100
Starting training epoch 30
Epoch : 31, Loss : 0.125275, Accuracy: 0.964000, Test accuracy: 0.964400
Starting training epoch 31
Epoch : 32, Loss : 0.133550, Accuracy: 0.968000, Test accuracy: 0.964800
Starting training epoch 32
Epoch : 33, Loss : 0.095563, Accuracy: 0.976000, Test accuracy: 0.964900
Starting training epoch 33
Epoch : 34, Loss : 0.093040, Accuracy: 0.968000, Test accuracy: 0.965900
Starting training epoch 34
Epoch : 35, Loss : 0.089266, Accuracy: 0.964000, Test accuracy: 0.966000
Starting training epoch 35
Epoch : 36, Loss : 0.369810, Accuracy: 0.944000, Test accuracy: 0.965600
Starting training epoch 36
Epoch : 37, Loss : 0.081969, Accuracy: 0.968000, Test accuracy: 0.965800
Starting training epoch 37
Epoch : 38, Loss : 0.129668, Accuracy: 0.976000, Test accuracy: 0.966100
Starting training epoch 38
Epoch : 39, Loss : 0.071451, Accuracy: 0.976000, Test accuracy: 0.965900
Starting training epoch 39
Epoch : 40, Loss : 0.077381, Accuracy: 0.980000, Test accuracy: 0.966100
Starting training epoch 40
Epoch : 41, Loss : 0.109145, Accuracy: 0.960000, Test accuracy: 0.966900
Starting training epoch 41
Epoch : 42, Loss : 0.056447, Accuracy: 0.984000, Test accuracy: 0.966500
Starting training epoch 42
Epoch : 43, Loss : 0.078123, Accuracy: 0.964000, Test accuracy: 0.967700
Starting training epoch 43
Epoch : 44, Loss : 0.152600, Accuracy: 0.956000, Test accuracy: 0.968300
Starting training epoch 44
Epoch : 45, Loss : 0.149276, Accuracy: 0.956000, Test accuracy: 0.969200
Starting training epoch 45
Epoch : 46, Loss : 0.121156, Accuracy: 0.968000, Test accuracy: 0.969000
Starting training epoch 46
Epoch : 47, Loss : 0.140529, Accuracy: 0.964000, Test accuracy: 0.969300
Starting training epoch 47
Epoch : 48, Loss : 0.076469, Accuracy: 0.976000, Test accuracy: 0.968100
Starting training epoch 48
Epoch : 49, Loss : 0.107008, Accuracy: 0.976000, Test accuracy: 0.968400
Starting training epoch 49
Epoch : 50, Loss : 0.141049, Accuracy: 0.956000, Test accuracy: 0.969300
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 1.298454, Accuracy: 0.728000, Test accuracy: 0.740500
Starting training opoch 1
Epoch : 2, Loss : 0.598686, Accuracy: 0.852000, Test accuracy: 0.847500
Starting training opoch 2
Epoch : 3, Loss : 0.431399, Accuracy: 0.888000, Test accuracy: 0.876500
Starting training opoch 3
Epoch : 4, Loss : 0.384108, Accuracy: 0.908000, Test accuracy: 0.892200
Starting training opoch 4
Epoch : 5, Loss : 0.410131, Accuracy: 0.880000, Test accuracy: 0.901300
Starting training opoch 5
Epoch : 6, Loss : 0.295524, Accuracy: 0.916000, Test accuracy: 0.907700
Starting training opoch 6
Epoch : 7, Loss : 0.262601, Accuracy: 0.900000, Test accuracy: 0.914500
Starting training opoch 7
Epoch : 8, Loss : 0.318402, Accuracy: 0.892000, Test accuracy: 0.918800
Starting training opoch 8
Epoch : 9, Loss : 0.304556, Accuracy: 0.904000, Test accuracy: 0.922700
Starting training opoch 9
Epoch : 10, Loss : 0.358442, Accuracy: 0.900000, Test accuracy: 0.925100
Starting training opoch 10
Epoch : 11, Loss : 0.247519, Accuracy: 0.928000, Test accuracy: 0.928700
Starting training opoch 11
Epoch : 12, Loss : 0.252037, Accuracy: 0.932000, Test accuracy: 0.930900
Starting training opoch 12
Epoch : 13, Loss : 0.269551, Accuracy: 0.920000, Test accuracy: 0.934400
Starting training opoch 13
Epoch : 14, Loss : 0.238404, Accuracy: 0.936000, Test accuracy: 0.936500
Starting training opoch 14
Epoch : 15, Loss : 0.157250, Accuracy: 0.936000, Test accuracy: 0.939700
Starting training opoch 15
Epoch : 16, Loss : 0.259133, Accuracy: 0.920000, Test accuracy: 0.940600
Starting training opoch 16
Epoch : 17, Loss : 0.219910, Accuracy: 0.952000, Test accuracy: 0.943800
Starting training opoch 17
Epoch : 18, Loss : 0.261637, Accuracy: 0.932000, Test accuracy: 0.944800
Starting training opoch 18
Epoch : 19, Loss : 0.235609, Accuracy: 0.936000, Test accuracy: 0.946800
Starting training opoch 19
Epoch : 20, Loss : 0.206572, Accuracy: 0.952000, Test accuracy: 0.946800
Starting training opoch 20
Epoch : 21, Loss : 0.184390, Accuracy: 0.944000, Test accuracy: 0.948900
Starting training opoch 21
Epoch : 22, Loss : 0.227263, Accuracy: 0.956000, Test accuracy: 0.950000
Starting training opoch 22
Epoch : 23, Loss : 0.202463, Accuracy: 0.948000, Test accuracy: 0.951400
Starting training opoch 23
Epoch : 24, Loss : 0.235717, Accuracy: 0.952000, Test accuracy: 0.951100
Starting training opoch 24
Epoch : 25, Loss : 0.159398, Accuracy: 0.948000, Test accuracy: 0.952300
Starting training opoch 25
Epoch : 26, Loss : 0.111380, Accuracy: 0.968000, Test accuracy: 0.952500
Starting training opoch 26
Epoch : 27, Loss : 0.161417, Accuracy: 0.956000, Test accuracy: 0.953400
Starting training opoch 27
Epoch : 28, Loss : 0.156776, Accuracy: 0.948000, Test accuracy: 0.954400
Starting training opoch 28
Epoch : 29, Loss : 0.128634, Accuracy: 0.972000, Test accuracy: 0.955000
Starting training opoch 29
Epoch : 30, Loss : 0.193769, Accuracy: 0.940000, Test accuracy: 0.954800
Starting training opoch 30
Epoch : 31, Loss : 0.149964, Accuracy: 0.960000, Test accuracy: 0.955500
Starting training opoch 31
Epoch : 32, Loss : 0.227033, Accuracy: 0.936000, Test accuracy: 0.956600
Starting training opoch 32
Epoch : 33, Loss : 0.146782, Accuracy: 0.948000, Test accuracy: 0.955300
Starting training opoch 33
Epoch : 34, Loss : 0.230960, Accuracy: 0.964000, Test accuracy: 0.956900
Starting training opoch 34
Epoch : 35, Loss : 0.229147, Accuracy: 0.932000, Test accuracy: 0.956300
Starting training opoch 35
Epoch : 36, Loss : 0.156734, Accuracy: 0.956000, Test accuracy: 0.956800
Starting training opoch 36
Epoch : 37, Loss : 0.205473, Accuracy: 0.940000, Test accuracy: 0.958000
Starting training opoch 37
Epoch : 38, Loss : 0.113464, Accuracy: 0.976000, Test accuracy: 0.957100
Starting training opoch 38
Epoch : 39, Loss : 0.161618, Accuracy: 0.940000, Test accuracy: 0.958200
Starting training opoch 39
Epoch : 40, Loss : 0.142432, Accuracy: 0.968000, Test accuracy: 0.957700
Starting training opoch 40
Epoch : 41, Loss : 0.157781, Accuracy: 0.952000, Test accuracy: 0.958200
Starting training opoch 41
Epoch : 42, Loss : 0.125345, Accuracy: 0.968000, Test accuracy: 0.958400
Starting training opoch 42
Epoch : 43, Loss : 0.137795, Accuracy: 0.972000, Test accuracy: 0.957900
Starting training opoch 43
Epoch : 44, Loss : 0.221868, Accuracy: 0.944000, Test accuracy: 0.959000
Starting training opoch 44
Epoch : 45, Loss : 0.063573, Accuracy: 0.988000, Test accuracy: 0.958800
Starting training opoch 45
Epoch : 46, Loss : 0.242452, Accuracy: 0.956000, Test accuracy: 0.959700
Starting training opoch 46
Epoch : 47, Loss : 0.106466, Accuracy: 0.976000, Test accuracy: 0.960200
Starting training opoch 47
Epoch : 48, Loss : 0.118864, Accuracy: 0.956000, Test accuracy: 0.958800
Starting training opoch 48
Epoch : 49, Loss : 0.155658, Accuracy: 0.952000, Test accuracy: 0.959900
Starting training opoch 49
Epoch : 50, Loss : 0.184344, Accuracy: 0.936000, Test accuracy: 0.962000
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.726171, Accuracy: 0.784000, Test accuracy: 0.834800
Starting training epoch 1
Epoch : 2, Loss : 0.400341, Accuracy: 0.888000, Test accuracy: 0.895500
Starting training epoch 2
Epoch : 3, Loss : 0.325772, Accuracy: 0.896000, Test accuracy: 0.913700
Starting training epoch 3
Epoch : 4, Loss : 0.287124, Accuracy: 0.932000, Test accuracy: 0.924300
Starting training epoch 4
Epoch : 5, Loss : 0.320996, Accuracy: 0.912000, Test accuracy: 0.932800
Starting training epoch 5
Epoch : 6, Loss : 0.208188, Accuracy: 0.940000, Test accuracy: 0.939800
Starting training epoch 6
Epoch : 7, Loss : 0.185832, Accuracy: 0.944000, Test accuracy: 0.945000
Starting training epoch 7
Epoch : 8, Loss : 0.185450, Accuracy: 0.944000, Test accuracy: 0.949600
Starting training epoch 8
Epoch : 9, Loss : 0.139850, Accuracy: 0.964000, Test accuracy: 0.952000
Starting training epoch 9
Epoch : 10, Loss : 0.142753, Accuracy: 0.960000, Test accuracy: 0.954400
Starting training epoch 10
Epoch : 11, Loss : 0.161048, Accuracy: 0.952000, Test accuracy: 0.958800
Starting training epoch 11
Epoch : 12, Loss : 0.088906, Accuracy: 0.972000, Test accuracy: 0.961800
Starting training epoch 12
Epoch : 13, Loss : 0.186129, Accuracy: 0.948000, Test accuracy: 0.961400
Starting training epoch 13
Epoch : 14, Loss : 0.121933, Accuracy: 0.948000, Test accuracy: 0.963300
Starting training epoch 14
Epoch : 15, Loss : 0.172028, Accuracy: 0.956000, Test accuracy: 0.966500
Starting training epoch 15
Epoch : 16, Loss : 0.154051, Accuracy: 0.960000, Test accuracy: 0.967600
Starting training epoch 16
Epoch : 17, Loss : 0.090125, Accuracy: 0.972000, Test accuracy: 0.969800
Starting training epoch 17
Epoch : 18, Loss : 0.149985, Accuracy: 0.956000, Test accuracy: 0.970900
Starting training epoch 18
Epoch : 19, Loss : 0.193370, Accuracy: 0.948000, Test accuracy: 0.970200
Starting training epoch 19
Epoch : 20, Loss : 0.087572, Accuracy: 0.980000, Test accuracy: 0.968600
Starting training epoch 20
Epoch : 21, Loss : 0.069182, Accuracy: 0.984000, Test accuracy: 0.971500
Starting training epoch 21
Epoch : 22, Loss : 0.145824, Accuracy: 0.956000, Test accuracy: 0.973000
Starting training epoch 22
Epoch : 23, Loss : 0.094271, Accuracy: 0.968000, Test accuracy: 0.973100
Starting training epoch 23
Epoch : 24, Loss : 0.127260, Accuracy: 0.972000, Test accuracy: 0.972500
Starting training epoch 24
Epoch : 25, Loss : 0.143079, Accuracy: 0.964000, Test accuracy: 0.972100
Starting training epoch 25
Epoch : 26, Loss : 0.078693, Accuracy: 0.976000, Test accuracy: 0.974200
Starting training epoch 26
Epoch : 27, Loss : 0.076653, Accuracy: 0.968000, Test accuracy: 0.974400
Starting training epoch 27
Epoch : 28, Loss : 0.069488, Accuracy: 0.980000, Test accuracy: 0.973600
Starting training epoch 28
Epoch : 29, Loss : 0.097595, Accuracy: 0.964000, Test accuracy: 0.974600
Starting training epoch 29
Epoch : 30, Loss : 0.072637, Accuracy: 0.972000, Test accuracy: 0.975700
Starting training epoch 30
Epoch : 31, Loss : 0.075398, Accuracy: 0.980000, Test accuracy: 0.976500
Starting training epoch 31
Epoch : 32, Loss : 0.065058, Accuracy: 0.984000, Test accuracy: 0.976100
Starting training epoch 32
Epoch : 33, Loss : 0.107911, Accuracy: 0.956000, Test accuracy: 0.977800
Starting training epoch 33
Epoch : 34, Loss : 0.099545, Accuracy: 0.980000, Test accuracy: 0.976200
Starting training epoch 34
Epoch : 35, Loss : 0.058309, Accuracy: 0.984000, Test accuracy: 0.975900
Starting training epoch 35
Epoch : 36, Loss : 0.083375, Accuracy: 0.976000, Test accuracy: 0.976500
Starting training epoch 36
Epoch : 37, Loss : 0.066083, Accuracy: 0.980000, Test accuracy: 0.977400
Starting training epoch 37
Epoch : 38, Loss : 0.091990, Accuracy: 0.968000, Test accuracy: 0.978200
Starting training epoch 38
Epoch : 39, Loss : 0.060169, Accuracy: 0.980000, Test accuracy: 0.977300
Starting training epoch 39
Epoch : 40, Loss : 0.045045, Accuracy: 0.984000, Test accuracy: 0.977600
Starting training epoch 40
Epoch : 41, Loss : 0.096134, Accuracy: 0.976000, Test accuracy: 0.978300
Starting training epoch 41
Epoch : 42, Loss : 0.089013, Accuracy: 0.980000, Test accuracy: 0.978800
Starting training epoch 42
Epoch : 43, Loss : 0.151869, Accuracy: 0.964000, Test accuracy: 0.976500
Starting training epoch 43
Epoch : 44, Loss : 0.061560, Accuracy: 0.980000, Test accuracy: 0.979800
Starting training epoch 44
Epoch : 45, Loss : 0.054297, Accuracy: 0.988000, Test accuracy: 0.978400
Starting training epoch 45
Epoch : 46, Loss : 0.037518, Accuracy: 0.992000, Test accuracy: 0.979100
Starting training epoch 46
Epoch : 47, Loss : 0.079580, Accuracy: 0.968000, Test accuracy: 0.979300
Starting training epoch 47
Epoch : 48, Loss : 0.087204, Accuracy: 0.972000, Test accuracy: 0.978600
Starting training epoch 48
Epoch : 49, Loss : 0.046347, Accuracy: 0.984000, Test accuracy: 0.979000
Starting training epoch 49
Epoch : 50, Loss : 0.043634, Accuracy: 0.988000, Test accuracy: 0.980400
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.808041, Accuracy: 0.776000, Test accuracy: 0.814300
Starting training opoch 1
Epoch : 2, Loss : 0.570265, Accuracy: 0.848000, Test accuracy: 0.882500
Starting training opoch 2
Epoch : 3, Loss : 0.354411, Accuracy: 0.892000, Test accuracy: 0.903800
Starting training opoch 3
Epoch : 4, Loss : 0.309060, Accuracy: 0.916000, Test accuracy: 0.914300
Starting training opoch 4
Epoch : 5, Loss : 0.439735, Accuracy: 0.884000, Test accuracy: 0.922900
Starting training opoch 5
Epoch : 6, Loss : 0.479455, Accuracy: 0.872000, Test accuracy: 0.927300
Starting training opoch 6
Epoch : 7, Loss : 0.212161, Accuracy: 0.932000, Test accuracy: 0.931100
Starting training opoch 7
Epoch : 8, Loss : 0.170715, Accuracy: 0.948000, Test accuracy: 0.935900
Starting training opoch 8
Epoch : 9, Loss : 0.277896, Accuracy: 0.916000, Test accuracy: 0.940000
Starting training opoch 9
Epoch : 10, Loss : 0.182444, Accuracy: 0.944000, Test accuracy: 0.943700
Starting training opoch 10
Epoch : 11, Loss : 0.169414, Accuracy: 0.956000, Test accuracy: 0.944900
Starting training opoch 11
Epoch : 12, Loss : 0.196869, Accuracy: 0.944000, Test accuracy: 0.949500
Starting training opoch 12
Epoch : 13, Loss : 0.189669, Accuracy: 0.944000, Test accuracy: 0.950800
Starting training opoch 13
Epoch : 14, Loss : 0.161590, Accuracy: 0.952000, Test accuracy: 0.952500
Starting training opoch 14
Epoch : 15, Loss : 0.199877, Accuracy: 0.956000, Test accuracy: 0.954700
Starting training opoch 15
Epoch : 16, Loss : 0.238091, Accuracy: 0.944000, Test accuracy: 0.956400
Starting training opoch 16
Epoch : 17, Loss : 0.167814, Accuracy: 0.956000, Test accuracy: 0.956800
Starting training opoch 17
Epoch : 18, Loss : 0.174251, Accuracy: 0.940000, Test accuracy: 0.958900
Starting training opoch 18
Epoch : 19, Loss : 0.154468, Accuracy: 0.952000, Test accuracy: 0.958800
Starting training opoch 19
Epoch : 20, Loss : 0.115736, Accuracy: 0.964000, Test accuracy: 0.960000
Starting training opoch 20
Epoch : 21, Loss : 0.125135, Accuracy: 0.968000, Test accuracy: 0.961000
Starting training opoch 21
Epoch : 22, Loss : 0.190160, Accuracy: 0.952000, Test accuracy: 0.961600
Starting training opoch 22
Epoch : 23, Loss : 0.112505, Accuracy: 0.960000, Test accuracy: 0.962400
Starting training opoch 23
Epoch : 24, Loss : 0.148748, Accuracy: 0.960000, Test accuracy: 0.963600
Starting training opoch 24
Epoch : 25, Loss : 0.112863, Accuracy: 0.964000, Test accuracy: 0.964500
Starting training opoch 25
Epoch : 26, Loss : 0.112838, Accuracy: 0.972000, Test accuracy: 0.965300
Starting training opoch 26
Epoch : 27, Loss : 0.137320, Accuracy: 0.964000, Test accuracy: 0.966100
Starting training opoch 27
Epoch : 28, Loss : 0.091169, Accuracy: 0.968000, Test accuracy: 0.966100
Starting training opoch 28
Epoch : 29, Loss : 0.096829, Accuracy: 0.964000, Test accuracy: 0.966900
Starting training opoch 29
Epoch : 30, Loss : 0.080275, Accuracy: 0.976000, Test accuracy: 0.967300
Starting training opoch 30
Epoch : 31, Loss : 0.105056, Accuracy: 0.980000, Test accuracy: 0.967600
Starting training opoch 31
Epoch : 32, Loss : 0.092276, Accuracy: 0.980000, Test accuracy: 0.968500
Starting training opoch 32
Epoch : 33, Loss : 0.073518, Accuracy: 0.968000, Test accuracy: 0.968900
Starting training opoch 33
Epoch : 34, Loss : 0.144976, Accuracy: 0.944000, Test accuracy: 0.969400
Starting training opoch 34
Epoch : 35, Loss : 0.136180, Accuracy: 0.956000, Test accuracy: 0.969200
Starting training opoch 35
Epoch : 36, Loss : 0.053299, Accuracy: 0.980000, Test accuracy: 0.969900
Starting training opoch 36
Epoch : 37, Loss : 0.077167, Accuracy: 0.980000, Test accuracy: 0.970500
Starting training opoch 37
Epoch : 38, Loss : 0.086758, Accuracy: 0.976000, Test accuracy: 0.971300
Starting training opoch 38
Epoch : 39, Loss : 0.127237, Accuracy: 0.972000, Test accuracy: 0.970200
Starting training opoch 39
Epoch : 40, Loss : 0.072357, Accuracy: 0.976000, Test accuracy: 0.970500
Starting training opoch 40
Epoch : 41, Loss : 0.123231, Accuracy: 0.964000, Test accuracy: 0.970500
Starting training opoch 41
Epoch : 42, Loss : 0.081282, Accuracy: 0.980000, Test accuracy: 0.971700
Starting training opoch 42
Epoch : 43, Loss : 0.083726, Accuracy: 0.972000, Test accuracy: 0.971800
Starting training opoch 43
Epoch : 44, Loss : 0.132385, Accuracy: 0.960000, Test accuracy: 0.972400
Starting training opoch 44
Epoch : 45, Loss : 0.075150, Accuracy: 0.976000, Test accuracy: 0.972700
Starting training opoch 45
Epoch : 46, Loss : 0.078365, Accuracy: 0.968000, Test accuracy: 0.973900
Starting training opoch 46
Epoch : 47, Loss : 0.098299, Accuracy: 0.976000, Test accuracy: 0.972300
Starting training opoch 47
Epoch : 48, Loss : 0.079103, Accuracy: 0.976000, Test accuracy: 0.972000
Starting training opoch 48
Epoch : 49, Loss : 0.079057, Accuracy: 0.976000, Test accuracy: 0.973500
Starting training opoch 49
Epoch : 50, Loss : 0.108068, Accuracy: 0.976000, Test accuracy: 0.973200
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.840975, Accuracy: 0.796000, Test accuracy: 0.807400
Starting training opoch 1
Epoch : 2, Loss : 0.599491, Accuracy: 0.824000, Test accuracy: 0.873500
Starting training opoch 2
Epoch : 3, Loss : 0.396660, Accuracy: 0.916000, Test accuracy: 0.892400
Starting training opoch 3
Epoch : 4, Loss : 0.315595, Accuracy: 0.912000, Test accuracy: 0.900100
Starting training opoch 4
Epoch : 5, Loss : 0.347811, Accuracy: 0.876000, Test accuracy: 0.903400
Starting training opoch 5
Epoch : 6, Loss : 0.366643, Accuracy: 0.904000, Test accuracy: 0.909100
Starting training opoch 6
Epoch : 7, Loss : 0.287030, Accuracy: 0.928000, Test accuracy: 0.910000
Starting training opoch 7
Epoch : 8, Loss : 0.342999, Accuracy: 0.888000, Test accuracy: 0.911600
Starting training opoch 8
Epoch : 9, Loss : 0.366724, Accuracy: 0.876000, Test accuracy: 0.913100
Starting training opoch 9
Epoch : 10, Loss : 0.323594, Accuracy: 0.912000, Test accuracy: 0.915700
Starting training opoch 10
Epoch : 11, Loss : 0.260688, Accuracy: 0.944000, Test accuracy: 0.914700
Starting training opoch 11
Epoch : 12, Loss : 0.357506, Accuracy: 0.904000, Test accuracy: 0.917400
Starting training opoch 12
Epoch : 13, Loss : 0.279484, Accuracy: 0.924000, Test accuracy: 0.918500
Starting training opoch 13
Epoch : 14, Loss : 0.249084, Accuracy: 0.920000, Test accuracy: 0.918400
Starting training opoch 14
Epoch : 15, Loss : 0.243656, Accuracy: 0.932000, Test accuracy: 0.920800
Starting training opoch 15
Epoch : 16, Loss : 0.255423, Accuracy: 0.932000, Test accuracy: 0.921600
Starting training opoch 16
Epoch : 17, Loss : 0.366006, Accuracy: 0.908000, Test accuracy: 0.922500
Starting training opoch 17
Epoch : 18, Loss : 0.336439, Accuracy: 0.924000, Test accuracy: 0.922800
Starting training opoch 18
Epoch : 19, Loss : 0.351664, Accuracy: 0.900000, Test accuracy: 0.925800
Starting training opoch 19
Epoch : 20, Loss : 0.209323, Accuracy: 0.936000, Test accuracy: 0.926300
Starting training opoch 20
Epoch : 21, Loss : 0.196865, Accuracy: 0.924000, Test accuracy: 0.928000
Starting training opoch 21
Epoch : 22, Loss : 0.256457, Accuracy: 0.932000, Test accuracy: 0.929300
Starting training opoch 22
Epoch : 23, Loss : 0.356597, Accuracy: 0.892000, Test accuracy: 0.929900
Starting training opoch 23
Epoch : 24, Loss : 0.229353, Accuracy: 0.936000, Test accuracy: 0.930800
Starting training opoch 24
Epoch : 25, Loss : 0.246047, Accuracy: 0.932000, Test accuracy: 0.932100
Starting training opoch 25
Epoch : 26, Loss : 0.260792, Accuracy: 0.916000, Test accuracy: 0.932800
Starting training opoch 26
Epoch : 27, Loss : 0.218824, Accuracy: 0.924000, Test accuracy: 0.934500
Starting training opoch 27
Epoch : 28, Loss : 0.243239, Accuracy: 0.940000, Test accuracy: 0.935400
Starting training opoch 28
Epoch : 29, Loss : 0.188147, Accuracy: 0.936000, Test accuracy: 0.936500
Starting training opoch 29
Epoch : 30, Loss : 0.205093, Accuracy: 0.952000, Test accuracy: 0.938200
Starting training opoch 30
Epoch : 31, Loss : 0.246587, Accuracy: 0.940000, Test accuracy: 0.939000
Starting training opoch 31
Epoch : 32, Loss : 0.219381, Accuracy: 0.940000, Test accuracy: 0.941000
Starting training opoch 32
Epoch : 33, Loss : 0.183150, Accuracy: 0.952000, Test accuracy: 0.941200
Starting training opoch 33
Epoch : 34, Loss : 0.222318, Accuracy: 0.940000, Test accuracy: 0.943300
Starting training opoch 34
Epoch : 35, Loss : 0.178449, Accuracy: 0.952000, Test accuracy: 0.942700
Starting training opoch 35
Epoch : 36, Loss : 0.176287, Accuracy: 0.940000, Test accuracy: 0.943400
Starting training opoch 36
Epoch : 37, Loss : 0.137938, Accuracy: 0.964000, Test accuracy: 0.945600
Starting training opoch 37
Epoch : 38, Loss : 0.189341, Accuracy: 0.956000, Test accuracy: 0.945000
Starting training opoch 38
Epoch : 39, Loss : 0.130915, Accuracy: 0.960000, Test accuracy: 0.947100
Starting training opoch 39
Epoch : 40, Loss : 0.191296, Accuracy: 0.944000, Test accuracy: 0.948200
Starting training opoch 40
Epoch : 41, Loss : 0.168851, Accuracy: 0.944000, Test accuracy: 0.945900
Starting training opoch 41
Epoch : 42, Loss : 0.214985, Accuracy: 0.928000, Test accuracy: 0.948400
Starting training opoch 42
Epoch : 43, Loss : 0.239875, Accuracy: 0.944000, Test accuracy: 0.949800
Starting training opoch 43
Epoch : 44, Loss : 0.199733, Accuracy: 0.928000, Test accuracy: 0.947800
Starting training opoch 44
Epoch : 45, Loss : 0.166583, Accuracy: 0.952000, Test accuracy: 0.949000
Starting training opoch 45
Epoch : 46, Loss : 0.236627, Accuracy: 0.936000, Test accuracy: 0.951500
Starting training opoch 46
Epoch : 47, Loss : 0.166075, Accuracy: 0.956000, Test accuracy: 0.952000
Starting training opoch 47
Epoch : 48, Loss : 0.224278, Accuracy: 0.944000, Test accuracy: 0.952000
Starting training opoch 48
Epoch : 49, Loss : 0.129679, Accuracy: 0.964000, Test accuracy: 0.953500
Starting training opoch 49
Epoch : 50, Loss : 0.174524, Accuracy: 0.948000, Test accuracy: 0.951900
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9932
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.713279, Accuracy: 0.806000, Test accuracy: 0.808900
Distillation: Epoch : 2, Loss : 0.394281, Accuracy: 0.889000, Test accuracy: 0.878700
Distillation: Epoch : 3, Loss : 0.396164, Accuracy: 0.893000, Test accuracy: 0.897400
Distillation: Epoch : 4, Loss : 0.335714, Accuracy: 0.897000, Test accuracy: 0.906300
Distillation: Epoch : 5, Loss : 0.267526, Accuracy: 0.923000, Test accuracy: 0.915100
Distillation: Epoch : 6, Loss : 0.307246, Accuracy: 0.918000, Test accuracy: 0.920100
Distillation: Epoch : 7, Loss : 0.286287, Accuracy: 0.914000, Test accuracy: 0.922400
Distillation: Epoch : 8, Loss : 0.257498, Accuracy: 0.931000, Test accuracy: 0.926100
Distillation: Epoch : 9, Loss : 0.252769, Accuracy: 0.926000, Test accuracy: 0.930100
Distillation: Epoch : 10, Loss : 0.238786, Accuracy: 0.940000, Test accuracy: 0.932700
Distillation: Epoch : 11, Loss : 0.222765, Accuracy: 0.929000, Test accuracy: 0.933600
Distillation: Epoch : 12, Loss : 0.191785, Accuracy: 0.953000, Test accuracy: 0.936400
Distillation: Epoch : 13, Loss : 0.240988, Accuracy: 0.931000, Test accuracy: 0.938300
Distillation: Epoch : 14, Loss : 0.186672, Accuracy: 0.945000, Test accuracy: 0.939800
Distillation: Epoch : 15, Loss : 0.217856, Accuracy: 0.937000, Test accuracy: 0.940800
Distillation: Epoch : 16, Loss : 0.231867, Accuracy: 0.940000, Test accuracy: 0.943500
Distillation: Epoch : 17, Loss : 0.194696, Accuracy: 0.940000, Test accuracy: 0.943700
Distillation: Epoch : 18, Loss : 0.164719, Accuracy: 0.958000, Test accuracy: 0.946500
Distillation: Epoch : 19, Loss : 0.186633, Accuracy: 0.950000, Test accuracy: 0.948100
Distillation: Epoch : 20, Loss : 0.167372, Accuracy: 0.951000, Test accuracy: 0.949400
Distillation: Epoch : 21, Loss : 0.164712, Accuracy: 0.953000, Test accuracy: 0.951000
Distillation: Epoch : 22, Loss : 0.150610, Accuracy: 0.960000, Test accuracy: 0.951300
Distillation: Epoch : 23, Loss : 0.163438, Accuracy: 0.952000, Test accuracy: 0.952900
Distillation: Epoch : 24, Loss : 0.154113, Accuracy: 0.955000, Test accuracy: 0.953300
Distillation: Epoch : 25, Loss : 0.136243, Accuracy: 0.961000, Test accuracy: 0.953900
Distillation: Epoch : 26, Loss : 0.136355, Accuracy: 0.955000, Test accuracy: 0.955400
Distillation: Epoch : 27, Loss : 0.129341, Accuracy: 0.960000, Test accuracy: 0.958000
Distillation: Epoch : 28, Loss : 0.138812, Accuracy: 0.956000, Test accuracy: 0.957700
Distillation: Epoch : 29, Loss : 0.139924, Accuracy: 0.951000, Test accuracy: 0.959400
Distillation: Epoch : 30, Loss : 0.164186, Accuracy: 0.952000, Test accuracy: 0.960400
Distillation: Epoch : 31, Loss : 0.129167, Accuracy: 0.963000, Test accuracy: 0.961100
Distillation: Epoch : 32, Loss : 0.153949, Accuracy: 0.955000, Test accuracy: 0.961900
Distillation: Epoch : 33, Loss : 0.161671, Accuracy: 0.958000, Test accuracy: 0.962600
Distillation: Epoch : 34, Loss : 0.101610, Accuracy: 0.966000, Test accuracy: 0.963700
Distillation: Epoch : 35, Loss : 0.116207, Accuracy: 0.967000, Test accuracy: 0.964000
Distillation: Epoch : 36, Loss : 0.137527, Accuracy: 0.962000, Test accuracy: 0.965200
Distillation: Epoch : 37, Loss : 0.122167, Accuracy: 0.959000, Test accuracy: 0.964900
Distillation: Epoch : 38, Loss : 0.112686, Accuracy: 0.964000, Test accuracy: 0.966400
Distillation: Epoch : 39, Loss : 0.139677, Accuracy: 0.962000, Test accuracy: 0.967100
Distillation: Epoch : 40, Loss : 0.104984, Accuracy: 0.964000, Test accuracy: 0.966000
Distillation: Epoch : 41, Loss : 0.131599, Accuracy: 0.962000, Test accuracy: 0.967200
Distillation: Epoch : 42, Loss : 0.108559, Accuracy: 0.971000, Test accuracy: 0.967900
Distillation: Epoch : 43, Loss : 0.091608, Accuracy: 0.974000, Test accuracy: 0.968700
Distillation: Epoch : 44, Loss : 0.093120, Accuracy: 0.970000, Test accuracy: 0.968800
Distillation: Epoch : 45, Loss : 0.115957, Accuracy: 0.970000, Test accuracy: 0.969700
Distillation: Epoch : 46, Loss : 0.111748, Accuracy: 0.962000, Test accuracy: 0.968900
Distillation: Epoch : 47, Loss : 0.094471, Accuracy: 0.971000, Test accuracy: 0.968600
Distillation: Epoch : 48, Loss : 0.079300, Accuracy: 0.976000, Test accuracy: 0.969500
Distillation: Epoch : 49, Loss : 0.071729, Accuracy: 0.981000, Test accuracy: 0.970500
Distillation: Epoch : 50, Loss : 0.092259, Accuracy: 0.970000, Test accuracy: 0.970300
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9703
Generating confusion matrix for student4
[[ 968.    0.    3.    1.    1.    2.    5.    0.    8.    2.]
 [   0. 1123.    6.    0.    0.    0.    2.    7.    1.    5.]
 [   1.    2.  997.    3.    3.    1.    3.   11.    5.    2.]
 [   1.    2.    3.  965.    1.    9.    1.    4.    6.    6.]
 [   0.    0.    4.    0.  961.    0.    4.    0.    5.   14.]
 [   3.    1.    0.   21.    1.  867.    1.    0.    4.    9.]
 [   5.    3.    1.    0.    3.    5.  939.    0.    6.    1.]
 [   1.    0.    9.   12.    5.    2.    0. 1001.    7.   13.]
 [   1.    4.    8.    5.    2.    5.    3.    0.  927.    2.]
 [   0.    0.    1.    3.    5.    1.    0.    5.    5.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.934612, Accuracy: 0.610000, Test accuracy: 0.634600
Distillation: Epoch : 2, Loss : 0.706900, Accuracy: 0.832000, Test accuracy: 0.840000
Distillation: Epoch : 3, Loss : 0.449088, Accuracy: 0.885000, Test accuracy: 0.883600
Distillation: Epoch : 4, Loss : 0.381824, Accuracy: 0.896000, Test accuracy: 0.900000
Distillation: Epoch : 5, Loss : 0.306733, Accuracy: 0.909000, Test accuracy: 0.911400
Distillation: Epoch : 6, Loss : 0.344533, Accuracy: 0.912000, Test accuracy: 0.916600
Distillation: Epoch : 7, Loss : 0.279595, Accuracy: 0.929000, Test accuracy: 0.922800
Distillation: Epoch : 8, Loss : 0.281931, Accuracy: 0.923000, Test accuracy: 0.926300
Distillation: Epoch : 9, Loss : 0.248745, Accuracy: 0.923000, Test accuracy: 0.929700
Distillation: Epoch : 10, Loss : 0.293647, Accuracy: 0.924000, Test accuracy: 0.932100
Distillation: Epoch : 11, Loss : 0.274265, Accuracy: 0.929000, Test accuracy: 0.935100
Distillation: Epoch : 12, Loss : 0.192490, Accuracy: 0.952000, Test accuracy: 0.937500
Distillation: Epoch : 13, Loss : 0.268833, Accuracy: 0.927000, Test accuracy: 0.939200
Distillation: Epoch : 14, Loss : 0.210373, Accuracy: 0.937000, Test accuracy: 0.941800
Distillation: Epoch : 15, Loss : 0.233837, Accuracy: 0.939000, Test accuracy: 0.942800
Distillation: Epoch : 16, Loss : 0.224770, Accuracy: 0.945000, Test accuracy: 0.944700
Distillation: Epoch : 17, Loss : 0.276442, Accuracy: 0.930000, Test accuracy: 0.945600
Distillation: Epoch : 18, Loss : 0.199496, Accuracy: 0.953000, Test accuracy: 0.946900
Distillation: Epoch : 19, Loss : 0.234124, Accuracy: 0.937000, Test accuracy: 0.947400
Distillation: Epoch : 20, Loss : 0.206486, Accuracy: 0.941000, Test accuracy: 0.948700
Distillation: Epoch : 21, Loss : 0.227767, Accuracy: 0.942000, Test accuracy: 0.948900
Distillation: Epoch : 22, Loss : 0.195359, Accuracy: 0.948000, Test accuracy: 0.949300
Distillation: Epoch : 23, Loss : 0.170854, Accuracy: 0.951000, Test accuracy: 0.950700
Distillation: Epoch : 24, Loss : 0.168997, Accuracy: 0.959000, Test accuracy: 0.952300
Distillation: Epoch : 25, Loss : 0.179494, Accuracy: 0.954000, Test accuracy: 0.952600
Distillation: Epoch : 26, Loss : 0.172298, Accuracy: 0.953000, Test accuracy: 0.954200
Distillation: Epoch : 27, Loss : 0.193689, Accuracy: 0.947000, Test accuracy: 0.954400
Distillation: Epoch : 28, Loss : 0.194830, Accuracy: 0.942000, Test accuracy: 0.954900
Distillation: Epoch : 29, Loss : 0.182421, Accuracy: 0.947000, Test accuracy: 0.955900
Distillation: Epoch : 30, Loss : 0.178769, Accuracy: 0.956000, Test accuracy: 0.956500
Distillation: Epoch : 31, Loss : 0.164422, Accuracy: 0.958000, Test accuracy: 0.957100
Distillation: Epoch : 32, Loss : 0.186222, Accuracy: 0.946000, Test accuracy: 0.958000
Distillation: Epoch : 33, Loss : 0.206727, Accuracy: 0.943000, Test accuracy: 0.957900
Distillation: Epoch : 34, Loss : 0.143912, Accuracy: 0.957000, Test accuracy: 0.959000
Distillation: Epoch : 35, Loss : 0.182766, Accuracy: 0.949000, Test accuracy: 0.959700
Distillation: Epoch : 36, Loss : 0.174853, Accuracy: 0.951000, Test accuracy: 0.960100
Distillation: Epoch : 37, Loss : 0.161498, Accuracy: 0.960000, Test accuracy: 0.960100
Distillation: Epoch : 38, Loss : 0.165862, Accuracy: 0.960000, Test accuracy: 0.959600
Distillation: Epoch : 39, Loss : 0.172923, Accuracy: 0.957000, Test accuracy: 0.960500
Distillation: Epoch : 40, Loss : 0.161293, Accuracy: 0.961000, Test accuracy: 0.961300
Distillation: Epoch : 41, Loss : 0.172782, Accuracy: 0.958000, Test accuracy: 0.961600
Distillation: Epoch : 42, Loss : 0.136661, Accuracy: 0.972000, Test accuracy: 0.962400
Distillation: Epoch : 43, Loss : 0.142568, Accuracy: 0.970000, Test accuracy: 0.962300
Distillation: Epoch : 44, Loss : 0.152235, Accuracy: 0.976000, Test accuracy: 0.962400
Distillation: Epoch : 45, Loss : 0.186295, Accuracy: 0.949000, Test accuracy: 0.962400
Distillation: Epoch : 46, Loss : 0.151084, Accuracy: 0.957000, Test accuracy: 0.962800
Distillation: Epoch : 47, Loss : 0.130557, Accuracy: 0.965000, Test accuracy: 0.963000
Distillation: Epoch : 48, Loss : 0.144859, Accuracy: 0.961000, Test accuracy: 0.963400
Distillation: Epoch : 49, Loss : 0.129806, Accuracy: 0.971000, Test accuracy: 0.964300
Distillation: Epoch : 50, Loss : 0.135981, Accuracy: 0.972000, Test accuracy: 0.964200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9642
Generating confusion matrix for student4
[[ 966.    0.    6.    0.    2.    2.    9.    1.    5.    6.]
 [   0. 1120.    4.    0.    3.    1.    3.    5.    2.    5.]
 [   0.    5.  987.   10.    5.    0.    3.   18.    3.    1.]
 [   0.    1.    7.  971.    0.   12.    1.    5.   11.    8.]
 [   0.    1.    4.    1.  958.    0.    4.    4.    5.   29.]
 [   2.    0.    0.    7.    0.  864.    6.    1.    5.    4.]
 [   4.    2.    1.    0.    0.    4.  928.    0.    3.    0.]
 [   2.    0.   10.   10.    2.    2.    0.  977.    6.   10.]
 [   5.    6.   11.    9.    2.    6.    4.    3.  931.    6.]
 [   1.    0.    2.    2.   10.    1.    0.   14.    3.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.153274, Accuracy: 0.790000, Test accuracy: 0.799700
Distillation: Epoch : 2, Loss : 0.774793, Accuracy: 0.872000, Test accuracy: 0.872600
Distillation: Epoch : 3, Loss : 0.752340, Accuracy: 0.882000, Test accuracy: 0.893400
Distillation: Epoch : 4, Loss : 0.686157, Accuracy: 0.898000, Test accuracy: 0.900500
Distillation: Epoch : 5, Loss : 0.669906, Accuracy: 0.909000, Test accuracy: 0.905300
Distillation: Epoch : 6, Loss : 0.662482, Accuracy: 0.900000, Test accuracy: 0.908000
Distillation: Epoch : 7, Loss : 0.691596, Accuracy: 0.904000, Test accuracy: 0.911200
Distillation: Epoch : 8, Loss : 0.675641, Accuracy: 0.896000, Test accuracy: 0.912600
Distillation: Epoch : 9, Loss : 0.648754, Accuracy: 0.897000, Test accuracy: 0.913900
Distillation: Epoch : 10, Loss : 0.619274, Accuracy: 0.918000, Test accuracy: 0.914800
Distillation: Epoch : 11, Loss : 0.631147, Accuracy: 0.913000, Test accuracy: 0.916400
Distillation: Epoch : 12, Loss : 0.624404, Accuracy: 0.922000, Test accuracy: 0.920700
Distillation: Epoch : 13, Loss : 0.608259, Accuracy: 0.927000, Test accuracy: 0.921300
Distillation: Epoch : 14, Loss : 0.605098, Accuracy: 0.923000, Test accuracy: 0.924200
Distillation: Epoch : 15, Loss : 0.612864, Accuracy: 0.926000, Test accuracy: 0.927400
Distillation: Epoch : 16, Loss : 0.609626, Accuracy: 0.935000, Test accuracy: 0.927800
Distillation: Epoch : 17, Loss : 0.616443, Accuracy: 0.915000, Test accuracy: 0.930400
Distillation: Epoch : 18, Loss : 0.584783, Accuracy: 0.923000, Test accuracy: 0.932700
Distillation: Epoch : 19, Loss : 0.567353, Accuracy: 0.940000, Test accuracy: 0.933500
Distillation: Epoch : 20, Loss : 0.581762, Accuracy: 0.928000, Test accuracy: 0.935800
Distillation: Epoch : 21, Loss : 0.622973, Accuracy: 0.927000, Test accuracy: 0.939100
Distillation: Epoch : 22, Loss : 0.600253, Accuracy: 0.933000, Test accuracy: 0.940400
Distillation: Epoch : 23, Loss : 0.606061, Accuracy: 0.941000, Test accuracy: 0.942600
Distillation: Epoch : 24, Loss : 0.563020, Accuracy: 0.940000, Test accuracy: 0.943300
Distillation: Epoch : 25, Loss : 0.572377, Accuracy: 0.947000, Test accuracy: 0.945400
Distillation: Epoch : 26, Loss : 0.553847, Accuracy: 0.939000, Test accuracy: 0.946800
Distillation: Epoch : 27, Loss : 0.520300, Accuracy: 0.953000, Test accuracy: 0.948400
Distillation: Epoch : 28, Loss : 0.536172, Accuracy: 0.939000, Test accuracy: 0.949800
Distillation: Epoch : 29, Loss : 0.521341, Accuracy: 0.947000, Test accuracy: 0.950300
Distillation: Epoch : 30, Loss : 0.496122, Accuracy: 0.963000, Test accuracy: 0.952100
Distillation: Epoch : 31, Loss : 0.542069, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 32, Loss : 0.555504, Accuracy: 0.948000, Test accuracy: 0.953100
Distillation: Epoch : 33, Loss : 0.534151, Accuracy: 0.949000, Test accuracy: 0.954100
Distillation: Epoch : 34, Loss : 0.504469, Accuracy: 0.952000, Test accuracy: 0.954500
Distillation: Epoch : 35, Loss : 0.538701, Accuracy: 0.953000, Test accuracy: 0.954600
Distillation: Epoch : 36, Loss : 0.512532, Accuracy: 0.958000, Test accuracy: 0.955700
Distillation: Epoch : 37, Loss : 0.522411, Accuracy: 0.957000, Test accuracy: 0.956400
Distillation: Epoch : 38, Loss : 0.557935, Accuracy: 0.953000, Test accuracy: 0.958100
Distillation: Epoch : 39, Loss : 0.529465, Accuracy: 0.962000, Test accuracy: 0.959600
Distillation: Epoch : 40, Loss : 0.542795, Accuracy: 0.953000, Test accuracy: 0.958500
Distillation: Epoch : 41, Loss : 0.519985, Accuracy: 0.953000, Test accuracy: 0.958100
Distillation: Epoch : 42, Loss : 0.503910, Accuracy: 0.967000, Test accuracy: 0.960400
Distillation: Epoch : 43, Loss : 0.517039, Accuracy: 0.957000, Test accuracy: 0.961000
Distillation: Epoch : 44, Loss : 0.524161, Accuracy: 0.956000, Test accuracy: 0.960500
Distillation: Epoch : 45, Loss : 0.514513, Accuracy: 0.963000, Test accuracy: 0.961500
Distillation: Epoch : 46, Loss : 0.495105, Accuracy: 0.969000, Test accuracy: 0.961700
Distillation: Epoch : 47, Loss : 0.478987, Accuracy: 0.965000, Test accuracy: 0.961600
Distillation: Epoch : 48, Loss : 0.515401, Accuracy: 0.953000, Test accuracy: 0.961900
Distillation: Epoch : 49, Loss : 0.496587, Accuracy: 0.966000, Test accuracy: 0.962200
Distillation: Epoch : 50, Loss : 0.507280, Accuracy: 0.966000, Test accuracy: 0.963500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9635
Generating confusion matrix for student4
[[ 967.    0.    3.    0.    1.    2.    5.    0.    6.    3.]
 [   0. 1116.    6.    0.    1.    1.    4.    6.    4.    6.]
 [   0.    2.  991.    9.    3.    2.    2.   16.    5.    0.]
 [   1.    6.    9.  975.    0.   14.    1.    4.   10.    7.]
 [   3.    1.    6.    0.  959.    0.    4.    4.    9.   22.]
 [   0.    0.    0.   10.    0.  853.    4.    2.    3.   13.]
 [   5.    2.    1.    1.    5.    9.  932.    0.    8.    0.]
 [   2.    0.   10.    7.    3.    5.    0.  985.    9.   11.]
 [   2.    8.    4.    5.    4.    2.    6.    0.  918.    8.]
 [   0.    0.    2.    3.    6.    4.    0.   11.    2.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.871613, Accuracy: 0.690000, Test accuracy: 0.694700
Distillation: Epoch : 2, Loss : 0.986918, Accuracy: 0.837000, Test accuracy: 0.856000
Distillation: Epoch : 3, Loss : 0.894142, Accuracy: 0.883000, Test accuracy: 0.886600
Distillation: Epoch : 4, Loss : 0.875387, Accuracy: 0.882000, Test accuracy: 0.896900
Distillation: Epoch : 5, Loss : 0.858323, Accuracy: 0.895000, Test accuracy: 0.900600
Distillation: Epoch : 6, Loss : 0.869665, Accuracy: 0.896000, Test accuracy: 0.906000
Distillation: Epoch : 7, Loss : 0.832036, Accuracy: 0.895000, Test accuracy: 0.908500
Distillation: Epoch : 8, Loss : 0.823458, Accuracy: 0.915000, Test accuracy: 0.910400
Distillation: Epoch : 9, Loss : 0.827334, Accuracy: 0.905000, Test accuracy: 0.914800
Distillation: Epoch : 10, Loss : 0.843933, Accuracy: 0.907000, Test accuracy: 0.916400
Distillation: Epoch : 11, Loss : 0.784628, Accuracy: 0.911000, Test accuracy: 0.917700
Distillation: Epoch : 12, Loss : 0.799959, Accuracy: 0.921000, Test accuracy: 0.920000
Distillation: Epoch : 13, Loss : 0.817313, Accuracy: 0.914000, Test accuracy: 0.923900
Distillation: Epoch : 14, Loss : 0.780181, Accuracy: 0.921000, Test accuracy: 0.926600
Distillation: Epoch : 15, Loss : 0.765530, Accuracy: 0.929000, Test accuracy: 0.927900
Distillation: Epoch : 16, Loss : 0.779392, Accuracy: 0.937000, Test accuracy: 0.929800
Distillation: Epoch : 17, Loss : 0.778852, Accuracy: 0.925000, Test accuracy: 0.931600
Distillation: Epoch : 18, Loss : 0.759078, Accuracy: 0.933000, Test accuracy: 0.934300
Distillation: Epoch : 19, Loss : 0.756466, Accuracy: 0.939000, Test accuracy: 0.934800
Distillation: Epoch : 20, Loss : 0.758565, Accuracy: 0.929000, Test accuracy: 0.938800
Distillation: Epoch : 21, Loss : 0.742866, Accuracy: 0.938000, Test accuracy: 0.940700
Distillation: Epoch : 22, Loss : 0.747520, Accuracy: 0.935000, Test accuracy: 0.942100
Distillation: Epoch : 23, Loss : 0.742312, Accuracy: 0.945000, Test accuracy: 0.942900
Distillation: Epoch : 24, Loss : 0.724491, Accuracy: 0.952000, Test accuracy: 0.944300
Distillation: Epoch : 25, Loss : 0.706935, Accuracy: 0.958000, Test accuracy: 0.945900
Distillation: Epoch : 26, Loss : 0.729128, Accuracy: 0.954000, Test accuracy: 0.945800
Distillation: Epoch : 27, Loss : 0.733632, Accuracy: 0.950000, Test accuracy: 0.949000
Distillation: Epoch : 28, Loss : 0.760034, Accuracy: 0.941000, Test accuracy: 0.949700
Distillation: Epoch : 29, Loss : 0.733387, Accuracy: 0.941000, Test accuracy: 0.949800
Distillation: Epoch : 30, Loss : 0.709801, Accuracy: 0.943000, Test accuracy: 0.951300
Distillation: Epoch : 31, Loss : 0.725678, Accuracy: 0.949000, Test accuracy: 0.951500
Distillation: Epoch : 32, Loss : 0.706541, Accuracy: 0.958000, Test accuracy: 0.951600
Distillation: Epoch : 33, Loss : 0.730954, Accuracy: 0.942000, Test accuracy: 0.953300
Distillation: Epoch : 34, Loss : 0.730105, Accuracy: 0.946000, Test accuracy: 0.953300
Distillation: Epoch : 35, Loss : 0.724857, Accuracy: 0.951000, Test accuracy: 0.954400
Distillation: Epoch : 36, Loss : 0.699890, Accuracy: 0.960000, Test accuracy: 0.954800
Distillation: Epoch : 37, Loss : 0.712104, Accuracy: 0.959000, Test accuracy: 0.954400
Distillation: Epoch : 38, Loss : 0.709126, Accuracy: 0.948000, Test accuracy: 0.956100
Distillation: Epoch : 39, Loss : 0.701527, Accuracy: 0.947000, Test accuracy: 0.955300
Distillation: Epoch : 40, Loss : 0.678358, Accuracy: 0.958000, Test accuracy: 0.956200
Distillation: Epoch : 41, Loss : 0.722607, Accuracy: 0.962000, Test accuracy: 0.956400
Distillation: Epoch : 42, Loss : 0.716728, Accuracy: 0.953000, Test accuracy: 0.955900
Distillation: Epoch : 43, Loss : 0.713042, Accuracy: 0.956000, Test accuracy: 0.957000
Distillation: Epoch : 44, Loss : 0.723303, Accuracy: 0.951000, Test accuracy: 0.957700
Distillation: Epoch : 45, Loss : 0.709448, Accuracy: 0.957000, Test accuracy: 0.957900
Distillation: Epoch : 46, Loss : 0.711253, Accuracy: 0.953000, Test accuracy: 0.957500
Distillation: Epoch : 47, Loss : 0.705918, Accuracy: 0.955000, Test accuracy: 0.958900
Distillation: Epoch : 48, Loss : 0.694339, Accuracy: 0.963000, Test accuracy: 0.959100
Distillation: Epoch : 49, Loss : 0.715856, Accuracy: 0.953000, Test accuracy: 0.959700
Distillation: Epoch : 50, Loss : 0.688404, Accuracy: 0.959000, Test accuracy: 0.959400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9594
Generating confusion matrix for student4
[[ 960.    0.    5.    1.    0.    1.    7.    2.    6.    5.]
 [   1. 1108.    6.    0.    1.    1.    3.    6.    3.    5.]
 [   0.    2.  963.    3.    5.    0.    1.   14.    7.    0.]
 [   0.    1.    9.  983.    1.   18.    0.    5.    9.   10.]
 [   3.    1.    4.    2.  947.    1.    1.    2.    7.    8.]
 [   2.    1.    0.    9.    2.  852.   17.    2.   11.   12.]
 [   6.    4.    3.    0.    2.    3.  925.    0.    2.    0.]
 [   3.    1.    7.    8.    3.    2.    0.  983.    5.   10.]
 [   5.   17.   32.    4.    2.   11.    4.    4.  920.    6.]
 [   0.    0.    3.    0.   19.    3.    0.   10.    4.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.639230, Accuracy: 0.726000, Test accuracy: 0.751600
Distillation: Epoch : 2, Loss : 1.092728, Accuracy: 0.861000, Test accuracy: 0.863000
Distillation: Epoch : 3, Loss : 1.087672, Accuracy: 0.863000, Test accuracy: 0.882000
Distillation: Epoch : 4, Loss : 1.044607, Accuracy: 0.886000, Test accuracy: 0.889600
Distillation: Epoch : 5, Loss : 1.078420, Accuracy: 0.873000, Test accuracy: 0.894100
Distillation: Epoch : 6, Loss : 1.050114, Accuracy: 0.863000, Test accuracy: 0.896000
Distillation: Epoch : 7, Loss : 1.051379, Accuracy: 0.897000, Test accuracy: 0.896700
Distillation: Epoch : 8, Loss : 1.046455, Accuracy: 0.887000, Test accuracy: 0.900700
Distillation: Epoch : 9, Loss : 1.023104, Accuracy: 0.894000, Test accuracy: 0.901000
Distillation: Epoch : 10, Loss : 1.025498, Accuracy: 0.908000, Test accuracy: 0.903900
Distillation: Epoch : 11, Loss : 1.036216, Accuracy: 0.892000, Test accuracy: 0.906100
Distillation: Epoch : 12, Loss : 0.996333, Accuracy: 0.916000, Test accuracy: 0.905300
Distillation: Epoch : 13, Loss : 1.002766, Accuracy: 0.890000, Test accuracy: 0.906200
Distillation: Epoch : 14, Loss : 1.017577, Accuracy: 0.893000, Test accuracy: 0.907200
Distillation: Epoch : 15, Loss : 0.990567, Accuracy: 0.909000, Test accuracy: 0.907400
Distillation: Epoch : 16, Loss : 1.032881, Accuracy: 0.889000, Test accuracy: 0.910100
Distillation: Epoch : 17, Loss : 0.997615, Accuracy: 0.904000, Test accuracy: 0.910700
Distillation: Epoch : 18, Loss : 1.033285, Accuracy: 0.879000, Test accuracy: 0.910600
Distillation: Epoch : 19, Loss : 0.956322, Accuracy: 0.911000, Test accuracy: 0.910100
Distillation: Epoch : 20, Loss : 0.998955, Accuracy: 0.895000, Test accuracy: 0.911900
Distillation: Epoch : 21, Loss : 1.006982, Accuracy: 0.913000, Test accuracy: 0.912800
Distillation: Epoch : 22, Loss : 1.009171, Accuracy: 0.910000, Test accuracy: 0.913300
Distillation: Epoch : 23, Loss : 0.998151, Accuracy: 0.910000, Test accuracy: 0.913300
Distillation: Epoch : 24, Loss : 1.009166, Accuracy: 0.902000, Test accuracy: 0.912700
Distillation: Epoch : 25, Loss : 1.031868, Accuracy: 0.884000, Test accuracy: 0.915200
Distillation: Epoch : 26, Loss : 0.957303, Accuracy: 0.917000, Test accuracy: 0.915200
Distillation: Epoch : 27, Loss : 1.002084, Accuracy: 0.910000, Test accuracy: 0.916500
Distillation: Epoch : 28, Loss : 0.987567, Accuracy: 0.896000, Test accuracy: 0.918000
Distillation: Epoch : 29, Loss : 1.006453, Accuracy: 0.915000, Test accuracy: 0.915200
Distillation: Epoch : 30, Loss : 0.977010, Accuracy: 0.917000, Test accuracy: 0.918300
Distillation: Epoch : 31, Loss : 0.971785, Accuracy: 0.923000, Test accuracy: 0.919200
Distillation: Epoch : 32, Loss : 0.974841, Accuracy: 0.928000, Test accuracy: 0.922000
Distillation: Epoch : 33, Loss : 0.971484, Accuracy: 0.914000, Test accuracy: 0.923500
Distillation: Epoch : 34, Loss : 0.938741, Accuracy: 0.934000, Test accuracy: 0.923700
Distillation: Epoch : 35, Loss : 0.973496, Accuracy: 0.925000, Test accuracy: 0.925800
Distillation: Epoch : 36, Loss : 0.964373, Accuracy: 0.926000, Test accuracy: 0.928600
Distillation: Epoch : 37, Loss : 0.929888, Accuracy: 0.938000, Test accuracy: 0.929700
Distillation: Epoch : 38, Loss : 0.952260, Accuracy: 0.923000, Test accuracy: 0.932200
Distillation: Epoch : 39, Loss : 0.907486, Accuracy: 0.940000, Test accuracy: 0.936100
Distillation: Epoch : 40, Loss : 0.920068, Accuracy: 0.936000, Test accuracy: 0.937400
Distillation: Epoch : 41, Loss : 0.948678, Accuracy: 0.937000, Test accuracy: 0.940900
Distillation: Epoch : 42, Loss : 0.910160, Accuracy: 0.936000, Test accuracy: 0.942700
Distillation: Epoch : 43, Loss : 0.915106, Accuracy: 0.934000, Test accuracy: 0.946400
Distillation: Epoch : 44, Loss : 0.903085, Accuracy: 0.951000, Test accuracy: 0.948100
Distillation: Epoch : 45, Loss : 0.869046, Accuracy: 0.955000, Test accuracy: 0.949700
Distillation: Epoch : 46, Loss : 0.925613, Accuracy: 0.945000, Test accuracy: 0.950500
Distillation: Epoch : 47, Loss : 0.882134, Accuracy: 0.961000, Test accuracy: 0.952600
Distillation: Epoch : 48, Loss : 0.888076, Accuracy: 0.949000, Test accuracy: 0.951900
Distillation: Epoch : 49, Loss : 0.876140, Accuracy: 0.960000, Test accuracy: 0.953300
Distillation: Epoch : 50, Loss : 0.904682, Accuracy: 0.944000, Test accuracy: 0.956400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9564
Generating confusion matrix for student4
[[ 966.    0.    6.    0.    1.    2.    6.    2.    6.    3.]
 [   0. 1116.    8.    0.    1.    1.    3.    6.    4.    7.]
 [   0.    2.  964.   11.    1.    2.    2.   18.    6.    1.]
 [   0.    2.   11.  966.    0.   14.    1.    4.   10.   13.]
 [   3.    1.    9.    1.  956.    0.    8.    5.   11.   31.]
 [   1.    0.    0.   15.    1.  856.    8.    1.    8.   12.]
 [   5.    5.    5.    0.    5.    5.  929.    0.    8.    0.]
 [   2.    0.   16.   10.    2.    5.    0.  977.    9.   11.]
 [   3.    9.   11.    6.    2.    0.    1.    0.  905.    2.]
 [   0.    0.    2.    1.   13.    7.    0.   15.    7.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.883029, Accuracy: 0.736000, Test accuracy: 0.735500
Distillation: Epoch : 2, Loss : 1.315852, Accuracy: 0.821000, Test accuracy: 0.843300
Distillation: Epoch : 3, Loss : 1.228490, Accuracy: 0.877000, Test accuracy: 0.873400
Distillation: Epoch : 4, Loss : 1.201743, Accuracy: 0.893000, Test accuracy: 0.890300
Distillation: Epoch : 5, Loss : 1.177580, Accuracy: 0.896000, Test accuracy: 0.898500
Distillation: Epoch : 6, Loss : 1.173723, Accuracy: 0.905000, Test accuracy: 0.903000
Distillation: Epoch : 7, Loss : 1.200267, Accuracy: 0.899000, Test accuracy: 0.906200
Distillation: Epoch : 8, Loss : 1.151973, Accuracy: 0.917000, Test accuracy: 0.908700
Distillation: Epoch : 9, Loss : 1.191225, Accuracy: 0.902000, Test accuracy: 0.911800
Distillation: Epoch : 10, Loss : 1.175065, Accuracy: 0.908000, Test accuracy: 0.915300
Distillation: Epoch : 11, Loss : 1.174222, Accuracy: 0.896000, Test accuracy: 0.917600
Distillation: Epoch : 12, Loss : 1.143315, Accuracy: 0.923000, Test accuracy: 0.920300
Distillation: Epoch : 13, Loss : 1.136660, Accuracy: 0.908000, Test accuracy: 0.922000
Distillation: Epoch : 14, Loss : 1.112405, Accuracy: 0.905000, Test accuracy: 0.924500
Distillation: Epoch : 15, Loss : 1.132196, Accuracy: 0.912000, Test accuracy: 0.926300
Distillation: Epoch : 16, Loss : 1.101939, Accuracy: 0.920000, Test accuracy: 0.927600
Distillation: Epoch : 17, Loss : 1.127427, Accuracy: 0.913000, Test accuracy: 0.930200
Distillation: Epoch : 18, Loss : 1.131961, Accuracy: 0.920000, Test accuracy: 0.930500
Distillation: Epoch : 19, Loss : 1.132727, Accuracy: 0.915000, Test accuracy: 0.933700
Distillation: Epoch : 20, Loss : 1.136519, Accuracy: 0.926000, Test accuracy: 0.932900
Distillation: Epoch : 21, Loss : 1.097853, Accuracy: 0.934000, Test accuracy: 0.934800
Distillation: Epoch : 22, Loss : 1.118174, Accuracy: 0.920000, Test accuracy: 0.935800
Distillation: Epoch : 23, Loss : 1.121250, Accuracy: 0.936000, Test accuracy: 0.937900
Distillation: Epoch : 24, Loss : 1.091748, Accuracy: 0.939000, Test accuracy: 0.938700
Distillation: Epoch : 25, Loss : 1.085400, Accuracy: 0.935000, Test accuracy: 0.940600
Distillation: Epoch : 26, Loss : 1.090209, Accuracy: 0.926000, Test accuracy: 0.942000
Distillation: Epoch : 27, Loss : 1.101769, Accuracy: 0.935000, Test accuracy: 0.943000
Distillation: Epoch : 28, Loss : 1.093071, Accuracy: 0.932000, Test accuracy: 0.945100
Distillation: Epoch : 29, Loss : 1.064215, Accuracy: 0.939000, Test accuracy: 0.945400
Distillation: Epoch : 30, Loss : 1.088467, Accuracy: 0.948000, Test accuracy: 0.946200
Distillation: Epoch : 31, Loss : 1.053865, Accuracy: 0.959000, Test accuracy: 0.947500
Distillation: Epoch : 32, Loss : 1.059475, Accuracy: 0.955000, Test accuracy: 0.948600
Distillation: Epoch : 33, Loss : 1.096961, Accuracy: 0.938000, Test accuracy: 0.949000
Distillation: Epoch : 34, Loss : 1.064622, Accuracy: 0.940000, Test accuracy: 0.949700
Distillation: Epoch : 35, Loss : 1.068426, Accuracy: 0.947000, Test accuracy: 0.949600
Distillation: Epoch : 36, Loss : 1.086228, Accuracy: 0.948000, Test accuracy: 0.950800
Distillation: Epoch : 37, Loss : 1.026478, Accuracy: 0.963000, Test accuracy: 0.951400
Distillation: Epoch : 38, Loss : 1.078400, Accuracy: 0.953000, Test accuracy: 0.951800
Distillation: Epoch : 39, Loss : 1.054596, Accuracy: 0.950000, Test accuracy: 0.952900
Distillation: Epoch : 40, Loss : 1.043979, Accuracy: 0.960000, Test accuracy: 0.953400
Distillation: Epoch : 41, Loss : 1.062474, Accuracy: 0.946000, Test accuracy: 0.953600
Distillation: Epoch : 42, Loss : 1.049916, Accuracy: 0.955000, Test accuracy: 0.954700
Distillation: Epoch : 43, Loss : 1.074010, Accuracy: 0.950000, Test accuracy: 0.955400
Distillation: Epoch : 44, Loss : 1.052034, Accuracy: 0.954000, Test accuracy: 0.956200
Distillation: Epoch : 45, Loss : 1.058306, Accuracy: 0.954000, Test accuracy: 0.957700
Distillation: Epoch : 46, Loss : 1.060522, Accuracy: 0.958000, Test accuracy: 0.957200
Distillation: Epoch : 47, Loss : 1.044324, Accuracy: 0.965000, Test accuracy: 0.958700
Distillation: Epoch : 48, Loss : 1.051169, Accuracy: 0.952000, Test accuracy: 0.957700
Distillation: Epoch : 49, Loss : 1.024093, Accuracy: 0.972000, Test accuracy: 0.959200
Distillation: Epoch : 50, Loss : 1.076828, Accuracy: 0.960000, Test accuracy: 0.960100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9601
Generating confusion matrix for student4
[[ 961.    0.    7.    0.    1.    3.    4.    0.    6.    3.]
 [   0. 1113.    9.    0.    0.    0.    2.    5.    2.    5.]
 [   1.    1.  963.    7.    6.    1.    1.   15.    5.    1.]
 [   0.    2.   11.  979.    0.   20.    0.    4.    9.   10.]
 [   0.    1.    9.    1.  945.    3.    6.    7.    9.   23.]
 [   2.    4.    1.    8.    1.  853.   11.    2.   10.    8.]
 [   6.    4.    2.    0.    3.    3.  931.    0.    3.    0.]
 [   1.    1.   12.   11.    2.    3.    0.  986.    4.    6.]
 [   8.    9.   17.    4.    2.    5.    3.    2.  920.    3.]
 [   1.    0.    1.    0.   22.    1.    0.    7.    6.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.825445, Accuracy: 0.732000, Test accuracy: 0.741400
Distillation: Epoch : 2, Loss : 1.439072, Accuracy: 0.836000, Test accuracy: 0.861900
Distillation: Epoch : 3, Loss : 1.402903, Accuracy: 0.857000, Test accuracy: 0.881600
Distillation: Epoch : 4, Loss : 1.360201, Accuracy: 0.873000, Test accuracy: 0.890600
Distillation: Epoch : 5, Loss : 1.379569, Accuracy: 0.883000, Test accuracy: 0.895200
Distillation: Epoch : 6, Loss : 1.359428, Accuracy: 0.885000, Test accuracy: 0.896400
Distillation: Epoch : 7, Loss : 1.336718, Accuracy: 0.878000, Test accuracy: 0.900200
Distillation: Epoch : 8, Loss : 1.303242, Accuracy: 0.901000, Test accuracy: 0.903700
Distillation: Epoch : 9, Loss : 1.315147, Accuracy: 0.905000, Test accuracy: 0.907800
Distillation: Epoch : 10, Loss : 1.302037, Accuracy: 0.907000, Test accuracy: 0.911000
Distillation: Epoch : 11, Loss : 1.307413, Accuracy: 0.904000, Test accuracy: 0.912500
Distillation: Epoch : 12, Loss : 1.291625, Accuracy: 0.914000, Test accuracy: 0.916300
Distillation: Epoch : 13, Loss : 1.310996, Accuracy: 0.902000, Test accuracy: 0.919200
Distillation: Epoch : 14, Loss : 1.289000, Accuracy: 0.915000, Test accuracy: 0.922800
Distillation: Epoch : 15, Loss : 1.303081, Accuracy: 0.924000, Test accuracy: 0.924400
Distillation: Epoch : 16, Loss : 1.260926, Accuracy: 0.922000, Test accuracy: 0.928100
Distillation: Epoch : 17, Loss : 1.244523, Accuracy: 0.937000, Test accuracy: 0.932500
Distillation: Epoch : 18, Loss : 1.281723, Accuracy: 0.932000, Test accuracy: 0.935500
Distillation: Epoch : 19, Loss : 1.254895, Accuracy: 0.933000, Test accuracy: 0.937500
Distillation: Epoch : 20, Loss : 1.262861, Accuracy: 0.935000, Test accuracy: 0.939900
Distillation: Epoch : 21, Loss : 1.250107, Accuracy: 0.941000, Test accuracy: 0.941500
Distillation: Epoch : 22, Loss : 1.240935, Accuracy: 0.951000, Test accuracy: 0.942800
Distillation: Epoch : 23, Loss : 1.255487, Accuracy: 0.939000, Test accuracy: 0.944900
Distillation: Epoch : 24, Loss : 1.250221, Accuracy: 0.939000, Test accuracy: 0.945800
Distillation: Epoch : 25, Loss : 1.247151, Accuracy: 0.939000, Test accuracy: 0.947600
Distillation: Epoch : 26, Loss : 1.220291, Accuracy: 0.954000, Test accuracy: 0.949200
Distillation: Epoch : 27, Loss : 1.236379, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 28, Loss : 1.237743, Accuracy: 0.946000, Test accuracy: 0.951800
Distillation: Epoch : 29, Loss : 1.221843, Accuracy: 0.952000, Test accuracy: 0.951700
Distillation: Epoch : 30, Loss : 1.257572, Accuracy: 0.933000, Test accuracy: 0.953000
Distillation: Epoch : 31, Loss : 1.220846, Accuracy: 0.951000, Test accuracy: 0.953700
Distillation: Epoch : 32, Loss : 1.258657, Accuracy: 0.946000, Test accuracy: 0.954100
Distillation: Epoch : 33, Loss : 1.223301, Accuracy: 0.950000, Test accuracy: 0.954300
Distillation: Epoch : 34, Loss : 1.243378, Accuracy: 0.943000, Test accuracy: 0.954300
Distillation: Epoch : 35, Loss : 1.216439, Accuracy: 0.948000, Test accuracy: 0.956000
Distillation: Epoch : 36, Loss : 1.205976, Accuracy: 0.954000, Test accuracy: 0.955100
Distillation: Epoch : 37, Loss : 1.217857, Accuracy: 0.962000, Test accuracy: 0.956500
Distillation: Epoch : 38, Loss : 1.212506, Accuracy: 0.954000, Test accuracy: 0.956500
Distillation: Epoch : 39, Loss : 1.247116, Accuracy: 0.950000, Test accuracy: 0.957800
Distillation: Epoch : 40, Loss : 1.228233, Accuracy: 0.949000, Test accuracy: 0.957700
Distillation: Epoch : 41, Loss : 1.211458, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 42, Loss : 1.217851, Accuracy: 0.951000, Test accuracy: 0.958400
Distillation: Epoch : 43, Loss : 1.199692, Accuracy: 0.966000, Test accuracy: 0.959400
Distillation: Epoch : 44, Loss : 1.233511, Accuracy: 0.954000, Test accuracy: 0.959200
Distillation: Epoch : 45, Loss : 1.208717, Accuracy: 0.960000, Test accuracy: 0.959200
Distillation: Epoch : 46, Loss : 1.217427, Accuracy: 0.953000, Test accuracy: 0.959200
Distillation: Epoch : 47, Loss : 1.208013, Accuracy: 0.962000, Test accuracy: 0.959700
Distillation: Epoch : 48, Loss : 1.235053, Accuracy: 0.945000, Test accuracy: 0.959100
Distillation: Epoch : 49, Loss : 1.215985, Accuracy: 0.944000, Test accuracy: 0.960000
Distillation: Epoch : 50, Loss : 1.211643, Accuracy: 0.952000, Test accuracy: 0.960100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9601
Generating confusion matrix for student4
[[ 966.    0.    5.    0.    2.    2.    5.    0.    6.    4.]
 [   0. 1112.    7.    0.    3.    1.    3.    9.    4.    6.]
 [   0.    3.  971.    7.    3.    2.    2.   13.    6.    0.]
 [   0.    4.   15.  973.    0.   12.    1.    3.   10.    9.]
 [   2.    2.    7.    1.  959.    0.    2.   11.   10.   22.]
 [   1.    0.    1.   10.    0.  854.    5.    1.    6.    9.]
 [   6.    3.    3.    1.    3.    7.  938.    0.    7.    1.]
 [   2.    0.   14.    9.    2.    6.    1.  975.    8.    9.]
 [   3.   11.    6.    9.    3.    3.    1.    2.  911.    7.]
 [   0.    0.    3.    0.    7.    5.    0.   14.    6.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.668471, Accuracy: 0.781000, Test accuracy: 0.796600
Distillation: Epoch : 2, Loss : 1.519713, Accuracy: 0.848000, Test accuracy: 0.866500
Distillation: Epoch : 3, Loss : 1.527020, Accuracy: 0.853000, Test accuracy: 0.876700
Distillation: Epoch : 4, Loss : 1.524730, Accuracy: 0.857000, Test accuracy: 0.883900
Distillation: Epoch : 5, Loss : 1.466953, Accuracy: 0.885000, Test accuracy: 0.888000
Distillation: Epoch : 6, Loss : 1.492280, Accuracy: 0.877000, Test accuracy: 0.888200
Distillation: Epoch : 7, Loss : 1.497443, Accuracy: 0.880000, Test accuracy: 0.890300
Distillation: Epoch : 8, Loss : 1.492411, Accuracy: 0.878000, Test accuracy: 0.893800
Distillation: Epoch : 9, Loss : 1.485642, Accuracy: 0.866000, Test accuracy: 0.894600
Distillation: Epoch : 10, Loss : 1.464636, Accuracy: 0.889000, Test accuracy: 0.894800
Distillation: Epoch : 11, Loss : 1.465640, Accuracy: 0.897000, Test accuracy: 0.895100
Distillation: Epoch : 12, Loss : 1.468894, Accuracy: 0.888000, Test accuracy: 0.893500
Distillation: Epoch : 13, Loss : 1.476185, Accuracy: 0.895000, Test accuracy: 0.895700
Distillation: Epoch : 14, Loss : 1.469745, Accuracy: 0.874000, Test accuracy: 0.895200
Distillation: Epoch : 15, Loss : 1.460722, Accuracy: 0.897000, Test accuracy: 0.897300
Distillation: Epoch : 16, Loss : 1.445479, Accuracy: 0.892000, Test accuracy: 0.896300
Distillation: Epoch : 17, Loss : 1.478593, Accuracy: 0.886000, Test accuracy: 0.898400
Distillation: Epoch : 18, Loss : 1.447000, Accuracy: 0.919000, Test accuracy: 0.898200
Distillation: Epoch : 19, Loss : 1.453694, Accuracy: 0.892000, Test accuracy: 0.897500
Distillation: Epoch : 20, Loss : 1.457928, Accuracy: 0.888000, Test accuracy: 0.897100
Distillation: Epoch : 21, Loss : 1.436151, Accuracy: 0.895000, Test accuracy: 0.900700
Distillation: Epoch : 22, Loss : 1.470424, Accuracy: 0.902000, Test accuracy: 0.897400
Distillation: Epoch : 23, Loss : 1.470190, Accuracy: 0.901000, Test accuracy: 0.898800
Distillation: Epoch : 24, Loss : 1.490344, Accuracy: 0.893000, Test accuracy: 0.899300
Distillation: Epoch : 25, Loss : 1.452237, Accuracy: 0.898000, Test accuracy: 0.898900
Distillation: Epoch : 26, Loss : 1.461043, Accuracy: 0.901000, Test accuracy: 0.901000
Distillation: Epoch : 27, Loss : 1.450814, Accuracy: 0.906000, Test accuracy: 0.899300
Distillation: Epoch : 28, Loss : 1.441974, Accuracy: 0.906000, Test accuracy: 0.900500
Distillation: Epoch : 29, Loss : 1.459480, Accuracy: 0.891000, Test accuracy: 0.900800
Distillation: Epoch : 30, Loss : 1.462297, Accuracy: 0.887000, Test accuracy: 0.900600
Distillation: Epoch : 31, Loss : 1.453771, Accuracy: 0.893000, Test accuracy: 0.902400
Distillation: Epoch : 32, Loss : 1.490734, Accuracy: 0.888000, Test accuracy: 0.901200
Distillation: Epoch : 33, Loss : 1.465478, Accuracy: 0.897000, Test accuracy: 0.901400
Distillation: Epoch : 34, Loss : 1.436960, Accuracy: 0.902000, Test accuracy: 0.900400
Distillation: Epoch : 35, Loss : 1.471955, Accuracy: 0.884000, Test accuracy: 0.899500
Distillation: Epoch : 36, Loss : 1.465779, Accuracy: 0.904000, Test accuracy: 0.900900
Distillation: Epoch : 37, Loss : 1.460522, Accuracy: 0.903000, Test accuracy: 0.902000
Distillation: Epoch : 38, Loss : 1.466624, Accuracy: 0.882000, Test accuracy: 0.902000
Distillation: Epoch : 39, Loss : 1.451306, Accuracy: 0.897000, Test accuracy: 0.904000
Distillation: Epoch : 40, Loss : 1.466155, Accuracy: 0.895000, Test accuracy: 0.904000
Distillation: Epoch : 41, Loss : 1.480945, Accuracy: 0.890000, Test accuracy: 0.903400
Distillation: Epoch : 42, Loss : 1.469129, Accuracy: 0.883000, Test accuracy: 0.901800
Distillation: Epoch : 43, Loss : 1.423891, Accuracy: 0.912000, Test accuracy: 0.903500
Distillation: Epoch : 44, Loss : 1.451125, Accuracy: 0.901000, Test accuracy: 0.902000
Distillation: Epoch : 45, Loss : 1.447183, Accuracy: 0.898000, Test accuracy: 0.904100
Distillation: Epoch : 46, Loss : 1.461962, Accuracy: 0.889000, Test accuracy: 0.902200
Distillation: Epoch : 47, Loss : 1.444403, Accuracy: 0.907000, Test accuracy: 0.903100
Distillation: Epoch : 48, Loss : 1.448700, Accuracy: 0.908000, Test accuracy: 0.902500
Distillation: Epoch : 49, Loss : 1.462001, Accuracy: 0.900000, Test accuracy: 0.900700
Distillation: Epoch : 50, Loss : 1.471896, Accuracy: 0.889000, Test accuracy: 0.902000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.902
Generating confusion matrix for student4
[[ 945.    0.    9.    5.    2.    7.    7.    1.    6.   10.]
 [   0. 1101.   28.    2.    1.    2.    4.   21.    8.    6.]
 [   0.    2.  872.   12.    5.    1.    5.   15.    6.    0.]
 [   4.    4.   34.  934.    1.   53.    1.    8.   43.   20.]
 [   2.    1.   18.    3.  929.   10.   13.   17.   26.   65.]
 [   8.    6.    2.   22.    3.  761.   27.    4.   47.   11.]
 [  12.    4.   11.    3.    7.   18.  898.    1.   12.    0.]
 [   2.    0.   13.   12.    1.    7.    1.  914.    7.   27.]
 [   6.   17.   38.   13.    8.   26.    2.    0.  804.    8.]
 [   1.    0.    7.    4.   25.    7.    0.   47.   15.  862.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.879852, Accuracy: 0.730000, Test accuracy: 0.748100
Distillation: Epoch : 2, Loss : 1.660025, Accuracy: 0.849000, Test accuracy: 0.849700
Distillation: Epoch : 3, Loss : 1.624084, Accuracy: 0.856000, Test accuracy: 0.871800
Distillation: Epoch : 4, Loss : 1.583949, Accuracy: 0.886000, Test accuracy: 0.885100
Distillation: Epoch : 5, Loss : 1.586993, Accuracy: 0.872000, Test accuracy: 0.891000
Distillation: Epoch : 6, Loss : 1.587364, Accuracy: 0.888000, Test accuracy: 0.899200
Distillation: Epoch : 7, Loss : 1.549018, Accuracy: 0.897000, Test accuracy: 0.904300
Distillation: Epoch : 8, Loss : 1.571873, Accuracy: 0.901000, Test accuracy: 0.911600
Distillation: Epoch : 9, Loss : 1.543398, Accuracy: 0.916000, Test accuracy: 0.919000
Distillation: Epoch : 10, Loss : 1.543689, Accuracy: 0.925000, Test accuracy: 0.925400
Distillation: Epoch : 11, Loss : 1.537774, Accuracy: 0.933000, Test accuracy: 0.930800
Distillation: Epoch : 12, Loss : 1.521638, Accuracy: 0.931000, Test accuracy: 0.935200
Distillation: Epoch : 13, Loss : 1.498852, Accuracy: 0.930000, Test accuracy: 0.940500
Distillation: Epoch : 14, Loss : 1.524189, Accuracy: 0.932000, Test accuracy: 0.941800
Distillation: Epoch : 15, Loss : 1.493322, Accuracy: 0.932000, Test accuracy: 0.944800
Distillation: Epoch : 16, Loss : 1.499368, Accuracy: 0.946000, Test accuracy: 0.945800
Distillation: Epoch : 17, Loss : 1.503174, Accuracy: 0.950000, Test accuracy: 0.947900
Distillation: Epoch : 18, Loss : 1.509034, Accuracy: 0.942000, Test accuracy: 0.950500
Distillation: Epoch : 19, Loss : 1.523676, Accuracy: 0.931000, Test accuracy: 0.950400
Distillation: Epoch : 20, Loss : 1.489720, Accuracy: 0.943000, Test accuracy: 0.952900
Distillation: Epoch : 21, Loss : 1.498845, Accuracy: 0.941000, Test accuracy: 0.952800
Distillation: Epoch : 22, Loss : 1.520907, Accuracy: 0.951000, Test accuracy: 0.954000
Distillation: Epoch : 23, Loss : 1.487343, Accuracy: 0.952000, Test accuracy: 0.955100
Distillation: Epoch : 24, Loss : 1.480298, Accuracy: 0.961000, Test accuracy: 0.954500
Distillation: Epoch : 25, Loss : 1.486027, Accuracy: 0.955000, Test accuracy: 0.955100
Distillation: Epoch : 26, Loss : 1.453047, Accuracy: 0.953000, Test accuracy: 0.955300
Distillation: Epoch : 27, Loss : 1.481776, Accuracy: 0.940000, Test accuracy: 0.955200
Distillation: Epoch : 28, Loss : 1.470064, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 29, Loss : 1.495884, Accuracy: 0.958000, Test accuracy: 0.956200
Distillation: Epoch : 30, Loss : 1.477753, Accuracy: 0.958000, Test accuracy: 0.956300
Distillation: Epoch : 31, Loss : 1.482044, Accuracy: 0.956000, Test accuracy: 0.956800
Distillation: Epoch : 32, Loss : 1.458692, Accuracy: 0.958000, Test accuracy: 0.956900
Distillation: Epoch : 33, Loss : 1.471642, Accuracy: 0.957000, Test accuracy: 0.956900
Distillation: Epoch : 34, Loss : 1.494950, Accuracy: 0.954000, Test accuracy: 0.957200
Distillation: Epoch : 35, Loss : 1.496393, Accuracy: 0.951000, Test accuracy: 0.957000
Distillation: Epoch : 36, Loss : 1.461572, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 37, Loss : 1.466247, Accuracy: 0.960000, Test accuracy: 0.957500
Distillation: Epoch : 38, Loss : 1.490870, Accuracy: 0.954000, Test accuracy: 0.957500
Distillation: Epoch : 39, Loss : 1.490012, Accuracy: 0.959000, Test accuracy: 0.956500
Distillation: Epoch : 40, Loss : 1.454642, Accuracy: 0.961000, Test accuracy: 0.957600
Distillation: Epoch : 41, Loss : 1.489052, Accuracy: 0.956000, Test accuracy: 0.957600
Distillation: Epoch : 42, Loss : 1.473892, Accuracy: 0.949000, Test accuracy: 0.956600
Distillation: Epoch : 43, Loss : 1.481967, Accuracy: 0.954000, Test accuracy: 0.957200
Distillation: Epoch : 44, Loss : 1.475317, Accuracy: 0.943000, Test accuracy: 0.958100
Distillation: Epoch : 45, Loss : 1.479740, Accuracy: 0.948000, Test accuracy: 0.959400
Distillation: Epoch : 46, Loss : 1.483177, Accuracy: 0.961000, Test accuracy: 0.958600
Distillation: Epoch : 47, Loss : 1.471301, Accuracy: 0.962000, Test accuracy: 0.958500
Distillation: Epoch : 48, Loss : 1.478759, Accuracy: 0.960000, Test accuracy: 0.957900
Distillation: Epoch : 49, Loss : 1.490483, Accuracy: 0.964000, Test accuracy: 0.958000
Distillation: Epoch : 50, Loss : 1.474936, Accuracy: 0.959000, Test accuracy: 0.958900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9589
Generating confusion matrix for student4
[[ 964.    0.    6.    0.    1.    2.    7.    2.    5.    7.]
 [   1. 1116.    4.    0.    0.    0.    2.    1.    0.    5.]
 [   2.    1.  973.    4.    4.    1.    1.   12.    6.    1.]
 [   0.    3.   12.  977.    1.   22.    0.   11.   14.   13.]
 [   0.    1.    2.    2.  957.    1.    5.    3.   11.   13.]
 [   4.    0.    1.    6.    0.  851.   21.    1.    9.   15.]
 [   6.    3.    2.    0.    4.    3.  920.    0.    3.    0.]
 [   1.    1.    9.    7.    2.    0.    0.  982.    7.    9.]
 [   2.   10.   23.   12.    2.    9.    2.    3.  907.    4.]
 [   0.    0.    0.    2.   11.    3.    0.   13.   12.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.044921, Accuracy: 0.760000, Test accuracy: 0.760200
Distillation: Epoch : 2, Loss : 1.887144, Accuracy: 0.844000, Test accuracy: 0.850600
Distillation: Epoch : 3, Loss : 1.851134, Accuracy: 0.866000, Test accuracy: 0.873600
Distillation: Epoch : 4, Loss : 1.836242, Accuracy: 0.874000, Test accuracy: 0.881400
Distillation: Epoch : 5, Loss : 1.830120, Accuracy: 0.899000, Test accuracy: 0.891400
Distillation: Epoch : 6, Loss : 1.829755, Accuracy: 0.899000, Test accuracy: 0.898600
Distillation: Epoch : 7, Loss : 1.813442, Accuracy: 0.916000, Test accuracy: 0.905400
Distillation: Epoch : 8, Loss : 1.812719, Accuracy: 0.894000, Test accuracy: 0.912200
Distillation: Epoch : 9, Loss : 1.818768, Accuracy: 0.897000, Test accuracy: 0.915900
Distillation: Epoch : 10, Loss : 1.791795, Accuracy: 0.923000, Test accuracy: 0.921500
Distillation: Epoch : 11, Loss : 1.792638, Accuracy: 0.914000, Test accuracy: 0.923600
Distillation: Epoch : 12, Loss : 1.784281, Accuracy: 0.930000, Test accuracy: 0.927500
Distillation: Epoch : 13, Loss : 1.797532, Accuracy: 0.929000, Test accuracy: 0.932000
Distillation: Epoch : 14, Loss : 1.794278, Accuracy: 0.915000, Test accuracy: 0.935000
Distillation: Epoch : 15, Loss : 1.785178, Accuracy: 0.926000, Test accuracy: 0.939700
Distillation: Epoch : 16, Loss : 1.777855, Accuracy: 0.936000, Test accuracy: 0.942800
Distillation: Epoch : 17, Loss : 1.782601, Accuracy: 0.944000, Test accuracy: 0.946300
Distillation: Epoch : 18, Loss : 1.750000, Accuracy: 0.944000, Test accuracy: 0.949700
Distillation: Epoch : 19, Loss : 1.782057, Accuracy: 0.940000, Test accuracy: 0.950700
Distillation: Epoch : 20, Loss : 1.772573, Accuracy: 0.945000, Test accuracy: 0.952300
Distillation: Epoch : 21, Loss : 1.768642, Accuracy: 0.949000, Test accuracy: 0.953300
Distillation: Epoch : 22, Loss : 1.764951, Accuracy: 0.943000, Test accuracy: 0.954000
Distillation: Epoch : 23, Loss : 1.762389, Accuracy: 0.944000, Test accuracy: 0.955000
Distillation: Epoch : 24, Loss : 1.758738, Accuracy: 0.951000, Test accuracy: 0.956500
Distillation: Epoch : 25, Loss : 1.768036, Accuracy: 0.950000, Test accuracy: 0.957000
Distillation: Epoch : 26, Loss : 1.768650, Accuracy: 0.965000, Test accuracy: 0.957800
Distillation: Epoch : 27, Loss : 1.762746, Accuracy: 0.955000, Test accuracy: 0.957600
Distillation: Epoch : 28, Loss : 1.764665, Accuracy: 0.961000, Test accuracy: 0.959200
Distillation: Epoch : 29, Loss : 1.768251, Accuracy: 0.953000, Test accuracy: 0.957900
Distillation: Epoch : 30, Loss : 1.756309, Accuracy: 0.954000, Test accuracy: 0.959400
Distillation: Epoch : 31, Loss : 1.762891, Accuracy: 0.946000, Test accuracy: 0.959300
Distillation: Epoch : 32, Loss : 1.761103, Accuracy: 0.942000, Test accuracy: 0.959300
Distillation: Epoch : 33, Loss : 1.755401, Accuracy: 0.963000, Test accuracy: 0.959600
Distillation: Epoch : 34, Loss : 1.775292, Accuracy: 0.960000, Test accuracy: 0.959900
Distillation: Epoch : 35, Loss : 1.743508, Accuracy: 0.964000, Test accuracy: 0.960500
Distillation: Epoch : 36, Loss : 1.745741, Accuracy: 0.958000, Test accuracy: 0.960600
Distillation: Epoch : 37, Loss : 1.760939, Accuracy: 0.955000, Test accuracy: 0.961300
Distillation: Epoch : 38, Loss : 1.765991, Accuracy: 0.957000, Test accuracy: 0.961700
Distillation: Epoch : 39, Loss : 1.749467, Accuracy: 0.965000, Test accuracy: 0.961700
Distillation: Epoch : 40, Loss : 1.760347, Accuracy: 0.961000, Test accuracy: 0.961200
Distillation: Epoch : 41, Loss : 1.756773, Accuracy: 0.954000, Test accuracy: 0.961500
Distillation: Epoch : 42, Loss : 1.757527, Accuracy: 0.956000, Test accuracy: 0.961400
Distillation: Epoch : 43, Loss : 1.746564, Accuracy: 0.942000, Test accuracy: 0.961000
Distillation: Epoch : 44, Loss : 1.755047, Accuracy: 0.963000, Test accuracy: 0.962600
Distillation: Epoch : 45, Loss : 1.734042, Accuracy: 0.965000, Test accuracy: 0.962900
Distillation: Epoch : 46, Loss : 1.755416, Accuracy: 0.962000, Test accuracy: 0.962000
Distillation: Epoch : 47, Loss : 1.753824, Accuracy: 0.961000, Test accuracy: 0.961700
Distillation: Epoch : 48, Loss : 1.752768, Accuracy: 0.955000, Test accuracy: 0.963400
Distillation: Epoch : 49, Loss : 1.759164, Accuracy: 0.968000, Test accuracy: 0.963100
Distillation: Epoch : 50, Loss : 1.763118, Accuracy: 0.963000, Test accuracy: 0.963600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9636
Generating confusion matrix for student4
[[ 971.    0.    3.    0.    1.    2.    9.    1.    5.    3.]
 [   1. 1115.   10.    0.    2.    0.    3.    6.    5.    6.]
 [   1.    1.  981.    3.    1.    2.    0.   15.    5.    1.]
 [   0.    1.    8.  985.    0.   13.    0.    3.    8.    9.]
 [   1.    3.    5.    0.  966.    0.    6.    8.   11.   21.]
 [   0.    0.    0.    8.    0.  858.    8.    0.    2.    6.]
 [   5.    5.    0.    0.    3.    5.  928.    0.    9.    1.]
 [   1.    0.   13.    8.    0.    2.    0.  977.   13.   11.]
 [   0.   10.   11.    4.    3.    5.    4.    3.  907.    3.]
 [   0.    0.    1.    2.    6.    5.    0.   15.    9.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.143909, Accuracy: 0.773000, Test accuracy: 0.765000
Distillation: Epoch : 2, Loss : 2.083985, Accuracy: 0.832000, Test accuracy: 0.844400
Distillation: Epoch : 3, Loss : 2.054828, Accuracy: 0.868000, Test accuracy: 0.863000
Distillation: Epoch : 4, Loss : 2.058842, Accuracy: 0.874000, Test accuracy: 0.873000
Distillation: Epoch : 5, Loss : 2.062310, Accuracy: 0.856000, Test accuracy: 0.882500
Distillation: Epoch : 6, Loss : 2.061762, Accuracy: 0.874000, Test accuracy: 0.891600
Distillation: Epoch : 7, Loss : 2.047121, Accuracy: 0.904000, Test accuracy: 0.896700
Distillation: Epoch : 8, Loss : 2.042206, Accuracy: 0.897000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 2.041814, Accuracy: 0.912000, Test accuracy: 0.907000
Distillation: Epoch : 10, Loss : 2.038672, Accuracy: 0.897000, Test accuracy: 0.911600
Distillation: Epoch : 11, Loss : 2.045424, Accuracy: 0.908000, Test accuracy: 0.915100
Distillation: Epoch : 12, Loss : 2.041233, Accuracy: 0.901000, Test accuracy: 0.918300
Distillation: Epoch : 13, Loss : 2.041795, Accuracy: 0.898000, Test accuracy: 0.921500
Distillation: Epoch : 14, Loss : 2.031351, Accuracy: 0.922000, Test accuracy: 0.925400
Distillation: Epoch : 15, Loss : 2.033571, Accuracy: 0.919000, Test accuracy: 0.927400
Distillation: Epoch : 16, Loss : 2.034772, Accuracy: 0.915000, Test accuracy: 0.930000
Distillation: Epoch : 17, Loss : 2.026658, Accuracy: 0.927000, Test accuracy: 0.931800
Distillation: Epoch : 18, Loss : 2.017572, Accuracy: 0.941000, Test accuracy: 0.932800
Distillation: Epoch : 19, Loss : 2.019341, Accuracy: 0.923000, Test accuracy: 0.935000
Distillation: Epoch : 20, Loss : 2.021112, Accuracy: 0.943000, Test accuracy: 0.936400
Distillation: Epoch : 21, Loss : 2.023386, Accuracy: 0.945000, Test accuracy: 0.936900
Distillation: Epoch : 22, Loss : 2.027314, Accuracy: 0.934000, Test accuracy: 0.937900
Distillation: Epoch : 23, Loss : 2.024671, Accuracy: 0.935000, Test accuracy: 0.938300
Distillation: Epoch : 24, Loss : 2.020037, Accuracy: 0.927000, Test accuracy: 0.939900
Distillation: Epoch : 25, Loss : 2.012569, Accuracy: 0.937000, Test accuracy: 0.940500
Distillation: Epoch : 26, Loss : 2.014813, Accuracy: 0.946000, Test accuracy: 0.940300
Distillation: Epoch : 27, Loss : 2.013959, Accuracy: 0.931000, Test accuracy: 0.940100
Distillation: Epoch : 28, Loss : 2.022268, Accuracy: 0.938000, Test accuracy: 0.942000
Distillation: Epoch : 29, Loss : 2.023917, Accuracy: 0.930000, Test accuracy: 0.940100
Distillation: Epoch : 30, Loss : 2.017020, Accuracy: 0.948000, Test accuracy: 0.941700
Distillation: Epoch : 31, Loss : 2.022750, Accuracy: 0.928000, Test accuracy: 0.941300
Distillation: Epoch : 32, Loss : 2.020774, Accuracy: 0.935000, Test accuracy: 0.943000
Distillation: Epoch : 33, Loss : 2.023175, Accuracy: 0.939000, Test accuracy: 0.943100
Distillation: Epoch : 34, Loss : 2.022617, Accuracy: 0.934000, Test accuracy: 0.942800
Distillation: Epoch : 35, Loss : 2.020979, Accuracy: 0.927000, Test accuracy: 0.942800
Distillation: Epoch : 36, Loss : 2.020079, Accuracy: 0.935000, Test accuracy: 0.943200
Distillation: Epoch : 37, Loss : 2.011867, Accuracy: 0.936000, Test accuracy: 0.943300
Distillation: Epoch : 38, Loss : 2.028888, Accuracy: 0.942000, Test accuracy: 0.944900
Distillation: Epoch : 39, Loss : 2.015492, Accuracy: 0.935000, Test accuracy: 0.943800
Distillation: Epoch : 40, Loss : 2.020771, Accuracy: 0.940000, Test accuracy: 0.944500
Distillation: Epoch : 41, Loss : 2.014592, Accuracy: 0.936000, Test accuracy: 0.944800
Distillation: Epoch : 42, Loss : 2.015029, Accuracy: 0.944000, Test accuracy: 0.944900
Distillation: Epoch : 43, Loss : 2.011562, Accuracy: 0.948000, Test accuracy: 0.945100
Distillation: Epoch : 44, Loss : 2.004014, Accuracy: 0.950000, Test accuracy: 0.945300
Distillation: Epoch : 45, Loss : 2.018666, Accuracy: 0.931000, Test accuracy: 0.945100
Distillation: Epoch : 46, Loss : 2.019672, Accuracy: 0.952000, Test accuracy: 0.947200
Distillation: Epoch : 47, Loss : 2.015072, Accuracy: 0.943000, Test accuracy: 0.946500
Distillation: Epoch : 48, Loss : 2.024845, Accuracy: 0.937000, Test accuracy: 0.947000
Distillation: Epoch : 49, Loss : 2.024019, Accuracy: 0.941000, Test accuracy: 0.946600
Distillation: Epoch : 50, Loss : 2.019613, Accuracy: 0.940000, Test accuracy: 0.947200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9472
Generating confusion matrix for student4
[[ 954.    0.   11.    5.    0.    7.    7.    0.    5.    3.]
 [   0. 1106.   14.    0.    0.    0.    3.    8.    1.    4.]
 [   0.    3.  957.    6.    6.    0.    1.   12.    2.    0.]
 [   5.    4.   16.  959.    2.   14.    0.    8.    9.    7.]
 [   0.    2.   12.    1.  937.    4.    7.   19.    9.   31.]
 [   6.    2.    1.   19.    2.  843.   21.    0.   16.   14.]
 [   9.    6.    3.    3.    8.   11.  918.    0.    6.    1.]
 [   0.    0.   11.   11.    3.    3.    0.  959.    6.    9.]
 [   5.   12.    7.    6.    4.    6.    1.    2.  908.    9.]
 [   1.    0.    0.    0.   20.    4.    0.   20.   12.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.896248, Accuracy: 0.796000, Test accuracy: 0.795500
Distillation: Epoch : 2, Loss : 0.427617, Accuracy: 0.879000, Test accuracy: 0.873600
Distillation: Epoch : 3, Loss : 0.340420, Accuracy: 0.903000, Test accuracy: 0.891600
Distillation: Epoch : 4, Loss : 0.337944, Accuracy: 0.912000, Test accuracy: 0.900800
Distillation: Epoch : 5, Loss : 0.343356, Accuracy: 0.889000, Test accuracy: 0.907100
Distillation: Epoch : 6, Loss : 0.298481, Accuracy: 0.912000, Test accuracy: 0.912700
Distillation: Epoch : 7, Loss : 0.301964, Accuracy: 0.904000, Test accuracy: 0.913900
Distillation: Epoch : 8, Loss : 0.298544, Accuracy: 0.902000, Test accuracy: 0.916200
Distillation: Epoch : 9, Loss : 0.284869, Accuracy: 0.920000, Test accuracy: 0.919800
Distillation: Epoch : 10, Loss : 0.329897, Accuracy: 0.907000, Test accuracy: 0.922900
Distillation: Epoch : 11, Loss : 0.281786, Accuracy: 0.925000, Test accuracy: 0.924900
Distillation: Epoch : 12, Loss : 0.288392, Accuracy: 0.911000, Test accuracy: 0.927900
Distillation: Epoch : 13, Loss : 0.237426, Accuracy: 0.937000, Test accuracy: 0.928900
Distillation: Epoch : 14, Loss : 0.282061, Accuracy: 0.919000, Test accuracy: 0.930600
Distillation: Epoch : 15, Loss : 0.243930, Accuracy: 0.933000, Test accuracy: 0.933100
Distillation: Epoch : 16, Loss : 0.216954, Accuracy: 0.933000, Test accuracy: 0.933800
Distillation: Epoch : 17, Loss : 0.187391, Accuracy: 0.943000, Test accuracy: 0.935600
Distillation: Epoch : 18, Loss : 0.271002, Accuracy: 0.922000, Test accuracy: 0.937300
Distillation: Epoch : 19, Loss : 0.189529, Accuracy: 0.939000, Test accuracy: 0.938300
Distillation: Epoch : 20, Loss : 0.213217, Accuracy: 0.945000, Test accuracy: 0.940800
Distillation: Epoch : 21, Loss : 0.206858, Accuracy: 0.938000, Test accuracy: 0.940500
Distillation: Epoch : 22, Loss : 0.231949, Accuracy: 0.932000, Test accuracy: 0.942700
Distillation: Epoch : 23, Loss : 0.212989, Accuracy: 0.940000, Test accuracy: 0.942400
Distillation: Epoch : 24, Loss : 0.179423, Accuracy: 0.954000, Test accuracy: 0.944400
Distillation: Epoch : 25, Loss : 0.174616, Accuracy: 0.951000, Test accuracy: 0.945200
Distillation: Epoch : 26, Loss : 0.205334, Accuracy: 0.946000, Test accuracy: 0.946200
Distillation: Epoch : 27, Loss : 0.156363, Accuracy: 0.956000, Test accuracy: 0.947100
Distillation: Epoch : 28, Loss : 0.187075, Accuracy: 0.940000, Test accuracy: 0.948800
Distillation: Epoch : 29, Loss : 0.159827, Accuracy: 0.953000, Test accuracy: 0.949400
Distillation: Epoch : 30, Loss : 0.184278, Accuracy: 0.943000, Test accuracy: 0.949200
Distillation: Epoch : 31, Loss : 0.160788, Accuracy: 0.954000, Test accuracy: 0.950700
Distillation: Epoch : 32, Loss : 0.194907, Accuracy: 0.942000, Test accuracy: 0.951300
Distillation: Epoch : 33, Loss : 0.160205, Accuracy: 0.955000, Test accuracy: 0.951000
Distillation: Epoch : 34, Loss : 0.174420, Accuracy: 0.946000, Test accuracy: 0.952400
Distillation: Epoch : 35, Loss : 0.184309, Accuracy: 0.949000, Test accuracy: 0.952300
Distillation: Epoch : 36, Loss : 0.134570, Accuracy: 0.959000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 0.211623, Accuracy: 0.949000, Test accuracy: 0.953800
Distillation: Epoch : 38, Loss : 0.164171, Accuracy: 0.945000, Test accuracy: 0.953500
Distillation: Epoch : 39, Loss : 0.122281, Accuracy: 0.970000, Test accuracy: 0.953900
Distillation: Epoch : 40, Loss : 0.127881, Accuracy: 0.963000, Test accuracy: 0.954900
Distillation: Epoch : 41, Loss : 0.154365, Accuracy: 0.959000, Test accuracy: 0.954800
Distillation: Epoch : 42, Loss : 0.103741, Accuracy: 0.967000, Test accuracy: 0.955300
Distillation: Epoch : 43, Loss : 0.116604, Accuracy: 0.958000, Test accuracy: 0.955200
Distillation: Epoch : 44, Loss : 0.135445, Accuracy: 0.963000, Test accuracy: 0.955800
Distillation: Epoch : 45, Loss : 0.164000, Accuracy: 0.949000, Test accuracy: 0.956900
Distillation: Epoch : 46, Loss : 0.133888, Accuracy: 0.952000, Test accuracy: 0.956600
Distillation: Epoch : 47, Loss : 0.165294, Accuracy: 0.951000, Test accuracy: 0.956600
Distillation: Epoch : 48, Loss : 0.159678, Accuracy: 0.959000, Test accuracy: 0.958300
Distillation: Epoch : 49, Loss : 0.135549, Accuracy: 0.963000, Test accuracy: 0.958100
Distillation: Epoch : 50, Loss : 0.126758, Accuracy: 0.962000, Test accuracy: 0.957500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9575
Generating confusion matrix for student5
[[ 965.    0.    2.    0.    0.    4.    4.    0.    7.    6.]
 [   0. 1116.    8.    0.    1.    4.    3.    6.    3.    7.]
 [   2.    5.  974.    6.    5.    1.    3.   17.    4.    1.]
 [   3.    3.   20.  972.    1.   16.    2.   12.   12.    8.]
 [   0.    1.    8.    1.  946.    3.    3.    7.    7.   14.]
 [   2.    1.    2.   12.    2.  834.    5.    1.    3.   10.]
 [   3.    2.    2.    1.    6.   11.  932.    0.   10.    0.]
 [   3.    0.   11.   11.    5.    5.    1.  972.    6.    7.]
 [   2.    7.    2.    7.    4.   10.    5.    1.  915.    7.]
 [   0.    0.    3.    0.   12.    4.    0.   12.    7.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.034137, Accuracy: 0.572000, Test accuracy: 0.586800
Distillation: Epoch : 2, Loss : 0.930221, Accuracy: 0.794000, Test accuracy: 0.813600
Distillation: Epoch : 3, Loss : 0.620512, Accuracy: 0.843000, Test accuracy: 0.849900
Distillation: Epoch : 4, Loss : 0.563248, Accuracy: 0.848000, Test accuracy: 0.869100
Distillation: Epoch : 5, Loss : 0.433119, Accuracy: 0.891000, Test accuracy: 0.880500
Distillation: Epoch : 6, Loss : 0.483317, Accuracy: 0.867000, Test accuracy: 0.889900
Distillation: Epoch : 7, Loss : 0.414502, Accuracy: 0.876000, Test accuracy: 0.897100
Distillation: Epoch : 8, Loss : 0.374303, Accuracy: 0.891000, Test accuracy: 0.903500
Distillation: Epoch : 9, Loss : 0.403076, Accuracy: 0.896000, Test accuracy: 0.906400
Distillation: Epoch : 10, Loss : 0.363336, Accuracy: 0.901000, Test accuracy: 0.911000
Distillation: Epoch : 11, Loss : 0.317796, Accuracy: 0.917000, Test accuracy: 0.913900
Distillation: Epoch : 12, Loss : 0.305716, Accuracy: 0.922000, Test accuracy: 0.916700
Distillation: Epoch : 13, Loss : 0.276194, Accuracy: 0.926000, Test accuracy: 0.918500
Distillation: Epoch : 14, Loss : 0.303486, Accuracy: 0.919000, Test accuracy: 0.921400
Distillation: Epoch : 15, Loss : 0.319809, Accuracy: 0.906000, Test accuracy: 0.922900
Distillation: Epoch : 16, Loss : 0.249638, Accuracy: 0.941000, Test accuracy: 0.924300
Distillation: Epoch : 17, Loss : 0.280750, Accuracy: 0.913000, Test accuracy: 0.925700
Distillation: Epoch : 18, Loss : 0.271962, Accuracy: 0.930000, Test accuracy: 0.927200
Distillation: Epoch : 19, Loss : 0.317247, Accuracy: 0.920000, Test accuracy: 0.929300
Distillation: Epoch : 20, Loss : 0.297688, Accuracy: 0.916000, Test accuracy: 0.930200
Distillation: Epoch : 21, Loss : 0.255093, Accuracy: 0.935000, Test accuracy: 0.930000
Distillation: Epoch : 22, Loss : 0.243123, Accuracy: 0.940000, Test accuracy: 0.931800
Distillation: Epoch : 23, Loss : 0.295179, Accuracy: 0.933000, Test accuracy: 0.932100
Distillation: Epoch : 24, Loss : 0.262809, Accuracy: 0.928000, Test accuracy: 0.933400
Distillation: Epoch : 25, Loss : 0.218057, Accuracy: 0.940000, Test accuracy: 0.934000
Distillation: Epoch : 26, Loss : 0.240735, Accuracy: 0.934000, Test accuracy: 0.933900
Distillation: Epoch : 27, Loss : 0.229214, Accuracy: 0.944000, Test accuracy: 0.934300
Distillation: Epoch : 28, Loss : 0.237232, Accuracy: 0.927000, Test accuracy: 0.935800
Distillation: Epoch : 29, Loss : 0.223257, Accuracy: 0.936000, Test accuracy: 0.936700
Distillation: Epoch : 30, Loss : 0.264867, Accuracy: 0.923000, Test accuracy: 0.936300
Distillation: Epoch : 31, Loss : 0.225479, Accuracy: 0.939000, Test accuracy: 0.937400
Distillation: Epoch : 32, Loss : 0.262881, Accuracy: 0.926000, Test accuracy: 0.937900
Distillation: Epoch : 33, Loss : 0.235161, Accuracy: 0.937000, Test accuracy: 0.938900
Distillation: Epoch : 34, Loss : 0.256178, Accuracy: 0.942000, Test accuracy: 0.940000
Distillation: Epoch : 35, Loss : 0.215925, Accuracy: 0.943000, Test accuracy: 0.939500
Distillation: Epoch : 36, Loss : 0.208133, Accuracy: 0.945000, Test accuracy: 0.939700
Distillation: Epoch : 37, Loss : 0.253478, Accuracy: 0.932000, Test accuracy: 0.940400
Distillation: Epoch : 38, Loss : 0.248757, Accuracy: 0.942000, Test accuracy: 0.940900
Distillation: Epoch : 39, Loss : 0.218163, Accuracy: 0.939000, Test accuracy: 0.941300
Distillation: Epoch : 40, Loss : 0.256848, Accuracy: 0.933000, Test accuracy: 0.942200
Distillation: Epoch : 41, Loss : 0.213754, Accuracy: 0.940000, Test accuracy: 0.943000
Distillation: Epoch : 42, Loss : 0.249607, Accuracy: 0.944000, Test accuracy: 0.942700
Distillation: Epoch : 43, Loss : 0.217311, Accuracy: 0.935000, Test accuracy: 0.943700
Distillation: Epoch : 44, Loss : 0.212204, Accuracy: 0.943000, Test accuracy: 0.944400
Distillation: Epoch : 45, Loss : 0.231533, Accuracy: 0.936000, Test accuracy: 0.944500
Distillation: Epoch : 46, Loss : 0.211996, Accuracy: 0.947000, Test accuracy: 0.944600
Distillation: Epoch : 47, Loss : 0.204763, Accuracy: 0.951000, Test accuracy: 0.946200
Distillation: Epoch : 48, Loss : 0.188485, Accuracy: 0.951000, Test accuracy: 0.946300
Distillation: Epoch : 49, Loss : 0.226867, Accuracy: 0.939000, Test accuracy: 0.947400
Distillation: Epoch : 50, Loss : 0.201463, Accuracy: 0.948000, Test accuracy: 0.947200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9472
Generating confusion matrix for student5
[[ 962.    0.    4.    2.    1.    5.    8.    0.    5.    4.]
 [   0. 1116.    9.    0.    1.    3.    3.   12.    1.    7.]
 [   1.    3.  958.   15.    4.    2.    6.   23.    4.    1.]
 [   2.    3.   15.  942.    2.   30.    0.    8.    9.   11.]
 [   0.    0.    9.    0.  925.    4.    5.    4.    8.   22.]
 [   6.    0.    6.   25.    3.  819.    6.    2.    7.   10.]
 [   4.    2.    4.    1.   10.   12.  924.    0.    7.    1.]
 [   3.    0.   13.   14.    2.    4.    1.  961.    5.    7.]
 [   2.   11.   12.    6.    7.    9.    5.    1.  924.    5.]
 [   0.    0.    2.    5.   27.    4.    0.   17.    4.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.703554, Accuracy: 0.747000, Test accuracy: 0.729200
Distillation: Epoch : 2, Loss : 0.874843, Accuracy: 0.836000, Test accuracy: 0.851300
Distillation: Epoch : 3, Loss : 0.765804, Accuracy: 0.860000, Test accuracy: 0.883300
Distillation: Epoch : 4, Loss : 0.716963, Accuracy: 0.887000, Test accuracy: 0.896200
Distillation: Epoch : 5, Loss : 0.675881, Accuracy: 0.907000, Test accuracy: 0.901300
Distillation: Epoch : 6, Loss : 0.674724, Accuracy: 0.903000, Test accuracy: 0.905500
Distillation: Epoch : 7, Loss : 0.704677, Accuracy: 0.889000, Test accuracy: 0.908200
Distillation: Epoch : 8, Loss : 0.653689, Accuracy: 0.909000, Test accuracy: 0.910100
Distillation: Epoch : 9, Loss : 0.673281, Accuracy: 0.900000, Test accuracy: 0.910200
Distillation: Epoch : 10, Loss : 0.645937, Accuracy: 0.903000, Test accuracy: 0.911700
Distillation: Epoch : 11, Loss : 0.690023, Accuracy: 0.897000, Test accuracy: 0.913500
Distillation: Epoch : 12, Loss : 0.668122, Accuracy: 0.898000, Test accuracy: 0.913900
Distillation: Epoch : 13, Loss : 0.663697, Accuracy: 0.908000, Test accuracy: 0.915300
Distillation: Epoch : 14, Loss : 0.617746, Accuracy: 0.913000, Test accuracy: 0.915900
Distillation: Epoch : 15, Loss : 0.658526, Accuracy: 0.907000, Test accuracy: 0.917300
Distillation: Epoch : 16, Loss : 0.643137, Accuracy: 0.905000, Test accuracy: 0.918500
Distillation: Epoch : 17, Loss : 0.652829, Accuracy: 0.905000, Test accuracy: 0.918700
Distillation: Epoch : 18, Loss : 0.637196, Accuracy: 0.925000, Test accuracy: 0.918800
Distillation: Epoch : 19, Loss : 0.646719, Accuracy: 0.912000, Test accuracy: 0.918900
Distillation: Epoch : 20, Loss : 0.673581, Accuracy: 0.915000, Test accuracy: 0.920200
Distillation: Epoch : 21, Loss : 0.624705, Accuracy: 0.909000, Test accuracy: 0.920300
Distillation: Epoch : 22, Loss : 0.648023, Accuracy: 0.912000, Test accuracy: 0.921600
Distillation: Epoch : 23, Loss : 0.624344, Accuracy: 0.927000, Test accuracy: 0.921600
Distillation: Epoch : 24, Loss : 0.679179, Accuracy: 0.897000, Test accuracy: 0.922400
Distillation: Epoch : 25, Loss : 0.613587, Accuracy: 0.921000, Test accuracy: 0.921000
Distillation: Epoch : 26, Loss : 0.615527, Accuracy: 0.933000, Test accuracy: 0.922000
Distillation: Epoch : 27, Loss : 0.628180, Accuracy: 0.922000, Test accuracy: 0.923900
Distillation: Epoch : 28, Loss : 0.654775, Accuracy: 0.914000, Test accuracy: 0.923300
Distillation: Epoch : 29, Loss : 0.625620, Accuracy: 0.916000, Test accuracy: 0.924400
Distillation: Epoch : 30, Loss : 0.598784, Accuracy: 0.920000, Test accuracy: 0.923300
Distillation: Epoch : 31, Loss : 0.608284, Accuracy: 0.925000, Test accuracy: 0.924200
Distillation: Epoch : 32, Loss : 0.637219, Accuracy: 0.927000, Test accuracy: 0.924800
Distillation: Epoch : 33, Loss : 0.648289, Accuracy: 0.910000, Test accuracy: 0.925300
Distillation: Epoch : 34, Loss : 0.608043, Accuracy: 0.933000, Test accuracy: 0.925100
Distillation: Epoch : 35, Loss : 0.616126, Accuracy: 0.912000, Test accuracy: 0.927100
Distillation: Epoch : 36, Loss : 0.595812, Accuracy: 0.934000, Test accuracy: 0.926600
Distillation: Epoch : 37, Loss : 0.639803, Accuracy: 0.903000, Test accuracy: 0.926000
Distillation: Epoch : 38, Loss : 0.647184, Accuracy: 0.917000, Test accuracy: 0.927700
Distillation: Epoch : 39, Loss : 0.572455, Accuracy: 0.930000, Test accuracy: 0.928700
Distillation: Epoch : 40, Loss : 0.599227, Accuracy: 0.923000, Test accuracy: 0.929900
Distillation: Epoch : 41, Loss : 0.590920, Accuracy: 0.923000, Test accuracy: 0.930700
Distillation: Epoch : 42, Loss : 0.568533, Accuracy: 0.937000, Test accuracy: 0.930600
Distillation: Epoch : 43, Loss : 0.588966, Accuracy: 0.923000, Test accuracy: 0.931400
Distillation: Epoch : 44, Loss : 0.599668, Accuracy: 0.936000, Test accuracy: 0.931700
Distillation: Epoch : 45, Loss : 0.626391, Accuracy: 0.918000, Test accuracy: 0.933000
Distillation: Epoch : 46, Loss : 0.607371, Accuracy: 0.927000, Test accuracy: 0.934300
Distillation: Epoch : 47, Loss : 0.568249, Accuracy: 0.930000, Test accuracy: 0.933400
Distillation: Epoch : 48, Loss : 0.576733, Accuracy: 0.947000, Test accuracy: 0.934500
Distillation: Epoch : 49, Loss : 0.581586, Accuracy: 0.927000, Test accuracy: 0.936000
Distillation: Epoch : 50, Loss : 0.569411, Accuracy: 0.934000, Test accuracy: 0.938400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9384
Generating confusion matrix for student5
[[ 955.    0.    7.    0.    2.    5.    6.    0.    6.    6.]
 [   0. 1110.   13.    2.    2.    2.    3.   11.   12.    8.]
 [   1.    2.  936.   18.    4.    2.    2.   19.    6.    1.]
 [   1.    3.   16.  951.    1.   28.    0.    4.   20.   13.]
 [   1.    2.   13.    1.  934.    2.    6.    8.   11.   43.]
 [   3.    2.    1.   10.    0.  826.   12.    2.   18.    9.]
 [  11.    3.    6.    1.    8.   11.  926.    0.    8.    0.]
 [   2.    0.   13.   15.    2.    3.    1.  962.    9.   19.]
 [   5.   13.   20.    7.    4.    7.    2.    1.  878.    4.]
 [   1.    0.    7.    5.   25.    6.    0.   21.    6.  906.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.665536, Accuracy: 0.738000, Test accuracy: 0.747500
Distillation: Epoch : 2, Loss : 1.029967, Accuracy: 0.813000, Test accuracy: 0.846100
Distillation: Epoch : 3, Loss : 0.973383, Accuracy: 0.851000, Test accuracy: 0.879100
Distillation: Epoch : 4, Loss : 0.905657, Accuracy: 0.887000, Test accuracy: 0.889100
Distillation: Epoch : 5, Loss : 0.865038, Accuracy: 0.889000, Test accuracy: 0.894400
Distillation: Epoch : 6, Loss : 0.896518, Accuracy: 0.895000, Test accuracy: 0.897300
Distillation: Epoch : 7, Loss : 0.851858, Accuracy: 0.886000, Test accuracy: 0.900100
Distillation: Epoch : 8, Loss : 0.849734, Accuracy: 0.903000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 0.880805, Accuracy: 0.892000, Test accuracy: 0.902200
Distillation: Epoch : 10, Loss : 0.882547, Accuracy: 0.869000, Test accuracy: 0.902800
Distillation: Epoch : 11, Loss : 0.836257, Accuracy: 0.899000, Test accuracy: 0.903100
Distillation: Epoch : 12, Loss : 0.885191, Accuracy: 0.885000, Test accuracy: 0.906100
Distillation: Epoch : 13, Loss : 0.858583, Accuracy: 0.899000, Test accuracy: 0.905400
Distillation: Epoch : 14, Loss : 0.836401, Accuracy: 0.902000, Test accuracy: 0.906100
Distillation: Epoch : 15, Loss : 0.874316, Accuracy: 0.876000, Test accuracy: 0.906500
Distillation: Epoch : 16, Loss : 0.830527, Accuracy: 0.916000, Test accuracy: 0.905300
Distillation: Epoch : 17, Loss : 0.842494, Accuracy: 0.895000, Test accuracy: 0.906800
Distillation: Epoch : 18, Loss : 0.828051, Accuracy: 0.888000, Test accuracy: 0.908700
Distillation: Epoch : 19, Loss : 0.835008, Accuracy: 0.904000, Test accuracy: 0.908900
Distillation: Epoch : 20, Loss : 0.838906, Accuracy: 0.893000, Test accuracy: 0.906700
Distillation: Epoch : 21, Loss : 0.833957, Accuracy: 0.907000, Test accuracy: 0.909400
Distillation: Epoch : 22, Loss : 0.818885, Accuracy: 0.909000, Test accuracy: 0.908500
Distillation: Epoch : 23, Loss : 0.864407, Accuracy: 0.892000, Test accuracy: 0.908100
Distillation: Epoch : 24, Loss : 0.847550, Accuracy: 0.913000, Test accuracy: 0.909100
Distillation: Epoch : 25, Loss : 0.856356, Accuracy: 0.895000, Test accuracy: 0.910300
Distillation: Epoch : 26, Loss : 0.799462, Accuracy: 0.925000, Test accuracy: 0.910500
Distillation: Epoch : 27, Loss : 0.784539, Accuracy: 0.922000, Test accuracy: 0.909400
Distillation: Epoch : 28, Loss : 0.840236, Accuracy: 0.896000, Test accuracy: 0.909600
Distillation: Epoch : 29, Loss : 0.846794, Accuracy: 0.903000, Test accuracy: 0.912000
Distillation: Epoch : 30, Loss : 0.836891, Accuracy: 0.898000, Test accuracy: 0.911200
Distillation: Epoch : 31, Loss : 0.829704, Accuracy: 0.897000, Test accuracy: 0.910200
Distillation: Epoch : 32, Loss : 0.831221, Accuracy: 0.914000, Test accuracy: 0.912100
Distillation: Epoch : 33, Loss : 0.841295, Accuracy: 0.895000, Test accuracy: 0.912000
Distillation: Epoch : 34, Loss : 0.788496, Accuracy: 0.926000, Test accuracy: 0.911700
Distillation: Epoch : 35, Loss : 0.820710, Accuracy: 0.899000, Test accuracy: 0.912600
Distillation: Epoch : 36, Loss : 0.799434, Accuracy: 0.916000, Test accuracy: 0.912200
Distillation: Epoch : 37, Loss : 0.808201, Accuracy: 0.911000, Test accuracy: 0.911500
Distillation: Epoch : 38, Loss : 0.820368, Accuracy: 0.907000, Test accuracy: 0.912700
Distillation: Epoch : 39, Loss : 0.838824, Accuracy: 0.898000, Test accuracy: 0.912000
Distillation: Epoch : 40, Loss : 0.810607, Accuracy: 0.910000, Test accuracy: 0.914400
Distillation: Epoch : 41, Loss : 0.803168, Accuracy: 0.914000, Test accuracy: 0.912300
Distillation: Epoch : 42, Loss : 0.837099, Accuracy: 0.909000, Test accuracy: 0.912500
Distillation: Epoch : 43, Loss : 0.856542, Accuracy: 0.900000, Test accuracy: 0.912700
Distillation: Epoch : 44, Loss : 0.819020, Accuracy: 0.905000, Test accuracy: 0.912800
Distillation: Epoch : 45, Loss : 0.782907, Accuracy: 0.919000, Test accuracy: 0.914000
Distillation: Epoch : 46, Loss : 0.840353, Accuracy: 0.894000, Test accuracy: 0.913600
Distillation: Epoch : 47, Loss : 0.813542, Accuracy: 0.907000, Test accuracy: 0.914600
Distillation: Epoch : 48, Loss : 0.822929, Accuracy: 0.907000, Test accuracy: 0.913700
Distillation: Epoch : 49, Loss : 0.815731, Accuracy: 0.908000, Test accuracy: 0.913300
Distillation: Epoch : 50, Loss : 0.822732, Accuracy: 0.914000, Test accuracy: 0.914100
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9141
Generating confusion matrix for student5
[[ 956.    0.    9.    3.    1.    7.    9.    2.    7.    9.]
 [   0. 1108.   14.    2.    2.    4.    4.   18.    9.    7.]
 [   0.    2.  898.   19.    5.    2.    6.   18.    7.    0.]
 [   3.    3.   27.  932.    1.   44.    1.    7.   30.   17.]
 [   0.    1.   13.    2.  922.   10.   10.   12.   20.   41.]
 [   6.    4.    1.   21.    1.  767.   19.    0.   40.    9.]
 [   9.    4.   13.    2.    8.   16.  906.    0.   12.    1.]
 [   2.    0.   12.   10.    2.    9.    2.  937.    9.   29.]
 [   4.   13.   38.   14.    6.   27.    1.    1.  829.   10.]
 [   0.    0.    7.    5.   34.    6.    0.   33.   11.  886.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.935275, Accuracy: 0.665000, Test accuracy: 0.669000
Distillation: Epoch : 2, Loss : 1.174224, Accuracy: 0.847000, Test accuracy: 0.837800
Distillation: Epoch : 3, Loss : 1.073157, Accuracy: 0.870000, Test accuracy: 0.871600
Distillation: Epoch : 4, Loss : 1.064687, Accuracy: 0.878000, Test accuracy: 0.887400
Distillation: Epoch : 5, Loss : 1.077439, Accuracy: 0.868000, Test accuracy: 0.894300
Distillation: Epoch : 6, Loss : 1.036482, Accuracy: 0.890000, Test accuracy: 0.900900
Distillation: Epoch : 7, Loss : 1.020735, Accuracy: 0.892000, Test accuracy: 0.903900
Distillation: Epoch : 8, Loss : 0.986268, Accuracy: 0.918000, Test accuracy: 0.910900
Distillation: Epoch : 9, Loss : 1.018117, Accuracy: 0.908000, Test accuracy: 0.914300
Distillation: Epoch : 10, Loss : 0.998368, Accuracy: 0.912000, Test accuracy: 0.917600
Distillation: Epoch : 11, Loss : 0.974664, Accuracy: 0.910000, Test accuracy: 0.921300
Distillation: Epoch : 12, Loss : 0.977119, Accuracy: 0.907000, Test accuracy: 0.924600
Distillation: Epoch : 13, Loss : 0.961071, Accuracy: 0.917000, Test accuracy: 0.928500
Distillation: Epoch : 14, Loss : 0.936639, Accuracy: 0.937000, Test accuracy: 0.933000
Distillation: Epoch : 15, Loss : 0.944184, Accuracy: 0.928000, Test accuracy: 0.935600
Distillation: Epoch : 16, Loss : 0.975357, Accuracy: 0.923000, Test accuracy: 0.937400
Distillation: Epoch : 17, Loss : 0.926693, Accuracy: 0.952000, Test accuracy: 0.939000
Distillation: Epoch : 18, Loss : 0.937951, Accuracy: 0.946000, Test accuracy: 0.941100
Distillation: Epoch : 19, Loss : 0.918678, Accuracy: 0.929000, Test accuracy: 0.942000
Distillation: Epoch : 20, Loss : 0.930071, Accuracy: 0.936000, Test accuracy: 0.944500
Distillation: Epoch : 21, Loss : 0.910093, Accuracy: 0.946000, Test accuracy: 0.947000
Distillation: Epoch : 22, Loss : 0.922546, Accuracy: 0.933000, Test accuracy: 0.948500
Distillation: Epoch : 23, Loss : 0.868074, Accuracy: 0.958000, Test accuracy: 0.950000
Distillation: Epoch : 24, Loss : 0.896443, Accuracy: 0.949000, Test accuracy: 0.951800
Distillation: Epoch : 25, Loss : 0.915928, Accuracy: 0.947000, Test accuracy: 0.952600
Distillation: Epoch : 26, Loss : 0.891086, Accuracy: 0.962000, Test accuracy: 0.953800
Distillation: Epoch : 27, Loss : 0.883137, Accuracy: 0.963000, Test accuracy: 0.955700
Distillation: Epoch : 28, Loss : 0.908021, Accuracy: 0.950000, Test accuracy: 0.956500
Distillation: Epoch : 29, Loss : 0.926872, Accuracy: 0.938000, Test accuracy: 0.956400
Distillation: Epoch : 30, Loss : 0.898724, Accuracy: 0.948000, Test accuracy: 0.957200
Distillation: Epoch : 31, Loss : 0.907843, Accuracy: 0.946000, Test accuracy: 0.957900
Distillation: Epoch : 32, Loss : 0.902242, Accuracy: 0.943000, Test accuracy: 0.958200
Distillation: Epoch : 33, Loss : 0.870537, Accuracy: 0.954000, Test accuracy: 0.958100
Distillation: Epoch : 34, Loss : 0.885588, Accuracy: 0.950000, Test accuracy: 0.958300
Distillation: Epoch : 35, Loss : 0.882005, Accuracy: 0.958000, Test accuracy: 0.958900
Distillation: Epoch : 36, Loss : 0.893084, Accuracy: 0.950000, Test accuracy: 0.959200
Distillation: Epoch : 37, Loss : 0.886508, Accuracy: 0.960000, Test accuracy: 0.959500
Distillation: Epoch : 38, Loss : 0.859227, Accuracy: 0.953000, Test accuracy: 0.959300
Distillation: Epoch : 39, Loss : 0.881894, Accuracy: 0.955000, Test accuracy: 0.959500
Distillation: Epoch : 40, Loss : 0.868348, Accuracy: 0.955000, Test accuracy: 0.960100
Distillation: Epoch : 41, Loss : 0.904863, Accuracy: 0.943000, Test accuracy: 0.960100
Distillation: Epoch : 42, Loss : 0.881733, Accuracy: 0.959000, Test accuracy: 0.961000
Distillation: Epoch : 43, Loss : 0.856056, Accuracy: 0.969000, Test accuracy: 0.960900
Distillation: Epoch : 44, Loss : 0.884206, Accuracy: 0.952000, Test accuracy: 0.960600
Distillation: Epoch : 45, Loss : 0.899361, Accuracy: 0.963000, Test accuracy: 0.961000
Distillation: Epoch : 46, Loss : 0.905547, Accuracy: 0.936000, Test accuracy: 0.960600
Distillation: Epoch : 47, Loss : 0.870347, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 48, Loss : 0.899720, Accuracy: 0.948000, Test accuracy: 0.962000
Distillation: Epoch : 49, Loss : 0.881495, Accuracy: 0.957000, Test accuracy: 0.961600
Distillation: Epoch : 50, Loss : 0.906642, Accuracy: 0.960000, Test accuracy: 0.961200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9612
Generating confusion matrix for student5
[[ 964.    0.    2.    0.    1.    1.    6.    3.    6.    4.]
 [   0. 1119.    9.    1.    3.    1.    3.   10.    6.    8.]
 [   1.    5.  981.    6.    4.    0.    1.   13.    6.    1.]
 [   0.    2.    8.  979.    0.   20.    0.    6.    8.    9.]
 [   1.    0.    8.    1.  960.    0.    6.    6.   10.   23.]
 [   1.    0.    0.   10.    0.  854.   10.    0.    5.    8.]
 [   9.    2.    2.    0.    3.    7.  930.    0.   10.    0.]
 [   1.    1.   10.    4.    2.    2.    0.  980.    8.   14.]
 [   2.    6.   11.    7.    3.    3.    2.    1.  905.    2.]
 [   1.    0.    1.    2.    6.    4.    0.    9.   10.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.009604, Accuracy: 0.592000, Test accuracy: 0.604900
Distillation: Epoch : 2, Loss : 1.319027, Accuracy: 0.833000, Test accuracy: 0.836900
Distillation: Epoch : 3, Loss : 1.288619, Accuracy: 0.846000, Test accuracy: 0.870200
Distillation: Epoch : 4, Loss : 1.226975, Accuracy: 0.879000, Test accuracy: 0.879900
Distillation: Epoch : 5, Loss : 1.228953, Accuracy: 0.879000, Test accuracy: 0.886400
Distillation: Epoch : 6, Loss : 1.214884, Accuracy: 0.869000, Test accuracy: 0.891200
Distillation: Epoch : 7, Loss : 1.190065, Accuracy: 0.897000, Test accuracy: 0.893400
Distillation: Epoch : 8, Loss : 1.208777, Accuracy: 0.898000, Test accuracy: 0.895500
Distillation: Epoch : 9, Loss : 1.196921, Accuracy: 0.896000, Test accuracy: 0.899700
Distillation: Epoch : 10, Loss : 1.205644, Accuracy: 0.889000, Test accuracy: 0.899900
Distillation: Epoch : 11, Loss : 1.202315, Accuracy: 0.898000, Test accuracy: 0.902900
Distillation: Epoch : 12, Loss : 1.168905, Accuracy: 0.899000, Test accuracy: 0.904600
Distillation: Epoch : 13, Loss : 1.171865, Accuracy: 0.897000, Test accuracy: 0.905700
Distillation: Epoch : 14, Loss : 1.150197, Accuracy: 0.904000, Test accuracy: 0.909200
Distillation: Epoch : 15, Loss : 1.173589, Accuracy: 0.901000, Test accuracy: 0.911700
Distillation: Epoch : 16, Loss : 1.152931, Accuracy: 0.911000, Test accuracy: 0.913600
Distillation: Epoch : 17, Loss : 1.181596, Accuracy: 0.889000, Test accuracy: 0.913900
Distillation: Epoch : 18, Loss : 1.177248, Accuracy: 0.919000, Test accuracy: 0.916900
Distillation: Epoch : 19, Loss : 1.138828, Accuracy: 0.910000, Test accuracy: 0.917400
Distillation: Epoch : 20, Loss : 1.182999, Accuracy: 0.907000, Test accuracy: 0.919200
Distillation: Epoch : 21, Loss : 1.072623, Accuracy: 0.936000, Test accuracy: 0.920100
Distillation: Epoch : 22, Loss : 1.124147, Accuracy: 0.916000, Test accuracy: 0.923800
Distillation: Epoch : 23, Loss : 1.112635, Accuracy: 0.930000, Test accuracy: 0.926700
Distillation: Epoch : 24, Loss : 1.124444, Accuracy: 0.935000, Test accuracy: 0.927100
Distillation: Epoch : 25, Loss : 1.080332, Accuracy: 0.939000, Test accuracy: 0.930800
Distillation: Epoch : 26, Loss : 1.089365, Accuracy: 0.950000, Test accuracy: 0.933700
Distillation: Epoch : 27, Loss : 1.131517, Accuracy: 0.925000, Test accuracy: 0.935600
Distillation: Epoch : 28, Loss : 1.131588, Accuracy: 0.915000, Test accuracy: 0.937300
Distillation: Epoch : 29, Loss : 1.089153, Accuracy: 0.938000, Test accuracy: 0.938100
Distillation: Epoch : 30, Loss : 1.085931, Accuracy: 0.930000, Test accuracy: 0.939200
Distillation: Epoch : 31, Loss : 1.087730, Accuracy: 0.938000, Test accuracy: 0.942200
Distillation: Epoch : 32, Loss : 1.091324, Accuracy: 0.943000, Test accuracy: 0.944000
Distillation: Epoch : 33, Loss : 1.092238, Accuracy: 0.938000, Test accuracy: 0.945500
Distillation: Epoch : 34, Loss : 1.103022, Accuracy: 0.938000, Test accuracy: 0.945900
Distillation: Epoch : 35, Loss : 1.072109, Accuracy: 0.952000, Test accuracy: 0.947100
Distillation: Epoch : 36, Loss : 1.077385, Accuracy: 0.948000, Test accuracy: 0.948100
Distillation: Epoch : 37, Loss : 1.093808, Accuracy: 0.936000, Test accuracy: 0.948200
Distillation: Epoch : 38, Loss : 1.091134, Accuracy: 0.931000, Test accuracy: 0.949100
Distillation: Epoch : 39, Loss : 1.095228, Accuracy: 0.946000, Test accuracy: 0.950000
Distillation: Epoch : 40, Loss : 1.073059, Accuracy: 0.936000, Test accuracy: 0.950300
Distillation: Epoch : 41, Loss : 1.097640, Accuracy: 0.949000, Test accuracy: 0.950800
Distillation: Epoch : 42, Loss : 1.071955, Accuracy: 0.945000, Test accuracy: 0.951000
Distillation: Epoch : 43, Loss : 1.070576, Accuracy: 0.950000, Test accuracy: 0.951900
Distillation: Epoch : 44, Loss : 1.058321, Accuracy: 0.953000, Test accuracy: 0.952100
Distillation: Epoch : 45, Loss : 1.070946, Accuracy: 0.951000, Test accuracy: 0.952300
Distillation: Epoch : 46, Loss : 1.076359, Accuracy: 0.960000, Test accuracy: 0.953200
Distillation: Epoch : 47, Loss : 1.061648, Accuracy: 0.950000, Test accuracy: 0.953500
Distillation: Epoch : 48, Loss : 1.060273, Accuracy: 0.953000, Test accuracy: 0.954000
Distillation: Epoch : 49, Loss : 1.047318, Accuracy: 0.956000, Test accuracy: 0.953300
Distillation: Epoch : 50, Loss : 1.068998, Accuracy: 0.946000, Test accuracy: 0.954600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9546
Generating confusion matrix for student5
[[ 965.    0.    3.    0.    1.    1.    5.    3.    7.    4.]
 [   0. 1108.   11.    0.    1.    0.    3.   11.    8.    7.]
 [   2.    4.  974.    3.    3.    1.    2.   14.    3.    1.]
 [   0.    4.   11.  981.    1.   24.    0.    7.   11.   18.]
 [   0.    0.   11.    2.  948.    2.    6.    7.   11.   26.]
 [   1.    0.    0.    9.    0.  852.    8.    1.    8.    7.]
 [   7.    1.    3.    0.    4.    5.  931.    0.   11.    1.]
 [   1.    2.   10.    5.    1.    2.    1.  960.    9.   12.]
 [   3.   16.    8.    8.    5.    1.    2.    1.  898.    4.]
 [   1.    0.    1.    2.   18.    4.    0.   24.    8.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.103602, Accuracy: 0.518000, Test accuracy: 0.517600
Distillation: Epoch : 2, Loss : 1.508608, Accuracy: 0.830000, Test accuracy: 0.813100
Distillation: Epoch : 3, Loss : 1.447648, Accuracy: 0.856000, Test accuracy: 0.853700
Distillation: Epoch : 4, Loss : 1.418411, Accuracy: 0.853000, Test accuracy: 0.869500
Distillation: Epoch : 5, Loss : 1.379350, Accuracy: 0.861000, Test accuracy: 0.880100
Distillation: Epoch : 6, Loss : 1.356140, Accuracy: 0.882000, Test accuracy: 0.885300
Distillation: Epoch : 7, Loss : 1.346014, Accuracy: 0.886000, Test accuracy: 0.889900
Distillation: Epoch : 8, Loss : 1.356096, Accuracy: 0.883000, Test accuracy: 0.893100
Distillation: Epoch : 9, Loss : 1.338776, Accuracy: 0.889000, Test accuracy: 0.895200
Distillation: Epoch : 10, Loss : 1.351074, Accuracy: 0.890000, Test accuracy: 0.898300
Distillation: Epoch : 11, Loss : 1.340613, Accuracy: 0.894000, Test accuracy: 0.899400
Distillation: Epoch : 12, Loss : 1.313100, Accuracy: 0.905000, Test accuracy: 0.900900
Distillation: Epoch : 13, Loss : 1.350109, Accuracy: 0.899000, Test accuracy: 0.901500
Distillation: Epoch : 14, Loss : 1.326326, Accuracy: 0.896000, Test accuracy: 0.903600
Distillation: Epoch : 15, Loss : 1.371007, Accuracy: 0.888000, Test accuracy: 0.905500
Distillation: Epoch : 16, Loss : 1.294082, Accuracy: 0.924000, Test accuracy: 0.908500
Distillation: Epoch : 17, Loss : 1.280607, Accuracy: 0.912000, Test accuracy: 0.911400
Distillation: Epoch : 18, Loss : 1.252997, Accuracy: 0.927000, Test accuracy: 0.915900
Distillation: Epoch : 19, Loss : 1.279951, Accuracy: 0.916000, Test accuracy: 0.917600
Distillation: Epoch : 20, Loss : 1.296196, Accuracy: 0.901000, Test accuracy: 0.917300
Distillation: Epoch : 21, Loss : 1.293728, Accuracy: 0.920000, Test accuracy: 0.920700
Distillation: Epoch : 22, Loss : 1.251711, Accuracy: 0.933000, Test accuracy: 0.923700
Distillation: Epoch : 23, Loss : 1.284548, Accuracy: 0.915000, Test accuracy: 0.927300
Distillation: Epoch : 24, Loss : 1.287623, Accuracy: 0.923000, Test accuracy: 0.928900
Distillation: Epoch : 25, Loss : 1.251684, Accuracy: 0.932000, Test accuracy: 0.931100
Distillation: Epoch : 26, Loss : 1.231869, Accuracy: 0.937000, Test accuracy: 0.933900
Distillation: Epoch : 27, Loss : 1.262647, Accuracy: 0.942000, Test accuracy: 0.934400
Distillation: Epoch : 28, Loss : 1.280187, Accuracy: 0.910000, Test accuracy: 0.935700
Distillation: Epoch : 29, Loss : 1.254083, Accuracy: 0.945000, Test accuracy: 0.936900
Distillation: Epoch : 30, Loss : 1.254798, Accuracy: 0.947000, Test accuracy: 0.939400
Distillation: Epoch : 31, Loss : 1.248261, Accuracy: 0.941000, Test accuracy: 0.941000
Distillation: Epoch : 32, Loss : 1.241192, Accuracy: 0.945000, Test accuracy: 0.941700
Distillation: Epoch : 33, Loss : 1.256668, Accuracy: 0.945000, Test accuracy: 0.944000
Distillation: Epoch : 34, Loss : 1.234874, Accuracy: 0.944000, Test accuracy: 0.945200
Distillation: Epoch : 35, Loss : 1.219078, Accuracy: 0.948000, Test accuracy: 0.945600
Distillation: Epoch : 36, Loss : 1.231909, Accuracy: 0.949000, Test accuracy: 0.945600
Distillation: Epoch : 37, Loss : 1.233043, Accuracy: 0.937000, Test accuracy: 0.948100
Distillation: Epoch : 38, Loss : 1.219972, Accuracy: 0.949000, Test accuracy: 0.948300
Distillation: Epoch : 39, Loss : 1.214082, Accuracy: 0.945000, Test accuracy: 0.947600
Distillation: Epoch : 40, Loss : 1.226171, Accuracy: 0.949000, Test accuracy: 0.949800
Distillation: Epoch : 41, Loss : 1.243864, Accuracy: 0.944000, Test accuracy: 0.949500
Distillation: Epoch : 42, Loss : 1.218182, Accuracy: 0.951000, Test accuracy: 0.950400
Distillation: Epoch : 43, Loss : 1.218323, Accuracy: 0.960000, Test accuracy: 0.951300
Distillation: Epoch : 44, Loss : 1.190231, Accuracy: 0.945000, Test accuracy: 0.951000
Distillation: Epoch : 45, Loss : 1.208993, Accuracy: 0.950000, Test accuracy: 0.951800
Distillation: Epoch : 46, Loss : 1.213474, Accuracy: 0.945000, Test accuracy: 0.952900
Distillation: Epoch : 47, Loss : 1.228491, Accuracy: 0.939000, Test accuracy: 0.951200
Distillation: Epoch : 48, Loss : 1.236116, Accuracy: 0.950000, Test accuracy: 0.953800
Distillation: Epoch : 49, Loss : 1.202731, Accuracy: 0.957000, Test accuracy: 0.954600
Distillation: Epoch : 50, Loss : 1.228784, Accuracy: 0.948000, Test accuracy: 0.953100
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9531
Generating confusion matrix for student5
[[ 963.    0.    3.    0.    1.    1.    8.    3.    6.    5.]
 [   0. 1113.   10.    0.    2.    0.    3.    9.   11.    6.]
 [   1.    2.  962.    5.    1.    1.    1.   17.    6.    1.]
 [   0.    3.   12.  980.    1.   21.    1.    5.   11.   11.]
 [   1.    0.   11.    0.  948.    0.    4.    9.   14.   30.]
 [   1.    0.    0.    5.    0.  851.   11.    0.    7.   10.]
 [   9.    5.    3.    0.    4.    8.  927.    0.    7.    1.]
 [   1.    1.   10.    8.    1.    3.    0.  962.   10.   10.]
 [   4.   11.   20.    9.    5.    4.    3.    2.  894.    4.]
 [   0.    0.    1.    3.   19.    3.    0.   21.    8.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.096283, Accuracy: 0.567000, Test accuracy: 0.574000
Distillation: Epoch : 2, Loss : 1.609429, Accuracy: 0.831000, Test accuracy: 0.832300
Distillation: Epoch : 3, Loss : 1.510508, Accuracy: 0.861000, Test accuracy: 0.863400
Distillation: Epoch : 4, Loss : 1.506274, Accuracy: 0.854000, Test accuracy: 0.877400
Distillation: Epoch : 5, Loss : 1.466328, Accuracy: 0.895000, Test accuracy: 0.883600
Distillation: Epoch : 6, Loss : 1.479161, Accuracy: 0.894000, Test accuracy: 0.890000
Distillation: Epoch : 7, Loss : 1.471109, Accuracy: 0.887000, Test accuracy: 0.893600
Distillation: Epoch : 8, Loss : 1.450287, Accuracy: 0.904000, Test accuracy: 0.898300
Distillation: Epoch : 9, Loss : 1.456951, Accuracy: 0.888000, Test accuracy: 0.901100
Distillation: Epoch : 10, Loss : 1.437329, Accuracy: 0.898000, Test accuracy: 0.905600
Distillation: Epoch : 11, Loss : 1.429122, Accuracy: 0.910000, Test accuracy: 0.908800
Distillation: Epoch : 12, Loss : 1.447480, Accuracy: 0.896000, Test accuracy: 0.911800
Distillation: Epoch : 13, Loss : 1.428227, Accuracy: 0.903000, Test accuracy: 0.916100
Distillation: Epoch : 14, Loss : 1.414237, Accuracy: 0.905000, Test accuracy: 0.918600
Distillation: Epoch : 15, Loss : 1.441970, Accuracy: 0.904000, Test accuracy: 0.921300
Distillation: Epoch : 16, Loss : 1.406978, Accuracy: 0.924000, Test accuracy: 0.925400
Distillation: Epoch : 17, Loss : 1.432942, Accuracy: 0.918000, Test accuracy: 0.927800
Distillation: Epoch : 18, Loss : 1.377065, Accuracy: 0.943000, Test accuracy: 0.929500
Distillation: Epoch : 19, Loss : 1.419230, Accuracy: 0.928000, Test accuracy: 0.930900
Distillation: Epoch : 20, Loss : 1.375109, Accuracy: 0.938000, Test accuracy: 0.933800
Distillation: Epoch : 21, Loss : 1.411473, Accuracy: 0.929000, Test accuracy: 0.935500
Distillation: Epoch : 22, Loss : 1.391988, Accuracy: 0.931000, Test accuracy: 0.936600
Distillation: Epoch : 23, Loss : 1.388923, Accuracy: 0.935000, Test accuracy: 0.938600
Distillation: Epoch : 24, Loss : 1.363552, Accuracy: 0.937000, Test accuracy: 0.939100
Distillation: Epoch : 25, Loss : 1.379171, Accuracy: 0.930000, Test accuracy: 0.941200
Distillation: Epoch : 26, Loss : 1.362912, Accuracy: 0.941000, Test accuracy: 0.941800
Distillation: Epoch : 27, Loss : 1.395230, Accuracy: 0.946000, Test accuracy: 0.943300
Distillation: Epoch : 28, Loss : 1.358541, Accuracy: 0.946000, Test accuracy: 0.944200
Distillation: Epoch : 29, Loss : 1.383328, Accuracy: 0.942000, Test accuracy: 0.945400
Distillation: Epoch : 30, Loss : 1.362712, Accuracy: 0.942000, Test accuracy: 0.947400
Distillation: Epoch : 31, Loss : 1.356895, Accuracy: 0.944000, Test accuracy: 0.947900
Distillation: Epoch : 32, Loss : 1.391325, Accuracy: 0.944000, Test accuracy: 0.949100
Distillation: Epoch : 33, Loss : 1.385305, Accuracy: 0.949000, Test accuracy: 0.949000
Distillation: Epoch : 34, Loss : 1.372298, Accuracy: 0.956000, Test accuracy: 0.949600
Distillation: Epoch : 35, Loss : 1.364785, Accuracy: 0.946000, Test accuracy: 0.950900
Distillation: Epoch : 36, Loss : 1.372573, Accuracy: 0.956000, Test accuracy: 0.951700
Distillation: Epoch : 37, Loss : 1.347257, Accuracy: 0.960000, Test accuracy: 0.951500
Distillation: Epoch : 38, Loss : 1.358389, Accuracy: 0.945000, Test accuracy: 0.951700
Distillation: Epoch : 39, Loss : 1.362907, Accuracy: 0.942000, Test accuracy: 0.952300
Distillation: Epoch : 40, Loss : 1.348148, Accuracy: 0.945000, Test accuracy: 0.952800
Distillation: Epoch : 41, Loss : 1.344028, Accuracy: 0.950000, Test accuracy: 0.953000
Distillation: Epoch : 42, Loss : 1.397591, Accuracy: 0.943000, Test accuracy: 0.952700
Distillation: Epoch : 43, Loss : 1.363125, Accuracy: 0.956000, Test accuracy: 0.953500
Distillation: Epoch : 44, Loss : 1.346682, Accuracy: 0.951000, Test accuracy: 0.954100
Distillation: Epoch : 45, Loss : 1.364172, Accuracy: 0.967000, Test accuracy: 0.953600
Distillation: Epoch : 46, Loss : 1.386085, Accuracy: 0.947000, Test accuracy: 0.954900
Distillation: Epoch : 47, Loss : 1.364248, Accuracy: 0.950000, Test accuracy: 0.953300
Distillation: Epoch : 48, Loss : 1.361220, Accuracy: 0.954000, Test accuracy: 0.956100
Distillation: Epoch : 49, Loss : 1.356024, Accuracy: 0.957000, Test accuracy: 0.955100
Distillation: Epoch : 50, Loss : 1.351089, Accuracy: 0.953000, Test accuracy: 0.955200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9552
Generating confusion matrix for student5
[[ 964.    0.    4.    0.    1.    1.    5.    2.    7.    5.]
 [   0. 1108.   16.    0.    3.    1.    3.   11.    9.    6.]
 [   1.    3.  963.    2.    1.    0.    0.   11.    7.    1.]
 [   0.    6.    8.  984.    0.   14.    0.    5.    7.   14.]
 [   1.    0.   11.    0.  959.    0.    8.   10.   21.   26.]
 [   1.    0.    0.    8.    0.  863.   12.    0.    8.   11.]
 [   9.    1.    2.    0.    4.    5.  928.    0.    9.    0.]
 [   1.    2.   11.    6.    1.    2.    0.  970.   12.   16.]
 [   3.   15.   16.    8.    3.    3.    2.    3.  883.    0.]
 [   0.    0.    1.    2.   10.    3.    0.   16.   11.  930.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.283303, Accuracy: 0.100000, Test accuracy: 0.101000
Distillation: Epoch : 2, Loss : 2.230358, Accuracy: 0.180000, Test accuracy: 0.188300
Distillation: Epoch : 3, Loss : 2.069296, Accuracy: 0.718000, Test accuracy: 0.687800
Distillation: Epoch : 4, Loss : 1.825498, Accuracy: 0.787000, Test accuracy: 0.798800
Distillation: Epoch : 5, Loss : 1.686666, Accuracy: 0.830000, Test accuracy: 0.839300
Distillation: Epoch : 6, Loss : 1.627766, Accuracy: 0.838000, Test accuracy: 0.862900
Distillation: Epoch : 7, Loss : 1.588878, Accuracy: 0.883000, Test accuracy: 0.875100
Distillation: Epoch : 8, Loss : 1.609953, Accuracy: 0.877000, Test accuracy: 0.883700
Distillation: Epoch : 9, Loss : 1.568781, Accuracy: 0.892000, Test accuracy: 0.890100
Distillation: Epoch : 10, Loss : 1.579039, Accuracy: 0.899000, Test accuracy: 0.894600
Distillation: Epoch : 11, Loss : 1.569135, Accuracy: 0.910000, Test accuracy: 0.898100
Distillation: Epoch : 12, Loss : 1.569358, Accuracy: 0.891000, Test accuracy: 0.902000
Distillation: Epoch : 13, Loss : 1.549480, Accuracy: 0.880000, Test accuracy: 0.904600
Distillation: Epoch : 14, Loss : 1.559502, Accuracy: 0.907000, Test accuracy: 0.906800
Distillation: Epoch : 15, Loss : 1.542519, Accuracy: 0.901000, Test accuracy: 0.909400
Distillation: Epoch : 16, Loss : 1.564108, Accuracy: 0.888000, Test accuracy: 0.912800
Distillation: Epoch : 17, Loss : 1.569189, Accuracy: 0.895000, Test accuracy: 0.916700
Distillation: Epoch : 18, Loss : 1.522120, Accuracy: 0.921000, Test accuracy: 0.917700
Distillation: Epoch : 19, Loss : 1.527062, Accuracy: 0.900000, Test accuracy: 0.919700
Distillation: Epoch : 20, Loss : 1.530382, Accuracy: 0.917000, Test accuracy: 0.921400
Distillation: Epoch : 21, Loss : 1.541966, Accuracy: 0.913000, Test accuracy: 0.923300
Distillation: Epoch : 22, Loss : 1.541829, Accuracy: 0.911000, Test accuracy: 0.924800
Distillation: Epoch : 23, Loss : 1.527367, Accuracy: 0.928000, Test accuracy: 0.926900
Distillation: Epoch : 24, Loss : 1.525376, Accuracy: 0.924000, Test accuracy: 0.930600
Distillation: Epoch : 25, Loss : 1.500340, Accuracy: 0.935000, Test accuracy: 0.932100
Distillation: Epoch : 26, Loss : 1.513023, Accuracy: 0.931000, Test accuracy: 0.934500
Distillation: Epoch : 27, Loss : 1.507551, Accuracy: 0.933000, Test accuracy: 0.937800
Distillation: Epoch : 28, Loss : 1.512616, Accuracy: 0.940000, Test accuracy: 0.940900
Distillation: Epoch : 29, Loss : 1.498353, Accuracy: 0.940000, Test accuracy: 0.942000
Distillation: Epoch : 30, Loss : 1.500572, Accuracy: 0.933000, Test accuracy: 0.944400
Distillation: Epoch : 31, Loss : 1.492269, Accuracy: 0.937000, Test accuracy: 0.945700
Distillation: Epoch : 32, Loss : 1.483601, Accuracy: 0.937000, Test accuracy: 0.946700
Distillation: Epoch : 33, Loss : 1.509101, Accuracy: 0.940000, Test accuracy: 0.948900
Distillation: Epoch : 34, Loss : 1.488756, Accuracy: 0.954000, Test accuracy: 0.949300
Distillation: Epoch : 35, Loss : 1.516650, Accuracy: 0.930000, Test accuracy: 0.950300
Distillation: Epoch : 36, Loss : 1.495692, Accuracy: 0.951000, Test accuracy: 0.951300
Distillation: Epoch : 37, Loss : 1.474929, Accuracy: 0.955000, Test accuracy: 0.952300
Distillation: Epoch : 38, Loss : 1.462709, Accuracy: 0.941000, Test accuracy: 0.952600
Distillation: Epoch : 39, Loss : 1.481274, Accuracy: 0.940000, Test accuracy: 0.953600
Distillation: Epoch : 40, Loss : 1.485575, Accuracy: 0.954000, Test accuracy: 0.954100
Distillation: Epoch : 41, Loss : 1.465222, Accuracy: 0.952000, Test accuracy: 0.954200
Distillation: Epoch : 42, Loss : 1.469076, Accuracy: 0.954000, Test accuracy: 0.955500
Distillation: Epoch : 43, Loss : 1.484127, Accuracy: 0.951000, Test accuracy: 0.956000
Distillation: Epoch : 44, Loss : 1.481541, Accuracy: 0.969000, Test accuracy: 0.956400
Distillation: Epoch : 45, Loss : 1.458735, Accuracy: 0.962000, Test accuracy: 0.957100
Distillation: Epoch : 46, Loss : 1.481545, Accuracy: 0.960000, Test accuracy: 0.957000
Distillation: Epoch : 47, Loss : 1.466086, Accuracy: 0.953000, Test accuracy: 0.957200
Distillation: Epoch : 48, Loss : 1.471462, Accuracy: 0.960000, Test accuracy: 0.957700
Distillation: Epoch : 49, Loss : 1.494760, Accuracy: 0.945000, Test accuracy: 0.958200
Distillation: Epoch : 50, Loss : 1.499539, Accuracy: 0.957000, Test accuracy: 0.958200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9582
Generating confusion matrix for student5
[[ 963.    0.    3.    0.    1.    0.    6.    1.    9.    4.]
 [   0. 1124.   11.    0.    0.    0.    4.   10.    1.    6.]
 [   0.    3.  945.    6.    3.    1.    1.   15.    7.    2.]
 [   0.    1.   17.  980.    0.   13.    0.    7.   16.   14.]
 [   5.    0.   10.    2.  963.    0.    7.   13.    6.   15.]
 [   0.    0.    0.    4.    0.  864.    7.    1.    4.    3.]
 [   9.    5.    6.    0.    3.    5.  931.    0.    2.    0.]
 [   2.    0.   12.    9.    1.    2.    0.  951.   10.   13.]
 [   1.    2.   27.    6.    2.    6.    2.    6.  912.    3.]
 [   0.    0.    1.    3.    9.    1.    0.   24.    7.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.205840, Accuracy: 0.403000, Test accuracy: 0.395900
Distillation: Epoch : 2, Loss : 1.894617, Accuracy: 0.837000, Test accuracy: 0.827200
Distillation: Epoch : 3, Loss : 1.874233, Accuracy: 0.818000, Test accuracy: 0.857400
Distillation: Epoch : 4, Loss : 1.849093, Accuracy: 0.852000, Test accuracy: 0.866600
Distillation: Epoch : 5, Loss : 1.842412, Accuracy: 0.872000, Test accuracy: 0.875200
Distillation: Epoch : 6, Loss : 1.852001, Accuracy: 0.853000, Test accuracy: 0.879500
Distillation: Epoch : 7, Loss : 1.848282, Accuracy: 0.875000, Test accuracy: 0.884100
Distillation: Epoch : 8, Loss : 1.846554, Accuracy: 0.884000, Test accuracy: 0.887000
Distillation: Epoch : 9, Loss : 1.850435, Accuracy: 0.867000, Test accuracy: 0.889100
Distillation: Epoch : 10, Loss : 1.835827, Accuracy: 0.880000, Test accuracy: 0.888100
Distillation: Epoch : 11, Loss : 1.822148, Accuracy: 0.893000, Test accuracy: 0.890500
Distillation: Epoch : 12, Loss : 1.840551, Accuracy: 0.893000, Test accuracy: 0.894000
Distillation: Epoch : 13, Loss : 1.843844, Accuracy: 0.888000, Test accuracy: 0.891000
Distillation: Epoch : 14, Loss : 1.842618, Accuracy: 0.868000, Test accuracy: 0.892700
Distillation: Epoch : 15, Loss : 1.830906, Accuracy: 0.880000, Test accuracy: 0.894900
Distillation: Epoch : 16, Loss : 1.826483, Accuracy: 0.892000, Test accuracy: 0.896700
Distillation: Epoch : 17, Loss : 1.846898, Accuracy: 0.879000, Test accuracy: 0.898200
Distillation: Epoch : 18, Loss : 1.811906, Accuracy: 0.896000, Test accuracy: 0.897900
Distillation: Epoch : 19, Loss : 1.816171, Accuracy: 0.888000, Test accuracy: 0.900100
Distillation: Epoch : 20, Loss : 1.814019, Accuracy: 0.897000, Test accuracy: 0.902300
Distillation: Epoch : 21, Loss : 1.804876, Accuracy: 0.894000, Test accuracy: 0.904700
Distillation: Epoch : 22, Loss : 1.809287, Accuracy: 0.895000, Test accuracy: 0.907900
Distillation: Epoch : 23, Loss : 1.816941, Accuracy: 0.899000, Test accuracy: 0.908400
Distillation: Epoch : 24, Loss : 1.809417, Accuracy: 0.898000, Test accuracy: 0.911500
Distillation: Epoch : 25, Loss : 1.797672, Accuracy: 0.917000, Test accuracy: 0.914600
Distillation: Epoch : 26, Loss : 1.797844, Accuracy: 0.923000, Test accuracy: 0.918200
Distillation: Epoch : 27, Loss : 1.804203, Accuracy: 0.907000, Test accuracy: 0.918900
Distillation: Epoch : 28, Loss : 1.794608, Accuracy: 0.916000, Test accuracy: 0.919800
Distillation: Epoch : 29, Loss : 1.819786, Accuracy: 0.907000, Test accuracy: 0.922900
Distillation: Epoch : 30, Loss : 1.814365, Accuracy: 0.906000, Test accuracy: 0.927000
Distillation: Epoch : 31, Loss : 1.786634, Accuracy: 0.929000, Test accuracy: 0.928300
Distillation: Epoch : 32, Loss : 1.780348, Accuracy: 0.941000, Test accuracy: 0.932900
Distillation: Epoch : 33, Loss : 1.790607, Accuracy: 0.944000, Test accuracy: 0.935300
Distillation: Epoch : 34, Loss : 1.797397, Accuracy: 0.937000, Test accuracy: 0.936500
Distillation: Epoch : 35, Loss : 1.789090, Accuracy: 0.927000, Test accuracy: 0.939600
Distillation: Epoch : 36, Loss : 1.788576, Accuracy: 0.928000, Test accuracy: 0.939600
Distillation: Epoch : 37, Loss : 1.778493, Accuracy: 0.930000, Test accuracy: 0.941600
Distillation: Epoch : 38, Loss : 1.781000, Accuracy: 0.942000, Test accuracy: 0.943300
Distillation: Epoch : 39, Loss : 1.755574, Accuracy: 0.949000, Test accuracy: 0.946100
Distillation: Epoch : 40, Loss : 1.782380, Accuracy: 0.934000, Test accuracy: 0.945800
Distillation: Epoch : 41, Loss : 1.778301, Accuracy: 0.934000, Test accuracy: 0.947500
Distillation: Epoch : 42, Loss : 1.767926, Accuracy: 0.946000, Test accuracy: 0.948400
Distillation: Epoch : 43, Loss : 1.765896, Accuracy: 0.952000, Test accuracy: 0.949600
Distillation: Epoch : 44, Loss : 1.765866, Accuracy: 0.942000, Test accuracy: 0.950300
Distillation: Epoch : 45, Loss : 1.767537, Accuracy: 0.935000, Test accuracy: 0.951500
Distillation: Epoch : 46, Loss : 1.753145, Accuracy: 0.957000, Test accuracy: 0.953200
Distillation: Epoch : 47, Loss : 1.754804, Accuracy: 0.943000, Test accuracy: 0.953100
Distillation: Epoch : 48, Loss : 1.771409, Accuracy: 0.953000, Test accuracy: 0.953300
Distillation: Epoch : 49, Loss : 1.761813, Accuracy: 0.955000, Test accuracy: 0.953600
Distillation: Epoch : 50, Loss : 1.756844, Accuracy: 0.950000, Test accuracy: 0.953600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9536
Generating confusion matrix for student5
[[ 961.    0.    4.    0.    1.    0.    8.    2.    6.    6.]
 [   0. 1111.    9.    0.    1.    0.    3.    8.    6.    7.]
 [   2.    4.  945.    3.    2.    0.    1.    9.    7.    1.]
 [   0.    1.   14.  988.    0.   25.    0.    7.    9.   12.]
 [   1.    0.   12.    0.  961.    0.    6.    9.   20.   27.]
 [   1.    0.    0.    6.    0.  849.   11.    0.   11.   12.]
 [  10.    3.    5.    0.    4.    7.  925.    0.    7.    1.]
 [   1.    1.   13.    7.    0.    2.    0.  973.   13.   10.]
 [   4.   15.   29.    3.    5.    7.    4.    3.  891.    1.]
 [   0.    0.    1.    3.    8.    2.    0.   17.    4.  932.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.236964, Accuracy: 0.525000, Test accuracy: 0.515700
Distillation: Epoch : 2, Loss : 2.090647, Accuracy: 0.830000, Test accuracy: 0.828200
Distillation: Epoch : 3, Loss : 2.072712, Accuracy: 0.833000, Test accuracy: 0.849200
Distillation: Epoch : 4, Loss : 2.047296, Accuracy: 0.874000, Test accuracy: 0.867900
Distillation: Epoch : 5, Loss : 2.051048, Accuracy: 0.876000, Test accuracy: 0.881200
Distillation: Epoch : 6, Loss : 2.057710, Accuracy: 0.880000, Test accuracy: 0.891000
Distillation: Epoch : 7, Loss : 2.051288, Accuracy: 0.883000, Test accuracy: 0.900600
Distillation: Epoch : 8, Loss : 2.038178, Accuracy: 0.892000, Test accuracy: 0.906200
Distillation: Epoch : 9, Loss : 2.037957, Accuracy: 0.909000, Test accuracy: 0.911500
Distillation: Epoch : 10, Loss : 2.038068, Accuracy: 0.903000, Test accuracy: 0.916100
Distillation: Epoch : 11, Loss : 2.033433, Accuracy: 0.927000, Test accuracy: 0.920300
Distillation: Epoch : 12, Loss : 2.035863, Accuracy: 0.912000, Test accuracy: 0.922200
Distillation: Epoch : 13, Loss : 2.034891, Accuracy: 0.926000, Test accuracy: 0.927300
Distillation: Epoch : 14, Loss : 2.024499, Accuracy: 0.936000, Test accuracy: 0.929400
Distillation: Epoch : 15, Loss : 2.033921, Accuracy: 0.937000, Test accuracy: 0.931800
Distillation: Epoch : 16, Loss : 2.026188, Accuracy: 0.923000, Test accuracy: 0.933900
Distillation: Epoch : 17, Loss : 2.031233, Accuracy: 0.932000, Test accuracy: 0.936900
Distillation: Epoch : 18, Loss : 2.023363, Accuracy: 0.935000, Test accuracy: 0.938000
Distillation: Epoch : 19, Loss : 2.020572, Accuracy: 0.931000, Test accuracy: 0.939600
Distillation: Epoch : 20, Loss : 2.023931, Accuracy: 0.943000, Test accuracy: 0.939600
Distillation: Epoch : 21, Loss : 2.013490, Accuracy: 0.946000, Test accuracy: 0.941800
Distillation: Epoch : 22, Loss : 2.019994, Accuracy: 0.932000, Test accuracy: 0.944300
Distillation: Epoch : 23, Loss : 2.013396, Accuracy: 0.942000, Test accuracy: 0.944200
Distillation: Epoch : 24, Loss : 2.014963, Accuracy: 0.926000, Test accuracy: 0.946900
Distillation: Epoch : 25, Loss : 2.024384, Accuracy: 0.939000, Test accuracy: 0.946900
Distillation: Epoch : 26, Loss : 2.021792, Accuracy: 0.945000, Test accuracy: 0.948100
Distillation: Epoch : 27, Loss : 2.015829, Accuracy: 0.941000, Test accuracy: 0.949000
Distillation: Epoch : 28, Loss : 2.021165, Accuracy: 0.945000, Test accuracy: 0.949000
Distillation: Epoch : 29, Loss : 2.013522, Accuracy: 0.938000, Test accuracy: 0.948600
Distillation: Epoch : 30, Loss : 2.002113, Accuracy: 0.937000, Test accuracy: 0.950100
Distillation: Epoch : 31, Loss : 2.017555, Accuracy: 0.936000, Test accuracy: 0.950200
Distillation: Epoch : 32, Loss : 2.007921, Accuracy: 0.947000, Test accuracy: 0.950900
Distillation: Epoch : 33, Loss : 2.009661, Accuracy: 0.954000, Test accuracy: 0.950300
Distillation: Epoch : 34, Loss : 2.022594, Accuracy: 0.939000, Test accuracy: 0.950500
Distillation: Epoch : 35, Loss : 2.019016, Accuracy: 0.947000, Test accuracy: 0.950500
Distillation: Epoch : 36, Loss : 2.008769, Accuracy: 0.950000, Test accuracy: 0.952100
Distillation: Epoch : 37, Loss : 2.017780, Accuracy: 0.945000, Test accuracy: 0.950800
Distillation: Epoch : 38, Loss : 2.013651, Accuracy: 0.947000, Test accuracy: 0.951300
Distillation: Epoch : 39, Loss : 2.020126, Accuracy: 0.950000, Test accuracy: 0.950600
Distillation: Epoch : 40, Loss : 2.005729, Accuracy: 0.943000, Test accuracy: 0.951800
Distillation: Epoch : 41, Loss : 2.015030, Accuracy: 0.935000, Test accuracy: 0.952300
Distillation: Epoch : 42, Loss : 2.007610, Accuracy: 0.956000, Test accuracy: 0.952300
Distillation: Epoch : 43, Loss : 2.008305, Accuracy: 0.954000, Test accuracy: 0.953000
Distillation: Epoch : 44, Loss : 2.016760, Accuracy: 0.932000, Test accuracy: 0.951400
Distillation: Epoch : 45, Loss : 2.011071, Accuracy: 0.958000, Test accuracy: 0.952600
Distillation: Epoch : 46, Loss : 2.011769, Accuracy: 0.956000, Test accuracy: 0.952400
Distillation: Epoch : 47, Loss : 2.010802, Accuracy: 0.953000, Test accuracy: 0.952800
Distillation: Epoch : 48, Loss : 2.007592, Accuracy: 0.954000, Test accuracy: 0.952300
Distillation: Epoch : 49, Loss : 2.012637, Accuracy: 0.946000, Test accuracy: 0.952300
Distillation: Epoch : 50, Loss : 2.005888, Accuracy: 0.948000, Test accuracy: 0.953000
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.953
Generating confusion matrix for student5
[[ 964.    0.    1.    0.    1.    1.    9.    2.    9.    7.]
 [   1. 1111.   16.    0.    3.    0.    3.    8.    8.    8.]
 [   1.    4.  963.    3.    2.    0.    1.   13.    5.    0.]
 [   0.    3.   12.  987.    0.   18.    0.    5.   14.   12.]
 [   2.    0.    9.    0.  956.    0.    7.   14.   14.   37.]
 [   0.    0.    0.    5.    0.  859.   10.    0.   12.   13.]
 [   9.    1.    1.    0.    3.    5.  925.    0.    7.    1.]
 [   1.    0.   13.    8.    0.    1.    0.  963.   12.   13.]
 [   2.   16.   16.    4.    4.    5.    3.    4.  885.    1.]
 [   0.    0.    1.    3.   13.    3.    0.   19.    8.  917.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.708976, Accuracy: 0.797000, Test accuracy: 0.800900
Distillation: Epoch : 2, Loss : 0.426380, Accuracy: 0.850000, Test accuracy: 0.873300
Distillation: Epoch : 3, Loss : 0.405600, Accuracy: 0.879000, Test accuracy: 0.895800
Distillation: Epoch : 4, Loss : 0.314655, Accuracy: 0.905000, Test accuracy: 0.909900
Distillation: Epoch : 5, Loss : 0.282142, Accuracy: 0.930000, Test accuracy: 0.918900
Distillation: Epoch : 6, Loss : 0.235956, Accuracy: 0.930000, Test accuracy: 0.928400
Distillation: Epoch : 7, Loss : 0.234184, Accuracy: 0.933000, Test accuracy: 0.936300
Distillation: Epoch : 8, Loss : 0.216562, Accuracy: 0.943000, Test accuracy: 0.942200
Distillation: Epoch : 9, Loss : 0.221962, Accuracy: 0.935000, Test accuracy: 0.948300
Distillation: Epoch : 10, Loss : 0.168093, Accuracy: 0.947000, Test accuracy: 0.951600
Distillation: Epoch : 11, Loss : 0.159663, Accuracy: 0.952000, Test accuracy: 0.953500
Distillation: Epoch : 12, Loss : 0.175523, Accuracy: 0.955000, Test accuracy: 0.957700
Distillation: Epoch : 13, Loss : 0.116184, Accuracy: 0.968000, Test accuracy: 0.960700
Distillation: Epoch : 14, Loss : 0.130912, Accuracy: 0.967000, Test accuracy: 0.962700
Distillation: Epoch : 15, Loss : 0.132112, Accuracy: 0.962000, Test accuracy: 0.963200
Distillation: Epoch : 16, Loss : 0.132467, Accuracy: 0.964000, Test accuracy: 0.966100
Distillation: Epoch : 17, Loss : 0.090170, Accuracy: 0.967000, Test accuracy: 0.967200
Distillation: Epoch : 18, Loss : 0.120233, Accuracy: 0.960000, Test accuracy: 0.967100
Distillation: Epoch : 19, Loss : 0.126982, Accuracy: 0.962000, Test accuracy: 0.970000
Distillation: Epoch : 20, Loss : 0.115708, Accuracy: 0.972000, Test accuracy: 0.970400
Distillation: Epoch : 21, Loss : 0.095306, Accuracy: 0.973000, Test accuracy: 0.972100
Distillation: Epoch : 22, Loss : 0.081551, Accuracy: 0.975000, Test accuracy: 0.972000
Distillation: Epoch : 23, Loss : 0.073652, Accuracy: 0.975000, Test accuracy: 0.973500
Distillation: Epoch : 24, Loss : 0.063951, Accuracy: 0.980000, Test accuracy: 0.974100
Distillation: Epoch : 25, Loss : 0.082695, Accuracy: 0.977000, Test accuracy: 0.974800
Distillation: Epoch : 26, Loss : 0.067397, Accuracy: 0.980000, Test accuracy: 0.974300
Distillation: Epoch : 27, Loss : 0.070500, Accuracy: 0.981000, Test accuracy: 0.975200
Distillation: Epoch : 28, Loss : 0.058883, Accuracy: 0.977000, Test accuracy: 0.975400
Distillation: Epoch : 29, Loss : 0.060737, Accuracy: 0.979000, Test accuracy: 0.975200
Distillation: Epoch : 30, Loss : 0.084654, Accuracy: 0.973000, Test accuracy: 0.977400
Distillation: Epoch : 31, Loss : 0.069405, Accuracy: 0.980000, Test accuracy: 0.976800
Distillation: Epoch : 32, Loss : 0.070924, Accuracy: 0.984000, Test accuracy: 0.977100
Distillation: Epoch : 33, Loss : 0.076879, Accuracy: 0.978000, Test accuracy: 0.977500
Distillation: Epoch : 34, Loss : 0.070708, Accuracy: 0.970000, Test accuracy: 0.977500
Distillation: Epoch : 35, Loss : 0.076119, Accuracy: 0.973000, Test accuracy: 0.979000
Distillation: Epoch : 36, Loss : 0.060785, Accuracy: 0.975000, Test accuracy: 0.979100
Distillation: Epoch : 37, Loss : 0.070663, Accuracy: 0.975000, Test accuracy: 0.979100
Distillation: Epoch : 38, Loss : 0.082511, Accuracy: 0.976000, Test accuracy: 0.979200
Distillation: Epoch : 39, Loss : 0.075593, Accuracy: 0.980000, Test accuracy: 0.979700
Distillation: Epoch : 40, Loss : 0.054464, Accuracy: 0.987000, Test accuracy: 0.980000
Distillation: Epoch : 41, Loss : 0.075574, Accuracy: 0.974000, Test accuracy: 0.980700
Distillation: Epoch : 42, Loss : 0.052509, Accuracy: 0.985000, Test accuracy: 0.979500
Distillation: Epoch : 43, Loss : 0.052749, Accuracy: 0.984000, Test accuracy: 0.980100
Distillation: Epoch : 44, Loss : 0.057321, Accuracy: 0.982000, Test accuracy: 0.979900
Distillation: Epoch : 45, Loss : 0.044760, Accuracy: 0.985000, Test accuracy: 0.980100
Distillation: Epoch : 46, Loss : 0.057478, Accuracy: 0.981000, Test accuracy: 0.981300
Distillation: Epoch : 47, Loss : 0.054534, Accuracy: 0.982000, Test accuracy: 0.980800
Distillation: Epoch : 48, Loss : 0.054654, Accuracy: 0.981000, Test accuracy: 0.981100
Distillation: Epoch : 49, Loss : 0.075869, Accuracy: 0.979000, Test accuracy: 0.980000
Distillation: Epoch : 50, Loss : 0.061051, Accuracy: 0.982000, Test accuracy: 0.980000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.98
Generating confusion matrix for student
[[ 970.    0.    1.    1.    0.    4.    6.    0.    5.    1.]
 [   0. 1130.    4.    0.    3.    0.    5.    6.    2.    5.]
 [   2.    1. 1009.    2.    3.    1.    0.    6.    5.    1.]
 [   0.    0.    7.  998.    1.   12.    0.    5.    6.    6.]
 [   0.    0.    2.    0.  967.    0.    4.    0.    3.    8.]
 [   1.    0.    0.    1.    0.  867.    2.    0.    2.    5.]
 [   1.    3.    1.    0.    0.    4.  940.    0.    1.    0.]
 [   1.    0.    6.    6.    1.    2.    0. 1004.    2.    6.]
 [   3.    1.    2.    2.    0.    2.    1.    1.  940.    2.]
 [   2.    0.    0.    0.    7.    0.    0.    6.    8.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.870105, Accuracy: 0.805000, Test accuracy: 0.815600
Distillation: Epoch : 2, Loss : 0.434678, Accuracy: 0.877000, Test accuracy: 0.881800
Distillation: Epoch : 3, Loss : 0.401148, Accuracy: 0.898000, Test accuracy: 0.909400
Distillation: Epoch : 4, Loss : 0.348217, Accuracy: 0.902000, Test accuracy: 0.921400
Distillation: Epoch : 5, Loss : 0.265790, Accuracy: 0.922000, Test accuracy: 0.929100
Distillation: Epoch : 6, Loss : 0.233937, Accuracy: 0.932000, Test accuracy: 0.935700
Distillation: Epoch : 7, Loss : 0.219244, Accuracy: 0.938000, Test accuracy: 0.940600
Distillation: Epoch : 8, Loss : 0.214655, Accuracy: 0.942000, Test accuracy: 0.944400
Distillation: Epoch : 9, Loss : 0.175850, Accuracy: 0.952000, Test accuracy: 0.948800
Distillation: Epoch : 10, Loss : 0.200234, Accuracy: 0.946000, Test accuracy: 0.951200
Distillation: Epoch : 11, Loss : 0.206712, Accuracy: 0.946000, Test accuracy: 0.952800
Distillation: Epoch : 12, Loss : 0.210596, Accuracy: 0.953000, Test accuracy: 0.955800
Distillation: Epoch : 13, Loss : 0.176254, Accuracy: 0.951000, Test accuracy: 0.957000
Distillation: Epoch : 14, Loss : 0.166523, Accuracy: 0.962000, Test accuracy: 0.958300
Distillation: Epoch : 15, Loss : 0.161114, Accuracy: 0.958000, Test accuracy: 0.959900
Distillation: Epoch : 16, Loss : 0.160908, Accuracy: 0.963000, Test accuracy: 0.961300
Distillation: Epoch : 17, Loss : 0.180128, Accuracy: 0.954000, Test accuracy: 0.962300
Distillation: Epoch : 18, Loss : 0.168188, Accuracy: 0.958000, Test accuracy: 0.963000
Distillation: Epoch : 19, Loss : 0.131697, Accuracy: 0.974000, Test accuracy: 0.964400
Distillation: Epoch : 20, Loss : 0.136862, Accuracy: 0.966000, Test accuracy: 0.965300
Distillation: Epoch : 21, Loss : 0.150306, Accuracy: 0.963000, Test accuracy: 0.966800
Distillation: Epoch : 22, Loss : 0.154690, Accuracy: 0.963000, Test accuracy: 0.966700
Distillation: Epoch : 23, Loss : 0.127246, Accuracy: 0.968000, Test accuracy: 0.968100
Distillation: Epoch : 24, Loss : 0.114666, Accuracy: 0.979000, Test accuracy: 0.968000
Distillation: Epoch : 25, Loss : 0.132348, Accuracy: 0.967000, Test accuracy: 0.969000
Distillation: Epoch : 26, Loss : 0.136908, Accuracy: 0.969000, Test accuracy: 0.968700
Distillation: Epoch : 27, Loss : 0.116922, Accuracy: 0.971000, Test accuracy: 0.970100
Distillation: Epoch : 28, Loss : 0.115288, Accuracy: 0.975000, Test accuracy: 0.971900
Distillation: Epoch : 29, Loss : 0.132584, Accuracy: 0.968000, Test accuracy: 0.971100
Distillation: Epoch : 30, Loss : 0.133443, Accuracy: 0.970000, Test accuracy: 0.972100
Distillation: Epoch : 31, Loss : 0.104602, Accuracy: 0.978000, Test accuracy: 0.971600
Distillation: Epoch : 32, Loss : 0.125517, Accuracy: 0.973000, Test accuracy: 0.973300
Distillation: Epoch : 33, Loss : 0.115532, Accuracy: 0.976000, Test accuracy: 0.972100
Distillation: Epoch : 34, Loss : 0.104911, Accuracy: 0.977000, Test accuracy: 0.973200
Distillation: Epoch : 35, Loss : 0.107988, Accuracy: 0.979000, Test accuracy: 0.973700
Distillation: Epoch : 36, Loss : 0.112122, Accuracy: 0.974000, Test accuracy: 0.972700
Distillation: Epoch : 37, Loss : 0.118962, Accuracy: 0.973000, Test accuracy: 0.974300
Distillation: Epoch : 38, Loss : 0.138498, Accuracy: 0.967000, Test accuracy: 0.975300
Distillation: Epoch : 39, Loss : 0.126071, Accuracy: 0.970000, Test accuracy: 0.975400
Distillation: Epoch : 40, Loss : 0.117854, Accuracy: 0.976000, Test accuracy: 0.975100
Distillation: Epoch : 41, Loss : 0.120570, Accuracy: 0.976000, Test accuracy: 0.975300
Distillation: Epoch : 42, Loss : 0.114812, Accuracy: 0.969000, Test accuracy: 0.975500
Distillation: Epoch : 43, Loss : 0.095493, Accuracy: 0.983000, Test accuracy: 0.976300
Distillation: Epoch : 44, Loss : 0.105621, Accuracy: 0.975000, Test accuracy: 0.977000
Distillation: Epoch : 45, Loss : 0.105569, Accuracy: 0.974000, Test accuracy: 0.976300
Distillation: Epoch : 46, Loss : 0.100879, Accuracy: 0.975000, Test accuracy: 0.976100
Distillation: Epoch : 47, Loss : 0.124601, Accuracy: 0.969000, Test accuracy: 0.976000
Distillation: Epoch : 48, Loss : 0.107823, Accuracy: 0.975000, Test accuracy: 0.977100
Distillation: Epoch : 49, Loss : 0.123335, Accuracy: 0.968000, Test accuracy: 0.976900
Distillation: Epoch : 50, Loss : 0.118241, Accuracy: 0.974000, Test accuracy: 0.978400
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9784
Generating confusion matrix for student
[[ 970.    0.    1.    0.    1.    2.    2.    0.    2.    5.]
 [   0. 1127.    3.    0.    2.    0.    2.    3.    0.    5.]
 [   1.    2. 1004.    3.    2.    0.    0.   10.    5.    0.]
 [   0.    1.    6.  991.    0.   10.    0.    4.    5.    3.]
 [   0.    1.    0.    0.  965.    0.    3.    0.    4.   12.]
 [   1.    1.    1.    6.    0.  873.    5.    0.    5.    5.]
 [   3.    2.    0.    0.    3.    2.  945.    0.    2.    0.]
 [   1.    1.    6.    4.    3.    1.    0. 1005.    8.   13.]
 [   4.    0.   11.    6.    1.    2.    1.    2.  941.    3.]
 [   0.    0.    0.    0.    5.    2.    0.    4.    2.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.090398, Accuracy: 0.772000, Test accuracy: 0.792200
Distillation: Epoch : 2, Loss : 0.780461, Accuracy: 0.851000, Test accuracy: 0.868600
Distillation: Epoch : 3, Loss : 0.725805, Accuracy: 0.881000, Test accuracy: 0.893400
Distillation: Epoch : 4, Loss : 0.705139, Accuracy: 0.884000, Test accuracy: 0.905600
Distillation: Epoch : 5, Loss : 0.599406, Accuracy: 0.931000, Test accuracy: 0.914800
Distillation: Epoch : 6, Loss : 0.611938, Accuracy: 0.918000, Test accuracy: 0.922300
Distillation: Epoch : 7, Loss : 0.603059, Accuracy: 0.925000, Test accuracy: 0.927600
Distillation: Epoch : 8, Loss : 0.567461, Accuracy: 0.934000, Test accuracy: 0.934500
Distillation: Epoch : 9, Loss : 0.585119, Accuracy: 0.943000, Test accuracy: 0.939800
Distillation: Epoch : 10, Loss : 0.560512, Accuracy: 0.940000, Test accuracy: 0.941500
Distillation: Epoch : 11, Loss : 0.543490, Accuracy: 0.954000, Test accuracy: 0.947800
Distillation: Epoch : 12, Loss : 0.549587, Accuracy: 0.939000, Test accuracy: 0.951200
Distillation: Epoch : 13, Loss : 0.512946, Accuracy: 0.960000, Test accuracy: 0.955400
Distillation: Epoch : 14, Loss : 0.531125, Accuracy: 0.945000, Test accuracy: 0.957200
Distillation: Epoch : 15, Loss : 0.511549, Accuracy: 0.956000, Test accuracy: 0.960100
Distillation: Epoch : 16, Loss : 0.516986, Accuracy: 0.963000, Test accuracy: 0.960200
Distillation: Epoch : 17, Loss : 0.492962, Accuracy: 0.962000, Test accuracy: 0.962600
Distillation: Epoch : 18, Loss : 0.482754, Accuracy: 0.966000, Test accuracy: 0.964400
Distillation: Epoch : 19, Loss : 0.506663, Accuracy: 0.964000, Test accuracy: 0.966600
Distillation: Epoch : 20, Loss : 0.477255, Accuracy: 0.969000, Test accuracy: 0.966800
Distillation: Epoch : 21, Loss : 0.482832, Accuracy: 0.957000, Test accuracy: 0.969300
Distillation: Epoch : 22, Loss : 0.498875, Accuracy: 0.969000, Test accuracy: 0.969500
Distillation: Epoch : 23, Loss : 0.493463, Accuracy: 0.971000, Test accuracy: 0.971600
Distillation: Epoch : 24, Loss : 0.487787, Accuracy: 0.970000, Test accuracy: 0.972300
Distillation: Epoch : 25, Loss : 0.489443, Accuracy: 0.965000, Test accuracy: 0.973300
Distillation: Epoch : 26, Loss : 0.487148, Accuracy: 0.966000, Test accuracy: 0.973700
Distillation: Epoch : 27, Loss : 0.486651, Accuracy: 0.972000, Test accuracy: 0.973200
Distillation: Epoch : 28, Loss : 0.483396, Accuracy: 0.970000, Test accuracy: 0.973400
Distillation: Epoch : 29, Loss : 0.465518, Accuracy: 0.976000, Test accuracy: 0.973900
Distillation: Epoch : 30, Loss : 0.459343, Accuracy: 0.977000, Test accuracy: 0.975000
Distillation: Epoch : 31, Loss : 0.481452, Accuracy: 0.964000, Test accuracy: 0.975300
Distillation: Epoch : 32, Loss : 0.480290, Accuracy: 0.976000, Test accuracy: 0.975900
Distillation: Epoch : 33, Loss : 0.483677, Accuracy: 0.976000, Test accuracy: 0.975500
Distillation: Epoch : 34, Loss : 0.457565, Accuracy: 0.974000, Test accuracy: 0.977100
Distillation: Epoch : 35, Loss : 0.464389, Accuracy: 0.973000, Test accuracy: 0.977100
Distillation: Epoch : 36, Loss : 0.464896, Accuracy: 0.977000, Test accuracy: 0.977600
Distillation: Epoch : 37, Loss : 0.467381, Accuracy: 0.971000, Test accuracy: 0.977200
Distillation: Epoch : 38, Loss : 0.449658, Accuracy: 0.986000, Test accuracy: 0.977000
Distillation: Epoch : 39, Loss : 0.465712, Accuracy: 0.977000, Test accuracy: 0.977800
Distillation: Epoch : 40, Loss : 0.475387, Accuracy: 0.979000, Test accuracy: 0.978000
Distillation: Epoch : 41, Loss : 0.479777, Accuracy: 0.967000, Test accuracy: 0.978800
Distillation: Epoch : 42, Loss : 0.478424, Accuracy: 0.980000, Test accuracy: 0.978700
Distillation: Epoch : 43, Loss : 0.472941, Accuracy: 0.970000, Test accuracy: 0.979000
Distillation: Epoch : 44, Loss : 0.462644, Accuracy: 0.983000, Test accuracy: 0.978200
Distillation: Epoch : 45, Loss : 0.470029, Accuracy: 0.969000, Test accuracy: 0.979000
Distillation: Epoch : 46, Loss : 0.465808, Accuracy: 0.978000, Test accuracy: 0.979300
Distillation: Epoch : 47, Loss : 0.476458, Accuracy: 0.983000, Test accuracy: 0.979800
Distillation: Epoch : 48, Loss : 0.445885, Accuracy: 0.981000, Test accuracy: 0.979100
Distillation: Epoch : 49, Loss : 0.456737, Accuracy: 0.978000, Test accuracy: 0.979700
Distillation: Epoch : 50, Loss : 0.465249, Accuracy: 0.978000, Test accuracy: 0.979900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9799
Generating confusion matrix for student
[[ 973.    0.    7.    0.    1.    2.    5.    0.    3.    2.]
 [   0. 1120.    2.    0.    1.    0.    1.    3.    0.    4.]
 [   0.    2. 1004.    2.    2.    0.    0.    8.    2.    1.]
 [   0.    2.    5. 1000.    0.   10.    0.    3.    6.    9.]
 [   0.    0.    1.    0.  964.    0.    2.    2.    3.    3.]
 [   2.    0.    0.    2.    0.  875.    6.    0.    1.    7.]
 [   3.    4.    0.    0.    1.    3.  942.    0.    2.    1.]
 [   0.    1.    4.    2.    2.    0.    0. 1003.    5.    7.]
 [   1.    6.    9.    3.    2.    1.    2.    2.  946.    3.]
 [   1.    0.    0.    1.    9.    1.    0.    7.    6.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.323624, Accuracy: 0.778000, Test accuracy: 0.797700
Distillation: Epoch : 2, Loss : 0.931970, Accuracy: 0.861000, Test accuracy: 0.875600
Distillation: Epoch : 3, Loss : 0.854057, Accuracy: 0.905000, Test accuracy: 0.903200
Distillation: Epoch : 4, Loss : 0.846407, Accuracy: 0.900000, Test accuracy: 0.917500
Distillation: Epoch : 5, Loss : 0.773278, Accuracy: 0.934000, Test accuracy: 0.925800
Distillation: Epoch : 6, Loss : 0.774231, Accuracy: 0.917000, Test accuracy: 0.933100
Distillation: Epoch : 7, Loss : 0.765629, Accuracy: 0.915000, Test accuracy: 0.940200
Distillation: Epoch : 8, Loss : 0.732847, Accuracy: 0.928000, Test accuracy: 0.942100
Distillation: Epoch : 9, Loss : 0.712984, Accuracy: 0.953000, Test accuracy: 0.946900
Distillation: Epoch : 10, Loss : 0.728302, Accuracy: 0.945000, Test accuracy: 0.951400
Distillation: Epoch : 11, Loss : 0.704407, Accuracy: 0.941000, Test accuracy: 0.954100
Distillation: Epoch : 12, Loss : 0.683667, Accuracy: 0.964000, Test accuracy: 0.957100
Distillation: Epoch : 13, Loss : 0.681241, Accuracy: 0.956000, Test accuracy: 0.959900
Distillation: Epoch : 14, Loss : 0.678381, Accuracy: 0.967000, Test accuracy: 0.962600
Distillation: Epoch : 15, Loss : 0.688095, Accuracy: 0.967000, Test accuracy: 0.964200
Distillation: Epoch : 16, Loss : 0.673523, Accuracy: 0.971000, Test accuracy: 0.965700
Distillation: Epoch : 17, Loss : 0.672996, Accuracy: 0.964000, Test accuracy: 0.967300
Distillation: Epoch : 18, Loss : 0.662770, Accuracy: 0.973000, Test accuracy: 0.968000
Distillation: Epoch : 19, Loss : 0.657935, Accuracy: 0.972000, Test accuracy: 0.970000
Distillation: Epoch : 20, Loss : 0.661151, Accuracy: 0.966000, Test accuracy: 0.970500
Distillation: Epoch : 21, Loss : 0.660143, Accuracy: 0.973000, Test accuracy: 0.972200
Distillation: Epoch : 22, Loss : 0.679024, Accuracy: 0.972000, Test accuracy: 0.972100
Distillation: Epoch : 23, Loss : 0.672906, Accuracy: 0.974000, Test accuracy: 0.973600
Distillation: Epoch : 24, Loss : 0.641627, Accuracy: 0.979000, Test accuracy: 0.972700
Distillation: Epoch : 25, Loss : 0.672865, Accuracy: 0.976000, Test accuracy: 0.974400
Distillation: Epoch : 26, Loss : 0.657203, Accuracy: 0.975000, Test accuracy: 0.975100
Distillation: Epoch : 27, Loss : 0.636685, Accuracy: 0.979000, Test accuracy: 0.974300
Distillation: Epoch : 28, Loss : 0.670117, Accuracy: 0.976000, Test accuracy: 0.975100
Distillation: Epoch : 29, Loss : 0.635412, Accuracy: 0.971000, Test accuracy: 0.975300
Distillation: Epoch : 30, Loss : 0.628061, Accuracy: 0.980000, Test accuracy: 0.976000
Distillation: Epoch : 31, Loss : 0.664975, Accuracy: 0.972000, Test accuracy: 0.976100
Distillation: Epoch : 32, Loss : 0.639002, Accuracy: 0.976000, Test accuracy: 0.977700
Distillation: Epoch : 33, Loss : 0.646620, Accuracy: 0.977000, Test accuracy: 0.976900
Distillation: Epoch : 34, Loss : 0.644716, Accuracy: 0.978000, Test accuracy: 0.977400
Distillation: Epoch : 35, Loss : 0.631946, Accuracy: 0.978000, Test accuracy: 0.978200
Distillation: Epoch : 36, Loss : 0.640738, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 37, Loss : 0.661812, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 38, Loss : 0.643251, Accuracy: 0.974000, Test accuracy: 0.979100
Distillation: Epoch : 39, Loss : 0.651024, Accuracy: 0.977000, Test accuracy: 0.978800
Distillation: Epoch : 40, Loss : 0.644034, Accuracy: 0.988000, Test accuracy: 0.978900
Distillation: Epoch : 41, Loss : 0.656575, Accuracy: 0.972000, Test accuracy: 0.979500
Distillation: Epoch : 42, Loss : 0.666994, Accuracy: 0.973000, Test accuracy: 0.979600
Distillation: Epoch : 43, Loss : 0.659300, Accuracy: 0.972000, Test accuracy: 0.979700
Distillation: Epoch : 44, Loss : 0.644844, Accuracy: 0.979000, Test accuracy: 0.979500
Distillation: Epoch : 45, Loss : 0.646557, Accuracy: 0.980000, Test accuracy: 0.979600
Distillation: Epoch : 46, Loss : 0.630278, Accuracy: 0.984000, Test accuracy: 0.979100
Distillation: Epoch : 47, Loss : 0.607239, Accuracy: 0.984000, Test accuracy: 0.980300
Distillation: Epoch : 48, Loss : 0.634195, Accuracy: 0.983000, Test accuracy: 0.979900
Distillation: Epoch : 49, Loss : 0.648406, Accuracy: 0.980000, Test accuracy: 0.980300
Distillation: Epoch : 50, Loss : 0.624143, Accuracy: 0.987000, Test accuracy: 0.980300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9803
Generating confusion matrix for student
[[ 969.    0.    4.    1.    0.    1.    6.    1.    4.    4.]
 [   1. 1128.    2.    0.    0.    0.    3.    3.    0.    6.]
 [   1.    2. 1002.    0.    1.    0.    1.    7.    4.    1.]
 [   0.    1.    6. 1000.    0.    8.    0.    4.    6.    6.]
 [   0.    0.    2.    0.  967.    0.    3.    1.    2.    5.]
 [   2.    0.    0.    4.    0.  874.    4.    0.    3.    5.]
 [   4.    1.    0.    0.    1.    3.  938.    0.    2.    1.]
 [   0.    1.    4.    3.    2.    0.    0. 1004.    3.    6.]
 [   2.    2.   12.    2.    2.    4.    3.    2.  947.    1.]
 [   1.    0.    0.    0.    9.    2.    0.    6.    3.  974.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.421746, Accuracy: 0.734000, Test accuracy: 0.748700
Distillation: Epoch : 2, Loss : 1.151646, Accuracy: 0.844000, Test accuracy: 0.842600
Distillation: Epoch : 3, Loss : 1.109941, Accuracy: 0.872000, Test accuracy: 0.877700
Distillation: Epoch : 4, Loss : 1.025733, Accuracy: 0.903000, Test accuracy: 0.893800
Distillation: Epoch : 5, Loss : 0.999378, Accuracy: 0.911000, Test accuracy: 0.903500
Distillation: Epoch : 6, Loss : 0.999961, Accuracy: 0.902000, Test accuracy: 0.914600
Distillation: Epoch : 7, Loss : 0.980035, Accuracy: 0.929000, Test accuracy: 0.918300
Distillation: Epoch : 8, Loss : 0.963777, Accuracy: 0.933000, Test accuracy: 0.928400
Distillation: Epoch : 9, Loss : 0.946807, Accuracy: 0.931000, Test accuracy: 0.932600
Distillation: Epoch : 10, Loss : 0.954995, Accuracy: 0.934000, Test accuracy: 0.938400
Distillation: Epoch : 11, Loss : 0.908351, Accuracy: 0.950000, Test accuracy: 0.943600
Distillation: Epoch : 12, Loss : 0.913998, Accuracy: 0.952000, Test accuracy: 0.947800
Distillation: Epoch : 13, Loss : 0.897391, Accuracy: 0.947000, Test accuracy: 0.950900
Distillation: Epoch : 14, Loss : 0.896218, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 15, Loss : 0.893390, Accuracy: 0.944000, Test accuracy: 0.958600
Distillation: Epoch : 16, Loss : 0.891055, Accuracy: 0.956000, Test accuracy: 0.960500
Distillation: Epoch : 17, Loss : 0.891794, Accuracy: 0.947000, Test accuracy: 0.963100
Distillation: Epoch : 18, Loss : 0.868276, Accuracy: 0.958000, Test accuracy: 0.963400
Distillation: Epoch : 19, Loss : 0.847604, Accuracy: 0.962000, Test accuracy: 0.965600
Distillation: Epoch : 20, Loss : 0.878809, Accuracy: 0.961000, Test accuracy: 0.966900
Distillation: Epoch : 21, Loss : 0.864674, Accuracy: 0.960000, Test accuracy: 0.967800
Distillation: Epoch : 22, Loss : 0.849822, Accuracy: 0.971000, Test accuracy: 0.967700
Distillation: Epoch : 23, Loss : 0.852963, Accuracy: 0.962000, Test accuracy: 0.970200
Distillation: Epoch : 24, Loss : 0.882581, Accuracy: 0.966000, Test accuracy: 0.970100
Distillation: Epoch : 25, Loss : 0.841533, Accuracy: 0.967000, Test accuracy: 0.971400
Distillation: Epoch : 26, Loss : 0.855728, Accuracy: 0.972000, Test accuracy: 0.971100
Distillation: Epoch : 27, Loss : 0.851151, Accuracy: 0.972000, Test accuracy: 0.972600
Distillation: Epoch : 28, Loss : 0.866324, Accuracy: 0.962000, Test accuracy: 0.973600
Distillation: Epoch : 29, Loss : 0.840995, Accuracy: 0.978000, Test accuracy: 0.973800
Distillation: Epoch : 30, Loss : 0.849657, Accuracy: 0.962000, Test accuracy: 0.972700
Distillation: Epoch : 31, Loss : 0.851349, Accuracy: 0.977000, Test accuracy: 0.974300
Distillation: Epoch : 32, Loss : 0.855253, Accuracy: 0.974000, Test accuracy: 0.974900
Distillation: Epoch : 33, Loss : 0.832284, Accuracy: 0.983000, Test accuracy: 0.974900
Distillation: Epoch : 34, Loss : 0.842626, Accuracy: 0.980000, Test accuracy: 0.975900
Distillation: Epoch : 35, Loss : 0.821333, Accuracy: 0.969000, Test accuracy: 0.976600
Distillation: Epoch : 36, Loss : 0.853484, Accuracy: 0.968000, Test accuracy: 0.976000
Distillation: Epoch : 37, Loss : 0.823249, Accuracy: 0.971000, Test accuracy: 0.976600
Distillation: Epoch : 38, Loss : 0.835632, Accuracy: 0.966000, Test accuracy: 0.976300
Distillation: Epoch : 39, Loss : 0.835920, Accuracy: 0.966000, Test accuracy: 0.976700
Distillation: Epoch : 40, Loss : 0.808478, Accuracy: 0.984000, Test accuracy: 0.977300
Distillation: Epoch : 41, Loss : 0.849012, Accuracy: 0.976000, Test accuracy: 0.977800
Distillation: Epoch : 42, Loss : 0.852974, Accuracy: 0.966000, Test accuracy: 0.977700
Distillation: Epoch : 43, Loss : 0.856123, Accuracy: 0.974000, Test accuracy: 0.977900
Distillation: Epoch : 44, Loss : 0.817374, Accuracy: 0.969000, Test accuracy: 0.978300
Distillation: Epoch : 45, Loss : 0.838877, Accuracy: 0.982000, Test accuracy: 0.977600
Distillation: Epoch : 46, Loss : 0.845593, Accuracy: 0.973000, Test accuracy: 0.977200
Distillation: Epoch : 47, Loss : 0.829584, Accuracy: 0.975000, Test accuracy: 0.978600
Distillation: Epoch : 48, Loss : 0.813868, Accuracy: 0.979000, Test accuracy: 0.979200
Distillation: Epoch : 49, Loss : 0.817116, Accuracy: 0.981000, Test accuracy: 0.978800
Distillation: Epoch : 50, Loss : 0.828912, Accuracy: 0.977000, Test accuracy: 0.979300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9793
Generating confusion matrix for student
[[ 968.    0.    3.    0.    0.    2.    3.    0.    3.    4.]
 [   0. 1127.    0.    0.    0.    0.    3.    3.    0.    5.]
 [   0.    3. 1004.    2.    1.    0.    0.   12.    3.    1.]
 [   1.    1.    6.  997.    0.   11.    0.    3.    7.   11.]
 [   1.    0.    1.    0.  971.    1.    5.    3.    3.    5.]
 [   2.    0.    1.    2.    0.  873.    5.    0.    2.    6.]
 [   4.    2.    1.    0.    0.    2.  941.    0.    2.    0.]
 [   0.    0.    7.    1.    1.    0.    0.  999.    6.    5.]
 [   4.    2.    9.    6.    2.    0.    1.    3.  941.    0.]
 [   0.    0.    0.    2.    7.    3.    0.    5.    7.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.876313, Accuracy: 0.640000, Test accuracy: 0.660300
Distillation: Epoch : 2, Loss : 1.302568, Accuracy: 0.851000, Test accuracy: 0.864900
Distillation: Epoch : 3, Loss : 1.188758, Accuracy: 0.889000, Test accuracy: 0.900800
Distillation: Epoch : 4, Loss : 1.150299, Accuracy: 0.931000, Test accuracy: 0.923000
Distillation: Epoch : 5, Loss : 1.132073, Accuracy: 0.913000, Test accuracy: 0.934300
Distillation: Epoch : 6, Loss : 1.094818, Accuracy: 0.937000, Test accuracy: 0.941200
Distillation: Epoch : 7, Loss : 1.109174, Accuracy: 0.930000, Test accuracy: 0.947300
Distillation: Epoch : 8, Loss : 1.108858, Accuracy: 0.941000, Test accuracy: 0.952300
Distillation: Epoch : 9, Loss : 1.066686, Accuracy: 0.956000, Test accuracy: 0.954500
Distillation: Epoch : 10, Loss : 1.072199, Accuracy: 0.961000, Test accuracy: 0.958400
Distillation: Epoch : 11, Loss : 1.064518, Accuracy: 0.955000, Test accuracy: 0.961100
Distillation: Epoch : 12, Loss : 1.056578, Accuracy: 0.957000, Test accuracy: 0.963700
Distillation: Epoch : 13, Loss : 1.046934, Accuracy: 0.949000, Test accuracy: 0.965700
Distillation: Epoch : 14, Loss : 1.057393, Accuracy: 0.958000, Test accuracy: 0.967600
Distillation: Epoch : 15, Loss : 1.048179, Accuracy: 0.960000, Test accuracy: 0.969800
Distillation: Epoch : 16, Loss : 1.038770, Accuracy: 0.969000, Test accuracy: 0.970400
Distillation: Epoch : 17, Loss : 1.005392, Accuracy: 0.975000, Test accuracy: 0.971200
Distillation: Epoch : 18, Loss : 1.042258, Accuracy: 0.969000, Test accuracy: 0.973000
Distillation: Epoch : 19, Loss : 0.991277, Accuracy: 0.972000, Test accuracy: 0.974200
Distillation: Epoch : 20, Loss : 1.038199, Accuracy: 0.974000, Test accuracy: 0.974200
Distillation: Epoch : 21, Loss : 1.015118, Accuracy: 0.981000, Test accuracy: 0.975000
Distillation: Epoch : 22, Loss : 1.043974, Accuracy: 0.963000, Test accuracy: 0.976000
Distillation: Epoch : 23, Loss : 1.053575, Accuracy: 0.964000, Test accuracy: 0.975700
Distillation: Epoch : 24, Loss : 1.030536, Accuracy: 0.968000, Test accuracy: 0.976300
Distillation: Epoch : 25, Loss : 1.018563, Accuracy: 0.977000, Test accuracy: 0.976400
Distillation: Epoch : 26, Loss : 1.018993, Accuracy: 0.975000, Test accuracy: 0.977500
Distillation: Epoch : 27, Loss : 1.022703, Accuracy: 0.973000, Test accuracy: 0.977200
Distillation: Epoch : 28, Loss : 1.024527, Accuracy: 0.969000, Test accuracy: 0.977900
Distillation: Epoch : 29, Loss : 1.006498, Accuracy: 0.973000, Test accuracy: 0.978400
Distillation: Epoch : 30, Loss : 1.037821, Accuracy: 0.971000, Test accuracy: 0.978700
Distillation: Epoch : 31, Loss : 1.014846, Accuracy: 0.970000, Test accuracy: 0.978800
Distillation: Epoch : 32, Loss : 1.045848, Accuracy: 0.975000, Test accuracy: 0.978800
Distillation: Epoch : 33, Loss : 1.025730, Accuracy: 0.966000, Test accuracy: 0.978700
Distillation: Epoch : 34, Loss : 1.025365, Accuracy: 0.977000, Test accuracy: 0.979300
Distillation: Epoch : 35, Loss : 0.998526, Accuracy: 0.974000, Test accuracy: 0.979100
Distillation: Epoch : 36, Loss : 1.013363, Accuracy: 0.981000, Test accuracy: 0.980000
Distillation: Epoch : 37, Loss : 1.024195, Accuracy: 0.974000, Test accuracy: 0.978600
Distillation: Epoch : 38, Loss : 1.007857, Accuracy: 0.969000, Test accuracy: 0.979900
Distillation: Epoch : 39, Loss : 1.001116, Accuracy: 0.975000, Test accuracy: 0.980000
Distillation: Epoch : 40, Loss : 0.991039, Accuracy: 0.988000, Test accuracy: 0.980800
Distillation: Epoch : 41, Loss : 1.012553, Accuracy: 0.985000, Test accuracy: 0.980300
Distillation: Epoch : 42, Loss : 1.002708, Accuracy: 0.986000, Test accuracy: 0.980500
Distillation: Epoch : 43, Loss : 1.015080, Accuracy: 0.986000, Test accuracy: 0.981400
Distillation: Epoch : 44, Loss : 0.999540, Accuracy: 0.977000, Test accuracy: 0.981200
Distillation: Epoch : 45, Loss : 1.003164, Accuracy: 0.975000, Test accuracy: 0.981200
Distillation: Epoch : 46, Loss : 1.027492, Accuracy: 0.976000, Test accuracy: 0.981200
Distillation: Epoch : 47, Loss : 1.008567, Accuracy: 0.973000, Test accuracy: 0.981200
Distillation: Epoch : 48, Loss : 1.021228, Accuracy: 0.978000, Test accuracy: 0.981300
Distillation: Epoch : 49, Loss : 1.025675, Accuracy: 0.973000, Test accuracy: 0.981700
Distillation: Epoch : 50, Loss : 0.984467, Accuracy: 0.978000, Test accuracy: 0.982000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.982
Generating confusion matrix for student
[[ 971.    0.    3.    1.    0.    2.    3.    0.    3.    3.]
 [   0. 1128.    3.    0.    0.    0.    2.    4.    1.    4.]
 [   0.    3. 1005.    0.    2.    0.    0.    8.    3.    0.]
 [   1.    1.    4. 1000.    0.   11.    0.    3.    6.    8.]
 [   0.    0.    1.    0.  967.    0.    1.    2.    4.    7.]
 [   0.    2.    2.    1.    0.  876.    4.    0.    5.    2.]
 [   5.    1.    0.    0.    1.    2.  947.    0.    1.    0.]
 [   0.    0.    2.    5.    0.    0.    0. 1009.    5.    8.]
 [   3.    0.   12.    2.    2.    0.    1.    1.  941.    1.]
 [   0.    0.    0.    1.   10.    1.    0.    1.    5.  976.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.606970, Accuracy: 0.766000, Test accuracy: 0.776900
Distillation: Epoch : 2, Loss : 1.405634, Accuracy: 0.863000, Test accuracy: 0.862100
Distillation: Epoch : 3, Loss : 1.374222, Accuracy: 0.871000, Test accuracy: 0.881200
Distillation: Epoch : 4, Loss : 1.369281, Accuracy: 0.892000, Test accuracy: 0.891200
Distillation: Epoch : 5, Loss : 1.337611, Accuracy: 0.887000, Test accuracy: 0.901700
Distillation: Epoch : 6, Loss : 1.324829, Accuracy: 0.912000, Test accuracy: 0.912400
Distillation: Epoch : 7, Loss : 1.302704, Accuracy: 0.896000, Test accuracy: 0.919900
Distillation: Epoch : 8, Loss : 1.287806, Accuracy: 0.935000, Test accuracy: 0.927100
Distillation: Epoch : 9, Loss : 1.291698, Accuracy: 0.927000, Test accuracy: 0.935100
Distillation: Epoch : 10, Loss : 1.269257, Accuracy: 0.939000, Test accuracy: 0.943600
Distillation: Epoch : 11, Loss : 1.250811, Accuracy: 0.945000, Test accuracy: 0.948900
Distillation: Epoch : 12, Loss : 1.248163, Accuracy: 0.945000, Test accuracy: 0.953400
Distillation: Epoch : 13, Loss : 1.226111, Accuracy: 0.957000, Test accuracy: 0.954900
Distillation: Epoch : 14, Loss : 1.221458, Accuracy: 0.953000, Test accuracy: 0.958400
Distillation: Epoch : 15, Loss : 1.235476, Accuracy: 0.959000, Test accuracy: 0.961900
Distillation: Epoch : 16, Loss : 1.220807, Accuracy: 0.952000, Test accuracy: 0.962600
Distillation: Epoch : 17, Loss : 1.202868, Accuracy: 0.968000, Test accuracy: 0.964100
Distillation: Epoch : 18, Loss : 1.201056, Accuracy: 0.947000, Test accuracy: 0.966400
Distillation: Epoch : 19, Loss : 1.209028, Accuracy: 0.958000, Test accuracy: 0.967300
Distillation: Epoch : 20, Loss : 1.181423, Accuracy: 0.959000, Test accuracy: 0.966800
Distillation: Epoch : 21, Loss : 1.199201, Accuracy: 0.956000, Test accuracy: 0.968100
Distillation: Epoch : 22, Loss : 1.210847, Accuracy: 0.956000, Test accuracy: 0.968100
Distillation: Epoch : 23, Loss : 1.203928, Accuracy: 0.965000, Test accuracy: 0.968900
Distillation: Epoch : 24, Loss : 1.212674, Accuracy: 0.963000, Test accuracy: 0.969500
Distillation: Epoch : 25, Loss : 1.188030, Accuracy: 0.980000, Test accuracy: 0.970300
Distillation: Epoch : 26, Loss : 1.200656, Accuracy: 0.972000, Test accuracy: 0.971000
Distillation: Epoch : 27, Loss : 1.191745, Accuracy: 0.974000, Test accuracy: 0.971700
Distillation: Epoch : 28, Loss : 1.211977, Accuracy: 0.965000, Test accuracy: 0.972300
Distillation: Epoch : 29, Loss : 1.203182, Accuracy: 0.979000, Test accuracy: 0.973100
Distillation: Epoch : 30, Loss : 1.163402, Accuracy: 0.968000, Test accuracy: 0.973600
Distillation: Epoch : 31, Loss : 1.167789, Accuracy: 0.980000, Test accuracy: 0.974300
Distillation: Epoch : 32, Loss : 1.187879, Accuracy: 0.971000, Test accuracy: 0.974200
Distillation: Epoch : 33, Loss : 1.180290, Accuracy: 0.977000, Test accuracy: 0.975100
Distillation: Epoch : 34, Loss : 1.182866, Accuracy: 0.973000, Test accuracy: 0.975800
Distillation: Epoch : 35, Loss : 1.181765, Accuracy: 0.979000, Test accuracy: 0.976200
Distillation: Epoch : 36, Loss : 1.159633, Accuracy: 0.966000, Test accuracy: 0.977400
Distillation: Epoch : 37, Loss : 1.181001, Accuracy: 0.973000, Test accuracy: 0.977100
Distillation: Epoch : 38, Loss : 1.149330, Accuracy: 0.976000, Test accuracy: 0.977400
Distillation: Epoch : 39, Loss : 1.184408, Accuracy: 0.979000, Test accuracy: 0.977500
Distillation: Epoch : 40, Loss : 1.195955, Accuracy: 0.975000, Test accuracy: 0.978400
Distillation: Epoch : 41, Loss : 1.177577, Accuracy: 0.974000, Test accuracy: 0.977800
Distillation: Epoch : 42, Loss : 1.184256, Accuracy: 0.976000, Test accuracy: 0.977900
Distillation: Epoch : 43, Loss : 1.165500, Accuracy: 0.978000, Test accuracy: 0.977900
Distillation: Epoch : 44, Loss : 1.155867, Accuracy: 0.977000, Test accuracy: 0.979000
Distillation: Epoch : 45, Loss : 1.184454, Accuracy: 0.970000, Test accuracy: 0.979300
Distillation: Epoch : 46, Loss : 1.186717, Accuracy: 0.971000, Test accuracy: 0.978300
Distillation: Epoch : 47, Loss : 1.166442, Accuracy: 0.986000, Test accuracy: 0.979000
Distillation: Epoch : 48, Loss : 1.176017, Accuracy: 0.982000, Test accuracy: 0.980100
Distillation: Epoch : 49, Loss : 1.182254, Accuracy: 0.980000, Test accuracy: 0.979800
Distillation: Epoch : 50, Loss : 1.165583, Accuracy: 0.976000, Test accuracy: 0.978600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9786
Generating confusion matrix for student
[[ 973.    0.    3.    1.    0.    2.    5.    0.    4.    3.]
 [   0. 1125.    4.    0.    0.    0.    2.    4.    0.    6.]
 [   0.    1. 1004.    0.    2.    0.    0.    9.    1.    0.]
 [   0.    3.    9.  998.    0.   12.    0.    6.    8.   12.]
 [   1.    0.    3.    0.  965.    0.    4.    1.    4.   13.]
 [   0.    1.    0.    3.    0.  874.    7.    1.    5.    2.]
 [   1.    4.    0.    0.    3.    2.  938.    0.    2.    0.]
 [   2.    1.    5.    3.    1.    0.    0. 1001.    3.    5.]
 [   3.    0.    4.    4.    2.    1.    2.    2.  942.    2.]
 [   0.    0.    0.    1.    9.    1.    0.    4.    5.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.740337, Accuracy: 0.757000, Test accuracy: 0.773800
Distillation: Epoch : 2, Loss : 1.533086, Accuracy: 0.850000, Test accuracy: 0.864200
Distillation: Epoch : 3, Loss : 1.486546, Accuracy: 0.900000, Test accuracy: 0.886000
Distillation: Epoch : 4, Loss : 1.472127, Accuracy: 0.906000, Test accuracy: 0.901700
Distillation: Epoch : 5, Loss : 1.446778, Accuracy: 0.903000, Test accuracy: 0.914500
Distillation: Epoch : 6, Loss : 1.437442, Accuracy: 0.917000, Test accuracy: 0.924000
Distillation: Epoch : 7, Loss : 1.407376, Accuracy: 0.930000, Test accuracy: 0.932400
Distillation: Epoch : 8, Loss : 1.402919, Accuracy: 0.920000, Test accuracy: 0.941100
Distillation: Epoch : 9, Loss : 1.385582, Accuracy: 0.932000, Test accuracy: 0.948300
Distillation: Epoch : 10, Loss : 1.351639, Accuracy: 0.948000, Test accuracy: 0.953800
Distillation: Epoch : 11, Loss : 1.379434, Accuracy: 0.957000, Test accuracy: 0.957300
Distillation: Epoch : 12, Loss : 1.337359, Accuracy: 0.968000, Test accuracy: 0.958300
Distillation: Epoch : 13, Loss : 1.326965, Accuracy: 0.964000, Test accuracy: 0.960400
Distillation: Epoch : 14, Loss : 1.332835, Accuracy: 0.961000, Test accuracy: 0.962600
Distillation: Epoch : 15, Loss : 1.352428, Accuracy: 0.962000, Test accuracy: 0.963600
Distillation: Epoch : 16, Loss : 1.339769, Accuracy: 0.965000, Test accuracy: 0.965400
Distillation: Epoch : 17, Loss : 1.343064, Accuracy: 0.968000, Test accuracy: 0.965900
Distillation: Epoch : 18, Loss : 1.335010, Accuracy: 0.971000, Test accuracy: 0.966900
Distillation: Epoch : 19, Loss : 1.358663, Accuracy: 0.962000, Test accuracy: 0.967900
Distillation: Epoch : 20, Loss : 1.333574, Accuracy: 0.970000, Test accuracy: 0.968500
Distillation: Epoch : 21, Loss : 1.366548, Accuracy: 0.955000, Test accuracy: 0.969500
Distillation: Epoch : 22, Loss : 1.310789, Accuracy: 0.976000, Test accuracy: 0.970000
Distillation: Epoch : 23, Loss : 1.341269, Accuracy: 0.966000, Test accuracy: 0.970800
Distillation: Epoch : 24, Loss : 1.310831, Accuracy: 0.974000, Test accuracy: 0.971800
Distillation: Epoch : 25, Loss : 1.331234, Accuracy: 0.978000, Test accuracy: 0.971800
Distillation: Epoch : 26, Loss : 1.330115, Accuracy: 0.968000, Test accuracy: 0.972100
Distillation: Epoch : 27, Loss : 1.341904, Accuracy: 0.970000, Test accuracy: 0.973300
Distillation: Epoch : 28, Loss : 1.344565, Accuracy: 0.977000, Test accuracy: 0.974300
Distillation: Epoch : 29, Loss : 1.316753, Accuracy: 0.975000, Test accuracy: 0.975000
Distillation: Epoch : 30, Loss : 1.306284, Accuracy: 0.979000, Test accuracy: 0.975200
Distillation: Epoch : 31, Loss : 1.339046, Accuracy: 0.971000, Test accuracy: 0.974700
Distillation: Epoch : 32, Loss : 1.294687, Accuracy: 0.976000, Test accuracy: 0.975100
Distillation: Epoch : 33, Loss : 1.320811, Accuracy: 0.973000, Test accuracy: 0.975400
Distillation: Epoch : 34, Loss : 1.322040, Accuracy: 0.975000, Test accuracy: 0.975400
Distillation: Epoch : 35, Loss : 1.338609, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 36, Loss : 1.328310, Accuracy: 0.977000, Test accuracy: 0.976500
Distillation: Epoch : 37, Loss : 1.325640, Accuracy: 0.973000, Test accuracy: 0.977400
Distillation: Epoch : 38, Loss : 1.316274, Accuracy: 0.981000, Test accuracy: 0.977800
Distillation: Epoch : 39, Loss : 1.353587, Accuracy: 0.980000, Test accuracy: 0.977900
Distillation: Epoch : 40, Loss : 1.302117, Accuracy: 0.982000, Test accuracy: 0.978100
Distillation: Epoch : 41, Loss : 1.335993, Accuracy: 0.967000, Test accuracy: 0.978200
Distillation: Epoch : 42, Loss : 1.319331, Accuracy: 0.985000, Test accuracy: 0.977900
Distillation: Epoch : 43, Loss : 1.311769, Accuracy: 0.977000, Test accuracy: 0.978900
Distillation: Epoch : 44, Loss : 1.298703, Accuracy: 0.977000, Test accuracy: 0.978700
Distillation: Epoch : 45, Loss : 1.311560, Accuracy: 0.981000, Test accuracy: 0.978400
Distillation: Epoch : 46, Loss : 1.327552, Accuracy: 0.973000, Test accuracy: 0.978600
Distillation: Epoch : 47, Loss : 1.329801, Accuracy: 0.972000, Test accuracy: 0.979300
Distillation: Epoch : 48, Loss : 1.344492, Accuracy: 0.981000, Test accuracy: 0.980000
Distillation: Epoch : 49, Loss : 1.350134, Accuracy: 0.977000, Test accuracy: 0.979100
Distillation: Epoch : 50, Loss : 1.323496, Accuracy: 0.982000, Test accuracy: 0.979500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9795
Generating confusion matrix for student
[[ 970.    0.    3.    0.    1.    2.    3.    0.    3.    2.]
 [   0. 1128.    4.    0.    0.    0.    3.    4.    0.    6.]
 [   0.    1.  995.    2.    1.    0.    0.    9.    3.    0.]
 [   0.    1.    8.  994.    0.    8.    0.    3.    5.    8.]
 [   1.    0.    3.    0.  971.    1.    5.    3.    4.    6.]
 [   1.    0.    1.    5.    0.  872.    4.    0.    5.    3.]
 [   5.    4.    1.    0.    2.    5.  940.    0.    2.    1.]
 [   1.    0.    5.    4.    0.    1.    0. 1007.    3.    6.]
 [   2.    1.   12.    5.    2.    2.    3.    1.  946.    5.]
 [   0.    0.    0.    0.    5.    1.    0.    1.    3.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.797325, Accuracy: 0.751000, Test accuracy: 0.773200
Distillation: Epoch : 2, Loss : 1.669549, Accuracy: 0.838000, Test accuracy: 0.853000
Distillation: Epoch : 3, Loss : 1.604395, Accuracy: 0.871000, Test accuracy: 0.884600
Distillation: Epoch : 4, Loss : 1.571659, Accuracy: 0.892000, Test accuracy: 0.898500
Distillation: Epoch : 5, Loss : 1.558643, Accuracy: 0.895000, Test accuracy: 0.907400
Distillation: Epoch : 6, Loss : 1.566831, Accuracy: 0.910000, Test accuracy: 0.918200
Distillation: Epoch : 7, Loss : 1.542419, Accuracy: 0.928000, Test accuracy: 0.924500
Distillation: Epoch : 8, Loss : 1.534219, Accuracy: 0.915000, Test accuracy: 0.931200
Distillation: Epoch : 9, Loss : 1.512613, Accuracy: 0.948000, Test accuracy: 0.936900
Distillation: Epoch : 10, Loss : 1.482500, Accuracy: 0.952000, Test accuracy: 0.940900
Distillation: Epoch : 11, Loss : 1.518616, Accuracy: 0.929000, Test accuracy: 0.946200
Distillation: Epoch : 12, Loss : 1.486733, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 13, Loss : 1.493791, Accuracy: 0.956000, Test accuracy: 0.952100
Distillation: Epoch : 14, Loss : 1.496308, Accuracy: 0.954000, Test accuracy: 0.956900
Distillation: Epoch : 15, Loss : 1.471186, Accuracy: 0.954000, Test accuracy: 0.957800
Distillation: Epoch : 16, Loss : 1.477863, Accuracy: 0.956000, Test accuracy: 0.959900
Distillation: Epoch : 17, Loss : 1.476672, Accuracy: 0.961000, Test accuracy: 0.961100
Distillation: Epoch : 18, Loss : 1.460612, Accuracy: 0.965000, Test accuracy: 0.962700
Distillation: Epoch : 19, Loss : 1.460705, Accuracy: 0.977000, Test accuracy: 0.964200
Distillation: Epoch : 20, Loss : 1.478735, Accuracy: 0.967000, Test accuracy: 0.964600
Distillation: Epoch : 21, Loss : 1.473348, Accuracy: 0.953000, Test accuracy: 0.966000
Distillation: Epoch : 22, Loss : 1.465711, Accuracy: 0.964000, Test accuracy: 0.967500
Distillation: Epoch : 23, Loss : 1.447515, Accuracy: 0.973000, Test accuracy: 0.968500
Distillation: Epoch : 24, Loss : 1.473638, Accuracy: 0.966000, Test accuracy: 0.968400
Distillation: Epoch : 25, Loss : 1.459105, Accuracy: 0.966000, Test accuracy: 0.970500
Distillation: Epoch : 26, Loss : 1.482260, Accuracy: 0.967000, Test accuracy: 0.970200
Distillation: Epoch : 27, Loss : 1.460353, Accuracy: 0.964000, Test accuracy: 0.970000
Distillation: Epoch : 28, Loss : 1.446523, Accuracy: 0.973000, Test accuracy: 0.971000
Distillation: Epoch : 29, Loss : 1.466536, Accuracy: 0.975000, Test accuracy: 0.972300
Distillation: Epoch : 30, Loss : 1.468116, Accuracy: 0.961000, Test accuracy: 0.972700
Distillation: Epoch : 31, Loss : 1.461321, Accuracy: 0.965000, Test accuracy: 0.972800
Distillation: Epoch : 32, Loss : 1.445507, Accuracy: 0.976000, Test accuracy: 0.972700
Distillation: Epoch : 33, Loss : 1.456031, Accuracy: 0.967000, Test accuracy: 0.972700
Distillation: Epoch : 34, Loss : 1.457261, Accuracy: 0.972000, Test accuracy: 0.973200
Distillation: Epoch : 35, Loss : 1.465073, Accuracy: 0.966000, Test accuracy: 0.973500
Distillation: Epoch : 36, Loss : 1.453203, Accuracy: 0.973000, Test accuracy: 0.974100
Distillation: Epoch : 37, Loss : 1.429301, Accuracy: 0.974000, Test accuracy: 0.973700
Distillation: Epoch : 38, Loss : 1.453900, Accuracy: 0.972000, Test accuracy: 0.974900
Distillation: Epoch : 39, Loss : 1.451537, Accuracy: 0.973000, Test accuracy: 0.974200
Distillation: Epoch : 40, Loss : 1.459592, Accuracy: 0.974000, Test accuracy: 0.974900
Distillation: Epoch : 41, Loss : 1.459495, Accuracy: 0.975000, Test accuracy: 0.974900
Distillation: Epoch : 42, Loss : 1.451092, Accuracy: 0.968000, Test accuracy: 0.975300
Distillation: Epoch : 43, Loss : 1.450220, Accuracy: 0.981000, Test accuracy: 0.975700
Distillation: Epoch : 44, Loss : 1.446730, Accuracy: 0.971000, Test accuracy: 0.975100
Distillation: Epoch : 45, Loss : 1.457269, Accuracy: 0.975000, Test accuracy: 0.975500
Distillation: Epoch : 46, Loss : 1.441483, Accuracy: 0.975000, Test accuracy: 0.975800
Distillation: Epoch : 47, Loss : 1.444677, Accuracy: 0.979000, Test accuracy: 0.975900
Distillation: Epoch : 48, Loss : 1.439542, Accuracy: 0.969000, Test accuracy: 0.976000
Distillation: Epoch : 49, Loss : 1.458114, Accuracy: 0.972000, Test accuracy: 0.976400
Distillation: Epoch : 50, Loss : 1.447646, Accuracy: 0.977000, Test accuracy: 0.976600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9766
Generating confusion matrix for student
[[ 970.    0.    6.    0.    1.    2.    5.    1.    3.    4.]
 [   0. 1125.    4.    0.    0.    0.    2.    5.    0.    5.]
 [   0.    2.  989.    0.    2.    1.    0.    8.    2.    0.]
 [   0.    1.    5.  999.    0.   16.    0.    3.    6.    7.]
 [   0.    0.    3.    1.  967.    0.    4.    4.    5.    9.]
 [   0.    1.    0.    3.    0.  860.    1.    0.    2.    4.]
 [   5.    5.    0.    0.    2.    5.  944.    0.    4.    0.]
 [   2.    0.    9.    2.    1.    2.    0. 1002.    4.    9.]
 [   3.    1.   15.    3.    2.    2.    2.    1.  941.    2.]
 [   0.    0.    1.    2.    7.    4.    0.    4.    7.  969.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.958087, Accuracy: 0.760000, Test accuracy: 0.749800
Distillation: Epoch : 2, Loss : 1.872710, Accuracy: 0.858000, Test accuracy: 0.845300
Distillation: Epoch : 3, Loss : 1.852622, Accuracy: 0.874000, Test accuracy: 0.874500
Distillation: Epoch : 4, Loss : 1.824288, Accuracy: 0.893000, Test accuracy: 0.898800
Distillation: Epoch : 5, Loss : 1.803572, Accuracy: 0.914000, Test accuracy: 0.913000
Distillation: Epoch : 6, Loss : 1.807980, Accuracy: 0.914000, Test accuracy: 0.924200
Distillation: Epoch : 7, Loss : 1.793221, Accuracy: 0.937000, Test accuracy: 0.935100
Distillation: Epoch : 8, Loss : 1.768538, Accuracy: 0.944000, Test accuracy: 0.939600
Distillation: Epoch : 9, Loss : 1.770509, Accuracy: 0.942000, Test accuracy: 0.944800
Distillation: Epoch : 10, Loss : 1.767978, Accuracy: 0.951000, Test accuracy: 0.948200
Distillation: Epoch : 11, Loss : 1.777307, Accuracy: 0.947000, Test accuracy: 0.950000
Distillation: Epoch : 12, Loss : 1.757463, Accuracy: 0.947000, Test accuracy: 0.953100
Distillation: Epoch : 13, Loss : 1.794317, Accuracy: 0.945000, Test accuracy: 0.956000
Distillation: Epoch : 14, Loss : 1.766934, Accuracy: 0.954000, Test accuracy: 0.957800
Distillation: Epoch : 15, Loss : 1.768354, Accuracy: 0.958000, Test accuracy: 0.959300
Distillation: Epoch : 16, Loss : 1.739086, Accuracy: 0.965000, Test accuracy: 0.961200
Distillation: Epoch : 17, Loss : 1.765097, Accuracy: 0.961000, Test accuracy: 0.962500
Distillation: Epoch : 18, Loss : 1.765794, Accuracy: 0.964000, Test accuracy: 0.964200
Distillation: Epoch : 19, Loss : 1.751086, Accuracy: 0.951000, Test accuracy: 0.965900
Distillation: Epoch : 20, Loss : 1.762902, Accuracy: 0.967000, Test accuracy: 0.967000
Distillation: Epoch : 21, Loss : 1.739717, Accuracy: 0.963000, Test accuracy: 0.968100
Distillation: Epoch : 22, Loss : 1.747191, Accuracy: 0.965000, Test accuracy: 0.968900
Distillation: Epoch : 23, Loss : 1.725825, Accuracy: 0.966000, Test accuracy: 0.969900
Distillation: Epoch : 24, Loss : 1.742691, Accuracy: 0.969000, Test accuracy: 0.970400
Distillation: Epoch : 25, Loss : 1.749489, Accuracy: 0.958000, Test accuracy: 0.971300
Distillation: Epoch : 26, Loss : 1.738286, Accuracy: 0.970000, Test accuracy: 0.971700
Distillation: Epoch : 27, Loss : 1.736596, Accuracy: 0.966000, Test accuracy: 0.971800
Distillation: Epoch : 28, Loss : 1.730971, Accuracy: 0.961000, Test accuracy: 0.972700
Distillation: Epoch : 29, Loss : 1.733732, Accuracy: 0.976000, Test accuracy: 0.973100
Distillation: Epoch : 30, Loss : 1.747483, Accuracy: 0.968000, Test accuracy: 0.973400
Distillation: Epoch : 31, Loss : 1.734058, Accuracy: 0.965000, Test accuracy: 0.973600
Distillation: Epoch : 32, Loss : 1.749945, Accuracy: 0.973000, Test accuracy: 0.974200
Distillation: Epoch : 33, Loss : 1.750491, Accuracy: 0.973000, Test accuracy: 0.975200
Distillation: Epoch : 34, Loss : 1.760026, Accuracy: 0.968000, Test accuracy: 0.974500
Distillation: Epoch : 35, Loss : 1.754378, Accuracy: 0.981000, Test accuracy: 0.975200
Distillation: Epoch : 36, Loss : 1.754538, Accuracy: 0.971000, Test accuracy: 0.975400
Distillation: Epoch : 37, Loss : 1.746871, Accuracy: 0.977000, Test accuracy: 0.975700
Distillation: Epoch : 38, Loss : 1.740561, Accuracy: 0.977000, Test accuracy: 0.975700
Distillation: Epoch : 39, Loss : 1.747530, Accuracy: 0.980000, Test accuracy: 0.975800
Distillation: Epoch : 40, Loss : 1.734489, Accuracy: 0.972000, Test accuracy: 0.975400
Distillation: Epoch : 41, Loss : 1.735794, Accuracy: 0.974000, Test accuracy: 0.975800
Distillation: Epoch : 42, Loss : 1.731654, Accuracy: 0.973000, Test accuracy: 0.975900
Distillation: Epoch : 43, Loss : 1.737564, Accuracy: 0.980000, Test accuracy: 0.976200
Distillation: Epoch : 44, Loss : 1.736513, Accuracy: 0.971000, Test accuracy: 0.976900
Distillation: Epoch : 45, Loss : 1.757151, Accuracy: 0.969000, Test accuracy: 0.976800
Distillation: Epoch : 46, Loss : 1.759067, Accuracy: 0.975000, Test accuracy: 0.976900
Distillation: Epoch : 47, Loss : 1.746057, Accuracy: 0.970000, Test accuracy: 0.977000
Distillation: Epoch : 48, Loss : 1.739289, Accuracy: 0.976000, Test accuracy: 0.976900
Distillation: Epoch : 49, Loss : 1.741454, Accuracy: 0.971000, Test accuracy: 0.977000
Distillation: Epoch : 50, Loss : 1.734660, Accuracy: 0.971000, Test accuracy: 0.977700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9777
Generating confusion matrix for student
[[ 970.    0.    3.    1.    0.    2.    3.    0.    2.    4.]
 [   0. 1126.    2.    0.    1.    0.    3.    4.    0.    5.]
 [   0.    1. 1004.    0.    1.    0.    0.   10.    5.    0.]
 [   0.    3.    2.  996.    0.    8.    1.    4.    8.    7.]
 [   0.    0.    1.    0.  965.    0.    3.    1.    5.    6.]
 [   2.    0.    1.    2.    0.  873.    8.    2.    7.    8.]
 [   4.    2.    1.    0.    5.    4.  938.    0.    0.    0.]
 [   1.    0.    5.    7.    0.    1.    0.  999.    4.    8.]
 [   3.    3.   12.    3.    2.    2.    2.    2.  937.    2.]
 [   0.    0.    1.    1.    8.    2.    0.    6.    6.  969.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.184805, Accuracy: 0.653000, Test accuracy: 0.655500
Distillation: Epoch : 2, Loss : 2.088326, Accuracy: 0.807000, Test accuracy: 0.817200
Distillation: Epoch : 3, Loss : 2.056595, Accuracy: 0.861000, Test accuracy: 0.864000
Distillation: Epoch : 4, Loss : 2.044103, Accuracy: 0.886000, Test accuracy: 0.898700
Distillation: Epoch : 5, Loss : 2.043312, Accuracy: 0.917000, Test accuracy: 0.912700
Distillation: Epoch : 6, Loss : 2.026655, Accuracy: 0.934000, Test accuracy: 0.931100
Distillation: Epoch : 7, Loss : 2.025086, Accuracy: 0.938000, Test accuracy: 0.940900
Distillation: Epoch : 8, Loss : 2.017959, Accuracy: 0.953000, Test accuracy: 0.948300
Distillation: Epoch : 9, Loss : 2.013891, Accuracy: 0.949000, Test accuracy: 0.954000
Distillation: Epoch : 10, Loss : 2.015733, Accuracy: 0.959000, Test accuracy: 0.959000
Distillation: Epoch : 11, Loss : 2.024281, Accuracy: 0.948000, Test accuracy: 0.959200
Distillation: Epoch : 12, Loss : 2.018462, Accuracy: 0.953000, Test accuracy: 0.962200
Distillation: Epoch : 13, Loss : 2.008099, Accuracy: 0.942000, Test accuracy: 0.962900
Distillation: Epoch : 14, Loss : 2.007010, Accuracy: 0.956000, Test accuracy: 0.964700
Distillation: Epoch : 15, Loss : 2.003033, Accuracy: 0.958000, Test accuracy: 0.964400
Distillation: Epoch : 16, Loss : 2.006873, Accuracy: 0.967000, Test accuracy: 0.965800
Distillation: Epoch : 17, Loss : 2.011047, Accuracy: 0.964000, Test accuracy: 0.967000
Distillation: Epoch : 18, Loss : 2.015957, Accuracy: 0.960000, Test accuracy: 0.968500
Distillation: Epoch : 19, Loss : 2.003047, Accuracy: 0.962000, Test accuracy: 0.968000
Distillation: Epoch : 20, Loss : 2.006762, Accuracy: 0.957000, Test accuracy: 0.969300
Distillation: Epoch : 21, Loss : 2.002143, Accuracy: 0.976000, Test accuracy: 0.970800
Distillation: Epoch : 22, Loss : 1.996954, Accuracy: 0.971000, Test accuracy: 0.970900
Distillation: Epoch : 23, Loss : 2.004831, Accuracy: 0.968000, Test accuracy: 0.971600
Distillation: Epoch : 24, Loss : 1.999821, Accuracy: 0.971000, Test accuracy: 0.972700
Distillation: Epoch : 25, Loss : 1.999739, Accuracy: 0.964000, Test accuracy: 0.973000
Distillation: Epoch : 26, Loss : 1.999645, Accuracy: 0.979000, Test accuracy: 0.973300
Distillation: Epoch : 27, Loss : 1.992644, Accuracy: 0.969000, Test accuracy: 0.973500
Distillation: Epoch : 28, Loss : 2.005880, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 29, Loss : 2.006692, Accuracy: 0.974000, Test accuracy: 0.975100
Distillation: Epoch : 30, Loss : 2.011036, Accuracy: 0.965000, Test accuracy: 0.975200
Distillation: Epoch : 31, Loss : 2.003839, Accuracy: 0.971000, Test accuracy: 0.975500
Distillation: Epoch : 32, Loss : 2.001530, Accuracy: 0.977000, Test accuracy: 0.976000
Distillation: Epoch : 33, Loss : 2.002720, Accuracy: 0.967000, Test accuracy: 0.976000
Distillation: Epoch : 34, Loss : 1.996546, Accuracy: 0.974000, Test accuracy: 0.976000
Distillation: Epoch : 35, Loss : 2.004988, Accuracy: 0.972000, Test accuracy: 0.977400
Distillation: Epoch : 36, Loss : 1.990556, Accuracy: 0.976000, Test accuracy: 0.977800
Distillation: Epoch : 37, Loss : 1.990495, Accuracy: 0.977000, Test accuracy: 0.977500
Distillation: Epoch : 38, Loss : 1.992436, Accuracy: 0.977000, Test accuracy: 0.977700
Distillation: Epoch : 39, Loss : 2.007867, Accuracy: 0.966000, Test accuracy: 0.977900
Distillation: Epoch : 40, Loss : 1.988802, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 41, Loss : 2.005314, Accuracy: 0.966000, Test accuracy: 0.978400
Distillation: Epoch : 42, Loss : 1.996326, Accuracy: 0.978000, Test accuracy: 0.978000
Distillation: Epoch : 43, Loss : 1.994755, Accuracy: 0.976000, Test accuracy: 0.978900
Distillation: Epoch : 44, Loss : 1.997606, Accuracy: 0.982000, Test accuracy: 0.978900
Distillation: Epoch : 45, Loss : 1.995865, Accuracy: 0.978000, Test accuracy: 0.979100
Distillation: Epoch : 46, Loss : 2.005807, Accuracy: 0.977000, Test accuracy: 0.979100
Distillation: Epoch : 47, Loss : 1.999899, Accuracy: 0.982000, Test accuracy: 0.978900
Distillation: Epoch : 48, Loss : 1.993073, Accuracy: 0.977000, Test accuracy: 0.978500
Distillation: Epoch : 49, Loss : 1.992883, Accuracy: 0.983000, Test accuracy: 0.979600
Distillation: Epoch : 50, Loss : 1.982414, Accuracy: 0.978000, Test accuracy: 0.979100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9791
Generating confusion matrix for student
[[ 970.    0.    3.    0.    0.    2.    5.    0.    3.    4.]
 [   0. 1127.    6.    0.    0.    0.    2.    5.    0.    7.]
 [   0.    1.  994.    1.    0.    0.    0.    7.    1.    0.]
 [   0.    3.    6. 1001.    0.    9.    0.    1.    6.    7.]
 [   1.    0.    6.    0.  974.    0.    6.    1.    5.   15.]
 [   1.    0.    0.    2.    0.  874.   10.    0.    3.    6.]
 [   4.    2.    0.    0.    1.    3.  934.    0.    2.    0.]
 [   1.    1.    8.    1.    0.    1.    0. 1011.    5.    5.]
 [   3.    1.    9.    4.    2.    1.    1.    2.  945.    4.]
 [   0.    0.    0.    1.    5.    2.    0.    1.    4.  961.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.731363, Accuracy: 0.844000, Test accuracy: 0.827300
Distillation: Epoch : 2, Loss : 0.386297, Accuracy: 0.914000, Test accuracy: 0.892700
Distillation: Epoch : 3, Loss : 0.331654, Accuracy: 0.898000, Test accuracy: 0.912400
Distillation: Epoch : 4, Loss : 0.296249, Accuracy: 0.915000, Test accuracy: 0.922900
Distillation: Epoch : 5, Loss : 0.246524, Accuracy: 0.924000, Test accuracy: 0.929300
Distillation: Epoch : 6, Loss : 0.266848, Accuracy: 0.917000, Test accuracy: 0.935400
Distillation: Epoch : 7, Loss : 0.257508, Accuracy: 0.920000, Test accuracy: 0.937300
Distillation: Epoch : 8, Loss : 0.190876, Accuracy: 0.948000, Test accuracy: 0.941500
Distillation: Epoch : 9, Loss : 0.188859, Accuracy: 0.937000, Test accuracy: 0.943000
Distillation: Epoch : 10, Loss : 0.186130, Accuracy: 0.949000, Test accuracy: 0.946700
Distillation: Epoch : 11, Loss : 0.190774, Accuracy: 0.945000, Test accuracy: 0.948700
Distillation: Epoch : 12, Loss : 0.242001, Accuracy: 0.927000, Test accuracy: 0.951000
Distillation: Epoch : 13, Loss : 0.183582, Accuracy: 0.951000, Test accuracy: 0.951400
Distillation: Epoch : 14, Loss : 0.182799, Accuracy: 0.944000, Test accuracy: 0.953000
Distillation: Epoch : 15, Loss : 0.184131, Accuracy: 0.938000, Test accuracy: 0.954500
Distillation: Epoch : 16, Loss : 0.154397, Accuracy: 0.954000, Test accuracy: 0.956900
Distillation: Epoch : 17, Loss : 0.154842, Accuracy: 0.947000, Test accuracy: 0.956800
Distillation: Epoch : 18, Loss : 0.176319, Accuracy: 0.952000, Test accuracy: 0.958000
Distillation: Epoch : 19, Loss : 0.165312, Accuracy: 0.951000, Test accuracy: 0.959900
Distillation: Epoch : 20, Loss : 0.139335, Accuracy: 0.955000, Test accuracy: 0.961300
Distillation: Epoch : 21, Loss : 0.144796, Accuracy: 0.963000, Test accuracy: 0.961900
Distillation: Epoch : 22, Loss : 0.126841, Accuracy: 0.960000, Test accuracy: 0.961000
Distillation: Epoch : 23, Loss : 0.135019, Accuracy: 0.961000, Test accuracy: 0.962500
Distillation: Epoch : 24, Loss : 0.169455, Accuracy: 0.951000, Test accuracy: 0.962900
Distillation: Epoch : 25, Loss : 0.100776, Accuracy: 0.971000, Test accuracy: 0.962700
Distillation: Epoch : 26, Loss : 0.139141, Accuracy: 0.962000, Test accuracy: 0.964200
Distillation: Epoch : 27, Loss : 0.162203, Accuracy: 0.963000, Test accuracy: 0.964200
Distillation: Epoch : 28, Loss : 0.133650, Accuracy: 0.959000, Test accuracy: 0.965300
Distillation: Epoch : 29, Loss : 0.120891, Accuracy: 0.956000, Test accuracy: 0.966000
Distillation: Epoch : 30, Loss : 0.144098, Accuracy: 0.958000, Test accuracy: 0.966800
Distillation: Epoch : 31, Loss : 0.094833, Accuracy: 0.974000, Test accuracy: 0.966000
Distillation: Epoch : 32, Loss : 0.117930, Accuracy: 0.969000, Test accuracy: 0.967300
Distillation: Epoch : 33, Loss : 0.145891, Accuracy: 0.958000, Test accuracy: 0.967200
Distillation: Epoch : 34, Loss : 0.100217, Accuracy: 0.974000, Test accuracy: 0.967400
Distillation: Epoch : 35, Loss : 0.099403, Accuracy: 0.974000, Test accuracy: 0.967900
Distillation: Epoch : 36, Loss : 0.121605, Accuracy: 0.964000, Test accuracy: 0.968600
Distillation: Epoch : 37, Loss : 0.141504, Accuracy: 0.960000, Test accuracy: 0.968700
Distillation: Epoch : 38, Loss : 0.132671, Accuracy: 0.963000, Test accuracy: 0.968400
Distillation: Epoch : 39, Loss : 0.111651, Accuracy: 0.970000, Test accuracy: 0.968500
Distillation: Epoch : 40, Loss : 0.114635, Accuracy: 0.964000, Test accuracy: 0.969500
Distillation: Epoch : 41, Loss : 0.125666, Accuracy: 0.972000, Test accuracy: 0.969800
Distillation: Epoch : 42, Loss : 0.105541, Accuracy: 0.966000, Test accuracy: 0.968900
Distillation: Epoch : 43, Loss : 0.117584, Accuracy: 0.965000, Test accuracy: 0.969000
Distillation: Epoch : 44, Loss : 0.089861, Accuracy: 0.973000, Test accuracy: 0.969600
Distillation: Epoch : 45, Loss : 0.123320, Accuracy: 0.965000, Test accuracy: 0.969100
Distillation: Epoch : 46, Loss : 0.107131, Accuracy: 0.963000, Test accuracy: 0.969700
Distillation: Epoch : 47, Loss : 0.103338, Accuracy: 0.965000, Test accuracy: 0.970400
Distillation: Epoch : 48, Loss : 0.088808, Accuracy: 0.973000, Test accuracy: 0.971000
Distillation: Epoch : 49, Loss : 0.098250, Accuracy: 0.970000, Test accuracy: 0.970100
Distillation: Epoch : 50, Loss : 0.081891, Accuracy: 0.974000, Test accuracy: 0.970300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9703
Generating confusion matrix for student2
[[ 968.    0.    4.    0.    1.    1.   10.    1.    6.    8.]
 [   1. 1123.   10.    0.    2.    0.    3.    5.    2.    6.]
 [   1.    4.  984.    3.    2.    1.    1.   13.    8.    1.]
 [   0.    4.    7.  989.    0.    7.    0.    5.    9.    6.]
 [   0.    0.    3.    1.  966.    0.    7.    2.    3.   13.]
 [   0.    0.    0.    7.    0.  875.    8.    2.    9.    2.]
 [   5.    1.    2.    0.    2.    4.  927.    0.    2.    0.]
 [   3.    0.    8.    5.    0.    0.    0.  983.    5.    9.]
 [   2.    3.   12.    4.    2.    3.    2.    3.  929.    5.]
 [   0.    0.    2.    1.    7.    1.    0.   14.    1.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.082824, Accuracy: 0.779000, Test accuracy: 0.804600
Distillation: Epoch : 2, Loss : 0.579700, Accuracy: 0.858000, Test accuracy: 0.864800
Distillation: Epoch : 3, Loss : 0.449251, Accuracy: 0.879000, Test accuracy: 0.886200
Distillation: Epoch : 4, Loss : 0.383457, Accuracy: 0.888000, Test accuracy: 0.896000
Distillation: Epoch : 5, Loss : 0.369456, Accuracy: 0.892000, Test accuracy: 0.905400
Distillation: Epoch : 6, Loss : 0.298439, Accuracy: 0.920000, Test accuracy: 0.910200
Distillation: Epoch : 7, Loss : 0.350925, Accuracy: 0.894000, Test accuracy: 0.913200
Distillation: Epoch : 8, Loss : 0.334285, Accuracy: 0.909000, Test accuracy: 0.915700
Distillation: Epoch : 9, Loss : 0.322669, Accuracy: 0.916000, Test accuracy: 0.918100
Distillation: Epoch : 10, Loss : 0.316187, Accuracy: 0.906000, Test accuracy: 0.919400
Distillation: Epoch : 11, Loss : 0.305972, Accuracy: 0.918000, Test accuracy: 0.921200
Distillation: Epoch : 12, Loss : 0.308536, Accuracy: 0.916000, Test accuracy: 0.922900
Distillation: Epoch : 13, Loss : 0.286322, Accuracy: 0.928000, Test accuracy: 0.925000
Distillation: Epoch : 14, Loss : 0.297684, Accuracy: 0.915000, Test accuracy: 0.925900
Distillation: Epoch : 15, Loss : 0.286167, Accuracy: 0.922000, Test accuracy: 0.928000
Distillation: Epoch : 16, Loss : 0.270795, Accuracy: 0.926000, Test accuracy: 0.929600
Distillation: Epoch : 17, Loss : 0.315341, Accuracy: 0.921000, Test accuracy: 0.929700
Distillation: Epoch : 18, Loss : 0.275005, Accuracy: 0.929000, Test accuracy: 0.930900
Distillation: Epoch : 19, Loss : 0.241561, Accuracy: 0.940000, Test accuracy: 0.932400
Distillation: Epoch : 20, Loss : 0.252870, Accuracy: 0.929000, Test accuracy: 0.933200
Distillation: Epoch : 21, Loss : 0.235916, Accuracy: 0.930000, Test accuracy: 0.936100
Distillation: Epoch : 22, Loss : 0.198762, Accuracy: 0.952000, Test accuracy: 0.935000
Distillation: Epoch : 23, Loss : 0.300006, Accuracy: 0.924000, Test accuracy: 0.937000
Distillation: Epoch : 24, Loss : 0.227780, Accuracy: 0.935000, Test accuracy: 0.937400
Distillation: Epoch : 25, Loss : 0.224915, Accuracy: 0.936000, Test accuracy: 0.939300
Distillation: Epoch : 26, Loss : 0.207886, Accuracy: 0.942000, Test accuracy: 0.938400
Distillation: Epoch : 27, Loss : 0.229759, Accuracy: 0.936000, Test accuracy: 0.940200
Distillation: Epoch : 28, Loss : 0.255054, Accuracy: 0.932000, Test accuracy: 0.941000
Distillation: Epoch : 29, Loss : 0.216132, Accuracy: 0.939000, Test accuracy: 0.940500
Distillation: Epoch : 30, Loss : 0.221466, Accuracy: 0.941000, Test accuracy: 0.942800
Distillation: Epoch : 31, Loss : 0.206018, Accuracy: 0.950000, Test accuracy: 0.942300
Distillation: Epoch : 32, Loss : 0.235031, Accuracy: 0.938000, Test accuracy: 0.943100
Distillation: Epoch : 33, Loss : 0.200380, Accuracy: 0.956000, Test accuracy: 0.945400
Distillation: Epoch : 34, Loss : 0.219423, Accuracy: 0.939000, Test accuracy: 0.944400
Distillation: Epoch : 35, Loss : 0.216385, Accuracy: 0.940000, Test accuracy: 0.946100
Distillation: Epoch : 36, Loss : 0.223603, Accuracy: 0.940000, Test accuracy: 0.946600
Distillation: Epoch : 37, Loss : 0.186631, Accuracy: 0.956000, Test accuracy: 0.946800
Distillation: Epoch : 38, Loss : 0.227207, Accuracy: 0.948000, Test accuracy: 0.947800
Distillation: Epoch : 39, Loss : 0.207718, Accuracy: 0.949000, Test accuracy: 0.948100
Distillation: Epoch : 40, Loss : 0.205642, Accuracy: 0.952000, Test accuracy: 0.949000
Distillation: Epoch : 41, Loss : 0.190323, Accuracy: 0.957000, Test accuracy: 0.948700
Distillation: Epoch : 42, Loss : 0.184516, Accuracy: 0.950000, Test accuracy: 0.951100
Distillation: Epoch : 43, Loss : 0.186927, Accuracy: 0.959000, Test accuracy: 0.950400
Distillation: Epoch : 44, Loss : 0.201309, Accuracy: 0.940000, Test accuracy: 0.950500
Distillation: Epoch : 45, Loss : 0.187282, Accuracy: 0.945000, Test accuracy: 0.951400
Distillation: Epoch : 46, Loss : 0.206719, Accuracy: 0.940000, Test accuracy: 0.951900
Distillation: Epoch : 47, Loss : 0.242394, Accuracy: 0.934000, Test accuracy: 0.952500
Distillation: Epoch : 48, Loss : 0.201851, Accuracy: 0.950000, Test accuracy: 0.954200
Distillation: Epoch : 49, Loss : 0.183196, Accuracy: 0.957000, Test accuracy: 0.952900
Distillation: Epoch : 50, Loss : 0.202691, Accuracy: 0.948000, Test accuracy: 0.953100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9531
Generating confusion matrix for student2
[[ 971.    0.    7.    4.    1.    6.    8.    2.    8.    9.]
 [   0. 1116.    7.    0.    1.    2.    3.    7.    4.    6.]
 [   0.    3.  971.   11.    3.    1.    1.   22.   10.    3.]
 [   0.    1.    9.  959.    0.   11.    1.    5.   17.   10.]
 [   0.    0.    6.    0.  955.    0.    5.    2.    6.    9.]
 [   3.    0.    0.    9.    0.  840.    9.    0.   10.    3.]
 [   3.    4.    6.    1.    6.   11.  925.    0.    9.    0.]
 [   1.    1.    8.    9.    1.    2.    3.  957.    9.   16.]
 [   2.   10.   14.   11.    3.   14.    3.    1.  889.    5.]
 [   0.    0.    4.    6.   12.    5.    0.   32.   12.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.375371, Accuracy: 0.805000, Test accuracy: 0.804100
Distillation: Epoch : 2, Loss : 0.872126, Accuracy: 0.839000, Test accuracy: 0.849600
Distillation: Epoch : 3, Loss : 0.773228, Accuracy: 0.861000, Test accuracy: 0.876400
Distillation: Epoch : 4, Loss : 0.727751, Accuracy: 0.882000, Test accuracy: 0.888200
Distillation: Epoch : 5, Loss : 0.668931, Accuracy: 0.898000, Test accuracy: 0.896400
Distillation: Epoch : 6, Loss : 0.711189, Accuracy: 0.889000, Test accuracy: 0.901900
Distillation: Epoch : 7, Loss : 0.723734, Accuracy: 0.883000, Test accuracy: 0.906000
Distillation: Epoch : 8, Loss : 0.674948, Accuracy: 0.892000, Test accuracy: 0.906800
Distillation: Epoch : 9, Loss : 0.686470, Accuracy: 0.899000, Test accuracy: 0.910500
Distillation: Epoch : 10, Loss : 0.645199, Accuracy: 0.904000, Test accuracy: 0.910900
Distillation: Epoch : 11, Loss : 0.652448, Accuracy: 0.897000, Test accuracy: 0.913300
Distillation: Epoch : 12, Loss : 0.647506, Accuracy: 0.901000, Test accuracy: 0.913700
Distillation: Epoch : 13, Loss : 0.665239, Accuracy: 0.905000, Test accuracy: 0.915800
Distillation: Epoch : 14, Loss : 0.586522, Accuracy: 0.935000, Test accuracy: 0.916900
Distillation: Epoch : 15, Loss : 0.628973, Accuracy: 0.919000, Test accuracy: 0.918600
Distillation: Epoch : 16, Loss : 0.612895, Accuracy: 0.911000, Test accuracy: 0.920300
Distillation: Epoch : 17, Loss : 0.629735, Accuracy: 0.916000, Test accuracy: 0.922200
Distillation: Epoch : 18, Loss : 0.604588, Accuracy: 0.924000, Test accuracy: 0.923900
Distillation: Epoch : 19, Loss : 0.656612, Accuracy: 0.910000, Test accuracy: 0.926000
Distillation: Epoch : 20, Loss : 0.600499, Accuracy: 0.928000, Test accuracy: 0.928400
Distillation: Epoch : 21, Loss : 0.605157, Accuracy: 0.933000, Test accuracy: 0.930500
Distillation: Epoch : 22, Loss : 0.597261, Accuracy: 0.934000, Test accuracy: 0.931700
Distillation: Epoch : 23, Loss : 0.573972, Accuracy: 0.945000, Test accuracy: 0.933200
Distillation: Epoch : 24, Loss : 0.569701, Accuracy: 0.931000, Test accuracy: 0.934800
Distillation: Epoch : 25, Loss : 0.581636, Accuracy: 0.937000, Test accuracy: 0.935800
Distillation: Epoch : 26, Loss : 0.565259, Accuracy: 0.945000, Test accuracy: 0.939400
Distillation: Epoch : 27, Loss : 0.558328, Accuracy: 0.949000, Test accuracy: 0.940500
Distillation: Epoch : 28, Loss : 0.577838, Accuracy: 0.950000, Test accuracy: 0.942200
Distillation: Epoch : 29, Loss : 0.547588, Accuracy: 0.945000, Test accuracy: 0.944200
Distillation: Epoch : 30, Loss : 0.557421, Accuracy: 0.950000, Test accuracy: 0.945200
Distillation: Epoch : 31, Loss : 0.546690, Accuracy: 0.950000, Test accuracy: 0.947000
Distillation: Epoch : 32, Loss : 0.543996, Accuracy: 0.948000, Test accuracy: 0.948800
Distillation: Epoch : 33, Loss : 0.535319, Accuracy: 0.942000, Test accuracy: 0.949700
Distillation: Epoch : 34, Loss : 0.517987, Accuracy: 0.959000, Test accuracy: 0.951300
Distillation: Epoch : 35, Loss : 0.522424, Accuracy: 0.950000, Test accuracy: 0.953100
Distillation: Epoch : 36, Loss : 0.517767, Accuracy: 0.953000, Test accuracy: 0.952500
Distillation: Epoch : 37, Loss : 0.519267, Accuracy: 0.952000, Test accuracy: 0.954700
Distillation: Epoch : 38, Loss : 0.540077, Accuracy: 0.942000, Test accuracy: 0.956000
Distillation: Epoch : 39, Loss : 0.529841, Accuracy: 0.949000, Test accuracy: 0.956500
Distillation: Epoch : 40, Loss : 0.515365, Accuracy: 0.951000, Test accuracy: 0.957300
Distillation: Epoch : 41, Loss : 0.512188, Accuracy: 0.960000, Test accuracy: 0.957100
Distillation: Epoch : 42, Loss : 0.530752, Accuracy: 0.953000, Test accuracy: 0.958500
Distillation: Epoch : 43, Loss : 0.507302, Accuracy: 0.967000, Test accuracy: 0.959500
Distillation: Epoch : 44, Loss : 0.498357, Accuracy: 0.965000, Test accuracy: 0.959500
Distillation: Epoch : 45, Loss : 0.528179, Accuracy: 0.958000, Test accuracy: 0.960300
Distillation: Epoch : 46, Loss : 0.490054, Accuracy: 0.972000, Test accuracy: 0.961500
Distillation: Epoch : 47, Loss : 0.508342, Accuracy: 0.957000, Test accuracy: 0.962000
Distillation: Epoch : 48, Loss : 0.515895, Accuracy: 0.972000, Test accuracy: 0.962700
Distillation: Epoch : 49, Loss : 0.518451, Accuracy: 0.960000, Test accuracy: 0.963600
Distillation: Epoch : 50, Loss : 0.527075, Accuracy: 0.959000, Test accuracy: 0.964100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9641
Generating confusion matrix for student2
[[ 969.    0.    4.    1.    1.    1.    7.    2.    6.    4.]
 [   0. 1124.    6.    0.    2.    0.    3.    7.    5.    5.]
 [   0.    2.  979.    7.    1.    1.    2.   21.    6.    1.]
 [   1.    2.    9.  983.    0.    7.    1.    5.   11.   11.]
 [   1.    1.    2.    1.  959.    0.    7.    4.    9.   16.]
 [   1.    0.    1.    5.    0.  869.    5.    0.    8.    7.]
 [   5.    4.    2.    0.    3.    4.  931.    0.    4.    0.]
 [   2.    0.   10.    5.    3.    2.    0.  969.    7.   14.]
 [   1.    2.   15.    5.    2.    5.    2.    2.  909.    2.]
 [   0.    0.    4.    3.   11.    3.    0.   18.    9.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.704865, Accuracy: 0.757000, Test accuracy: 0.779500
Distillation: Epoch : 2, Loss : 1.070516, Accuracy: 0.844000, Test accuracy: 0.852000
Distillation: Epoch : 3, Loss : 0.879943, Accuracy: 0.882000, Test accuracy: 0.883400
Distillation: Epoch : 4, Loss : 0.924260, Accuracy: 0.877000, Test accuracy: 0.899300
Distillation: Epoch : 5, Loss : 0.805261, Accuracy: 0.925000, Test accuracy: 0.910800
Distillation: Epoch : 6, Loss : 0.810973, Accuracy: 0.919000, Test accuracy: 0.918100
Distillation: Epoch : 7, Loss : 0.797663, Accuracy: 0.915000, Test accuracy: 0.924200
Distillation: Epoch : 8, Loss : 0.787745, Accuracy: 0.927000, Test accuracy: 0.927800
Distillation: Epoch : 9, Loss : 0.800679, Accuracy: 0.914000, Test accuracy: 0.931700
Distillation: Epoch : 10, Loss : 0.732566, Accuracy: 0.939000, Test accuracy: 0.934300
Distillation: Epoch : 11, Loss : 0.713368, Accuracy: 0.948000, Test accuracy: 0.937600
Distillation: Epoch : 12, Loss : 0.733965, Accuracy: 0.932000, Test accuracy: 0.942300
Distillation: Epoch : 13, Loss : 0.732009, Accuracy: 0.939000, Test accuracy: 0.944500
Distillation: Epoch : 14, Loss : 0.740271, Accuracy: 0.926000, Test accuracy: 0.947700
Distillation: Epoch : 15, Loss : 0.734831, Accuracy: 0.938000, Test accuracy: 0.948900
Distillation: Epoch : 16, Loss : 0.712858, Accuracy: 0.951000, Test accuracy: 0.951000
Distillation: Epoch : 17, Loss : 0.744545, Accuracy: 0.937000, Test accuracy: 0.953400
Distillation: Epoch : 18, Loss : 0.667146, Accuracy: 0.958000, Test accuracy: 0.954400
Distillation: Epoch : 19, Loss : 0.703124, Accuracy: 0.943000, Test accuracy: 0.956900
Distillation: Epoch : 20, Loss : 0.691994, Accuracy: 0.964000, Test accuracy: 0.957700
Distillation: Epoch : 21, Loss : 0.685713, Accuracy: 0.959000, Test accuracy: 0.960100
Distillation: Epoch : 22, Loss : 0.704720, Accuracy: 0.958000, Test accuracy: 0.960400
Distillation: Epoch : 23, Loss : 0.681721, Accuracy: 0.960000, Test accuracy: 0.961500
Distillation: Epoch : 24, Loss : 0.678175, Accuracy: 0.962000, Test accuracy: 0.962500
Distillation: Epoch : 25, Loss : 0.676749, Accuracy: 0.964000, Test accuracy: 0.963500
Distillation: Epoch : 26, Loss : 0.691034, Accuracy: 0.975000, Test accuracy: 0.964100
Distillation: Epoch : 27, Loss : 0.694218, Accuracy: 0.961000, Test accuracy: 0.964600
Distillation: Epoch : 28, Loss : 0.687721, Accuracy: 0.959000, Test accuracy: 0.965700
Distillation: Epoch : 29, Loss : 0.671574, Accuracy: 0.967000, Test accuracy: 0.965900
Distillation: Epoch : 30, Loss : 0.690845, Accuracy: 0.950000, Test accuracy: 0.966900
Distillation: Epoch : 31, Loss : 0.693173, Accuracy: 0.962000, Test accuracy: 0.966800
Distillation: Epoch : 32, Loss : 0.668356, Accuracy: 0.966000, Test accuracy: 0.967500
Distillation: Epoch : 33, Loss : 0.687856, Accuracy: 0.963000, Test accuracy: 0.967500
Distillation: Epoch : 34, Loss : 0.665787, Accuracy: 0.974000, Test accuracy: 0.967500
Distillation: Epoch : 35, Loss : 0.679533, Accuracy: 0.970000, Test accuracy: 0.968400
Distillation: Epoch : 36, Loss : 0.688465, Accuracy: 0.969000, Test accuracy: 0.968800
Distillation: Epoch : 37, Loss : 0.648407, Accuracy: 0.972000, Test accuracy: 0.968500
Distillation: Epoch : 38, Loss : 0.670531, Accuracy: 0.973000, Test accuracy: 0.968900
Distillation: Epoch : 39, Loss : 0.661807, Accuracy: 0.964000, Test accuracy: 0.968700
Distillation: Epoch : 40, Loss : 0.679411, Accuracy: 0.966000, Test accuracy: 0.969300
Distillation: Epoch : 41, Loss : 0.673654, Accuracy: 0.972000, Test accuracy: 0.969000
Distillation: Epoch : 42, Loss : 0.651305, Accuracy: 0.970000, Test accuracy: 0.969500
Distillation: Epoch : 43, Loss : 0.675174, Accuracy: 0.968000, Test accuracy: 0.969500
Distillation: Epoch : 44, Loss : 0.673597, Accuracy: 0.966000, Test accuracy: 0.969900
Distillation: Epoch : 45, Loss : 0.679749, Accuracy: 0.964000, Test accuracy: 0.970300
Distillation: Epoch : 46, Loss : 0.660680, Accuracy: 0.972000, Test accuracy: 0.970200
Distillation: Epoch : 47, Loss : 0.661705, Accuracy: 0.959000, Test accuracy: 0.970500
Distillation: Epoch : 48, Loss : 0.664889, Accuracy: 0.970000, Test accuracy: 0.971000
Distillation: Epoch : 49, Loss : 0.657747, Accuracy: 0.976000, Test accuracy: 0.970600
Distillation: Epoch : 50, Loss : 0.658748, Accuracy: 0.971000, Test accuracy: 0.971100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9711
Generating confusion matrix for student2
[[ 973.    0.    4.    0.    1.    2.    7.    1.    6.    4.]
 [   1. 1119.    5.    0.    2.    1.    3.    4.    2.    5.]
 [   0.    2.  986.    4.    1.    0.    0.   14.    9.    1.]
 [   0.    2.    9.  990.    0.    8.    0.    2.    8.    8.]
 [   0.    0.    3.    0.  965.    0.    4.    1.    7.   11.]
 [   1.    1.    1.    6.    0.  874.    7.    1.    4.    8.]
 [   3.    4.    1.    0.    3.    2.  934.    0.    5.    0.]
 [   2.    0.    7.    7.    1.    2.    0.  995.    6.   15.]
 [   0.    7.   14.    2.    1.    2.    3.    2.  920.    2.]
 [   0.    0.    2.    1.    8.    1.    0.    8.    7.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.705532, Accuracy: 0.737000, Test accuracy: 0.757100
Distillation: Epoch : 2, Loss : 1.203730, Accuracy: 0.837000, Test accuracy: 0.839300
Distillation: Epoch : 3, Loss : 1.099866, Accuracy: 0.866000, Test accuracy: 0.870400
Distillation: Epoch : 4, Loss : 1.051298, Accuracy: 0.890000, Test accuracy: 0.886700
Distillation: Epoch : 5, Loss : 1.063863, Accuracy: 0.886000, Test accuracy: 0.896600
Distillation: Epoch : 6, Loss : 1.027567, Accuracy: 0.885000, Test accuracy: 0.901600
Distillation: Epoch : 7, Loss : 0.984061, Accuracy: 0.903000, Test accuracy: 0.907000
Distillation: Epoch : 8, Loss : 0.967180, Accuracy: 0.916000, Test accuracy: 0.912900
Distillation: Epoch : 9, Loss : 0.961379, Accuracy: 0.915000, Test accuracy: 0.916900
Distillation: Epoch : 10, Loss : 1.002162, Accuracy: 0.900000, Test accuracy: 0.919000
Distillation: Epoch : 11, Loss : 0.945184, Accuracy: 0.917000, Test accuracy: 0.922200
Distillation: Epoch : 12, Loss : 0.968757, Accuracy: 0.915000, Test accuracy: 0.924400
Distillation: Epoch : 13, Loss : 0.923922, Accuracy: 0.919000, Test accuracy: 0.926600
Distillation: Epoch : 14, Loss : 0.948102, Accuracy: 0.937000, Test accuracy: 0.928700
Distillation: Epoch : 15, Loss : 0.942881, Accuracy: 0.924000, Test accuracy: 0.930600
Distillation: Epoch : 16, Loss : 0.920246, Accuracy: 0.927000, Test accuracy: 0.933200
Distillation: Epoch : 17, Loss : 0.934928, Accuracy: 0.921000, Test accuracy: 0.935400
Distillation: Epoch : 18, Loss : 0.888582, Accuracy: 0.951000, Test accuracy: 0.936300
Distillation: Epoch : 19, Loss : 0.890766, Accuracy: 0.941000, Test accuracy: 0.937300
Distillation: Epoch : 20, Loss : 0.935738, Accuracy: 0.929000, Test accuracy: 0.939400
Distillation: Epoch : 21, Loss : 0.948256, Accuracy: 0.930000, Test accuracy: 0.939400
Distillation: Epoch : 22, Loss : 0.889620, Accuracy: 0.936000, Test accuracy: 0.941800
Distillation: Epoch : 23, Loss : 0.887205, Accuracy: 0.946000, Test accuracy: 0.943700
Distillation: Epoch : 24, Loss : 0.908172, Accuracy: 0.941000, Test accuracy: 0.943300
Distillation: Epoch : 25, Loss : 0.887151, Accuracy: 0.936000, Test accuracy: 0.945400
Distillation: Epoch : 26, Loss : 0.912563, Accuracy: 0.936000, Test accuracy: 0.946200
Distillation: Epoch : 27, Loss : 0.909615, Accuracy: 0.943000, Test accuracy: 0.946900
Distillation: Epoch : 28, Loss : 0.928285, Accuracy: 0.933000, Test accuracy: 0.948300
Distillation: Epoch : 29, Loss : 0.900722, Accuracy: 0.953000, Test accuracy: 0.948400
Distillation: Epoch : 30, Loss : 0.895249, Accuracy: 0.941000, Test accuracy: 0.950000
Distillation: Epoch : 31, Loss : 0.888276, Accuracy: 0.947000, Test accuracy: 0.950600
Distillation: Epoch : 32, Loss : 0.901414, Accuracy: 0.939000, Test accuracy: 0.952200
Distillation: Epoch : 33, Loss : 0.895873, Accuracy: 0.937000, Test accuracy: 0.952200
Distillation: Epoch : 34, Loss : 0.889992, Accuracy: 0.951000, Test accuracy: 0.953600
Distillation: Epoch : 35, Loss : 0.897422, Accuracy: 0.944000, Test accuracy: 0.953100
Distillation: Epoch : 36, Loss : 0.908198, Accuracy: 0.956000, Test accuracy: 0.954200
Distillation: Epoch : 37, Loss : 0.881462, Accuracy: 0.957000, Test accuracy: 0.954600
Distillation: Epoch : 38, Loss : 0.902302, Accuracy: 0.949000, Test accuracy: 0.954700
Distillation: Epoch : 39, Loss : 0.845364, Accuracy: 0.952000, Test accuracy: 0.956300
Distillation: Epoch : 40, Loss : 0.887401, Accuracy: 0.958000, Test accuracy: 0.956400
Distillation: Epoch : 41, Loss : 0.907043, Accuracy: 0.955000, Test accuracy: 0.956100
Distillation: Epoch : 42, Loss : 0.881256, Accuracy: 0.954000, Test accuracy: 0.956800
Distillation: Epoch : 43, Loss : 0.919376, Accuracy: 0.952000, Test accuracy: 0.957100
Distillation: Epoch : 44, Loss : 0.880048, Accuracy: 0.949000, Test accuracy: 0.957900
Distillation: Epoch : 45, Loss : 0.874622, Accuracy: 0.956000, Test accuracy: 0.958000
Distillation: Epoch : 46, Loss : 0.889224, Accuracy: 0.962000, Test accuracy: 0.958400
Distillation: Epoch : 47, Loss : 0.860204, Accuracy: 0.962000, Test accuracy: 0.959300
Distillation: Epoch : 48, Loss : 0.875243, Accuracy: 0.961000, Test accuracy: 0.959400
Distillation: Epoch : 49, Loss : 0.880621, Accuracy: 0.951000, Test accuracy: 0.959400
Distillation: Epoch : 50, Loss : 0.891784, Accuracy: 0.949000, Test accuracy: 0.960300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9603
Generating confusion matrix for student2
[[ 968.    0.    8.    1.    0.    2.    6.    0.    5.    5.]
 [   1. 1116.    9.    0.    1.    0.    3.    6.    1.    5.]
 [   0.    2.  961.    4.    3.    0.    0.   15.   10.    2.]
 [   0.    1.   12.  983.    0.   17.    0.    6.   16.   16.]
 [   0.    0.    6.    0.  954.    0.    1.    3.    8.   12.]
 [   4.    0.    0.    7.    0.  857.   16.    3.    4.    5.]
 [   3.    4.    3.    0.    5.    5.  930.    0.    3.    0.]
 [   3.    0.    7.    8.    3.    2.    0.  978.    5.   15.]
 [   1.   12.   23.    5.    2.    8.    2.    2.  912.    5.]
 [   0.    0.    3.    2.   14.    1.    0.   15.   10.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.796478, Accuracy: 0.757000, Test accuracy: 0.771900
Distillation: Epoch : 2, Loss : 1.340603, Accuracy: 0.825000, Test accuracy: 0.843000
Distillation: Epoch : 3, Loss : 1.262760, Accuracy: 0.869000, Test accuracy: 0.868500
Distillation: Epoch : 4, Loss : 1.232422, Accuracy: 0.887000, Test accuracy: 0.881700
Distillation: Epoch : 5, Loss : 1.253063, Accuracy: 0.855000, Test accuracy: 0.889800
Distillation: Epoch : 6, Loss : 1.201532, Accuracy: 0.895000, Test accuracy: 0.896300
Distillation: Epoch : 7, Loss : 1.214842, Accuracy: 0.885000, Test accuracy: 0.901000
Distillation: Epoch : 8, Loss : 1.192091, Accuracy: 0.887000, Test accuracy: 0.900800
Distillation: Epoch : 9, Loss : 1.167092, Accuracy: 0.898000, Test accuracy: 0.905300
Distillation: Epoch : 10, Loss : 1.168422, Accuracy: 0.897000, Test accuracy: 0.905500
Distillation: Epoch : 11, Loss : 1.184491, Accuracy: 0.914000, Test accuracy: 0.909200
Distillation: Epoch : 12, Loss : 1.172837, Accuracy: 0.893000, Test accuracy: 0.909600
Distillation: Epoch : 13, Loss : 1.177344, Accuracy: 0.887000, Test accuracy: 0.911800
Distillation: Epoch : 14, Loss : 1.159074, Accuracy: 0.904000, Test accuracy: 0.916800
Distillation: Epoch : 15, Loss : 1.120986, Accuracy: 0.922000, Test accuracy: 0.917600
Distillation: Epoch : 16, Loss : 1.133576, Accuracy: 0.918000, Test accuracy: 0.920900
Distillation: Epoch : 17, Loss : 1.119511, Accuracy: 0.919000, Test accuracy: 0.923900
Distillation: Epoch : 18, Loss : 1.156877, Accuracy: 0.917000, Test accuracy: 0.924900
Distillation: Epoch : 19, Loss : 1.129071, Accuracy: 0.924000, Test accuracy: 0.927400
Distillation: Epoch : 20, Loss : 1.097168, Accuracy: 0.933000, Test accuracy: 0.928600
Distillation: Epoch : 21, Loss : 1.127920, Accuracy: 0.906000, Test accuracy: 0.931100
Distillation: Epoch : 22, Loss : 1.094026, Accuracy: 0.922000, Test accuracy: 0.933600
Distillation: Epoch : 23, Loss : 1.109742, Accuracy: 0.929000, Test accuracy: 0.936300
Distillation: Epoch : 24, Loss : 1.119793, Accuracy: 0.940000, Test accuracy: 0.938000
Distillation: Epoch : 25, Loss : 1.093974, Accuracy: 0.940000, Test accuracy: 0.939800
Distillation: Epoch : 26, Loss : 1.097820, Accuracy: 0.938000, Test accuracy: 0.941700
Distillation: Epoch : 27, Loss : 1.104587, Accuracy: 0.932000, Test accuracy: 0.944100
Distillation: Epoch : 28, Loss : 1.070922, Accuracy: 0.946000, Test accuracy: 0.945100
Distillation: Epoch : 29, Loss : 1.083206, Accuracy: 0.934000, Test accuracy: 0.946400
Distillation: Epoch : 30, Loss : 1.084654, Accuracy: 0.946000, Test accuracy: 0.948700
Distillation: Epoch : 31, Loss : 1.084240, Accuracy: 0.940000, Test accuracy: 0.949500
Distillation: Epoch : 32, Loss : 1.093707, Accuracy: 0.953000, Test accuracy: 0.949700
Distillation: Epoch : 33, Loss : 1.075365, Accuracy: 0.955000, Test accuracy: 0.950900
Distillation: Epoch : 34, Loss : 1.093308, Accuracy: 0.943000, Test accuracy: 0.951600
Distillation: Epoch : 35, Loss : 1.059590, Accuracy: 0.968000, Test accuracy: 0.952600
Distillation: Epoch : 36, Loss : 1.057273, Accuracy: 0.949000, Test accuracy: 0.954200
Distillation: Epoch : 37, Loss : 1.074908, Accuracy: 0.947000, Test accuracy: 0.954100
Distillation: Epoch : 38, Loss : 1.047993, Accuracy: 0.956000, Test accuracy: 0.955200
Distillation: Epoch : 39, Loss : 1.069435, Accuracy: 0.950000, Test accuracy: 0.956500
Distillation: Epoch : 40, Loss : 1.041201, Accuracy: 0.958000, Test accuracy: 0.957200
Distillation: Epoch : 41, Loss : 1.072897, Accuracy: 0.958000, Test accuracy: 0.959000
Distillation: Epoch : 42, Loss : 1.054630, Accuracy: 0.958000, Test accuracy: 0.958400
Distillation: Epoch : 43, Loss : 1.044975, Accuracy: 0.957000, Test accuracy: 0.960400
Distillation: Epoch : 44, Loss : 1.058801, Accuracy: 0.964000, Test accuracy: 0.960700
Distillation: Epoch : 45, Loss : 1.075607, Accuracy: 0.961000, Test accuracy: 0.959100
Distillation: Epoch : 46, Loss : 1.064412, Accuracy: 0.959000, Test accuracy: 0.961000
Distillation: Epoch : 47, Loss : 1.028281, Accuracy: 0.966000, Test accuracy: 0.961300
Distillation: Epoch : 48, Loss : 1.040555, Accuracy: 0.964000, Test accuracy: 0.960600
Distillation: Epoch : 49, Loss : 1.046556, Accuracy: 0.966000, Test accuracy: 0.961100
Distillation: Epoch : 50, Loss : 1.037279, Accuracy: 0.966000, Test accuracy: 0.962200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9622
Generating confusion matrix for student2
[[ 969.    0.    3.    1.    0.    2.    6.    1.    7.    2.]
 [   0. 1117.    3.    0.    0.    0.    3.    7.    2.    5.]
 [   0.    2.  962.    6.    4.    1.    2.   10.    6.    0.]
 [   0.    6.   21.  980.    0.    9.    1.    3.   12.    4.]
 [   1.    1.   13.    0.  959.    0.    4.    8.    6.   14.]
 [   3.    1.    1.   10.    0.  853.   13.    0.   13.   11.]
 [   3.    4.    5.    1.    5.    7.  927.    0.    4.    0.]
 [   2.    0.    6.    7.    1.    4.    0.  989.    6.   12.]
 [   2.    4.   17.    4.    3.   12.    2.    1.  910.    5.]
 [   0.    0.    1.    1.   10.    4.    0.    9.    8.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.848050, Accuracy: 0.771000, Test accuracy: 0.746400
Distillation: Epoch : 2, Loss : 1.508858, Accuracy: 0.800000, Test accuracy: 0.828500
Distillation: Epoch : 3, Loss : 1.417339, Accuracy: 0.849000, Test accuracy: 0.863900
Distillation: Epoch : 4, Loss : 1.370386, Accuracy: 0.872000, Test accuracy: 0.883200
Distillation: Epoch : 5, Loss : 1.339684, Accuracy: 0.886000, Test accuracy: 0.894100
Distillation: Epoch : 6, Loss : 1.329614, Accuracy: 0.900000, Test accuracy: 0.902000
Distillation: Epoch : 7, Loss : 1.316723, Accuracy: 0.912000, Test accuracy: 0.906700
Distillation: Epoch : 8, Loss : 1.324793, Accuracy: 0.912000, Test accuracy: 0.911600
Distillation: Epoch : 9, Loss : 1.307858, Accuracy: 0.922000, Test accuracy: 0.914300
Distillation: Epoch : 10, Loss : 1.296287, Accuracy: 0.912000, Test accuracy: 0.919900
Distillation: Epoch : 11, Loss : 1.271489, Accuracy: 0.926000, Test accuracy: 0.921900
Distillation: Epoch : 12, Loss : 1.298955, Accuracy: 0.917000, Test accuracy: 0.925600
Distillation: Epoch : 13, Loss : 1.295903, Accuracy: 0.919000, Test accuracy: 0.928700
Distillation: Epoch : 14, Loss : 1.283887, Accuracy: 0.910000, Test accuracy: 0.931100
Distillation: Epoch : 15, Loss : 1.281425, Accuracy: 0.915000, Test accuracy: 0.934300
Distillation: Epoch : 16, Loss : 1.241434, Accuracy: 0.940000, Test accuracy: 0.937200
Distillation: Epoch : 17, Loss : 1.253960, Accuracy: 0.942000, Test accuracy: 0.940000
Distillation: Epoch : 18, Loss : 1.249059, Accuracy: 0.944000, Test accuracy: 0.941500
Distillation: Epoch : 19, Loss : 1.242300, Accuracy: 0.935000, Test accuracy: 0.943800
Distillation: Epoch : 20, Loss : 1.214805, Accuracy: 0.953000, Test accuracy: 0.944700
Distillation: Epoch : 21, Loss : 1.220621, Accuracy: 0.947000, Test accuracy: 0.946800
Distillation: Epoch : 22, Loss : 1.241058, Accuracy: 0.951000, Test accuracy: 0.948800
Distillation: Epoch : 23, Loss : 1.230365, Accuracy: 0.948000, Test accuracy: 0.949500
Distillation: Epoch : 24, Loss : 1.234042, Accuracy: 0.946000, Test accuracy: 0.950200
Distillation: Epoch : 25, Loss : 1.246647, Accuracy: 0.937000, Test accuracy: 0.950600
Distillation: Epoch : 26, Loss : 1.224837, Accuracy: 0.938000, Test accuracy: 0.952100
Distillation: Epoch : 27, Loss : 1.237911, Accuracy: 0.944000, Test accuracy: 0.952400
Distillation: Epoch : 28, Loss : 1.233855, Accuracy: 0.950000, Test accuracy: 0.953400
Distillation: Epoch : 29, Loss : 1.232083, Accuracy: 0.944000, Test accuracy: 0.954100
Distillation: Epoch : 30, Loss : 1.210091, Accuracy: 0.951000, Test accuracy: 0.954500
Distillation: Epoch : 31, Loss : 1.242091, Accuracy: 0.952000, Test accuracy: 0.956400
Distillation: Epoch : 32, Loss : 1.195670, Accuracy: 0.961000, Test accuracy: 0.956500
Distillation: Epoch : 33, Loss : 1.205022, Accuracy: 0.961000, Test accuracy: 0.956700
Distillation: Epoch : 34, Loss : 1.217658, Accuracy: 0.958000, Test accuracy: 0.957100
Distillation: Epoch : 35, Loss : 1.232422, Accuracy: 0.958000, Test accuracy: 0.958900
Distillation: Epoch : 36, Loss : 1.181479, Accuracy: 0.971000, Test accuracy: 0.958800
Distillation: Epoch : 37, Loss : 1.204809, Accuracy: 0.964000, Test accuracy: 0.958900
Distillation: Epoch : 38, Loss : 1.219075, Accuracy: 0.947000, Test accuracy: 0.959800
Distillation: Epoch : 39, Loss : 1.210300, Accuracy: 0.962000, Test accuracy: 0.960400
Distillation: Epoch : 40, Loss : 1.214251, Accuracy: 0.961000, Test accuracy: 0.959800
Distillation: Epoch : 41, Loss : 1.211777, Accuracy: 0.954000, Test accuracy: 0.960400
Distillation: Epoch : 42, Loss : 1.229112, Accuracy: 0.959000, Test accuracy: 0.960400
Distillation: Epoch : 43, Loss : 1.193351, Accuracy: 0.956000, Test accuracy: 0.961900
Distillation: Epoch : 44, Loss : 1.207097, Accuracy: 0.957000, Test accuracy: 0.961600
Distillation: Epoch : 45, Loss : 1.195961, Accuracy: 0.959000, Test accuracy: 0.961900
Distillation: Epoch : 46, Loss : 1.204305, Accuracy: 0.969000, Test accuracy: 0.962700
Distillation: Epoch : 47, Loss : 1.206171, Accuracy: 0.956000, Test accuracy: 0.962200
Distillation: Epoch : 48, Loss : 1.193633, Accuracy: 0.954000, Test accuracy: 0.962900
Distillation: Epoch : 49, Loss : 1.180514, Accuracy: 0.967000, Test accuracy: 0.962300
Distillation: Epoch : 50, Loss : 1.218369, Accuracy: 0.947000, Test accuracy: 0.962500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9625
Generating confusion matrix for student2
[[ 970.    0.    4.    1.    0.    1.    6.    1.    6.    5.]
 [   1. 1123.   10.    0.    2.    1.    3.    6.    0.    5.]
 [   1.    1.  966.    1.    3.    0.    0.   17.    8.    1.]
 [   0.    2.    9.  989.    0.   20.    0.    5.   19.   16.]
 [   1.    0.    5.    0.  957.    1.    2.    2.    6.   12.]
 [   1.    0.    2.    6.    0.  858.   15.    1.    6.    7.]
 [   4.    4.    3.    0.    5.    5.  930.    0.    2.    0.]
 [   1.    0.   11.    5.    2.    1.    0.  977.    7.   12.]
 [   1.    5.   21.    4.    2.    5.    2.    2.  906.    2.]
 [   0.    0.    1.    4.   11.    0.    0.   17.   14.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.016155, Accuracy: 0.672000, Test accuracy: 0.672900
Distillation: Epoch : 2, Loss : 1.618388, Accuracy: 0.824000, Test accuracy: 0.831700
Distillation: Epoch : 3, Loss : 1.556871, Accuracy: 0.854000, Test accuracy: 0.864400
Distillation: Epoch : 4, Loss : 1.507155, Accuracy: 0.881000, Test accuracy: 0.887800
Distillation: Epoch : 5, Loss : 1.485285, Accuracy: 0.879000, Test accuracy: 0.896700
Distillation: Epoch : 6, Loss : 1.450018, Accuracy: 0.891000, Test accuracy: 0.904000
Distillation: Epoch : 7, Loss : 1.426218, Accuracy: 0.909000, Test accuracy: 0.910300
Distillation: Epoch : 8, Loss : 1.432067, Accuracy: 0.911000, Test accuracy: 0.916500
Distillation: Epoch : 9, Loss : 1.402229, Accuracy: 0.917000, Test accuracy: 0.921300
Distillation: Epoch : 10, Loss : 1.392848, Accuracy: 0.916000, Test accuracy: 0.925500
Distillation: Epoch : 11, Loss : 1.399960, Accuracy: 0.926000, Test accuracy: 0.929400
Distillation: Epoch : 12, Loss : 1.389705, Accuracy: 0.929000, Test accuracy: 0.933500
Distillation: Epoch : 13, Loss : 1.379033, Accuracy: 0.946000, Test accuracy: 0.938200
Distillation: Epoch : 14, Loss : 1.385353, Accuracy: 0.949000, Test accuracy: 0.941200
Distillation: Epoch : 15, Loss : 1.369741, Accuracy: 0.955000, Test accuracy: 0.942200
Distillation: Epoch : 16, Loss : 1.385497, Accuracy: 0.939000, Test accuracy: 0.944300
Distillation: Epoch : 17, Loss : 1.373376, Accuracy: 0.948000, Test accuracy: 0.946600
Distillation: Epoch : 18, Loss : 1.390510, Accuracy: 0.934000, Test accuracy: 0.947300
Distillation: Epoch : 19, Loss : 1.380430, Accuracy: 0.952000, Test accuracy: 0.949200
Distillation: Epoch : 20, Loss : 1.370674, Accuracy: 0.944000, Test accuracy: 0.951700
Distillation: Epoch : 21, Loss : 1.395616, Accuracy: 0.946000, Test accuracy: 0.952700
Distillation: Epoch : 22, Loss : 1.361711, Accuracy: 0.939000, Test accuracy: 0.953300
Distillation: Epoch : 23, Loss : 1.371429, Accuracy: 0.956000, Test accuracy: 0.954600
Distillation: Epoch : 24, Loss : 1.357553, Accuracy: 0.951000, Test accuracy: 0.955300
Distillation: Epoch : 25, Loss : 1.350391, Accuracy: 0.957000, Test accuracy: 0.956100
Distillation: Epoch : 26, Loss : 1.363959, Accuracy: 0.954000, Test accuracy: 0.957300
Distillation: Epoch : 27, Loss : 1.354677, Accuracy: 0.960000, Test accuracy: 0.958000
Distillation: Epoch : 28, Loss : 1.367672, Accuracy: 0.957000, Test accuracy: 0.958600
Distillation: Epoch : 29, Loss : 1.355924, Accuracy: 0.948000, Test accuracy: 0.958800
Distillation: Epoch : 30, Loss : 1.372290, Accuracy: 0.964000, Test accuracy: 0.959800
Distillation: Epoch : 31, Loss : 1.377046, Accuracy: 0.945000, Test accuracy: 0.960400
Distillation: Epoch : 32, Loss : 1.340106, Accuracy: 0.958000, Test accuracy: 0.960700
Distillation: Epoch : 33, Loss : 1.363594, Accuracy: 0.949000, Test accuracy: 0.961100
Distillation: Epoch : 34, Loss : 1.352071, Accuracy: 0.959000, Test accuracy: 0.961300
Distillation: Epoch : 35, Loss : 1.359923, Accuracy: 0.963000, Test accuracy: 0.961600
Distillation: Epoch : 36, Loss : 1.373364, Accuracy: 0.955000, Test accuracy: 0.961000
Distillation: Epoch : 37, Loss : 1.361046, Accuracy: 0.953000, Test accuracy: 0.962600
Distillation: Epoch : 38, Loss : 1.349299, Accuracy: 0.978000, Test accuracy: 0.962600
Distillation: Epoch : 39, Loss : 1.335518, Accuracy: 0.967000, Test accuracy: 0.963500
Distillation: Epoch : 40, Loss : 1.330175, Accuracy: 0.958000, Test accuracy: 0.964700
Distillation: Epoch : 41, Loss : 1.315825, Accuracy: 0.968000, Test accuracy: 0.964400
Distillation: Epoch : 42, Loss : 1.366505, Accuracy: 0.959000, Test accuracy: 0.965400
Distillation: Epoch : 43, Loss : 1.348586, Accuracy: 0.962000, Test accuracy: 0.964400
Distillation: Epoch : 44, Loss : 1.336490, Accuracy: 0.964000, Test accuracy: 0.964900
Distillation: Epoch : 45, Loss : 1.352244, Accuracy: 0.971000, Test accuracy: 0.965400
Distillation: Epoch : 46, Loss : 1.347885, Accuracy: 0.966000, Test accuracy: 0.965200
Distillation: Epoch : 47, Loss : 1.361468, Accuracy: 0.961000, Test accuracy: 0.966800
Distillation: Epoch : 48, Loss : 1.351829, Accuracy: 0.961000, Test accuracy: 0.967100
Distillation: Epoch : 49, Loss : 1.352866, Accuracy: 0.968000, Test accuracy: 0.966200
Distillation: Epoch : 50, Loss : 1.346963, Accuracy: 0.964000, Test accuracy: 0.966900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9669
Generating confusion matrix for student2
[[ 970.    0.    4.    1.    1.    1.    3.    1.    6.    3.]
 [   1. 1121.    7.    0.    0.    0.    3.   10.    1.    5.]
 [   0.    3.  991.    2.    2.    1.    0.    7.    5.    0.]
 [   0.    3.    4.  993.    0.   16.    1.    4.   15.    7.]
 [   1.    1.    4.    0.  961.    0.    5.    4.    9.   12.]
 [   1.    0.    2.    8.    0.  861.   13.    0.   12.    8.]
 [   3.    2.    1.    0.    5.    5.  930.    0.    5.    1.]
 [   1.    0.    8.    3.    1.    2.    0.  988.   12.   14.]
 [   3.    5.    9.    2.    3.    5.    3.    2.  897.    2.]
 [   0.    0.    2.    1.    9.    1.    0.   12.   12.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.926532, Accuracy: 0.754000, Test accuracy: 0.766100
Distillation: Epoch : 2, Loss : 1.678042, Accuracy: 0.832000, Test accuracy: 0.829600
Distillation: Epoch : 3, Loss : 1.642676, Accuracy: 0.871000, Test accuracy: 0.857200
Distillation: Epoch : 4, Loss : 1.628511, Accuracy: 0.850000, Test accuracy: 0.867300
Distillation: Epoch : 5, Loss : 1.606644, Accuracy: 0.878000, Test accuracy: 0.876500
Distillation: Epoch : 6, Loss : 1.589426, Accuracy: 0.874000, Test accuracy: 0.881200
Distillation: Epoch : 7, Loss : 1.585333, Accuracy: 0.889000, Test accuracy: 0.883400
Distillation: Epoch : 8, Loss : 1.575913, Accuracy: 0.871000, Test accuracy: 0.889000
Distillation: Epoch : 9, Loss : 1.609241, Accuracy: 0.877000, Test accuracy: 0.889200
Distillation: Epoch : 10, Loss : 1.590584, Accuracy: 0.894000, Test accuracy: 0.890000
Distillation: Epoch : 11, Loss : 1.573485, Accuracy: 0.898000, Test accuracy: 0.894200
Distillation: Epoch : 12, Loss : 1.576075, Accuracy: 0.890000, Test accuracy: 0.890900
Distillation: Epoch : 13, Loss : 1.579011, Accuracy: 0.891000, Test accuracy: 0.893600
Distillation: Epoch : 14, Loss : 1.598426, Accuracy: 0.889000, Test accuracy: 0.896500
Distillation: Epoch : 15, Loss : 1.597174, Accuracy: 0.876000, Test accuracy: 0.896100
Distillation: Epoch : 16, Loss : 1.554768, Accuracy: 0.894000, Test accuracy: 0.895000
Distillation: Epoch : 17, Loss : 1.573041, Accuracy: 0.886000, Test accuracy: 0.897800
Distillation: Epoch : 18, Loss : 1.554122, Accuracy: 0.903000, Test accuracy: 0.899400
Distillation: Epoch : 19, Loss : 1.557757, Accuracy: 0.902000, Test accuracy: 0.899000
Distillation: Epoch : 20, Loss : 1.527851, Accuracy: 0.913000, Test accuracy: 0.900400
Distillation: Epoch : 21, Loss : 1.552782, Accuracy: 0.879000, Test accuracy: 0.902100
Distillation: Epoch : 22, Loss : 1.544301, Accuracy: 0.898000, Test accuracy: 0.904500
Distillation: Epoch : 23, Loss : 1.556352, Accuracy: 0.904000, Test accuracy: 0.905200
Distillation: Epoch : 24, Loss : 1.547363, Accuracy: 0.902000, Test accuracy: 0.907800
Distillation: Epoch : 25, Loss : 1.548062, Accuracy: 0.896000, Test accuracy: 0.910800
Distillation: Epoch : 26, Loss : 1.552984, Accuracy: 0.901000, Test accuracy: 0.914300
Distillation: Epoch : 27, Loss : 1.555293, Accuracy: 0.915000, Test accuracy: 0.917300
Distillation: Epoch : 28, Loss : 1.552801, Accuracy: 0.900000, Test accuracy: 0.920800
Distillation: Epoch : 29, Loss : 1.533739, Accuracy: 0.916000, Test accuracy: 0.923700
Distillation: Epoch : 30, Loss : 1.514310, Accuracy: 0.923000, Test accuracy: 0.925400
Distillation: Epoch : 31, Loss : 1.537965, Accuracy: 0.920000, Test accuracy: 0.928500
Distillation: Epoch : 32, Loss : 1.549981, Accuracy: 0.935000, Test accuracy: 0.932400
Distillation: Epoch : 33, Loss : 1.503390, Accuracy: 0.927000, Test accuracy: 0.936100
Distillation: Epoch : 34, Loss : 1.530311, Accuracy: 0.931000, Test accuracy: 0.938200
Distillation: Epoch : 35, Loss : 1.497497, Accuracy: 0.922000, Test accuracy: 0.941500
Distillation: Epoch : 36, Loss : 1.495703, Accuracy: 0.944000, Test accuracy: 0.942600
Distillation: Epoch : 37, Loss : 1.491552, Accuracy: 0.941000, Test accuracy: 0.945500
Distillation: Epoch : 38, Loss : 1.476567, Accuracy: 0.935000, Test accuracy: 0.946800
Distillation: Epoch : 39, Loss : 1.468517, Accuracy: 0.945000, Test accuracy: 0.947900
Distillation: Epoch : 40, Loss : 1.475636, Accuracy: 0.944000, Test accuracy: 0.949300
Distillation: Epoch : 41, Loss : 1.472536, Accuracy: 0.948000, Test accuracy: 0.951100
Distillation: Epoch : 42, Loss : 1.489253, Accuracy: 0.952000, Test accuracy: 0.953300
Distillation: Epoch : 43, Loss : 1.480978, Accuracy: 0.936000, Test accuracy: 0.954000
Distillation: Epoch : 44, Loss : 1.465869, Accuracy: 0.957000, Test accuracy: 0.954500
Distillation: Epoch : 45, Loss : 1.478298, Accuracy: 0.963000, Test accuracy: 0.956000
Distillation: Epoch : 46, Loss : 1.476190, Accuracy: 0.956000, Test accuracy: 0.956900
Distillation: Epoch : 47, Loss : 1.492673, Accuracy: 0.947000, Test accuracy: 0.957300
Distillation: Epoch : 48, Loss : 1.512570, Accuracy: 0.955000, Test accuracy: 0.959100
Distillation: Epoch : 49, Loss : 1.490872, Accuracy: 0.954000, Test accuracy: 0.960200
Distillation: Epoch : 50, Loss : 1.499239, Accuracy: 0.955000, Test accuracy: 0.960300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9603
Generating confusion matrix for student2
[[ 968.    0.    3.    1.    0.    0.    6.    2.    6.    6.]
 [   0. 1125.   11.    0.    0.    1.    3.    9.    2.    5.]
 [   1.    1.  957.    2.    4.    0.    1.   14.    8.    1.]
 [   0.    2.    8.  985.    0.   11.    0.    8.   14.   15.]
 [   3.    0.    7.    2.  965.    0.    9.    6.   10.   25.]
 [   1.    0.    0.    7.    0.  870.   16.    2.    6.    5.]
 [   4.    4.    4.    0.    1.    3.  923.    0.    3.    0.]
 [   1.    1.   14.    5.    1.    2.    0.  965.   10.   11.]
 [   2.    2.   27.    4.    2.    4.    0.    2.  906.    2.]
 [   0.    0.    1.    4.    9.    1.    0.   20.    9.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.085051, Accuracy: 0.720000, Test accuracy: 0.717000
Distillation: Epoch : 2, Loss : 1.907183, Accuracy: 0.808000, Test accuracy: 0.818400
Distillation: Epoch : 3, Loss : 1.864375, Accuracy: 0.839000, Test accuracy: 0.851600
Distillation: Epoch : 4, Loss : 1.865751, Accuracy: 0.852000, Test accuracy: 0.867000
Distillation: Epoch : 5, Loss : 1.861445, Accuracy: 0.871000, Test accuracy: 0.876800
Distillation: Epoch : 6, Loss : 1.825901, Accuracy: 0.872000, Test accuracy: 0.885200
Distillation: Epoch : 7, Loss : 1.826556, Accuracy: 0.883000, Test accuracy: 0.887700
Distillation: Epoch : 8, Loss : 1.821393, Accuracy: 0.883000, Test accuracy: 0.894400
Distillation: Epoch : 9, Loss : 1.827265, Accuracy: 0.902000, Test accuracy: 0.896100
Distillation: Epoch : 10, Loss : 1.821212, Accuracy: 0.898000, Test accuracy: 0.899400
Distillation: Epoch : 11, Loss : 1.819842, Accuracy: 0.895000, Test accuracy: 0.902300
Distillation: Epoch : 12, Loss : 1.821320, Accuracy: 0.895000, Test accuracy: 0.904800
Distillation: Epoch : 13, Loss : 1.820322, Accuracy: 0.895000, Test accuracy: 0.908600
Distillation: Epoch : 14, Loss : 1.799209, Accuracy: 0.918000, Test accuracy: 0.912200
Distillation: Epoch : 15, Loss : 1.816264, Accuracy: 0.905000, Test accuracy: 0.916800
Distillation: Epoch : 16, Loss : 1.801075, Accuracy: 0.920000, Test accuracy: 0.917800
Distillation: Epoch : 17, Loss : 1.807010, Accuracy: 0.912000, Test accuracy: 0.922400
Distillation: Epoch : 18, Loss : 1.799198, Accuracy: 0.911000, Test accuracy: 0.926400
Distillation: Epoch : 19, Loss : 1.806709, Accuracy: 0.913000, Test accuracy: 0.929000
Distillation: Epoch : 20, Loss : 1.785825, Accuracy: 0.943000, Test accuracy: 0.931100
Distillation: Epoch : 21, Loss : 1.791243, Accuracy: 0.926000, Test accuracy: 0.934100
Distillation: Epoch : 22, Loss : 1.777576, Accuracy: 0.934000, Test accuracy: 0.935800
Distillation: Epoch : 23, Loss : 1.756872, Accuracy: 0.931000, Test accuracy: 0.937500
Distillation: Epoch : 24, Loss : 1.790090, Accuracy: 0.917000, Test accuracy: 0.939100
Distillation: Epoch : 25, Loss : 1.783768, Accuracy: 0.941000, Test accuracy: 0.940300
Distillation: Epoch : 26, Loss : 1.768903, Accuracy: 0.931000, Test accuracy: 0.942800
Distillation: Epoch : 27, Loss : 1.759618, Accuracy: 0.950000, Test accuracy: 0.943000
Distillation: Epoch : 28, Loss : 1.765133, Accuracy: 0.933000, Test accuracy: 0.945000
Distillation: Epoch : 29, Loss : 1.760575, Accuracy: 0.935000, Test accuracy: 0.945600
Distillation: Epoch : 30, Loss : 1.765866, Accuracy: 0.943000, Test accuracy: 0.947400
Distillation: Epoch : 31, Loss : 1.789428, Accuracy: 0.933000, Test accuracy: 0.948900
Distillation: Epoch : 32, Loss : 1.772710, Accuracy: 0.947000, Test accuracy: 0.949500
Distillation: Epoch : 33, Loss : 1.760298, Accuracy: 0.956000, Test accuracy: 0.949500
Distillation: Epoch : 34, Loss : 1.778148, Accuracy: 0.937000, Test accuracy: 0.952200
Distillation: Epoch : 35, Loss : 1.769951, Accuracy: 0.946000, Test accuracy: 0.951700
Distillation: Epoch : 36, Loss : 1.766403, Accuracy: 0.944000, Test accuracy: 0.953000
Distillation: Epoch : 37, Loss : 1.765183, Accuracy: 0.955000, Test accuracy: 0.954400
Distillation: Epoch : 38, Loss : 1.762905, Accuracy: 0.948000, Test accuracy: 0.954500
Distillation: Epoch : 39, Loss : 1.761821, Accuracy: 0.953000, Test accuracy: 0.955000
Distillation: Epoch : 40, Loss : 1.761095, Accuracy: 0.946000, Test accuracy: 0.955800
Distillation: Epoch : 41, Loss : 1.756035, Accuracy: 0.963000, Test accuracy: 0.956300
Distillation: Epoch : 42, Loss : 1.764512, Accuracy: 0.957000, Test accuracy: 0.957400
Distillation: Epoch : 43, Loss : 1.764497, Accuracy: 0.957000, Test accuracy: 0.957500
Distillation: Epoch : 44, Loss : 1.768153, Accuracy: 0.952000, Test accuracy: 0.957900
Distillation: Epoch : 45, Loss : 1.768020, Accuracy: 0.953000, Test accuracy: 0.958300
Distillation: Epoch : 46, Loss : 1.759271, Accuracy: 0.960000, Test accuracy: 0.959000
Distillation: Epoch : 47, Loss : 1.756074, Accuracy: 0.951000, Test accuracy: 0.958600
Distillation: Epoch : 48, Loss : 1.738750, Accuracy: 0.961000, Test accuracy: 0.959300
Distillation: Epoch : 49, Loss : 1.755196, Accuracy: 0.963000, Test accuracy: 0.959600
Distillation: Epoch : 50, Loss : 1.768253, Accuracy: 0.950000, Test accuracy: 0.960000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.96
Generating confusion matrix for student2
[[ 968.    0.    4.    0.    0.    1.    5.    1.    5.    5.]
 [   0. 1127.    8.    0.    1.    0.    2.    8.    3.    5.]
 [   0.    1.  961.    4.    3.    0.    0.   16.    6.    0.]
 [   0.    2.    7.  987.    0.    9.    1.    6.   11.   15.]
 [   1.    0.    6.    1.  959.    0.   10.    4.   10.   25.]
 [   1.    0.    1.    4.    0.  874.   16.    1.    8.   11.]
 [   6.    3.    2.    0.    3.    4.  924.    0.    4.    0.]
 [   1.    0.   10.    6.    0.    1.    0.  964.   10.   11.]
 [   3.    2.   32.    5.    3.    2.    0.    4.  903.    4.]
 [   0.    0.    1.    3.   13.    1.    0.   24.   14.  933.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.172184, Accuracy: 0.714000, Test accuracy: 0.731000
Distillation: Epoch : 2, Loss : 2.089671, Accuracy: 0.808000, Test accuracy: 0.807300
Distillation: Epoch : 3, Loss : 2.070536, Accuracy: 0.838000, Test accuracy: 0.843200
Distillation: Epoch : 4, Loss : 2.077819, Accuracy: 0.840000, Test accuracy: 0.852100
Distillation: Epoch : 5, Loss : 2.061109, Accuracy: 0.864000, Test accuracy: 0.859900
Distillation: Epoch : 6, Loss : 2.065511, Accuracy: 0.860000, Test accuracy: 0.867900
Distillation: Epoch : 7, Loss : 2.060544, Accuracy: 0.858000, Test accuracy: 0.872200
Distillation: Epoch : 8, Loss : 2.067456, Accuracy: 0.871000, Test accuracy: 0.878100
Distillation: Epoch : 9, Loss : 2.058801, Accuracy: 0.869000, Test accuracy: 0.881000
Distillation: Epoch : 10, Loss : 2.050812, Accuracy: 0.886000, Test accuracy: 0.883700
Distillation: Epoch : 11, Loss : 2.051571, Accuracy: 0.887000, Test accuracy: 0.886900
Distillation: Epoch : 12, Loss : 2.038988, Accuracy: 0.902000, Test accuracy: 0.889500
Distillation: Epoch : 13, Loss : 2.047754, Accuracy: 0.889000, Test accuracy: 0.891700
Distillation: Epoch : 14, Loss : 2.036885, Accuracy: 0.893000, Test accuracy: 0.893800
Distillation: Epoch : 15, Loss : 2.050589, Accuracy: 0.892000, Test accuracy: 0.896600
Distillation: Epoch : 16, Loss : 2.035899, Accuracy: 0.898000, Test accuracy: 0.898100
Distillation: Epoch : 17, Loss : 2.042265, Accuracy: 0.897000, Test accuracy: 0.903000
Distillation: Epoch : 18, Loss : 2.031585, Accuracy: 0.906000, Test accuracy: 0.905900
Distillation: Epoch : 19, Loss : 2.045993, Accuracy: 0.907000, Test accuracy: 0.907600
Distillation: Epoch : 20, Loss : 2.037962, Accuracy: 0.893000, Test accuracy: 0.911000
Distillation: Epoch : 21, Loss : 2.032494, Accuracy: 0.906000, Test accuracy: 0.913800
Distillation: Epoch : 22, Loss : 2.043604, Accuracy: 0.894000, Test accuracy: 0.917700
Distillation: Epoch : 23, Loss : 2.035508, Accuracy: 0.921000, Test accuracy: 0.921000
Distillation: Epoch : 24, Loss : 2.034849, Accuracy: 0.903000, Test accuracy: 0.922900
Distillation: Epoch : 25, Loss : 2.029158, Accuracy: 0.929000, Test accuracy: 0.926100
Distillation: Epoch : 26, Loss : 2.024162, Accuracy: 0.917000, Test accuracy: 0.930100
Distillation: Epoch : 27, Loss : 2.023057, Accuracy: 0.936000, Test accuracy: 0.931200
Distillation: Epoch : 28, Loss : 2.024933, Accuracy: 0.921000, Test accuracy: 0.935500
Distillation: Epoch : 29, Loss : 2.015320, Accuracy: 0.939000, Test accuracy: 0.936300
Distillation: Epoch : 30, Loss : 2.028772, Accuracy: 0.926000, Test accuracy: 0.938000
Distillation: Epoch : 31, Loss : 2.031053, Accuracy: 0.931000, Test accuracy: 0.940200
Distillation: Epoch : 32, Loss : 2.007186, Accuracy: 0.958000, Test accuracy: 0.942500
Distillation: Epoch : 33, Loss : 2.007180, Accuracy: 0.940000, Test accuracy: 0.943600
Distillation: Epoch : 34, Loss : 2.008795, Accuracy: 0.937000, Test accuracy: 0.944900
Distillation: Epoch : 35, Loss : 2.026213, Accuracy: 0.931000, Test accuracy: 0.946400
Distillation: Epoch : 36, Loss : 2.010875, Accuracy: 0.944000, Test accuracy: 0.947200
Distillation: Epoch : 37, Loss : 2.005919, Accuracy: 0.954000, Test accuracy: 0.948700
Distillation: Epoch : 38, Loss : 2.018193, Accuracy: 0.945000, Test accuracy: 0.950500
Distillation: Epoch : 39, Loss : 2.004166, Accuracy: 0.951000, Test accuracy: 0.950400
Distillation: Epoch : 40, Loss : 2.003270, Accuracy: 0.948000, Test accuracy: 0.952900
Distillation: Epoch : 41, Loss : 2.000026, Accuracy: 0.952000, Test accuracy: 0.954600
Distillation: Epoch : 42, Loss : 2.019356, Accuracy: 0.959000, Test accuracy: 0.954900
Distillation: Epoch : 43, Loss : 2.005256, Accuracy: 0.949000, Test accuracy: 0.955200
Distillation: Epoch : 44, Loss : 2.016323, Accuracy: 0.954000, Test accuracy: 0.956200
Distillation: Epoch : 45, Loss : 2.009002, Accuracy: 0.947000, Test accuracy: 0.957200
Distillation: Epoch : 46, Loss : 2.004687, Accuracy: 0.959000, Test accuracy: 0.957700
Distillation: Epoch : 47, Loss : 2.017353, Accuracy: 0.957000, Test accuracy: 0.958400
Distillation: Epoch : 48, Loss : 2.015121, Accuracy: 0.944000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 2.011335, Accuracy: 0.951000, Test accuracy: 0.959200
Distillation: Epoch : 50, Loss : 1.994717, Accuracy: 0.963000, Test accuracy: 0.960100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9601
Generating confusion matrix for student2
[[ 967.    0.    6.    0.    1.    0.    9.    2.    4.    5.]
 [   0. 1120.    9.    0.    0.    1.    3.    7.    4.    5.]
 [   1.    1.  969.    4.    3.    1.    1.   11.    7.    0.]
 [   0.    3.    9.  984.    0.    8.    1.    5.   14.    9.]
 [   0.    1.    5.    0.  963.    0.    8.   12.   15.   22.]
 [   1.    1.    2.    7.    0.  869.   20.    2.    7.    9.]
 [   7.    4.    2.    0.    1.    5.  915.    0.    5.    0.]
 [   1.    0.   11.    8.    0.    1.    0.  973.    9.   13.]
 [   3.    5.   19.    5.    3.    4.    1.    3.  899.    4.]
 [   0.    0.    0.    2.   11.    3.    0.   13.   10.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.772181, Accuracy: 0.771000, Test accuracy: 0.813700
Distillation: Epoch : 2, Loss : 0.517899, Accuracy: 0.846000, Test accuracy: 0.866800
Distillation: Epoch : 3, Loss : 0.430620, Accuracy: 0.872000, Test accuracy: 0.885300
Distillation: Epoch : 4, Loss : 0.386337, Accuracy: 0.883000, Test accuracy: 0.894200
Distillation: Epoch : 5, Loss : 0.412216, Accuracy: 0.877000, Test accuracy: 0.898700
Distillation: Epoch : 6, Loss : 0.341795, Accuracy: 0.894000, Test accuracy: 0.902600
Distillation: Epoch : 7, Loss : 0.322196, Accuracy: 0.910000, Test accuracy: 0.904800
Distillation: Epoch : 8, Loss : 0.347571, Accuracy: 0.895000, Test accuracy: 0.906400
Distillation: Epoch : 9, Loss : 0.313256, Accuracy: 0.910000, Test accuracy: 0.909300
Distillation: Epoch : 10, Loss : 0.292042, Accuracy: 0.913000, Test accuracy: 0.911000
Distillation: Epoch : 11, Loss : 0.307251, Accuracy: 0.916000, Test accuracy: 0.912200
Distillation: Epoch : 12, Loss : 0.311168, Accuracy: 0.902000, Test accuracy: 0.913100
Distillation: Epoch : 13, Loss : 0.287600, Accuracy: 0.905000, Test accuracy: 0.912700
Distillation: Epoch : 14, Loss : 0.303165, Accuracy: 0.914000, Test accuracy: 0.915800
Distillation: Epoch : 15, Loss : 0.341683, Accuracy: 0.896000, Test accuracy: 0.915000
Distillation: Epoch : 16, Loss : 0.303862, Accuracy: 0.911000, Test accuracy: 0.915400
Distillation: Epoch : 17, Loss : 0.260061, Accuracy: 0.913000, Test accuracy: 0.916700
Distillation: Epoch : 18, Loss : 0.309413, Accuracy: 0.916000, Test accuracy: 0.916800
Distillation: Epoch : 19, Loss : 0.279956, Accuracy: 0.918000, Test accuracy: 0.917300
Distillation: Epoch : 20, Loss : 0.276599, Accuracy: 0.927000, Test accuracy: 0.919300
Distillation: Epoch : 21, Loss : 0.263221, Accuracy: 0.933000, Test accuracy: 0.919400
Distillation: Epoch : 22, Loss : 0.255813, Accuracy: 0.929000, Test accuracy: 0.919100
Distillation: Epoch : 23, Loss : 0.253773, Accuracy: 0.917000, Test accuracy: 0.920200
Distillation: Epoch : 24, Loss : 0.286688, Accuracy: 0.926000, Test accuracy: 0.921500
Distillation: Epoch : 25, Loss : 0.260166, Accuracy: 0.916000, Test accuracy: 0.921200
Distillation: Epoch : 26, Loss : 0.301836, Accuracy: 0.909000, Test accuracy: 0.922300
Distillation: Epoch : 27, Loss : 0.304277, Accuracy: 0.898000, Test accuracy: 0.922600
Distillation: Epoch : 28, Loss : 0.315325, Accuracy: 0.921000, Test accuracy: 0.922400
Distillation: Epoch : 29, Loss : 0.287272, Accuracy: 0.926000, Test accuracy: 0.923100
Distillation: Epoch : 30, Loss : 0.235567, Accuracy: 0.933000, Test accuracy: 0.924200
Distillation: Epoch : 31, Loss : 0.299222, Accuracy: 0.914000, Test accuracy: 0.925200
Distillation: Epoch : 32, Loss : 0.275087, Accuracy: 0.919000, Test accuracy: 0.925100
Distillation: Epoch : 33, Loss : 0.278474, Accuracy: 0.924000, Test accuracy: 0.925700
Distillation: Epoch : 34, Loss : 0.250725, Accuracy: 0.922000, Test accuracy: 0.926600
Distillation: Epoch : 35, Loss : 0.300976, Accuracy: 0.913000, Test accuracy: 0.926900
Distillation: Epoch : 36, Loss : 0.253510, Accuracy: 0.934000, Test accuracy: 0.927200
Distillation: Epoch : 37, Loss : 0.294815, Accuracy: 0.925000, Test accuracy: 0.928200
Distillation: Epoch : 38, Loss : 0.245665, Accuracy: 0.934000, Test accuracy: 0.929400
Distillation: Epoch : 39, Loss : 0.283424, Accuracy: 0.909000, Test accuracy: 0.929300
Distillation: Epoch : 40, Loss : 0.237610, Accuracy: 0.931000, Test accuracy: 0.930600
Distillation: Epoch : 41, Loss : 0.238048, Accuracy: 0.925000, Test accuracy: 0.931200
Distillation: Epoch : 42, Loss : 0.271458, Accuracy: 0.917000, Test accuracy: 0.932800
Distillation: Epoch : 43, Loss : 0.258641, Accuracy: 0.931000, Test accuracy: 0.934500
Distillation: Epoch : 44, Loss : 0.217018, Accuracy: 0.935000, Test accuracy: 0.934700
Distillation: Epoch : 45, Loss : 0.265424, Accuracy: 0.930000, Test accuracy: 0.934700
Distillation: Epoch : 46, Loss : 0.229115, Accuracy: 0.935000, Test accuracy: 0.935000
Distillation: Epoch : 47, Loss : 0.254228, Accuracy: 0.925000, Test accuracy: 0.936500
Distillation: Epoch : 48, Loss : 0.252996, Accuracy: 0.925000, Test accuracy: 0.937100
Distillation: Epoch : 49, Loss : 0.177597, Accuracy: 0.950000, Test accuracy: 0.937900
Distillation: Epoch : 50, Loss : 0.224602, Accuracy: 0.940000, Test accuracy: 0.938500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9385
Generating confusion matrix for student3
[[ 963.    0.   10.    4.    1.    8.   13.    3.    8.   11.]
 [   0. 1113.    6.    0.    2.    2.    3.    7.    4.    6.]
 [   1.    4.  943.   10.   10.    2.    5.   23.    9.    2.]
 [   2.    1.   19.  956.    1.   27.    2.    8.   19.   14.]
 [   0.    0.    4.    1.  915.    5.    6.    2.   10.   17.]
 [   5.    1.    0.    9.    0.  803.    8.    1.   18.    6.]
 [   6.    3.    9.    0.   10.    9.  917.    0.    7.    0.]
 [   1.    2.    9.    9.    3.    2.    3.  954.    4.   14.]
 [   2.   11.   26.   14.    8.   29.    1.    2.  887.    5.]
 [   0.    0.    6.    7.   32.    5.    0.   28.    8.  934.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.457733, Accuracy: 0.765000, Test accuracy: 0.768400
Distillation: Epoch : 2, Loss : 0.746601, Accuracy: 0.831000, Test accuracy: 0.847400
Distillation: Epoch : 3, Loss : 0.540742, Accuracy: 0.861000, Test accuracy: 0.878800
Distillation: Epoch : 4, Loss : 0.462360, Accuracy: 0.878000, Test accuracy: 0.896000
Distillation: Epoch : 5, Loss : 0.351882, Accuracy: 0.916000, Test accuracy: 0.904400
Distillation: Epoch : 6, Loss : 0.317805, Accuracy: 0.909000, Test accuracy: 0.911800
Distillation: Epoch : 7, Loss : 0.326796, Accuracy: 0.910000, Test accuracy: 0.918100
Distillation: Epoch : 8, Loss : 0.280017, Accuracy: 0.924000, Test accuracy: 0.921900
Distillation: Epoch : 9, Loss : 0.311255, Accuracy: 0.922000, Test accuracy: 0.925400
Distillation: Epoch : 10, Loss : 0.247671, Accuracy: 0.939000, Test accuracy: 0.928500
Distillation: Epoch : 11, Loss : 0.266599, Accuracy: 0.928000, Test accuracy: 0.931100
Distillation: Epoch : 12, Loss : 0.260030, Accuracy: 0.930000, Test accuracy: 0.934700
Distillation: Epoch : 13, Loss : 0.233343, Accuracy: 0.939000, Test accuracy: 0.936200
Distillation: Epoch : 14, Loss : 0.272344, Accuracy: 0.931000, Test accuracy: 0.938400
Distillation: Epoch : 15, Loss : 0.248593, Accuracy: 0.936000, Test accuracy: 0.939800
Distillation: Epoch : 16, Loss : 0.261513, Accuracy: 0.930000, Test accuracy: 0.940900
Distillation: Epoch : 17, Loss : 0.207227, Accuracy: 0.950000, Test accuracy: 0.942100
Distillation: Epoch : 18, Loss : 0.224542, Accuracy: 0.944000, Test accuracy: 0.943900
Distillation: Epoch : 19, Loss : 0.195208, Accuracy: 0.954000, Test accuracy: 0.945600
Distillation: Epoch : 20, Loss : 0.228756, Accuracy: 0.942000, Test accuracy: 0.946500
Distillation: Epoch : 21, Loss : 0.218128, Accuracy: 0.947000, Test accuracy: 0.947400
Distillation: Epoch : 22, Loss : 0.194543, Accuracy: 0.953000, Test accuracy: 0.949000
Distillation: Epoch : 23, Loss : 0.210132, Accuracy: 0.947000, Test accuracy: 0.949200
Distillation: Epoch : 24, Loss : 0.219349, Accuracy: 0.946000, Test accuracy: 0.950300
Distillation: Epoch : 25, Loss : 0.197697, Accuracy: 0.952000, Test accuracy: 0.951800
Distillation: Epoch : 26, Loss : 0.194793, Accuracy: 0.949000, Test accuracy: 0.953100
Distillation: Epoch : 27, Loss : 0.183727, Accuracy: 0.956000, Test accuracy: 0.953900
Distillation: Epoch : 28, Loss : 0.186448, Accuracy: 0.953000, Test accuracy: 0.954400
Distillation: Epoch : 29, Loss : 0.179242, Accuracy: 0.950000, Test accuracy: 0.955300
Distillation: Epoch : 30, Loss : 0.179590, Accuracy: 0.948000, Test accuracy: 0.956500
Distillation: Epoch : 31, Loss : 0.183452, Accuracy: 0.943000, Test accuracy: 0.956800
Distillation: Epoch : 32, Loss : 0.203785, Accuracy: 0.956000, Test accuracy: 0.957000
Distillation: Epoch : 33, Loss : 0.178416, Accuracy: 0.952000, Test accuracy: 0.957600
Distillation: Epoch : 34, Loss : 0.178368, Accuracy: 0.953000, Test accuracy: 0.958600
Distillation: Epoch : 35, Loss : 0.170938, Accuracy: 0.952000, Test accuracy: 0.958200
Distillation: Epoch : 36, Loss : 0.166242, Accuracy: 0.966000, Test accuracy: 0.959400
Distillation: Epoch : 37, Loss : 0.187501, Accuracy: 0.956000, Test accuracy: 0.959800
Distillation: Epoch : 38, Loss : 0.173907, Accuracy: 0.965000, Test accuracy: 0.959400
Distillation: Epoch : 39, Loss : 0.171474, Accuracy: 0.964000, Test accuracy: 0.960000
Distillation: Epoch : 40, Loss : 0.203873, Accuracy: 0.953000, Test accuracy: 0.960200
Distillation: Epoch : 41, Loss : 0.196345, Accuracy: 0.952000, Test accuracy: 0.960900
Distillation: Epoch : 42, Loss : 0.157119, Accuracy: 0.963000, Test accuracy: 0.961300
Distillation: Epoch : 43, Loss : 0.166451, Accuracy: 0.956000, Test accuracy: 0.961100
Distillation: Epoch : 44, Loss : 0.147362, Accuracy: 0.969000, Test accuracy: 0.962600
Distillation: Epoch : 45, Loss : 0.167013, Accuracy: 0.957000, Test accuracy: 0.961400
Distillation: Epoch : 46, Loss : 0.140927, Accuracy: 0.966000, Test accuracy: 0.962300
Distillation: Epoch : 47, Loss : 0.192804, Accuracy: 0.947000, Test accuracy: 0.962300
Distillation: Epoch : 48, Loss : 0.166040, Accuracy: 0.958000, Test accuracy: 0.963000
Distillation: Epoch : 49, Loss : 0.143173, Accuracy: 0.964000, Test accuracy: 0.963300
Distillation: Epoch : 50, Loss : 0.141456, Accuracy: 0.966000, Test accuracy: 0.963700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9637
Generating confusion matrix for student3
[[ 968.    0.    3.    1.    1.    2.    7.    2.    6.    9.]
 [   0. 1121.    4.    0.    1.    1.    3.    4.    3.    5.]
 [   0.    3.  983.    4.    1.    0.    3.   22.    9.    1.]
 [   0.    0.   10.  977.    1.   19.    0.    4.   10.   11.]
 [   0.    0.    3.    0.  961.    0.    1.    1.    4.    9.]
 [   0.    1.    0.    5.    0.  847.    3.    0.    9.    4.]
 [   6.    3.    2.    0.    2.    7.  937.    0.    0.    0.]
 [   3.    1.    5.    4.    2.    2.    1.  970.    6.    9.]
 [   3.    5.   20.   15.    2.   10.    3.    5.  917.    5.]
 [   0.    1.    2.    4.   11.    4.    0.   20.   10.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.593831, Accuracy: 0.733000, Test accuracy: 0.750400
Distillation: Epoch : 2, Loss : 1.020134, Accuracy: 0.815000, Test accuracy: 0.825400
Distillation: Epoch : 3, Loss : 0.873380, Accuracy: 0.841000, Test accuracy: 0.859700
Distillation: Epoch : 4, Loss : 0.783645, Accuracy: 0.864000, Test accuracy: 0.874000
Distillation: Epoch : 5, Loss : 0.766221, Accuracy: 0.870000, Test accuracy: 0.887000
Distillation: Epoch : 6, Loss : 0.717247, Accuracy: 0.880000, Test accuracy: 0.895200
Distillation: Epoch : 7, Loss : 0.679412, Accuracy: 0.903000, Test accuracy: 0.900200
Distillation: Epoch : 8, Loss : 0.702106, Accuracy: 0.892000, Test accuracy: 0.905000
Distillation: Epoch : 9, Loss : 0.649958, Accuracy: 0.919000, Test accuracy: 0.907900
Distillation: Epoch : 10, Loss : 0.650016, Accuracy: 0.909000, Test accuracy: 0.910400
Distillation: Epoch : 11, Loss : 0.662703, Accuracy: 0.907000, Test accuracy: 0.912800
Distillation: Epoch : 12, Loss : 0.618084, Accuracy: 0.910000, Test accuracy: 0.917500
Distillation: Epoch : 13, Loss : 0.591928, Accuracy: 0.919000, Test accuracy: 0.918700
Distillation: Epoch : 14, Loss : 0.650908, Accuracy: 0.913000, Test accuracy: 0.921600
Distillation: Epoch : 15, Loss : 0.627733, Accuracy: 0.917000, Test accuracy: 0.922700
Distillation: Epoch : 16, Loss : 0.629590, Accuracy: 0.910000, Test accuracy: 0.924400
Distillation: Epoch : 17, Loss : 0.655419, Accuracy: 0.907000, Test accuracy: 0.925600
Distillation: Epoch : 18, Loss : 0.613118, Accuracy: 0.926000, Test accuracy: 0.927500
Distillation: Epoch : 19, Loss : 0.605810, Accuracy: 0.924000, Test accuracy: 0.927900
Distillation: Epoch : 20, Loss : 0.605151, Accuracy: 0.922000, Test accuracy: 0.930100
Distillation: Epoch : 21, Loss : 0.613076, Accuracy: 0.925000, Test accuracy: 0.930900
Distillation: Epoch : 22, Loss : 0.588305, Accuracy: 0.922000, Test accuracy: 0.931300
Distillation: Epoch : 23, Loss : 0.569291, Accuracy: 0.927000, Test accuracy: 0.932600
Distillation: Epoch : 24, Loss : 0.585043, Accuracy: 0.927000, Test accuracy: 0.934500
Distillation: Epoch : 25, Loss : 0.598042, Accuracy: 0.933000, Test accuracy: 0.934300
Distillation: Epoch : 26, Loss : 0.598545, Accuracy: 0.919000, Test accuracy: 0.936200
Distillation: Epoch : 27, Loss : 0.566179, Accuracy: 0.950000, Test accuracy: 0.937500
Distillation: Epoch : 28, Loss : 0.564742, Accuracy: 0.948000, Test accuracy: 0.938600
Distillation: Epoch : 29, Loss : 0.538660, Accuracy: 0.950000, Test accuracy: 0.939300
Distillation: Epoch : 30, Loss : 0.596650, Accuracy: 0.932000, Test accuracy: 0.941800
Distillation: Epoch : 31, Loss : 0.596067, Accuracy: 0.930000, Test accuracy: 0.941700
Distillation: Epoch : 32, Loss : 0.561784, Accuracy: 0.938000, Test accuracy: 0.942900
Distillation: Epoch : 33, Loss : 0.554434, Accuracy: 0.948000, Test accuracy: 0.943800
Distillation: Epoch : 34, Loss : 0.547602, Accuracy: 0.939000, Test accuracy: 0.944600
Distillation: Epoch : 35, Loss : 0.544173, Accuracy: 0.942000, Test accuracy: 0.945700
Distillation: Epoch : 36, Loss : 0.536632, Accuracy: 0.941000, Test accuracy: 0.945900
Distillation: Epoch : 37, Loss : 0.578920, Accuracy: 0.934000, Test accuracy: 0.946400
Distillation: Epoch : 38, Loss : 0.585550, Accuracy: 0.939000, Test accuracy: 0.947600
Distillation: Epoch : 39, Loss : 0.546911, Accuracy: 0.949000, Test accuracy: 0.948100
Distillation: Epoch : 40, Loss : 0.542150, Accuracy: 0.951000, Test accuracy: 0.948200
Distillation: Epoch : 41, Loss : 0.558052, Accuracy: 0.939000, Test accuracy: 0.949000
Distillation: Epoch : 42, Loss : 0.534584, Accuracy: 0.954000, Test accuracy: 0.949700
Distillation: Epoch : 43, Loss : 0.515380, Accuracy: 0.954000, Test accuracy: 0.950200
Distillation: Epoch : 44, Loss : 0.520977, Accuracy: 0.952000, Test accuracy: 0.950700
Distillation: Epoch : 45, Loss : 0.523076, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 46, Loss : 0.536624, Accuracy: 0.947000, Test accuracy: 0.951000
Distillation: Epoch : 47, Loss : 0.552462, Accuracy: 0.938000, Test accuracy: 0.951000
Distillation: Epoch : 48, Loss : 0.537189, Accuracy: 0.951000, Test accuracy: 0.951500
Distillation: Epoch : 49, Loss : 0.526275, Accuracy: 0.955000, Test accuracy: 0.952000
Distillation: Epoch : 50, Loss : 0.529865, Accuracy: 0.950000, Test accuracy: 0.952400
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9524
Generating confusion matrix for student3
[[ 968.    0.    7.    1.    0.    3.    7.    0.    9.    6.]
 [   0. 1112.    5.    0.    3.    1.    4.    7.    6.    7.]
 [   1.    2.  953.    8.    5.    0.    3.   20.   10.    2.]
 [   1.    2.   16.  975.    0.   26.    0.    7.   16.   17.]
 [   1.    0.    6.    1.  947.    0.    7.    1.    9.   14.]
 [   1.    1.    1.    7.    0.  841.   12.    2.   12.    4.]
 [   6.    5.    3.    0.    3.    8.  922.    0.    5.    0.]
 [   1.    1.    9.    8.    1.    1.    1.  970.    7.   14.]
 [   1.   12.   27.    6.    3.   10.    2.    2.  896.    5.]
 [   0.    0.    5.    4.   20.    2.    0.   19.    4.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.753237, Accuracy: 0.729000, Test accuracy: 0.731200
Distillation: Epoch : 2, Loss : 1.101790, Accuracy: 0.847000, Test accuracy: 0.825800
Distillation: Epoch : 3, Loss : 1.004292, Accuracy: 0.833000, Test accuracy: 0.857300
Distillation: Epoch : 4, Loss : 0.971573, Accuracy: 0.869000, Test accuracy: 0.874700
Distillation: Epoch : 5, Loss : 0.897122, Accuracy: 0.888000, Test accuracy: 0.883500
Distillation: Epoch : 6, Loss : 0.901891, Accuracy: 0.891000, Test accuracy: 0.889500
Distillation: Epoch : 7, Loss : 0.889597, Accuracy: 0.880000, Test accuracy: 0.893900
Distillation: Epoch : 8, Loss : 0.879086, Accuracy: 0.891000, Test accuracy: 0.896100
Distillation: Epoch : 9, Loss : 0.859391, Accuracy: 0.901000, Test accuracy: 0.897700
Distillation: Epoch : 10, Loss : 0.827154, Accuracy: 0.915000, Test accuracy: 0.900900
Distillation: Epoch : 11, Loss : 0.812606, Accuracy: 0.912000, Test accuracy: 0.902200
Distillation: Epoch : 12, Loss : 0.855751, Accuracy: 0.894000, Test accuracy: 0.903300
Distillation: Epoch : 13, Loss : 0.821093, Accuracy: 0.896000, Test accuracy: 0.905000
Distillation: Epoch : 14, Loss : 0.838772, Accuracy: 0.894000, Test accuracy: 0.906600
Distillation: Epoch : 15, Loss : 0.830869, Accuracy: 0.898000, Test accuracy: 0.905800
Distillation: Epoch : 16, Loss : 0.816588, Accuracy: 0.902000, Test accuracy: 0.906900
Distillation: Epoch : 17, Loss : 0.835662, Accuracy: 0.903000, Test accuracy: 0.907700
Distillation: Epoch : 18, Loss : 0.846803, Accuracy: 0.907000, Test accuracy: 0.907400
Distillation: Epoch : 19, Loss : 0.890023, Accuracy: 0.881000, Test accuracy: 0.909800
Distillation: Epoch : 20, Loss : 0.871987, Accuracy: 0.884000, Test accuracy: 0.909300
Distillation: Epoch : 21, Loss : 0.870757, Accuracy: 0.885000, Test accuracy: 0.910300
Distillation: Epoch : 22, Loss : 0.817865, Accuracy: 0.911000, Test accuracy: 0.912100
Distillation: Epoch : 23, Loss : 0.805155, Accuracy: 0.916000, Test accuracy: 0.911500
Distillation: Epoch : 24, Loss : 0.805913, Accuracy: 0.909000, Test accuracy: 0.912500
Distillation: Epoch : 25, Loss : 0.791884, Accuracy: 0.917000, Test accuracy: 0.912900
Distillation: Epoch : 26, Loss : 0.845716, Accuracy: 0.900000, Test accuracy: 0.912900
Distillation: Epoch : 27, Loss : 0.817667, Accuracy: 0.913000, Test accuracy: 0.913800
Distillation: Epoch : 28, Loss : 0.823003, Accuracy: 0.902000, Test accuracy: 0.914500
Distillation: Epoch : 29, Loss : 0.794207, Accuracy: 0.915000, Test accuracy: 0.915200
Distillation: Epoch : 30, Loss : 0.839493, Accuracy: 0.902000, Test accuracy: 0.915900
Distillation: Epoch : 31, Loss : 0.808129, Accuracy: 0.905000, Test accuracy: 0.915900
Distillation: Epoch : 32, Loss : 0.804159, Accuracy: 0.891000, Test accuracy: 0.915200
Distillation: Epoch : 33, Loss : 0.776723, Accuracy: 0.923000, Test accuracy: 0.916000
Distillation: Epoch : 34, Loss : 0.817405, Accuracy: 0.909000, Test accuracy: 0.917100
Distillation: Epoch : 35, Loss : 0.803282, Accuracy: 0.907000, Test accuracy: 0.916900
Distillation: Epoch : 36, Loss : 0.808831, Accuracy: 0.916000, Test accuracy: 0.918400
Distillation: Epoch : 37, Loss : 0.822123, Accuracy: 0.916000, Test accuracy: 0.917100
Distillation: Epoch : 38, Loss : 0.828340, Accuracy: 0.910000, Test accuracy: 0.919600
Distillation: Epoch : 39, Loss : 0.810232, Accuracy: 0.905000, Test accuracy: 0.920100
Distillation: Epoch : 40, Loss : 0.832438, Accuracy: 0.912000, Test accuracy: 0.920000
Distillation: Epoch : 41, Loss : 0.807692, Accuracy: 0.905000, Test accuracy: 0.921000
Distillation: Epoch : 42, Loss : 0.787023, Accuracy: 0.922000, Test accuracy: 0.921400
Distillation: Epoch : 43, Loss : 0.794675, Accuracy: 0.924000, Test accuracy: 0.920100
Distillation: Epoch : 44, Loss : 0.840584, Accuracy: 0.895000, Test accuracy: 0.922100
Distillation: Epoch : 45, Loss : 0.797641, Accuracy: 0.918000, Test accuracy: 0.922500
Distillation: Epoch : 46, Loss : 0.820104, Accuracy: 0.917000, Test accuracy: 0.922500
Distillation: Epoch : 47, Loss : 0.797008, Accuracy: 0.916000, Test accuracy: 0.925200
Distillation: Epoch : 48, Loss : 0.834688, Accuracy: 0.911000, Test accuracy: 0.925600
Distillation: Epoch : 49, Loss : 0.800113, Accuracy: 0.920000, Test accuracy: 0.924500
Distillation: Epoch : 50, Loss : 0.785517, Accuracy: 0.925000, Test accuracy: 0.927000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.927
Generating confusion matrix for student3
[[ 956.    0.    9.    2.    0.    8.    8.    2.    6.    8.]
 [   0. 1105.    9.    1.    1.    2.    3.   12.    4.    4.]
 [   1.    3.  916.   12.    7.    1.    3.   15.    5.    2.]
 [   3.    4.   24.  947.    0.   34.    1.    7.   22.   14.]
 [   0.    1.   11.    3.  928.    4.    9.   10.   11.   38.]
 [   4.    3.    1.   17.    2.  787.   19.    1.   30.    8.]
 [  10.    4.    9.    3.    7.   16.  912.    0.    8.    0.]
 [   1.    1.   11.    9.    2.    7.    2.  947.    8.   24.]
 [   5.   14.   35.   12.    7.   28.    1.    1.  872.   11.]
 [   0.    0.    7.    4.   28.    5.    0.   33.    8.  900.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.837901, Accuracy: 0.747000, Test accuracy: 0.744700
Distillation: Epoch : 2, Loss : 1.273011, Accuracy: 0.813000, Test accuracy: 0.827500
Distillation: Epoch : 3, Loss : 1.154775, Accuracy: 0.834000, Test accuracy: 0.868900
Distillation: Epoch : 4, Loss : 1.081733, Accuracy: 0.868000, Test accuracy: 0.886200
Distillation: Epoch : 5, Loss : 1.036022, Accuracy: 0.890000, Test accuracy: 0.898600
Distillation: Epoch : 6, Loss : 1.014405, Accuracy: 0.896000, Test accuracy: 0.908000
Distillation: Epoch : 7, Loss : 0.990234, Accuracy: 0.915000, Test accuracy: 0.914300
Distillation: Epoch : 8, Loss : 0.993442, Accuracy: 0.909000, Test accuracy: 0.919500
Distillation: Epoch : 9, Loss : 0.984521, Accuracy: 0.925000, Test accuracy: 0.922700
Distillation: Epoch : 10, Loss : 0.967380, Accuracy: 0.916000, Test accuracy: 0.925500
Distillation: Epoch : 11, Loss : 0.936060, Accuracy: 0.922000, Test accuracy: 0.927800
Distillation: Epoch : 12, Loss : 0.925849, Accuracy: 0.923000, Test accuracy: 0.929700
Distillation: Epoch : 13, Loss : 0.925513, Accuracy: 0.940000, Test accuracy: 0.930700
Distillation: Epoch : 14, Loss : 0.945172, Accuracy: 0.920000, Test accuracy: 0.934800
Distillation: Epoch : 15, Loss : 0.931251, Accuracy: 0.921000, Test accuracy: 0.935800
Distillation: Epoch : 16, Loss : 0.918384, Accuracy: 0.947000, Test accuracy: 0.937100
Distillation: Epoch : 17, Loss : 0.918972, Accuracy: 0.947000, Test accuracy: 0.939100
Distillation: Epoch : 18, Loss : 0.904308, Accuracy: 0.945000, Test accuracy: 0.941400
Distillation: Epoch : 19, Loss : 0.921104, Accuracy: 0.933000, Test accuracy: 0.942200
Distillation: Epoch : 20, Loss : 0.923613, Accuracy: 0.932000, Test accuracy: 0.943400
Distillation: Epoch : 21, Loss : 0.909801, Accuracy: 0.951000, Test accuracy: 0.944100
Distillation: Epoch : 22, Loss : 0.897610, Accuracy: 0.947000, Test accuracy: 0.946100
Distillation: Epoch : 23, Loss : 0.910000, Accuracy: 0.937000, Test accuracy: 0.946900
Distillation: Epoch : 24, Loss : 0.943420, Accuracy: 0.936000, Test accuracy: 0.948500
Distillation: Epoch : 25, Loss : 0.917668, Accuracy: 0.939000, Test accuracy: 0.948600
Distillation: Epoch : 26, Loss : 0.901186, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 27, Loss : 0.901217, Accuracy: 0.937000, Test accuracy: 0.949500
Distillation: Epoch : 28, Loss : 0.899090, Accuracy: 0.959000, Test accuracy: 0.951300
Distillation: Epoch : 29, Loss : 0.891000, Accuracy: 0.952000, Test accuracy: 0.951600
Distillation: Epoch : 30, Loss : 0.898325, Accuracy: 0.934000, Test accuracy: 0.952500
Distillation: Epoch : 31, Loss : 0.887110, Accuracy: 0.954000, Test accuracy: 0.952300
Distillation: Epoch : 32, Loss : 0.918993, Accuracy: 0.942000, Test accuracy: 0.954100
Distillation: Epoch : 33, Loss : 0.884681, Accuracy: 0.961000, Test accuracy: 0.954000
Distillation: Epoch : 34, Loss : 0.887287, Accuracy: 0.943000, Test accuracy: 0.955300
Distillation: Epoch : 35, Loss : 0.886306, Accuracy: 0.951000, Test accuracy: 0.954300
Distillation: Epoch : 36, Loss : 0.879712, Accuracy: 0.956000, Test accuracy: 0.954700
Distillation: Epoch : 37, Loss : 0.899165, Accuracy: 0.957000, Test accuracy: 0.955800
Distillation: Epoch : 38, Loss : 0.886588, Accuracy: 0.956000, Test accuracy: 0.956500
Distillation: Epoch : 39, Loss : 0.884888, Accuracy: 0.953000, Test accuracy: 0.957500
Distillation: Epoch : 40, Loss : 0.879434, Accuracy: 0.957000, Test accuracy: 0.957500
Distillation: Epoch : 41, Loss : 0.883650, Accuracy: 0.957000, Test accuracy: 0.957200
Distillation: Epoch : 42, Loss : 0.905125, Accuracy: 0.958000, Test accuracy: 0.957400
Distillation: Epoch : 43, Loss : 0.897264, Accuracy: 0.953000, Test accuracy: 0.957200
Distillation: Epoch : 44, Loss : 0.879087, Accuracy: 0.951000, Test accuracy: 0.957400
Distillation: Epoch : 45, Loss : 0.893138, Accuracy: 0.956000, Test accuracy: 0.958000
Distillation: Epoch : 46, Loss : 0.884028, Accuracy: 0.967000, Test accuracy: 0.958300
Distillation: Epoch : 47, Loss : 0.911172, Accuracy: 0.951000, Test accuracy: 0.958700
Distillation: Epoch : 48, Loss : 0.905050, Accuracy: 0.948000, Test accuracy: 0.958000
Distillation: Epoch : 49, Loss : 0.909747, Accuracy: 0.941000, Test accuracy: 0.958900
Distillation: Epoch : 50, Loss : 0.896966, Accuracy: 0.942000, Test accuracy: 0.959000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.959
Generating confusion matrix for student3
[[ 965.    0.    3.    0.    1.    1.    5.    2.    6.    5.]
 [   0. 1115.    6.    0.    2.    1.    3.    5.    4.    5.]
 [   1.    4.  968.    4.    1.    1.    0.   17.    6.    1.]
 [   0.    2.    9.  983.    0.   14.    0.    6.   12.   14.]
 [   2.    0.    9.    2.  954.    0.    7.    4.    8.   24.]
 [   1.    0.    1.    8.    0.  861.   10.    0.   13.    7.]
 [   7.    4.    3.    0.    4.    5.  930.    0.    5.    1.]
 [   1.    1.    9.    5.    3.    1.    0.  973.    8.   12.]
 [   3.    8.   22.    6.    3.    5.    3.    3.  902.    1.]
 [   0.    1.    2.    2.   14.    3.    0.   18.   10.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.880998, Accuracy: 0.742000, Test accuracy: 0.739800
Distillation: Epoch : 2, Loss : 1.420053, Accuracy: 0.809000, Test accuracy: 0.834300
Distillation: Epoch : 3, Loss : 1.287079, Accuracy: 0.839000, Test accuracy: 0.862900
Distillation: Epoch : 4, Loss : 1.252690, Accuracy: 0.872000, Test accuracy: 0.880500
Distillation: Epoch : 5, Loss : 1.182974, Accuracy: 0.898000, Test accuracy: 0.892000
Distillation: Epoch : 6, Loss : 1.196243, Accuracy: 0.898000, Test accuracy: 0.897800
Distillation: Epoch : 7, Loss : 1.144504, Accuracy: 0.910000, Test accuracy: 0.905000
Distillation: Epoch : 8, Loss : 1.218587, Accuracy: 0.885000, Test accuracy: 0.908500
Distillation: Epoch : 9, Loss : 1.188950, Accuracy: 0.884000, Test accuracy: 0.912300
Distillation: Epoch : 10, Loss : 1.129166, Accuracy: 0.923000, Test accuracy: 0.916000
Distillation: Epoch : 11, Loss : 1.143621, Accuracy: 0.910000, Test accuracy: 0.920600
Distillation: Epoch : 12, Loss : 1.140265, Accuracy: 0.905000, Test accuracy: 0.923600
Distillation: Epoch : 13, Loss : 1.126325, Accuracy: 0.935000, Test accuracy: 0.926500
Distillation: Epoch : 14, Loss : 1.107953, Accuracy: 0.929000, Test accuracy: 0.928300
Distillation: Epoch : 15, Loss : 1.127012, Accuracy: 0.929000, Test accuracy: 0.929500
Distillation: Epoch : 16, Loss : 1.118041, Accuracy: 0.930000, Test accuracy: 0.931500
Distillation: Epoch : 17, Loss : 1.100629, Accuracy: 0.929000, Test accuracy: 0.934200
Distillation: Epoch : 18, Loss : 1.116127, Accuracy: 0.919000, Test accuracy: 0.935300
Distillation: Epoch : 19, Loss : 1.112599, Accuracy: 0.922000, Test accuracy: 0.937200
Distillation: Epoch : 20, Loss : 1.099359, Accuracy: 0.938000, Test accuracy: 0.940000
Distillation: Epoch : 21, Loss : 1.088701, Accuracy: 0.935000, Test accuracy: 0.940700
Distillation: Epoch : 22, Loss : 1.096165, Accuracy: 0.941000, Test accuracy: 0.942700
Distillation: Epoch : 23, Loss : 1.100719, Accuracy: 0.929000, Test accuracy: 0.943400
Distillation: Epoch : 24, Loss : 1.089684, Accuracy: 0.948000, Test accuracy: 0.944000
Distillation: Epoch : 25, Loss : 1.076389, Accuracy: 0.947000, Test accuracy: 0.945200
Distillation: Epoch : 26, Loss : 1.067443, Accuracy: 0.960000, Test accuracy: 0.946200
Distillation: Epoch : 27, Loss : 1.086432, Accuracy: 0.939000, Test accuracy: 0.947800
Distillation: Epoch : 28, Loss : 1.068917, Accuracy: 0.951000, Test accuracy: 0.948200
Distillation: Epoch : 29, Loss : 1.077056, Accuracy: 0.942000, Test accuracy: 0.948300
Distillation: Epoch : 30, Loss : 1.101040, Accuracy: 0.944000, Test accuracy: 0.949400
Distillation: Epoch : 31, Loss : 1.035287, Accuracy: 0.959000, Test accuracy: 0.949800
Distillation: Epoch : 32, Loss : 1.112367, Accuracy: 0.934000, Test accuracy: 0.949900
Distillation: Epoch : 33, Loss : 1.056434, Accuracy: 0.946000, Test accuracy: 0.949800
Distillation: Epoch : 34, Loss : 1.080512, Accuracy: 0.957000, Test accuracy: 0.951400
Distillation: Epoch : 35, Loss : 1.077090, Accuracy: 0.950000, Test accuracy: 0.951500
Distillation: Epoch : 36, Loss : 1.058005, Accuracy: 0.959000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 1.055425, Accuracy: 0.954000, Test accuracy: 0.952600
Distillation: Epoch : 38, Loss : 1.048162, Accuracy: 0.940000, Test accuracy: 0.953600
Distillation: Epoch : 39, Loss : 1.051622, Accuracy: 0.947000, Test accuracy: 0.952400
Distillation: Epoch : 40, Loss : 1.013422, Accuracy: 0.956000, Test accuracy: 0.953400
Distillation: Epoch : 41, Loss : 1.060796, Accuracy: 0.947000, Test accuracy: 0.954300
Distillation: Epoch : 42, Loss : 1.055578, Accuracy: 0.959000, Test accuracy: 0.954100
Distillation: Epoch : 43, Loss : 1.048580, Accuracy: 0.953000, Test accuracy: 0.954100
Distillation: Epoch : 44, Loss : 1.066295, Accuracy: 0.931000, Test accuracy: 0.953700
Distillation: Epoch : 45, Loss : 1.085649, Accuracy: 0.953000, Test accuracy: 0.955000
Distillation: Epoch : 46, Loss : 1.051553, Accuracy: 0.954000, Test accuracy: 0.954600
Distillation: Epoch : 47, Loss : 1.066095, Accuracy: 0.959000, Test accuracy: 0.954900
Distillation: Epoch : 48, Loss : 1.083040, Accuracy: 0.951000, Test accuracy: 0.955300
Distillation: Epoch : 49, Loss : 1.063039, Accuracy: 0.954000, Test accuracy: 0.955600
Distillation: Epoch : 50, Loss : 1.083440, Accuracy: 0.948000, Test accuracy: 0.954900
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9549
Generating confusion matrix for student3
[[ 962.    0.    3.    0.    1.    1.    6.    2.    5.    4.]
 [   0. 1122.    4.    0.    1.    0.    3.    8.    4.    6.]
 [   1.    2.  960.    4.    2.    0.    0.   18.    5.    1.]
 [   0.    2.   17.  983.    0.   19.    0.    8.   17.   14.]
 [   2.    1.    9.    2.  952.    0.   10.    3.   15.   23.]
 [   1.    0.    1.    6.    1.  857.   10.    0.   13.   12.]
 [   8.    3.    2.    0.    1.    4.  925.    0.    5.    1.]
 [   2.    0.    7.    4.    3.    1.    0.  965.   12.   11.]
 [   4.    4.   26.    8.    5.    7.    4.    3.  888.    2.]
 [   0.    1.    3.    3.   16.    3.    0.   21.   10.  935.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.882862, Accuracy: 0.686000, Test accuracy: 0.716500
Distillation: Epoch : 2, Loss : 1.533917, Accuracy: 0.804000, Test accuracy: 0.813000
Distillation: Epoch : 3, Loss : 1.477949, Accuracy: 0.807000, Test accuracy: 0.848800
Distillation: Epoch : 4, Loss : 1.422965, Accuracy: 0.850000, Test accuracy: 0.864100
Distillation: Epoch : 5, Loss : 1.375913, Accuracy: 0.858000, Test accuracy: 0.872600
Distillation: Epoch : 6, Loss : 1.346430, Accuracy: 0.874000, Test accuracy: 0.879700
Distillation: Epoch : 7, Loss : 1.375144, Accuracy: 0.862000, Test accuracy: 0.885800
Distillation: Epoch : 8, Loss : 1.352588, Accuracy: 0.883000, Test accuracy: 0.888500
Distillation: Epoch : 9, Loss : 1.370627, Accuracy: 0.884000, Test accuracy: 0.889900
Distillation: Epoch : 10, Loss : 1.395629, Accuracy: 0.874000, Test accuracy: 0.892200
Distillation: Epoch : 11, Loss : 1.349637, Accuracy: 0.896000, Test accuracy: 0.892200
Distillation: Epoch : 12, Loss : 1.323845, Accuracy: 0.905000, Test accuracy: 0.894300
Distillation: Epoch : 13, Loss : 1.367300, Accuracy: 0.883000, Test accuracy: 0.895900
Distillation: Epoch : 14, Loss : 1.320779, Accuracy: 0.874000, Test accuracy: 0.898000
Distillation: Epoch : 15, Loss : 1.363287, Accuracy: 0.876000, Test accuracy: 0.898500
Distillation: Epoch : 16, Loss : 1.352191, Accuracy: 0.880000, Test accuracy: 0.898900
Distillation: Epoch : 17, Loss : 1.316856, Accuracy: 0.908000, Test accuracy: 0.898200
Distillation: Epoch : 18, Loss : 1.347454, Accuracy: 0.883000, Test accuracy: 0.900100
Distillation: Epoch : 19, Loss : 1.302034, Accuracy: 0.900000, Test accuracy: 0.899100
Distillation: Epoch : 20, Loss : 1.295325, Accuracy: 0.912000, Test accuracy: 0.900200
Distillation: Epoch : 21, Loss : 1.354871, Accuracy: 0.880000, Test accuracy: 0.901300
Distillation: Epoch : 22, Loss : 1.325838, Accuracy: 0.901000, Test accuracy: 0.901900
Distillation: Epoch : 23, Loss : 1.291648, Accuracy: 0.906000, Test accuracy: 0.901400
Distillation: Epoch : 24, Loss : 1.322422, Accuracy: 0.888000, Test accuracy: 0.905000
Distillation: Epoch : 25, Loss : 1.324447, Accuracy: 0.890000, Test accuracy: 0.904900
Distillation: Epoch : 26, Loss : 1.311004, Accuracy: 0.900000, Test accuracy: 0.906200
Distillation: Epoch : 27, Loss : 1.318646, Accuracy: 0.904000, Test accuracy: 0.906100
Distillation: Epoch : 28, Loss : 1.319429, Accuracy: 0.902000, Test accuracy: 0.905800
Distillation: Epoch : 29, Loss : 1.309531, Accuracy: 0.918000, Test accuracy: 0.909400
Distillation: Epoch : 30, Loss : 1.338918, Accuracy: 0.890000, Test accuracy: 0.906500
Distillation: Epoch : 31, Loss : 1.301063, Accuracy: 0.921000, Test accuracy: 0.909500
Distillation: Epoch : 32, Loss : 1.289331, Accuracy: 0.917000, Test accuracy: 0.909800
Distillation: Epoch : 33, Loss : 1.309389, Accuracy: 0.905000, Test accuracy: 0.910900
Distillation: Epoch : 34, Loss : 1.296233, Accuracy: 0.900000, Test accuracy: 0.910700
Distillation: Epoch : 35, Loss : 1.296466, Accuracy: 0.908000, Test accuracy: 0.911100
Distillation: Epoch : 36, Loss : 1.305779, Accuracy: 0.911000, Test accuracy: 0.912800
Distillation: Epoch : 37, Loss : 1.301934, Accuracy: 0.903000, Test accuracy: 0.913700
Distillation: Epoch : 38, Loss : 1.314539, Accuracy: 0.899000, Test accuracy: 0.913700
Distillation: Epoch : 39, Loss : 1.293180, Accuracy: 0.904000, Test accuracy: 0.915500
Distillation: Epoch : 40, Loss : 1.298434, Accuracy: 0.915000, Test accuracy: 0.915500
Distillation: Epoch : 41, Loss : 1.305283, Accuracy: 0.916000, Test accuracy: 0.916300
Distillation: Epoch : 42, Loss : 1.304186, Accuracy: 0.907000, Test accuracy: 0.916500
Distillation: Epoch : 43, Loss : 1.277133, Accuracy: 0.909000, Test accuracy: 0.918300
Distillation: Epoch : 44, Loss : 1.314794, Accuracy: 0.890000, Test accuracy: 0.919000
Distillation: Epoch : 45, Loss : 1.278397, Accuracy: 0.913000, Test accuracy: 0.920600
Distillation: Epoch : 46, Loss : 1.307832, Accuracy: 0.902000, Test accuracy: 0.921600
Distillation: Epoch : 47, Loss : 1.280470, Accuracy: 0.911000, Test accuracy: 0.922300
Distillation: Epoch : 48, Loss : 1.243978, Accuracy: 0.912000, Test accuracy: 0.921000
Distillation: Epoch : 49, Loss : 1.290735, Accuracy: 0.917000, Test accuracy: 0.923100
Distillation: Epoch : 50, Loss : 1.259808, Accuracy: 0.926000, Test accuracy: 0.923800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9238
Generating confusion matrix for student3
[[ 958.    0.   11.    4.    1.    7.    7.    0.    5.    8.]
 [   0. 1105.   12.    1.    0.    2.    3.   14.    5.    5.]
 [   0.    2.  894.   12.    5.    1.    3.   14.    7.    0.]
 [   2.    7.   35.  948.    0.   38.    1.    8.   26.   16.]
 [   2.    0.   14.    2.  941.    7.    9.   19.   18.   47.]
 [   5.    4.    0.   19.    2.  793.   17.    0.   35.    7.]
 [   8.    4.   11.    3.    6.   15.  914.    0.   10.    0.]
 [   1.    1.   16.    9.    1.    5.    2.  936.    8.   22.]
 [   4.   12.   33.    9.    6.   20.    2.    1.  852.    7.]
 [   0.    0.    6.    3.   20.    4.    0.   36.    8.  897.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.004501, Accuracy: 0.689000, Test accuracy: 0.703700
Distillation: Epoch : 2, Loss : 1.665720, Accuracy: 0.762000, Test accuracy: 0.804700
Distillation: Epoch : 3, Loss : 1.565127, Accuracy: 0.837000, Test accuracy: 0.843000
Distillation: Epoch : 4, Loss : 1.541368, Accuracy: 0.860000, Test accuracy: 0.858900
Distillation: Epoch : 5, Loss : 1.501231, Accuracy: 0.863000, Test accuracy: 0.869700
Distillation: Epoch : 6, Loss : 1.525386, Accuracy: 0.865000, Test accuracy: 0.876600
Distillation: Epoch : 7, Loss : 1.482164, Accuracy: 0.878000, Test accuracy: 0.881900
Distillation: Epoch : 8, Loss : 1.483656, Accuracy: 0.886000, Test accuracy: 0.885500
Distillation: Epoch : 9, Loss : 1.478648, Accuracy: 0.884000, Test accuracy: 0.890300
Distillation: Epoch : 10, Loss : 1.475147, Accuracy: 0.902000, Test accuracy: 0.893700
Distillation: Epoch : 11, Loss : 1.438819, Accuracy: 0.899000, Test accuracy: 0.895400
Distillation: Epoch : 12, Loss : 1.450045, Accuracy: 0.872000, Test accuracy: 0.898200
Distillation: Epoch : 13, Loss : 1.449877, Accuracy: 0.896000, Test accuracy: 0.899200
Distillation: Epoch : 14, Loss : 1.453176, Accuracy: 0.887000, Test accuracy: 0.900400
Distillation: Epoch : 15, Loss : 1.445609, Accuracy: 0.914000, Test accuracy: 0.901200
Distillation: Epoch : 16, Loss : 1.464630, Accuracy: 0.878000, Test accuracy: 0.903600
Distillation: Epoch : 17, Loss : 1.410475, Accuracy: 0.911000, Test accuracy: 0.906200
Distillation: Epoch : 18, Loss : 1.444517, Accuracy: 0.893000, Test accuracy: 0.907700
Distillation: Epoch : 19, Loss : 1.456876, Accuracy: 0.897000, Test accuracy: 0.909400
Distillation: Epoch : 20, Loss : 1.423555, Accuracy: 0.901000, Test accuracy: 0.909100
Distillation: Epoch : 21, Loss : 1.442096, Accuracy: 0.919000, Test accuracy: 0.913200
Distillation: Epoch : 22, Loss : 1.419416, Accuracy: 0.906000, Test accuracy: 0.912300
Distillation: Epoch : 23, Loss : 1.422503, Accuracy: 0.912000, Test accuracy: 0.915000
Distillation: Epoch : 24, Loss : 1.421660, Accuracy: 0.915000, Test accuracy: 0.916800
Distillation: Epoch : 25, Loss : 1.412298, Accuracy: 0.908000, Test accuracy: 0.918000
Distillation: Epoch : 26, Loss : 1.431988, Accuracy: 0.909000, Test accuracy: 0.919800
Distillation: Epoch : 27, Loss : 1.420778, Accuracy: 0.919000, Test accuracy: 0.921500
Distillation: Epoch : 28, Loss : 1.400763, Accuracy: 0.914000, Test accuracy: 0.922900
Distillation: Epoch : 29, Loss : 1.392643, Accuracy: 0.924000, Test accuracy: 0.924500
Distillation: Epoch : 30, Loss : 1.431244, Accuracy: 0.911000, Test accuracy: 0.924500
Distillation: Epoch : 31, Loss : 1.392447, Accuracy: 0.927000, Test accuracy: 0.927200
Distillation: Epoch : 32, Loss : 1.423325, Accuracy: 0.916000, Test accuracy: 0.929100
Distillation: Epoch : 33, Loss : 1.405091, Accuracy: 0.921000, Test accuracy: 0.929800
Distillation: Epoch : 34, Loss : 1.377685, Accuracy: 0.926000, Test accuracy: 0.931900
Distillation: Epoch : 35, Loss : 1.415666, Accuracy: 0.918000, Test accuracy: 0.932600
Distillation: Epoch : 36, Loss : 1.402858, Accuracy: 0.936000, Test accuracy: 0.933200
Distillation: Epoch : 37, Loss : 1.405541, Accuracy: 0.922000, Test accuracy: 0.934200
Distillation: Epoch : 38, Loss : 1.407715, Accuracy: 0.930000, Test accuracy: 0.935300
Distillation: Epoch : 39, Loss : 1.384267, Accuracy: 0.930000, Test accuracy: 0.936600
Distillation: Epoch : 40, Loss : 1.398945, Accuracy: 0.926000, Test accuracy: 0.937000
Distillation: Epoch : 41, Loss : 1.391338, Accuracy: 0.930000, Test accuracy: 0.938300
Distillation: Epoch : 42, Loss : 1.402506, Accuracy: 0.929000, Test accuracy: 0.938700
Distillation: Epoch : 43, Loss : 1.385779, Accuracy: 0.939000, Test accuracy: 0.938200
Distillation: Epoch : 44, Loss : 1.426584, Accuracy: 0.924000, Test accuracy: 0.939100
Distillation: Epoch : 45, Loss : 1.382919, Accuracy: 0.931000, Test accuracy: 0.940000
Distillation: Epoch : 46, Loss : 1.398786, Accuracy: 0.933000, Test accuracy: 0.940700
Distillation: Epoch : 47, Loss : 1.377910, Accuracy: 0.929000, Test accuracy: 0.940900
Distillation: Epoch : 48, Loss : 1.390399, Accuracy: 0.944000, Test accuracy: 0.942800
Distillation: Epoch : 49, Loss : 1.367648, Accuracy: 0.941000, Test accuracy: 0.943200
Distillation: Epoch : 50, Loss : 1.381831, Accuracy: 0.941000, Test accuracy: 0.943500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9435
Generating confusion matrix for student3
[[ 960.    0.    9.    1.    0.    4.    5.    0.    6.    5.]
 [   0. 1098.    7.    0.    2.    1.    2.    8.    2.    6.]
 [   3.    2.  939.    7.    4.    1.    0.   17.    8.    1.]
 [   0.    3.   10.  977.    0.   21.    0.   10.   20.   19.]
 [   1.    1.    8.    2.  950.    0.    7.    6.   14.   30.]
 [   3.    4.    0.    7.    0.  846.   29.    3.   21.    7.]
 [  10.    4.    6.    2.    5.    8.  915.    0.    2.    0.]
 [   2.    1.   15.    8.    0.    0.    0.  946.    5.   20.]
 [   1.   22.   33.    5.    4.   10.    0.    3.  886.    3.]
 [   0.    0.    5.    1.   17.    1.    0.   35.   10.  918.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.116309, Accuracy: 0.581000, Test accuracy: 0.564000
Distillation: Epoch : 2, Loss : 1.804298, Accuracy: 0.800000, Test accuracy: 0.802100
Distillation: Epoch : 3, Loss : 1.669871, Accuracy: 0.847000, Test accuracy: 0.848200
Distillation: Epoch : 4, Loss : 1.648579, Accuracy: 0.849000, Test accuracy: 0.866600
Distillation: Epoch : 5, Loss : 1.607064, Accuracy: 0.869000, Test accuracy: 0.878100
Distillation: Epoch : 6, Loss : 1.611801, Accuracy: 0.864000, Test accuracy: 0.884700
Distillation: Epoch : 7, Loss : 1.568254, Accuracy: 0.912000, Test accuracy: 0.889500
Distillation: Epoch : 8, Loss : 1.585225, Accuracy: 0.880000, Test accuracy: 0.893900
Distillation: Epoch : 9, Loss : 1.573052, Accuracy: 0.901000, Test accuracy: 0.897400
Distillation: Epoch : 10, Loss : 1.540044, Accuracy: 0.894000, Test accuracy: 0.900700
Distillation: Epoch : 11, Loss : 1.580431, Accuracy: 0.883000, Test accuracy: 0.904500
Distillation: Epoch : 12, Loss : 1.551117, Accuracy: 0.910000, Test accuracy: 0.906400
Distillation: Epoch : 13, Loss : 1.569340, Accuracy: 0.910000, Test accuracy: 0.910400
Distillation: Epoch : 14, Loss : 1.542506, Accuracy: 0.913000, Test accuracy: 0.911600
Distillation: Epoch : 15, Loss : 1.536257, Accuracy: 0.920000, Test accuracy: 0.916000
Distillation: Epoch : 16, Loss : 1.533444, Accuracy: 0.908000, Test accuracy: 0.917600
Distillation: Epoch : 17, Loss : 1.531563, Accuracy: 0.919000, Test accuracy: 0.919000
Distillation: Epoch : 18, Loss : 1.511145, Accuracy: 0.925000, Test accuracy: 0.922400
Distillation: Epoch : 19, Loss : 1.526282, Accuracy: 0.913000, Test accuracy: 0.923400
Distillation: Epoch : 20, Loss : 1.551307, Accuracy: 0.909000, Test accuracy: 0.925300
Distillation: Epoch : 21, Loss : 1.525747, Accuracy: 0.920000, Test accuracy: 0.927700
Distillation: Epoch : 22, Loss : 1.520905, Accuracy: 0.932000, Test accuracy: 0.927900
Distillation: Epoch : 23, Loss : 1.525931, Accuracy: 0.912000, Test accuracy: 0.929500
Distillation: Epoch : 24, Loss : 1.529334, Accuracy: 0.932000, Test accuracy: 0.931500
Distillation: Epoch : 25, Loss : 1.548772, Accuracy: 0.926000, Test accuracy: 0.932100
Distillation: Epoch : 26, Loss : 1.519477, Accuracy: 0.924000, Test accuracy: 0.933300
Distillation: Epoch : 27, Loss : 1.524185, Accuracy: 0.916000, Test accuracy: 0.934000
Distillation: Epoch : 28, Loss : 1.509313, Accuracy: 0.939000, Test accuracy: 0.935800
Distillation: Epoch : 29, Loss : 1.510201, Accuracy: 0.929000, Test accuracy: 0.936300
Distillation: Epoch : 30, Loss : 1.498527, Accuracy: 0.933000, Test accuracy: 0.938000
Distillation: Epoch : 31, Loss : 1.507516, Accuracy: 0.934000, Test accuracy: 0.939500
Distillation: Epoch : 32, Loss : 1.536868, Accuracy: 0.939000, Test accuracy: 0.940100
Distillation: Epoch : 33, Loss : 1.526890, Accuracy: 0.933000, Test accuracy: 0.940600
Distillation: Epoch : 34, Loss : 1.538842, Accuracy: 0.929000, Test accuracy: 0.942300
Distillation: Epoch : 35, Loss : 1.521008, Accuracy: 0.929000, Test accuracy: 0.942800
Distillation: Epoch : 36, Loss : 1.509534, Accuracy: 0.937000, Test accuracy: 0.943000
Distillation: Epoch : 37, Loss : 1.536076, Accuracy: 0.931000, Test accuracy: 0.943600
Distillation: Epoch : 38, Loss : 1.526282, Accuracy: 0.930000, Test accuracy: 0.943800
Distillation: Epoch : 39, Loss : 1.512136, Accuracy: 0.932000, Test accuracy: 0.944000
Distillation: Epoch : 40, Loss : 1.497742, Accuracy: 0.945000, Test accuracy: 0.944600
Distillation: Epoch : 41, Loss : 1.519539, Accuracy: 0.928000, Test accuracy: 0.946500
Distillation: Epoch : 42, Loss : 1.516078, Accuracy: 0.942000, Test accuracy: 0.945700
Distillation: Epoch : 43, Loss : 1.520475, Accuracy: 0.935000, Test accuracy: 0.946200
Distillation: Epoch : 44, Loss : 1.500262, Accuracy: 0.948000, Test accuracy: 0.946700
Distillation: Epoch : 45, Loss : 1.506862, Accuracy: 0.935000, Test accuracy: 0.946200
Distillation: Epoch : 46, Loss : 1.498145, Accuracy: 0.940000, Test accuracy: 0.946300
Distillation: Epoch : 47, Loss : 1.517598, Accuracy: 0.946000, Test accuracy: 0.947100
Distillation: Epoch : 48, Loss : 1.507902, Accuracy: 0.942000, Test accuracy: 0.947000
Distillation: Epoch : 49, Loss : 1.518875, Accuracy: 0.951000, Test accuracy: 0.948100
Distillation: Epoch : 50, Loss : 1.510939, Accuracy: 0.947000, Test accuracy: 0.947600
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9476
Generating confusion matrix for student3
[[ 962.    0.    7.    2.    0.    6.    7.    0.    6.    3.]
 [   0. 1111.    3.    0.    0.    0.    2.   10.    7.    6.]
 [   1.    1.  957.   12.    4.    1.    1.   17.    5.    0.]
 [   2.    3.   24.  956.    2.   14.    0.    9.   14.   10.]
 [   2.    1.   13.    1.  943.    3.    7.   12.   12.   26.]
 [   3.    2.    1.   23.    5.  847.   12.    1.   21.   10.]
 [   7.    6.    3.    1.    3.    8.  929.    0.    6.    2.]
 [   1.    0.    9.   12.    2.    2.    0.  957.    9.   15.]
 [   2.   11.   14.    3.    2.    7.    0.    2.  885.    8.]
 [   0.    0.    1.    0.   21.    4.    0.   20.    9.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.123734, Accuracy: 0.655000, Test accuracy: 0.657000
Distillation: Epoch : 2, Loss : 1.946052, Accuracy: 0.780000, Test accuracy: 0.795100
Distillation: Epoch : 3, Loss : 1.897874, Accuracy: 0.825000, Test accuracy: 0.827600
Distillation: Epoch : 4, Loss : 1.863959, Accuracy: 0.840000, Test accuracy: 0.850800
Distillation: Epoch : 5, Loss : 1.842251, Accuracy: 0.867000, Test accuracy: 0.860600
Distillation: Epoch : 6, Loss : 1.846469, Accuracy: 0.871000, Test accuracy: 0.867300
Distillation: Epoch : 7, Loss : 1.832877, Accuracy: 0.892000, Test accuracy: 0.873900
Distillation: Epoch : 8, Loss : 1.842687, Accuracy: 0.875000, Test accuracy: 0.880600
Distillation: Epoch : 9, Loss : 1.818995, Accuracy: 0.886000, Test accuracy: 0.882200
Distillation: Epoch : 10, Loss : 1.839655, Accuracy: 0.867000, Test accuracy: 0.884800
Distillation: Epoch : 11, Loss : 1.824286, Accuracy: 0.881000, Test accuracy: 0.887900
Distillation: Epoch : 12, Loss : 1.830514, Accuracy: 0.879000, Test accuracy: 0.888300
Distillation: Epoch : 13, Loss : 1.840044, Accuracy: 0.896000, Test accuracy: 0.893500
Distillation: Epoch : 14, Loss : 1.821061, Accuracy: 0.894000, Test accuracy: 0.892300
Distillation: Epoch : 15, Loss : 1.833601, Accuracy: 0.893000, Test accuracy: 0.894900
Distillation: Epoch : 16, Loss : 1.829514, Accuracy: 0.899000, Test accuracy: 0.893100
Distillation: Epoch : 17, Loss : 1.833306, Accuracy: 0.888000, Test accuracy: 0.897600
Distillation: Epoch : 18, Loss : 1.835361, Accuracy: 0.879000, Test accuracy: 0.899100
Distillation: Epoch : 19, Loss : 1.824645, Accuracy: 0.891000, Test accuracy: 0.898700
Distillation: Epoch : 20, Loss : 1.820980, Accuracy: 0.908000, Test accuracy: 0.901000
Distillation: Epoch : 21, Loss : 1.818729, Accuracy: 0.904000, Test accuracy: 0.904500
Distillation: Epoch : 22, Loss : 1.814622, Accuracy: 0.905000, Test accuracy: 0.905400
Distillation: Epoch : 23, Loss : 1.817716, Accuracy: 0.910000, Test accuracy: 0.907600
Distillation: Epoch : 24, Loss : 1.811629, Accuracy: 0.891000, Test accuracy: 0.909000
Distillation: Epoch : 25, Loss : 1.801331, Accuracy: 0.913000, Test accuracy: 0.911800
Distillation: Epoch : 26, Loss : 1.807982, Accuracy: 0.907000, Test accuracy: 0.911400
Distillation: Epoch : 27, Loss : 1.806709, Accuracy: 0.922000, Test accuracy: 0.914800
Distillation: Epoch : 28, Loss : 1.814879, Accuracy: 0.899000, Test accuracy: 0.917200
Distillation: Epoch : 29, Loss : 1.808125, Accuracy: 0.895000, Test accuracy: 0.918900
Distillation: Epoch : 30, Loss : 1.817048, Accuracy: 0.908000, Test accuracy: 0.920800
Distillation: Epoch : 31, Loss : 1.808158, Accuracy: 0.913000, Test accuracy: 0.924000
Distillation: Epoch : 32, Loss : 1.787784, Accuracy: 0.916000, Test accuracy: 0.924700
Distillation: Epoch : 33, Loss : 1.787500, Accuracy: 0.935000, Test accuracy: 0.927000
Distillation: Epoch : 34, Loss : 1.795033, Accuracy: 0.918000, Test accuracy: 0.930100
Distillation: Epoch : 35, Loss : 1.788865, Accuracy: 0.934000, Test accuracy: 0.930700
Distillation: Epoch : 36, Loss : 1.810931, Accuracy: 0.928000, Test accuracy: 0.933500
Distillation: Epoch : 37, Loss : 1.809679, Accuracy: 0.927000, Test accuracy: 0.933900
Distillation: Epoch : 38, Loss : 1.788087, Accuracy: 0.923000, Test accuracy: 0.936200
Distillation: Epoch : 39, Loss : 1.768461, Accuracy: 0.938000, Test accuracy: 0.936500
Distillation: Epoch : 40, Loss : 1.765170, Accuracy: 0.928000, Test accuracy: 0.938300
Distillation: Epoch : 41, Loss : 1.789028, Accuracy: 0.931000, Test accuracy: 0.939800
Distillation: Epoch : 42, Loss : 1.797516, Accuracy: 0.943000, Test accuracy: 0.941300
Distillation: Epoch : 43, Loss : 1.762930, Accuracy: 0.935000, Test accuracy: 0.943100
Distillation: Epoch : 44, Loss : 1.786375, Accuracy: 0.925000, Test accuracy: 0.944500
Distillation: Epoch : 45, Loss : 1.800160, Accuracy: 0.932000, Test accuracy: 0.944400
Distillation: Epoch : 46, Loss : 1.791828, Accuracy: 0.946000, Test accuracy: 0.944400
Distillation: Epoch : 47, Loss : 1.789231, Accuracy: 0.944000, Test accuracy: 0.945900
Distillation: Epoch : 48, Loss : 1.792063, Accuracy: 0.938000, Test accuracy: 0.945300
Distillation: Epoch : 49, Loss : 1.768122, Accuracy: 0.935000, Test accuracy: 0.946300
Distillation: Epoch : 50, Loss : 1.781008, Accuracy: 0.942000, Test accuracy: 0.947500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9475
Generating confusion matrix for student3
[[ 957.    0.    6.    1.    0.    4.    7.    1.    6.    6.]
 [   0. 1117.   13.    0.    1.    1.    3.    9.    4.    5.]
 [   2.    1.  942.    2.    8.    1.    1.   15.    7.    0.]
 [   1.    4.   10.  981.    0.   17.    0.    4.   18.   17.]
 [   4.    0.   10.    1.  945.    2.   11.   13.   15.   36.]
 [   3.    4.    1.    6.    1.  853.   24.    3.   14.   10.]
 [  10.    5.    7.    2.    6.    7.  911.    0.    3.    0.]
 [   1.    0.   14.    6.    0.    2.    0.  957.    8.   11.]
 [   2.    4.   27.    7.    2.    4.    1.    2.  889.    1.]
 [   0.    0.    2.    4.   19.    1.    0.   24.   10.  923.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.194853, Accuracy: 0.664000, Test accuracy: 0.669100
Distillation: Epoch : 2, Loss : 2.099284, Accuracy: 0.795000, Test accuracy: 0.785800
Distillation: Epoch : 3, Loss : 2.074129, Accuracy: 0.838000, Test accuracy: 0.818900
Distillation: Epoch : 4, Loss : 2.069749, Accuracy: 0.830000, Test accuracy: 0.834200
Distillation: Epoch : 5, Loss : 2.065681, Accuracy: 0.836000, Test accuracy: 0.845500
Distillation: Epoch : 6, Loss : 2.066355, Accuracy: 0.849000, Test accuracy: 0.855900
Distillation: Epoch : 7, Loss : 2.065702, Accuracy: 0.851000, Test accuracy: 0.859700
Distillation: Epoch : 8, Loss : 2.067554, Accuracy: 0.862000, Test accuracy: 0.866700
Distillation: Epoch : 9, Loss : 2.059016, Accuracy: 0.860000, Test accuracy: 0.867400
Distillation: Epoch : 10, Loss : 2.057963, Accuracy: 0.859000, Test accuracy: 0.872400
Distillation: Epoch : 11, Loss : 2.051803, Accuracy: 0.868000, Test accuracy: 0.871500
Distillation: Epoch : 12, Loss : 2.058808, Accuracy: 0.870000, Test accuracy: 0.872800
Distillation: Epoch : 13, Loss : 2.057677, Accuracy: 0.883000, Test accuracy: 0.876600
Distillation: Epoch : 14, Loss : 2.056251, Accuracy: 0.889000, Test accuracy: 0.879600
Distillation: Epoch : 15, Loss : 2.056547, Accuracy: 0.874000, Test accuracy: 0.879000
Distillation: Epoch : 16, Loss : 2.049619, Accuracy: 0.886000, Test accuracy: 0.880400
Distillation: Epoch : 17, Loss : 2.043617, Accuracy: 0.888000, Test accuracy: 0.881400
Distillation: Epoch : 18, Loss : 2.052246, Accuracy: 0.873000, Test accuracy: 0.882400
Distillation: Epoch : 19, Loss : 2.062363, Accuracy: 0.851000, Test accuracy: 0.879900
Distillation: Epoch : 20, Loss : 2.047615, Accuracy: 0.887000, Test accuracy: 0.881400
Distillation: Epoch : 21, Loss : 2.052153, Accuracy: 0.867000, Test accuracy: 0.882400
Distillation: Epoch : 22, Loss : 2.041968, Accuracy: 0.878000, Test accuracy: 0.882200
Distillation: Epoch : 23, Loss : 2.057687, Accuracy: 0.878000, Test accuracy: 0.883900
Distillation: Epoch : 24, Loss : 2.061454, Accuracy: 0.880000, Test accuracy: 0.883300
Distillation: Epoch : 25, Loss : 2.049742, Accuracy: 0.869000, Test accuracy: 0.883800
Distillation: Epoch : 26, Loss : 2.055808, Accuracy: 0.872000, Test accuracy: 0.886200
Distillation: Epoch : 27, Loss : 2.070619, Accuracy: 0.878000, Test accuracy: 0.887000
Distillation: Epoch : 28, Loss : 2.052614, Accuracy: 0.879000, Test accuracy: 0.887400
Distillation: Epoch : 29, Loss : 2.054619, Accuracy: 0.891000, Test accuracy: 0.888500
Distillation: Epoch : 30, Loss : 2.045835, Accuracy: 0.883000, Test accuracy: 0.889700
Distillation: Epoch : 31, Loss : 2.045330, Accuracy: 0.886000, Test accuracy: 0.889100
Distillation: Epoch : 32, Loss : 2.051787, Accuracy: 0.892000, Test accuracy: 0.890500
Distillation: Epoch : 33, Loss : 2.052997, Accuracy: 0.890000, Test accuracy: 0.889900
Distillation: Epoch : 34, Loss : 2.045825, Accuracy: 0.887000, Test accuracy: 0.890800
Distillation: Epoch : 35, Loss : 2.051265, Accuracy: 0.877000, Test accuracy: 0.889900
Distillation: Epoch : 36, Loss : 2.038351, Accuracy: 0.882000, Test accuracy: 0.894600
Distillation: Epoch : 37, Loss : 2.039976, Accuracy: 0.887000, Test accuracy: 0.896800
Distillation: Epoch : 38, Loss : 2.045176, Accuracy: 0.890000, Test accuracy: 0.898700
Distillation: Epoch : 39, Loss : 2.042152, Accuracy: 0.897000, Test accuracy: 0.898200
Distillation: Epoch : 40, Loss : 2.038224, Accuracy: 0.898000, Test accuracy: 0.900100
Distillation: Epoch : 41, Loss : 2.049298, Accuracy: 0.886000, Test accuracy: 0.900600
Distillation: Epoch : 42, Loss : 2.040220, Accuracy: 0.893000, Test accuracy: 0.901700
Distillation: Epoch : 43, Loss : 2.026902, Accuracy: 0.900000, Test accuracy: 0.902100
Distillation: Epoch : 44, Loss : 2.035810, Accuracy: 0.898000, Test accuracy: 0.903100
Distillation: Epoch : 45, Loss : 2.051380, Accuracy: 0.878000, Test accuracy: 0.905600
Distillation: Epoch : 46, Loss : 2.039531, Accuracy: 0.896000, Test accuracy: 0.906000
Distillation: Epoch : 47, Loss : 2.031131, Accuracy: 0.888000, Test accuracy: 0.908200
Distillation: Epoch : 48, Loss : 2.035539, Accuracy: 0.884000, Test accuracy: 0.909500
Distillation: Epoch : 49, Loss : 2.041396, Accuracy: 0.899000, Test accuracy: 0.911700
Distillation: Epoch : 50, Loss : 2.036206, Accuracy: 0.910000, Test accuracy: 0.912300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9123
Generating confusion matrix for student3
[[ 946.    0.   13.    5.    0.    8.    8.    2.    3.    7.]
 [   0. 1107.   11.    1.    0.    1.    3.   15.    6.    5.]
 [   1.    1.  867.   11.    6.    1.    1.   14.    8.    0.]
 [   5.    5.   36.  950.    0.   38.    1.    8.   40.   19.]
 [   4.    1.   25.    2.  931.   10.   13.   25.   17.   59.]
 [   6.    7.    1.   13.    4.  791.   25.    3.   36.   10.]
 [  11.    4.   18.    3.    7.   15.  907.    0.    8.    0.]
 [   1.    0.   14.   12.    1.    4.    0.  919.    9.   34.]
 [   6.   10.   46.    9.    9.   19.    0.    1.  834.    4.]
 [   0.    0.    1.    4.   24.    5.    0.   41.   13.  871.]]
</confusion_matrix>
