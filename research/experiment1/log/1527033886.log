Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.112102, Accuracy: 0.972000, Test accuracy: 0.967500
Starting training epoch 1
Epoch : 2, Loss : 0.068621, Accuracy: 0.976000, Test accuracy: 0.977900
Starting training epoch 2
Epoch : 3, Loss : 0.048716, Accuracy: 0.984000, Test accuracy: 0.983600
Starting training epoch 3
Epoch : 4, Loss : 0.011356, Accuracy: 0.996000, Test accuracy: 0.986200
Starting training epoch 4
Epoch : 5, Loss : 0.033696, Accuracy: 0.992000, Test accuracy: 0.988900
Starting training epoch 5
Epoch : 6, Loss : 0.018053, Accuracy: 0.992000, Test accuracy: 0.988600
Starting training epoch 6
Epoch : 7, Loss : 0.031920, Accuracy: 0.988000, Test accuracy: 0.989200
Starting training epoch 7
Epoch : 8, Loss : 0.009232, Accuracy: 0.996000, Test accuracy: 0.989900
Starting training epoch 8
Epoch : 9, Loss : 0.012405, Accuracy: 0.996000, Test accuracy: 0.990300
Starting training epoch 9
Epoch : 10, Loss : 0.007600, Accuracy: 0.996000, Test accuracy: 0.991300
Starting training epoch 10
Epoch : 11, Loss : 0.007456, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 11
Epoch : 12, Loss : 0.004614, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 12
Epoch : 13, Loss : 0.006322, Accuracy: 0.996000, Test accuracy: 0.991300
Starting training epoch 13
Epoch : 14, Loss : 0.004722, Accuracy: 0.996000, Test accuracy: 0.992800
Starting training epoch 14
Epoch : 15, Loss : 0.002935, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 15
Epoch : 16, Loss : 0.006073, Accuracy: 0.996000, Test accuracy: 0.993100
Starting training epoch 16
Epoch : 17, Loss : 0.032577, Accuracy: 0.996000, Test accuracy: 0.992500
Starting training epoch 17
Epoch : 18, Loss : 0.002685, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 18
Epoch : 19, Loss : 0.001332, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 19
Epoch : 20, Loss : 0.002788, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 20
Epoch : 21, Loss : 0.001657, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 21
Epoch : 22, Loss : 0.000652, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 22
Epoch : 23, Loss : 0.001461, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 23
Epoch : 24, Loss : 0.001007, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 24
Epoch : 25, Loss : 0.000318, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 25
Epoch : 26, Loss : 0.000378, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 26
Epoch : 27, Loss : 0.001005, Accuracy: 1.000000, Test accuracy: 0.991800
Starting training epoch 27
Epoch : 28, Loss : 0.000476, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 28
Epoch : 29, Loss : 0.000038, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 29
Epoch : 30, Loss : 0.000273, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 30
Epoch : 31, Loss : 0.000219, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 31
Epoch : 32, Loss : 0.000155, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 32
Epoch : 33, Loss : 0.000083, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 33
Epoch : 34, Loss : 0.000241, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 34
Epoch : 35, Loss : 0.000453, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 35
Epoch : 36, Loss : 0.000032, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 36
Epoch : 37, Loss : 0.000057, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 37
Epoch : 38, Loss : 0.000131, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 38
Epoch : 39, Loss : 0.000127, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 39
Epoch : 40, Loss : 0.000042, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 40
Epoch : 41, Loss : 0.000045, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 41
Epoch : 42, Loss : 0.000645, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 42
Epoch : 43, Loss : 0.001428, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 43
Epoch : 44, Loss : 0.000216, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 44
Epoch : 45, Loss : 0.000006, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 45
Epoch : 46, Loss : 0.000064, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 46
Epoch : 47, Loss : 0.000026, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 47
Epoch : 48, Loss : 0.000088, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 48
Epoch : 49, Loss : 0.000199, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 49
Epoch : 50, Loss : 0.000016, Accuracy: 1.000000, Test accuracy: 0.993700
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 0.601347, Accuracy: 0.852000, Test accuracy: 0.814400
Starting training epoch 1
Epoch : 2, Loss : 0.589406, Accuracy: 0.820000, Test accuracy: 0.889100
Starting training epoch 2
Epoch : 3, Loss : 0.350060, Accuracy: 0.892000, Test accuracy: 0.907600
Starting training epoch 3
Epoch : 4, Loss : 0.203626, Accuracy: 0.932000, Test accuracy: 0.915500
Starting training epoch 4
Epoch : 5, Loss : 0.246448, Accuracy: 0.928000, Test accuracy: 0.922000
Starting training epoch 5
Epoch : 6, Loss : 0.299732, Accuracy: 0.920000, Test accuracy: 0.927400
Starting training epoch 6
Epoch : 7, Loss : 0.252388, Accuracy: 0.932000, Test accuracy: 0.930300
Starting training epoch 7
Epoch : 8, Loss : 0.190755, Accuracy: 0.964000, Test accuracy: 0.933600
Starting training epoch 8
Epoch : 9, Loss : 0.262821, Accuracy: 0.932000, Test accuracy: 0.936900
Starting training epoch 9
Epoch : 10, Loss : 0.193319, Accuracy: 0.948000, Test accuracy: 0.939600
Starting training epoch 10
Epoch : 11, Loss : 0.178317, Accuracy: 0.948000, Test accuracy: 0.941500
Starting training epoch 11
Epoch : 12, Loss : 0.190654, Accuracy: 0.932000, Test accuracy: 0.942000
Starting training epoch 12
Epoch : 13, Loss : 0.159149, Accuracy: 0.952000, Test accuracy: 0.944700
Starting training epoch 13
Epoch : 14, Loss : 0.166077, Accuracy: 0.956000, Test accuracy: 0.946700
Starting training epoch 14
Epoch : 15, Loss : 0.178188, Accuracy: 0.956000, Test accuracy: 0.949500
Starting training epoch 15
Epoch : 16, Loss : 0.129749, Accuracy: 0.964000, Test accuracy: 0.950000
Starting training epoch 16
Epoch : 17, Loss : 0.094437, Accuracy: 0.964000, Test accuracy: 0.953100
Starting training epoch 17
Epoch : 18, Loss : 0.167365, Accuracy: 0.956000, Test accuracy: 0.953500
Starting training epoch 18
Epoch : 19, Loss : 0.089640, Accuracy: 0.972000, Test accuracy: 0.955100
Starting training epoch 19
Epoch : 20, Loss : 0.083388, Accuracy: 0.972000, Test accuracy: 0.956700
Starting training epoch 20
Epoch : 21, Loss : 0.153446, Accuracy: 0.948000, Test accuracy: 0.957800
Starting training epoch 21
Epoch : 22, Loss : 0.202685, Accuracy: 0.948000, Test accuracy: 0.958700
Starting training epoch 22
Epoch : 23, Loss : 0.117772, Accuracy: 0.956000, Test accuracy: 0.960100
Starting training epoch 23
Epoch : 24, Loss : 0.153098, Accuracy: 0.956000, Test accuracy: 0.961300
Starting training epoch 24
Epoch : 25, Loss : 0.188323, Accuracy: 0.936000, Test accuracy: 0.962500
Starting training epoch 25
Epoch : 26, Loss : 0.100606, Accuracy: 0.968000, Test accuracy: 0.962800
Starting training epoch 26
Epoch : 27, Loss : 0.108115, Accuracy: 0.968000, Test accuracy: 0.964100
Starting training epoch 27
Epoch : 28, Loss : 0.168266, Accuracy: 0.952000, Test accuracy: 0.964300
Starting training epoch 28
Epoch : 29, Loss : 0.118367, Accuracy: 0.968000, Test accuracy: 0.965700
Starting training epoch 29
Epoch : 30, Loss : 0.089381, Accuracy: 0.984000, Test accuracy: 0.964800
Starting training epoch 30
Epoch : 31, Loss : 0.148052, Accuracy: 0.952000, Test accuracy: 0.967700
Starting training epoch 31
Epoch : 32, Loss : 0.055421, Accuracy: 0.988000, Test accuracy: 0.967800
Starting training epoch 32
Epoch : 33, Loss : 0.081259, Accuracy: 0.980000, Test accuracy: 0.967900
Starting training epoch 33
Epoch : 34, Loss : 0.184322, Accuracy: 0.956000, Test accuracy: 0.969200
Starting training epoch 34
Epoch : 35, Loss : 0.084252, Accuracy: 0.976000, Test accuracy: 0.968900
Starting training epoch 35
Epoch : 36, Loss : 0.090258, Accuracy: 0.972000, Test accuracy: 0.969800
Starting training epoch 36
Epoch : 37, Loss : 0.097147, Accuracy: 0.964000, Test accuracy: 0.969200
Starting training epoch 37
Epoch : 38, Loss : 0.105469, Accuracy: 0.976000, Test accuracy: 0.970100
Starting training epoch 38
Epoch : 39, Loss : 0.186405, Accuracy: 0.960000, Test accuracy: 0.969300
Starting training epoch 39
Epoch : 40, Loss : 0.072748, Accuracy: 0.968000, Test accuracy: 0.970800
Starting training epoch 40
Epoch : 41, Loss : 0.100604, Accuracy: 0.976000, Test accuracy: 0.971400
Starting training epoch 41
Epoch : 42, Loss : 0.082595, Accuracy: 0.980000, Test accuracy: 0.971200
Starting training epoch 42
Epoch : 43, Loss : 0.060466, Accuracy: 0.972000, Test accuracy: 0.971800
Starting training epoch 43
Epoch : 44, Loss : 0.072282, Accuracy: 0.980000, Test accuracy: 0.971700
Starting training epoch 44
Epoch : 45, Loss : 0.098038, Accuracy: 0.968000, Test accuracy: 0.971500
Starting training epoch 45
Epoch : 46, Loss : 0.090691, Accuracy: 0.960000, Test accuracy: 0.971800
Starting training epoch 46
Epoch : 47, Loss : 0.074736, Accuracy: 0.976000, Test accuracy: 0.972900
Starting training epoch 47
Epoch : 48, Loss : 0.062682, Accuracy: 0.976000, Test accuracy: 0.973200
Starting training epoch 48
Epoch : 49, Loss : 0.053479, Accuracy: 0.988000, Test accuracy: 0.973700
Starting training epoch 49
Epoch : 50, Loss : 0.056132, Accuracy: 0.980000, Test accuracy: 0.973200
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 1.343364, Accuracy: 0.728000, Test accuracy: 0.778000
Starting training opoch 1
Epoch : 2, Loss : 0.559955, Accuracy: 0.828000, Test accuracy: 0.876800
Starting training opoch 2
Epoch : 3, Loss : 0.398798, Accuracy: 0.888000, Test accuracy: 0.902100
Starting training opoch 3
Epoch : 4, Loss : 0.360701, Accuracy: 0.896000, Test accuracy: 0.916000
Starting training opoch 4
Epoch : 5, Loss : 0.357976, Accuracy: 0.932000, Test accuracy: 0.923600
Starting training opoch 5
Epoch : 6, Loss : 0.309233, Accuracy: 0.912000, Test accuracy: 0.928800
Starting training opoch 6
Epoch : 7, Loss : 0.206341, Accuracy: 0.936000, Test accuracy: 0.932900
Starting training opoch 7
Epoch : 8, Loss : 0.179723, Accuracy: 0.956000, Test accuracy: 0.936400
Starting training opoch 8
Epoch : 9, Loss : 0.227739, Accuracy: 0.932000, Test accuracy: 0.939600
Starting training opoch 9
Epoch : 10, Loss : 0.236493, Accuracy: 0.928000, Test accuracy: 0.940200
Starting training opoch 10
Epoch : 11, Loss : 0.286222, Accuracy: 0.916000, Test accuracy: 0.943700
Starting training opoch 11
Epoch : 12, Loss : 0.232662, Accuracy: 0.924000, Test accuracy: 0.944800
Starting training opoch 12
Epoch : 13, Loss : 0.191532, Accuracy: 0.944000, Test accuracy: 0.945700
Starting training opoch 13
Epoch : 14, Loss : 0.157533, Accuracy: 0.960000, Test accuracy: 0.947400
Starting training opoch 14
Epoch : 15, Loss : 0.117043, Accuracy: 0.968000, Test accuracy: 0.949800
Starting training opoch 15
Epoch : 16, Loss : 0.185318, Accuracy: 0.936000, Test accuracy: 0.950500
Starting training opoch 16
Epoch : 17, Loss : 0.100430, Accuracy: 0.972000, Test accuracy: 0.951000
Starting training opoch 17
Epoch : 18, Loss : 0.202851, Accuracy: 0.944000, Test accuracy: 0.951900
Starting training opoch 18
Epoch : 19, Loss : 0.145476, Accuracy: 0.940000, Test accuracy: 0.952700
Starting training opoch 19
Epoch : 20, Loss : 0.098833, Accuracy: 0.964000, Test accuracy: 0.953400
Starting training opoch 20
Epoch : 21, Loss : 0.139551, Accuracy: 0.964000, Test accuracy: 0.954700
Starting training opoch 21
Epoch : 22, Loss : 0.140087, Accuracy: 0.952000, Test accuracy: 0.954200
Starting training opoch 22
Epoch : 23, Loss : 0.178861, Accuracy: 0.944000, Test accuracy: 0.956100
Starting training opoch 23
Epoch : 24, Loss : 0.145494, Accuracy: 0.952000, Test accuracy: 0.956000
Starting training opoch 24
Epoch : 25, Loss : 0.224501, Accuracy: 0.932000, Test accuracy: 0.957600
Starting training opoch 25
Epoch : 26, Loss : 0.186741, Accuracy: 0.952000, Test accuracy: 0.958700
Starting training opoch 26
Epoch : 27, Loss : 0.089841, Accuracy: 0.960000, Test accuracy: 0.958700
Starting training opoch 27
Epoch : 28, Loss : 0.169960, Accuracy: 0.944000, Test accuracy: 0.958100
Starting training opoch 28
Epoch : 29, Loss : 0.146898, Accuracy: 0.956000, Test accuracy: 0.959000
Starting training opoch 29
Epoch : 30, Loss : 0.141666, Accuracy: 0.944000, Test accuracy: 0.959000
Starting training opoch 30
Epoch : 31, Loss : 0.140023, Accuracy: 0.960000, Test accuracy: 0.960600
Starting training opoch 31
Epoch : 32, Loss : 0.180299, Accuracy: 0.976000, Test accuracy: 0.961400
Starting training opoch 32
Epoch : 33, Loss : 0.125213, Accuracy: 0.960000, Test accuracy: 0.961600
Starting training opoch 33
Epoch : 34, Loss : 0.095356, Accuracy: 0.968000, Test accuracy: 0.961000
Starting training opoch 34
Epoch : 35, Loss : 0.171534, Accuracy: 0.968000, Test accuracy: 0.960900
Starting training opoch 35
Epoch : 36, Loss : 0.129188, Accuracy: 0.960000, Test accuracy: 0.963300
Starting training opoch 36
Epoch : 37, Loss : 0.108808, Accuracy: 0.972000, Test accuracy: 0.962800
Starting training opoch 37
Epoch : 38, Loss : 0.157626, Accuracy: 0.956000, Test accuracy: 0.962200
Starting training opoch 38
Epoch : 39, Loss : 0.106839, Accuracy: 0.964000, Test accuracy: 0.963700
Starting training opoch 39
Epoch : 40, Loss : 0.085956, Accuracy: 0.972000, Test accuracy: 0.964400
Starting training opoch 40
Epoch : 41, Loss : 0.171648, Accuracy: 0.944000, Test accuracy: 0.965000
Starting training opoch 41
Epoch : 42, Loss : 0.243159, Accuracy: 0.948000, Test accuracy: 0.964300
Starting training opoch 42
Epoch : 43, Loss : 0.122551, Accuracy: 0.956000, Test accuracy: 0.965500
Starting training opoch 43
Epoch : 44, Loss : 0.116703, Accuracy: 0.968000, Test accuracy: 0.965600
Starting training opoch 44
Epoch : 45, Loss : 0.092985, Accuracy: 0.968000, Test accuracy: 0.965400
Starting training opoch 45
Epoch : 46, Loss : 0.125908, Accuracy: 0.968000, Test accuracy: 0.964500
Starting training opoch 46
Epoch : 47, Loss : 0.066223, Accuracy: 0.984000, Test accuracy: 0.964600
Starting training opoch 47
Epoch : 48, Loss : 0.158255, Accuracy: 0.952000, Test accuracy: 0.966100
Starting training opoch 48
Epoch : 49, Loss : 0.101837, Accuracy: 0.972000, Test accuracy: 0.965300
Starting training opoch 49
Epoch : 50, Loss : 0.108282, Accuracy: 0.968000, Test accuracy: 0.965500
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.713508, Accuracy: 0.812000, Test accuracy: 0.825100
Starting training epoch 1
Epoch : 2, Loss : 0.403721, Accuracy: 0.868000, Test accuracy: 0.883000
Starting training epoch 2
Epoch : 3, Loss : 0.333113, Accuracy: 0.892000, Test accuracy: 0.903200
Starting training epoch 3
Epoch : 4, Loss : 0.407784, Accuracy: 0.884000, Test accuracy: 0.912600
Starting training epoch 4
Epoch : 5, Loss : 0.332929, Accuracy: 0.908000, Test accuracy: 0.922400
Starting training epoch 5
Epoch : 6, Loss : 0.286693, Accuracy: 0.908000, Test accuracy: 0.929300
Starting training epoch 6
Epoch : 7, Loss : 0.227925, Accuracy: 0.952000, Test accuracy: 0.934400
Starting training epoch 7
Epoch : 8, Loss : 0.196979, Accuracy: 0.952000, Test accuracy: 0.938600
Starting training epoch 8
Epoch : 9, Loss : 0.124342, Accuracy: 0.956000, Test accuracy: 0.943700
Starting training epoch 9
Epoch : 10, Loss : 0.250037, Accuracy: 0.944000, Test accuracy: 0.948500
Starting training epoch 10
Epoch : 11, Loss : 0.142247, Accuracy: 0.960000, Test accuracy: 0.949800
Starting training epoch 11
Epoch : 12, Loss : 0.169656, Accuracy: 0.948000, Test accuracy: 0.953300
Starting training epoch 12
Epoch : 13, Loss : 0.182967, Accuracy: 0.944000, Test accuracy: 0.956400
Starting training epoch 13
Epoch : 14, Loss : 0.179957, Accuracy: 0.936000, Test accuracy: 0.958500
Starting training epoch 14
Epoch : 15, Loss : 0.119587, Accuracy: 0.972000, Test accuracy: 0.961800
Starting training epoch 15
Epoch : 16, Loss : 0.137290, Accuracy: 0.968000, Test accuracy: 0.963500
Starting training epoch 16
Epoch : 17, Loss : 0.136840, Accuracy: 0.948000, Test accuracy: 0.964400
Starting training epoch 17
Epoch : 18, Loss : 0.103043, Accuracy: 0.968000, Test accuracy: 0.966100
Starting training epoch 18
Epoch : 19, Loss : 0.151056, Accuracy: 0.940000, Test accuracy: 0.967200
Starting training epoch 19
Epoch : 20, Loss : 0.080391, Accuracy: 0.988000, Test accuracy: 0.967400
Starting training epoch 20
Epoch : 21, Loss : 0.195825, Accuracy: 0.960000, Test accuracy: 0.968800
Starting training epoch 21
Epoch : 22, Loss : 0.106242, Accuracy: 0.988000, Test accuracy: 0.970300
Starting training epoch 22
Epoch : 23, Loss : 0.196883, Accuracy: 0.960000, Test accuracy: 0.970000
Starting training epoch 23
Epoch : 24, Loss : 0.105282, Accuracy: 0.972000, Test accuracy: 0.971100
Starting training epoch 24
Epoch : 25, Loss : 0.094715, Accuracy: 0.968000, Test accuracy: 0.971600
Starting training epoch 25
Epoch : 26, Loss : 0.076104, Accuracy: 0.964000, Test accuracy: 0.971700
Starting training epoch 26
Epoch : 27, Loss : 0.115821, Accuracy: 0.960000, Test accuracy: 0.972200
Starting training epoch 27
Epoch : 28, Loss : 0.102664, Accuracy: 0.968000, Test accuracy: 0.972800
Starting training epoch 28
Epoch : 29, Loss : 0.086632, Accuracy: 0.980000, Test accuracy: 0.974100
Starting training epoch 29
Epoch : 30, Loss : 0.061757, Accuracy: 0.980000, Test accuracy: 0.973900
Starting training epoch 30
Epoch : 31, Loss : 0.123083, Accuracy: 0.968000, Test accuracy: 0.974800
Starting training epoch 31
Epoch : 32, Loss : 0.041647, Accuracy: 0.988000, Test accuracy: 0.975300
Starting training epoch 32
Epoch : 33, Loss : 0.040906, Accuracy: 0.988000, Test accuracy: 0.975500
Starting training epoch 33
Epoch : 34, Loss : 0.044226, Accuracy: 0.988000, Test accuracy: 0.975900
Starting training epoch 34
Epoch : 35, Loss : 0.079311, Accuracy: 0.968000, Test accuracy: 0.976600
Starting training epoch 35
Epoch : 36, Loss : 0.155961, Accuracy: 0.972000, Test accuracy: 0.975900
Starting training epoch 36
Epoch : 37, Loss : 0.058349, Accuracy: 0.976000, Test accuracy: 0.977400
Starting training epoch 37
Epoch : 38, Loss : 0.022980, Accuracy: 0.992000, Test accuracy: 0.976900
Starting training epoch 38
Epoch : 39, Loss : 0.042785, Accuracy: 0.992000, Test accuracy: 0.977400
Starting training epoch 39
Epoch : 40, Loss : 0.068603, Accuracy: 0.976000, Test accuracy: 0.978200
Starting training epoch 40
Epoch : 41, Loss : 0.102856, Accuracy: 0.976000, Test accuracy: 0.977800
Starting training epoch 41
Epoch : 42, Loss : 0.035014, Accuracy: 0.992000, Test accuracy: 0.979600
Starting training epoch 42
Epoch : 43, Loss : 0.144624, Accuracy: 0.968000, Test accuracy: 0.978400
Starting training epoch 43
Epoch : 44, Loss : 0.044298, Accuracy: 0.980000, Test accuracy: 0.978500
Starting training epoch 44
Epoch : 45, Loss : 0.101242, Accuracy: 0.980000, Test accuracy: 0.978800
Starting training epoch 45
Epoch : 46, Loss : 0.099233, Accuracy: 0.976000, Test accuracy: 0.979000
Starting training epoch 46
Epoch : 47, Loss : 0.071329, Accuracy: 0.968000, Test accuracy: 0.977300
Starting training epoch 47
Epoch : 48, Loss : 0.150618, Accuracy: 0.968000, Test accuracy: 0.979800
Starting training epoch 48
Epoch : 49, Loss : 0.025088, Accuracy: 0.992000, Test accuracy: 0.979400
Starting training epoch 49
Epoch : 50, Loss : 0.058276, Accuracy: 0.976000, Test accuracy: 0.979500
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.666861, Accuracy: 0.840000, Test accuracy: 0.855600
Starting training opoch 1
Epoch : 2, Loss : 0.435165, Accuracy: 0.884000, Test accuracy: 0.908500
Starting training opoch 2
Epoch : 3, Loss : 0.265060, Accuracy: 0.940000, Test accuracy: 0.923300
Starting training opoch 3
Epoch : 4, Loss : 0.268476, Accuracy: 0.936000, Test accuracy: 0.931700
Starting training opoch 4
Epoch : 5, Loss : 0.287933, Accuracy: 0.936000, Test accuracy: 0.938000
Starting training opoch 5
Epoch : 6, Loss : 0.257132, Accuracy: 0.916000, Test accuracy: 0.942200
Starting training opoch 6
Epoch : 7, Loss : 0.212371, Accuracy: 0.932000, Test accuracy: 0.944200
Starting training opoch 7
Epoch : 8, Loss : 0.176408, Accuracy: 0.960000, Test accuracy: 0.946700
Starting training opoch 8
Epoch : 9, Loss : 0.135478, Accuracy: 0.972000, Test accuracy: 0.948500
Starting training opoch 9
Epoch : 10, Loss : 0.182928, Accuracy: 0.956000, Test accuracy: 0.950500
Starting training opoch 10
Epoch : 11, Loss : 0.162779, Accuracy: 0.964000, Test accuracy: 0.952600
Starting training opoch 11
Epoch : 12, Loss : 0.156123, Accuracy: 0.952000, Test accuracy: 0.954000
Starting training opoch 12
Epoch : 13, Loss : 0.166101, Accuracy: 0.952000, Test accuracy: 0.955300
Starting training opoch 13
Epoch : 14, Loss : 0.150970, Accuracy: 0.952000, Test accuracy: 0.955500
Starting training opoch 14
Epoch : 15, Loss : 0.196438, Accuracy: 0.948000, Test accuracy: 0.958100
Starting training opoch 15
Epoch : 16, Loss : 0.194043, Accuracy: 0.944000, Test accuracy: 0.958400
Starting training opoch 16
Epoch : 17, Loss : 0.112030, Accuracy: 0.964000, Test accuracy: 0.959400
Starting training opoch 17
Epoch : 18, Loss : 0.183846, Accuracy: 0.936000, Test accuracy: 0.960400
Starting training opoch 18
Epoch : 19, Loss : 0.087041, Accuracy: 0.972000, Test accuracy: 0.961600
Starting training opoch 19
Epoch : 20, Loss : 0.130062, Accuracy: 0.964000, Test accuracy: 0.962000
Starting training opoch 20
Epoch : 21, Loss : 0.136978, Accuracy: 0.960000, Test accuracy: 0.963700
Starting training opoch 21
Epoch : 22, Loss : 0.083949, Accuracy: 0.972000, Test accuracy: 0.964600
Starting training opoch 22
Epoch : 23, Loss : 0.139495, Accuracy: 0.972000, Test accuracy: 0.965300
Starting training opoch 23
Epoch : 24, Loss : 0.085934, Accuracy: 0.976000, Test accuracy: 0.965400
Starting training opoch 24
Epoch : 25, Loss : 0.139285, Accuracy: 0.964000, Test accuracy: 0.966100
Starting training opoch 25
Epoch : 26, Loss : 0.156286, Accuracy: 0.956000, Test accuracy: 0.967000
Starting training opoch 26
Epoch : 27, Loss : 0.172362, Accuracy: 0.952000, Test accuracy: 0.967300
Starting training opoch 27
Epoch : 28, Loss : 0.101280, Accuracy: 0.968000, Test accuracy: 0.967200
Starting training opoch 28
Epoch : 29, Loss : 0.159466, Accuracy: 0.976000, Test accuracy: 0.968700
Starting training opoch 29
Epoch : 30, Loss : 0.038171, Accuracy: 0.996000, Test accuracy: 0.968500
Starting training opoch 30
Epoch : 31, Loss : 0.079422, Accuracy: 0.972000, Test accuracy: 0.968400
Starting training opoch 31
Epoch : 32, Loss : 0.095264, Accuracy: 0.960000, Test accuracy: 0.969000
Starting training opoch 32
Epoch : 33, Loss : 0.084586, Accuracy: 0.976000, Test accuracy: 0.969900
Starting training opoch 33
Epoch : 34, Loss : 0.078872, Accuracy: 0.988000, Test accuracy: 0.969200
Starting training opoch 34
Epoch : 35, Loss : 0.086115, Accuracy: 0.976000, Test accuracy: 0.970200
Starting training opoch 35
Epoch : 36, Loss : 0.073910, Accuracy: 0.972000, Test accuracy: 0.970400
Starting training opoch 36
Epoch : 37, Loss : 0.067958, Accuracy: 0.980000, Test accuracy: 0.970700
Starting training opoch 37
Epoch : 38, Loss : 0.105076, Accuracy: 0.960000, Test accuracy: 0.971500
Starting training opoch 38
Epoch : 39, Loss : 0.107939, Accuracy: 0.976000, Test accuracy: 0.970900
Starting training opoch 39
Epoch : 40, Loss : 0.085373, Accuracy: 0.972000, Test accuracy: 0.971300
Starting training opoch 40
Epoch : 41, Loss : 0.100383, Accuracy: 0.972000, Test accuracy: 0.971400
Starting training opoch 41
Epoch : 42, Loss : 0.113222, Accuracy: 0.972000, Test accuracy: 0.971500
Starting training opoch 42
Epoch : 43, Loss : 0.065513, Accuracy: 0.988000, Test accuracy: 0.972000
Starting training opoch 43
Epoch : 44, Loss : 0.061435, Accuracy: 0.984000, Test accuracy: 0.971500
Starting training opoch 44
Epoch : 45, Loss : 0.077944, Accuracy: 0.972000, Test accuracy: 0.971200
Starting training opoch 45
Epoch : 46, Loss : 0.037147, Accuracy: 0.992000, Test accuracy: 0.971800
Starting training opoch 46
Epoch : 47, Loss : 0.066784, Accuracy: 0.976000, Test accuracy: 0.973100
Starting training opoch 47
Epoch : 48, Loss : 0.049605, Accuracy: 0.988000, Test accuracy: 0.972900
Starting training opoch 48
Epoch : 49, Loss : 0.102341, Accuracy: 0.972000, Test accuracy: 0.972800
Starting training opoch 49
Epoch : 50, Loss : 0.091410, Accuracy: 0.968000, Test accuracy: 0.972600
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.976833, Accuracy: 0.748000, Test accuracy: 0.770400
Starting training opoch 1
Epoch : 2, Loss : 0.527542, Accuracy: 0.860000, Test accuracy: 0.867900
Starting training opoch 2
Epoch : 3, Loss : 0.506146, Accuracy: 0.824000, Test accuracy: 0.890600
Starting training opoch 3
Epoch : 4, Loss : 0.339753, Accuracy: 0.900000, Test accuracy: 0.902900
Starting training opoch 4
Epoch : 5, Loss : 0.303742, Accuracy: 0.912000, Test accuracy: 0.912800
Starting training opoch 5
Epoch : 6, Loss : 0.372803, Accuracy: 0.880000, Test accuracy: 0.918100
Starting training opoch 6
Epoch : 7, Loss : 0.225731, Accuracy: 0.924000, Test accuracy: 0.921700
Starting training opoch 7
Epoch : 8, Loss : 0.281886, Accuracy: 0.924000, Test accuracy: 0.925800
Starting training opoch 8
Epoch : 9, Loss : 0.220368, Accuracy: 0.924000, Test accuracy: 0.929900
Starting training opoch 9
Epoch : 10, Loss : 0.318725, Accuracy: 0.928000, Test accuracy: 0.932100
Starting training opoch 10
Epoch : 11, Loss : 0.228750, Accuracy: 0.924000, Test accuracy: 0.933900
Starting training opoch 11
Epoch : 12, Loss : 0.224208, Accuracy: 0.956000, Test accuracy: 0.935500
Starting training opoch 12
Epoch : 13, Loss : 0.196819, Accuracy: 0.924000, Test accuracy: 0.939500
Starting training opoch 13
Epoch : 14, Loss : 0.244487, Accuracy: 0.932000, Test accuracy: 0.941600
Starting training opoch 14
Epoch : 15, Loss : 0.156428, Accuracy: 0.968000, Test accuracy: 0.943500
Starting training opoch 15
Epoch : 16, Loss : 0.262056, Accuracy: 0.916000, Test accuracy: 0.944700
Starting training opoch 16
Epoch : 17, Loss : 0.171992, Accuracy: 0.948000, Test accuracy: 0.947300
Starting training opoch 17
Epoch : 18, Loss : 0.197999, Accuracy: 0.944000, Test accuracy: 0.947900
Starting training opoch 18
Epoch : 19, Loss : 0.215562, Accuracy: 0.956000, Test accuracy: 0.949700
Starting training opoch 19
Epoch : 20, Loss : 0.205502, Accuracy: 0.944000, Test accuracy: 0.950200
Starting training opoch 20
Epoch : 21, Loss : 0.282432, Accuracy: 0.924000, Test accuracy: 0.952700
Starting training opoch 21
Epoch : 22, Loss : 0.072919, Accuracy: 0.980000, Test accuracy: 0.953300
Starting training opoch 22
Epoch : 23, Loss : 0.097419, Accuracy: 0.984000, Test accuracy: 0.953600
Starting training opoch 23
Epoch : 24, Loss : 0.104616, Accuracy: 0.972000, Test accuracy: 0.955000
Starting training opoch 24
Epoch : 25, Loss : 0.185776, Accuracy: 0.944000, Test accuracy: 0.956900
Starting training opoch 25
Epoch : 26, Loss : 0.171405, Accuracy: 0.960000, Test accuracy: 0.956800
Starting training opoch 26
Epoch : 27, Loss : 0.176755, Accuracy: 0.944000, Test accuracy: 0.957600
Starting training opoch 27
Epoch : 28, Loss : 0.157851, Accuracy: 0.956000, Test accuracy: 0.958500
Starting training opoch 28
Epoch : 29, Loss : 0.098350, Accuracy: 0.972000, Test accuracy: 0.960000
Starting training opoch 29
Epoch : 30, Loss : 0.165402, Accuracy: 0.952000, Test accuracy: 0.960200
Starting training opoch 30
Epoch : 31, Loss : 0.118738, Accuracy: 0.968000, Test accuracy: 0.960600
Starting training opoch 31
Epoch : 32, Loss : 0.132066, Accuracy: 0.956000, Test accuracy: 0.961000
Starting training opoch 32
Epoch : 33, Loss : 0.133841, Accuracy: 0.964000, Test accuracy: 0.962100
Starting training opoch 33
Epoch : 34, Loss : 0.124498, Accuracy: 0.960000, Test accuracy: 0.962200
Starting training opoch 34
Epoch : 35, Loss : 0.109150, Accuracy: 0.976000, Test accuracy: 0.962000
Starting training opoch 35
Epoch : 36, Loss : 0.127056, Accuracy: 0.968000, Test accuracy: 0.963100
Starting training opoch 36
Epoch : 37, Loss : 0.128861, Accuracy: 0.972000, Test accuracy: 0.963700
Starting training opoch 37
Epoch : 38, Loss : 0.161020, Accuracy: 0.956000, Test accuracy: 0.963500
Starting training opoch 38
Epoch : 39, Loss : 0.086225, Accuracy: 0.968000, Test accuracy: 0.963600
Starting training opoch 39
Epoch : 40, Loss : 0.076279, Accuracy: 0.980000, Test accuracy: 0.964100
Starting training opoch 40
Epoch : 41, Loss : 0.202316, Accuracy: 0.948000, Test accuracy: 0.964400
Starting training opoch 41
Epoch : 42, Loss : 0.158381, Accuracy: 0.956000, Test accuracy: 0.964000
Starting training opoch 42
Epoch : 43, Loss : 0.120161, Accuracy: 0.952000, Test accuracy: 0.964200
Starting training opoch 43
Epoch : 44, Loss : 0.085401, Accuracy: 0.984000, Test accuracy: 0.964600
Starting training opoch 44
Epoch : 45, Loss : 0.185116, Accuracy: 0.948000, Test accuracy: 0.964700
Starting training opoch 45
Epoch : 46, Loss : 0.108741, Accuracy: 0.964000, Test accuracy: 0.965100
Starting training opoch 46
Epoch : 47, Loss : 0.157352, Accuracy: 0.956000, Test accuracy: 0.964600
Starting training opoch 47
Epoch : 48, Loss : 0.087337, Accuracy: 0.976000, Test accuracy: 0.965200
Starting training opoch 48
Epoch : 49, Loss : 0.090038, Accuracy: 0.964000, Test accuracy: 0.966000
Starting training opoch 49
Epoch : 50, Loss : 0.091109, Accuracy: 0.980000, Test accuracy: 0.965500
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9937
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.707601, Accuracy: 0.803000, Test accuracy: 0.804500
Distillation: Epoch : 2, Loss : 0.448535, Accuracy: 0.876000, Test accuracy: 0.877600
Distillation: Epoch : 3, Loss : 0.366990, Accuracy: 0.894000, Test accuracy: 0.901300
Distillation: Epoch : 4, Loss : 0.325256, Accuracy: 0.903000, Test accuracy: 0.913900
Distillation: Epoch : 5, Loss : 0.298569, Accuracy: 0.922000, Test accuracy: 0.922900
Distillation: Epoch : 6, Loss : 0.233583, Accuracy: 0.947000, Test accuracy: 0.931100
Distillation: Epoch : 7, Loss : 0.275709, Accuracy: 0.919000, Test accuracy: 0.935800
Distillation: Epoch : 8, Loss : 0.216689, Accuracy: 0.943000, Test accuracy: 0.940900
Distillation: Epoch : 9, Loss : 0.159969, Accuracy: 0.949000, Test accuracy: 0.945400
Distillation: Epoch : 10, Loss : 0.228320, Accuracy: 0.935000, Test accuracy: 0.948200
Distillation: Epoch : 11, Loss : 0.162199, Accuracy: 0.951000, Test accuracy: 0.950900
Distillation: Epoch : 12, Loss : 0.165110, Accuracy: 0.954000, Test accuracy: 0.951600
Distillation: Epoch : 13, Loss : 0.188375, Accuracy: 0.949000, Test accuracy: 0.956200
Distillation: Epoch : 14, Loss : 0.147372, Accuracy: 0.962000, Test accuracy: 0.957500
Distillation: Epoch : 15, Loss : 0.180843, Accuracy: 0.955000, Test accuracy: 0.960600
Distillation: Epoch : 16, Loss : 0.147913, Accuracy: 0.961000, Test accuracy: 0.959000
Distillation: Epoch : 17, Loss : 0.102795, Accuracy: 0.975000, Test accuracy: 0.962800
Distillation: Epoch : 18, Loss : 0.142783, Accuracy: 0.958000, Test accuracy: 0.963200
Distillation: Epoch : 19, Loss : 0.131195, Accuracy: 0.956000, Test accuracy: 0.963900
Distillation: Epoch : 20, Loss : 0.135224, Accuracy: 0.964000, Test accuracy: 0.964700
Distillation: Epoch : 21, Loss : 0.144448, Accuracy: 0.958000, Test accuracy: 0.964900
Distillation: Epoch : 22, Loss : 0.112239, Accuracy: 0.967000, Test accuracy: 0.965600
Distillation: Epoch : 23, Loss : 0.092958, Accuracy: 0.973000, Test accuracy: 0.966300
Distillation: Epoch : 24, Loss : 0.116678, Accuracy: 0.965000, Test accuracy: 0.967300
Distillation: Epoch : 25, Loss : 0.133241, Accuracy: 0.964000, Test accuracy: 0.968400
Distillation: Epoch : 26, Loss : 0.114710, Accuracy: 0.973000, Test accuracy: 0.968800
Distillation: Epoch : 27, Loss : 0.106147, Accuracy: 0.969000, Test accuracy: 0.967100
Distillation: Epoch : 28, Loss : 0.096988, Accuracy: 0.977000, Test accuracy: 0.969100
Distillation: Epoch : 29, Loss : 0.139478, Accuracy: 0.963000, Test accuracy: 0.969900
Distillation: Epoch : 30, Loss : 0.113635, Accuracy: 0.972000, Test accuracy: 0.967200
Distillation: Epoch : 31, Loss : 0.087234, Accuracy: 0.970000, Test accuracy: 0.969900
Distillation: Epoch : 32, Loss : 0.124582, Accuracy: 0.966000, Test accuracy: 0.969200
Distillation: Epoch : 33, Loss : 0.090236, Accuracy: 0.971000, Test accuracy: 0.970700
Distillation: Epoch : 34, Loss : 0.085620, Accuracy: 0.975000, Test accuracy: 0.970300
Distillation: Epoch : 35, Loss : 0.077734, Accuracy: 0.976000, Test accuracy: 0.969700
Distillation: Epoch : 36, Loss : 0.104395, Accuracy: 0.971000, Test accuracy: 0.969900
Distillation: Epoch : 37, Loss : 0.096149, Accuracy: 0.977000, Test accuracy: 0.969900
Distillation: Epoch : 38, Loss : 0.108942, Accuracy: 0.964000, Test accuracy: 0.969400
Distillation: Epoch : 39, Loss : 0.088491, Accuracy: 0.976000, Test accuracy: 0.971300
Distillation: Epoch : 40, Loss : 0.115558, Accuracy: 0.960000, Test accuracy: 0.970800
Distillation: Epoch : 41, Loss : 0.116428, Accuracy: 0.967000, Test accuracy: 0.968700
Distillation: Epoch : 42, Loss : 0.104926, Accuracy: 0.968000, Test accuracy: 0.971000
Distillation: Epoch : 43, Loss : 0.122548, Accuracy: 0.961000, Test accuracy: 0.971500
Distillation: Epoch : 44, Loss : 0.097874, Accuracy: 0.973000, Test accuracy: 0.971100
Distillation: Epoch : 45, Loss : 0.100370, Accuracy: 0.967000, Test accuracy: 0.971000
Distillation: Epoch : 46, Loss : 0.098636, Accuracy: 0.971000, Test accuracy: 0.972100
Distillation: Epoch : 47, Loss : 0.110447, Accuracy: 0.971000, Test accuracy: 0.970800
Distillation: Epoch : 48, Loss : 0.110334, Accuracy: 0.967000, Test accuracy: 0.971600
Distillation: Epoch : 49, Loss : 0.086908, Accuracy: 0.972000, Test accuracy: 0.970500
Distillation: Epoch : 50, Loss : 0.103120, Accuracy: 0.970000, Test accuracy: 0.971000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.971
Generating confusion matrix for student4
[[ 969.    0.    3.    1.    1.    3.    6.    2.    6.    6.]
 [   0. 1118.    4.    0.    1.    1.    2.    2.    3.    5.]
 [   3.    4.  999.    2.    3.    1.    3.   17.    6.    0.]
 [   0.    0.    9.  993.    0.   16.    1.    4.    6.    5.]
 [   0.    1.    2.    0.  953.    0.    1.    0.    2.    6.]
 [   0.    0.    0.    3.    0.  853.    5.    0.    4.    4.]
 [   5.    3.    2.    0.    4.    5.  937.    0.    2.    0.]
 [   2.    1.    1.    4.    1.    2.    0.  985.    5.   10.]
 [   1.    7.   12.    6.    2.    7.    3.    1.  933.    3.]
 [   0.    1.    0.    1.   17.    4.    0.   17.    7.  970.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.169356, Accuracy: 0.771000, Test accuracy: 0.783600
Distillation: Epoch : 2, Loss : 0.521566, Accuracy: 0.843000, Test accuracy: 0.877100
Distillation: Epoch : 3, Loss : 0.400846, Accuracy: 0.885000, Test accuracy: 0.893300
Distillation: Epoch : 4, Loss : 0.372294, Accuracy: 0.901000, Test accuracy: 0.902000
Distillation: Epoch : 5, Loss : 0.304208, Accuracy: 0.912000, Test accuracy: 0.910100
Distillation: Epoch : 6, Loss : 0.394446, Accuracy: 0.892000, Test accuracy: 0.913700
Distillation: Epoch : 7, Loss : 0.354630, Accuracy: 0.904000, Test accuracy: 0.916000
Distillation: Epoch : 8, Loss : 0.370275, Accuracy: 0.906000, Test accuracy: 0.919000
Distillation: Epoch : 9, Loss : 0.301180, Accuracy: 0.911000, Test accuracy: 0.920600
Distillation: Epoch : 10, Loss : 0.315277, Accuracy: 0.916000, Test accuracy: 0.923700
Distillation: Epoch : 11, Loss : 0.298086, Accuracy: 0.912000, Test accuracy: 0.924400
Distillation: Epoch : 12, Loss : 0.272319, Accuracy: 0.921000, Test accuracy: 0.926300
Distillation: Epoch : 13, Loss : 0.303105, Accuracy: 0.918000, Test accuracy: 0.929000
Distillation: Epoch : 14, Loss : 0.246236, Accuracy: 0.925000, Test accuracy: 0.929500
Distillation: Epoch : 15, Loss : 0.282692, Accuracy: 0.924000, Test accuracy: 0.930800
Distillation: Epoch : 16, Loss : 0.291670, Accuracy: 0.922000, Test accuracy: 0.933700
Distillation: Epoch : 17, Loss : 0.213951, Accuracy: 0.942000, Test accuracy: 0.936200
Distillation: Epoch : 18, Loss : 0.240633, Accuracy: 0.932000, Test accuracy: 0.937400
Distillation: Epoch : 19, Loss : 0.227400, Accuracy: 0.941000, Test accuracy: 0.938900
Distillation: Epoch : 20, Loss : 0.240218, Accuracy: 0.939000, Test accuracy: 0.940200
Distillation: Epoch : 21, Loss : 0.222544, Accuracy: 0.939000, Test accuracy: 0.941200
Distillation: Epoch : 22, Loss : 0.269039, Accuracy: 0.934000, Test accuracy: 0.943300
Distillation: Epoch : 23, Loss : 0.270561, Accuracy: 0.927000, Test accuracy: 0.944400
Distillation: Epoch : 24, Loss : 0.200471, Accuracy: 0.947000, Test accuracy: 0.947000
Distillation: Epoch : 25, Loss : 0.226479, Accuracy: 0.940000, Test accuracy: 0.946300
Distillation: Epoch : 26, Loss : 0.233767, Accuracy: 0.943000, Test accuracy: 0.947900
Distillation: Epoch : 27, Loss : 0.215728, Accuracy: 0.949000, Test accuracy: 0.949300
Distillation: Epoch : 28, Loss : 0.197797, Accuracy: 0.948000, Test accuracy: 0.950400
Distillation: Epoch : 29, Loss : 0.191237, Accuracy: 0.953000, Test accuracy: 0.951300
Distillation: Epoch : 30, Loss : 0.209112, Accuracy: 0.938000, Test accuracy: 0.951700
Distillation: Epoch : 31, Loss : 0.196766, Accuracy: 0.940000, Test accuracy: 0.952800
Distillation: Epoch : 32, Loss : 0.188829, Accuracy: 0.958000, Test accuracy: 0.953600
Distillation: Epoch : 33, Loss : 0.197817, Accuracy: 0.952000, Test accuracy: 0.954000
Distillation: Epoch : 34, Loss : 0.178666, Accuracy: 0.956000, Test accuracy: 0.953800
Distillation: Epoch : 35, Loss : 0.167450, Accuracy: 0.955000, Test accuracy: 0.956800
Distillation: Epoch : 36, Loss : 0.165188, Accuracy: 0.951000, Test accuracy: 0.957600
Distillation: Epoch : 37, Loss : 0.162260, Accuracy: 0.955000, Test accuracy: 0.957300
Distillation: Epoch : 38, Loss : 0.182688, Accuracy: 0.951000, Test accuracy: 0.957600
Distillation: Epoch : 39, Loss : 0.173321, Accuracy: 0.953000, Test accuracy: 0.958500
Distillation: Epoch : 40, Loss : 0.165502, Accuracy: 0.956000, Test accuracy: 0.957100
Distillation: Epoch : 41, Loss : 0.158888, Accuracy: 0.958000, Test accuracy: 0.958700
Distillation: Epoch : 42, Loss : 0.148151, Accuracy: 0.961000, Test accuracy: 0.959800
Distillation: Epoch : 43, Loss : 0.124993, Accuracy: 0.972000, Test accuracy: 0.959900
Distillation: Epoch : 44, Loss : 0.158106, Accuracy: 0.963000, Test accuracy: 0.958200
Distillation: Epoch : 45, Loss : 0.168696, Accuracy: 0.959000, Test accuracy: 0.961700
Distillation: Epoch : 46, Loss : 0.163414, Accuracy: 0.952000, Test accuracy: 0.962600
Distillation: Epoch : 47, Loss : 0.139012, Accuracy: 0.968000, Test accuracy: 0.961400
Distillation: Epoch : 48, Loss : 0.147442, Accuracy: 0.966000, Test accuracy: 0.962000
Distillation: Epoch : 49, Loss : 0.166249, Accuracy: 0.958000, Test accuracy: 0.962300
Distillation: Epoch : 50, Loss : 0.159131, Accuracy: 0.954000, Test accuracy: 0.962500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9625
Generating confusion matrix for student4
[[ 969.    0.    3.    0.    1.    3.    6.    1.    6.    3.]
 [   0. 1123.    8.    0.    3.    3.    2.    9.    6.    8.]
 [   2.    3.  990.   13.    5.    0.    1.   18.    4.    2.]
 [   1.    0.    9.  958.    0.   10.    0.    4.    8.   10.]
 [   0.    0.    5.    1.  955.    2.    6.    3.    6.   17.]
 [   2.    0.    0.   11.    0.  855.    9.    1.   11.    5.]
 [   2.    2.    1.    1.    2.    8.  933.    0.    2.    1.]
 [   2.    1.    9.    8.    1.    3.    0.  974.    6.    8.]
 [   1.    6.    3.   13.    2.    4.    1.    3.  918.    5.]
 [   1.    0.    4.    5.   13.    4.    0.   15.    7.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.955788, Accuracy: 0.805000, Test accuracy: 0.812900
Distillation: Epoch : 2, Loss : 0.684766, Accuracy: 0.880000, Test accuracy: 0.868200
Distillation: Epoch : 3, Loss : 0.640578, Accuracy: 0.889000, Test accuracy: 0.884900
Distillation: Epoch : 4, Loss : 0.622396, Accuracy: 0.891000, Test accuracy: 0.892900
Distillation: Epoch : 5, Loss : 0.635302, Accuracy: 0.884000, Test accuracy: 0.897700
Distillation: Epoch : 6, Loss : 0.625714, Accuracy: 0.902000, Test accuracy: 0.901100
Distillation: Epoch : 7, Loss : 0.590016, Accuracy: 0.900000, Test accuracy: 0.903100
Distillation: Epoch : 8, Loss : 0.607304, Accuracy: 0.896000, Test accuracy: 0.904900
Distillation: Epoch : 9, Loss : 0.561363, Accuracy: 0.929000, Test accuracy: 0.904600
Distillation: Epoch : 10, Loss : 0.611249, Accuracy: 0.902000, Test accuracy: 0.905400
Distillation: Epoch : 11, Loss : 0.615082, Accuracy: 0.895000, Test accuracy: 0.906900
Distillation: Epoch : 12, Loss : 0.573252, Accuracy: 0.905000, Test accuracy: 0.908000
Distillation: Epoch : 13, Loss : 0.602696, Accuracy: 0.911000, Test accuracy: 0.908800
Distillation: Epoch : 14, Loss : 0.600667, Accuracy: 0.904000, Test accuracy: 0.909700
Distillation: Epoch : 15, Loss : 0.560338, Accuracy: 0.908000, Test accuracy: 0.911200
Distillation: Epoch : 16, Loss : 0.585429, Accuracy: 0.908000, Test accuracy: 0.910100
Distillation: Epoch : 17, Loss : 0.616517, Accuracy: 0.907000, Test accuracy: 0.913500
Distillation: Epoch : 18, Loss : 0.591182, Accuracy: 0.906000, Test accuracy: 0.912700
Distillation: Epoch : 19, Loss : 0.599212, Accuracy: 0.901000, Test accuracy: 0.914100
Distillation: Epoch : 20, Loss : 0.615167, Accuracy: 0.904000, Test accuracy: 0.914400
Distillation: Epoch : 21, Loss : 0.596127, Accuracy: 0.907000, Test accuracy: 0.913800
Distillation: Epoch : 22, Loss : 0.574598, Accuracy: 0.911000, Test accuracy: 0.914300
Distillation: Epoch : 23, Loss : 0.587415, Accuracy: 0.909000, Test accuracy: 0.913900
Distillation: Epoch : 24, Loss : 0.599540, Accuracy: 0.904000, Test accuracy: 0.914700
Distillation: Epoch : 25, Loss : 0.593687, Accuracy: 0.909000, Test accuracy: 0.914800
Distillation: Epoch : 26, Loss : 0.571501, Accuracy: 0.913000, Test accuracy: 0.915800
Distillation: Epoch : 27, Loss : 0.599294, Accuracy: 0.905000, Test accuracy: 0.917000
Distillation: Epoch : 28, Loss : 0.551749, Accuracy: 0.923000, Test accuracy: 0.916200
Distillation: Epoch : 29, Loss : 0.591748, Accuracy: 0.900000, Test accuracy: 0.916100
Distillation: Epoch : 30, Loss : 0.542529, Accuracy: 0.925000, Test accuracy: 0.917500
Distillation: Epoch : 31, Loss : 0.561189, Accuracy: 0.922000, Test accuracy: 0.916800
Distillation: Epoch : 32, Loss : 0.524651, Accuracy: 0.931000, Test accuracy: 0.916800
Distillation: Epoch : 33, Loss : 0.601023, Accuracy: 0.902000, Test accuracy: 0.916600
Distillation: Epoch : 34, Loss : 0.594111, Accuracy: 0.909000, Test accuracy: 0.917000
Distillation: Epoch : 35, Loss : 0.545599, Accuracy: 0.926000, Test accuracy: 0.918300
Distillation: Epoch : 36, Loss : 0.547855, Accuracy: 0.924000, Test accuracy: 0.918600
Distillation: Epoch : 37, Loss : 0.542363, Accuracy: 0.927000, Test accuracy: 0.917600
Distillation: Epoch : 38, Loss : 0.610482, Accuracy: 0.895000, Test accuracy: 0.918300
Distillation: Epoch : 39, Loss : 0.604361, Accuracy: 0.893000, Test accuracy: 0.918600
Distillation: Epoch : 40, Loss : 0.576362, Accuracy: 0.924000, Test accuracy: 0.919000
Distillation: Epoch : 41, Loss : 0.562711, Accuracy: 0.921000, Test accuracy: 0.918200
Distillation: Epoch : 42, Loss : 0.571300, Accuracy: 0.916000, Test accuracy: 0.920000
Distillation: Epoch : 43, Loss : 0.597100, Accuracy: 0.907000, Test accuracy: 0.919200
Distillation: Epoch : 44, Loss : 0.549591, Accuracy: 0.911000, Test accuracy: 0.918800
Distillation: Epoch : 45, Loss : 0.571274, Accuracy: 0.927000, Test accuracy: 0.917400
Distillation: Epoch : 46, Loss : 0.598583, Accuracy: 0.897000, Test accuracy: 0.919900
Distillation: Epoch : 47, Loss : 0.553962, Accuracy: 0.916000, Test accuracy: 0.920500
Distillation: Epoch : 48, Loss : 0.556122, Accuracy: 0.914000, Test accuracy: 0.920800
Distillation: Epoch : 49, Loss : 0.560606, Accuracy: 0.922000, Test accuracy: 0.919600
Distillation: Epoch : 50, Loss : 0.545902, Accuracy: 0.931000, Test accuracy: 0.920700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9207
Generating confusion matrix for student4
[[ 961.    0.   10.    4.    1.    8.    9.    2.    8.   11.]
 [   0. 1113.   10.    1.    3.    4.    3.   16.    9.    6.]
 [   0.    2.  910.   16.    5.    2.    5.   19.    9.    1.]
 [   1.    2.   23.  924.    1.   36.    1.    5.   20.   12.]
 [   0.    1.   14.    1.  934.    9.    9.   15.   12.   36.]
 [   6.    2.    2.   22.    1.  766.   15.    0.   31.    5.]
 [   8.    4.   10.    2.    8.   16.  911.    0.   11.    1.]
 [   2.    1.   10.   11.    1.    9.    3.  930.   10.   23.]
 [   2.   10.   35.   20.    5.   32.    2.    1.  852.    8.]
 [   0.    0.    8.    9.   23.   10.    0.   40.   12.  906.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.157516, Accuracy: 0.813000, Test accuracy: 0.791700
Distillation: Epoch : 2, Loss : 0.862959, Accuracy: 0.868000, Test accuracy: 0.869700
Distillation: Epoch : 3, Loss : 0.784403, Accuracy: 0.885000, Test accuracy: 0.888200
Distillation: Epoch : 4, Loss : 0.776888, Accuracy: 0.903000, Test accuracy: 0.896200
Distillation: Epoch : 5, Loss : 0.786838, Accuracy: 0.887000, Test accuracy: 0.900400
Distillation: Epoch : 6, Loss : 0.778187, Accuracy: 0.891000, Test accuracy: 0.902900
Distillation: Epoch : 7, Loss : 0.770544, Accuracy: 0.894000, Test accuracy: 0.905900
Distillation: Epoch : 8, Loss : 0.716684, Accuracy: 0.906000, Test accuracy: 0.908400
Distillation: Epoch : 9, Loss : 0.753025, Accuracy: 0.915000, Test accuracy: 0.910000
Distillation: Epoch : 10, Loss : 0.695959, Accuracy: 0.921000, Test accuracy: 0.915200
Distillation: Epoch : 11, Loss : 0.746406, Accuracy: 0.917000, Test accuracy: 0.917100
Distillation: Epoch : 12, Loss : 0.732135, Accuracy: 0.909000, Test accuracy: 0.919100
Distillation: Epoch : 13, Loss : 0.743562, Accuracy: 0.915000, Test accuracy: 0.922900
Distillation: Epoch : 14, Loss : 0.719371, Accuracy: 0.920000, Test accuracy: 0.925200
Distillation: Epoch : 15, Loss : 0.688622, Accuracy: 0.927000, Test accuracy: 0.929200
Distillation: Epoch : 16, Loss : 0.709864, Accuracy: 0.929000, Test accuracy: 0.931100
Distillation: Epoch : 17, Loss : 0.682159, Accuracy: 0.935000, Test accuracy: 0.932700
Distillation: Epoch : 18, Loss : 0.670883, Accuracy: 0.939000, Test accuracy: 0.935800
Distillation: Epoch : 19, Loss : 0.703364, Accuracy: 0.932000, Test accuracy: 0.938000
Distillation: Epoch : 20, Loss : 0.648133, Accuracy: 0.942000, Test accuracy: 0.939700
Distillation: Epoch : 21, Loss : 0.687101, Accuracy: 0.937000, Test accuracy: 0.941300
Distillation: Epoch : 22, Loss : 0.653112, Accuracy: 0.927000, Test accuracy: 0.941000
Distillation: Epoch : 23, Loss : 0.658701, Accuracy: 0.950000, Test accuracy: 0.943800
Distillation: Epoch : 24, Loss : 0.635939, Accuracy: 0.945000, Test accuracy: 0.944200
Distillation: Epoch : 25, Loss : 0.643138, Accuracy: 0.947000, Test accuracy: 0.945500
Distillation: Epoch : 26, Loss : 0.662955, Accuracy: 0.938000, Test accuracy: 0.947600
Distillation: Epoch : 27, Loss : 0.601100, Accuracy: 0.964000, Test accuracy: 0.947700
Distillation: Epoch : 28, Loss : 0.631940, Accuracy: 0.947000, Test accuracy: 0.949000
Distillation: Epoch : 29, Loss : 0.649128, Accuracy: 0.945000, Test accuracy: 0.949300
Distillation: Epoch : 30, Loss : 0.655258, Accuracy: 0.947000, Test accuracy: 0.950000
Distillation: Epoch : 31, Loss : 0.641983, Accuracy: 0.946000, Test accuracy: 0.950800
Distillation: Epoch : 32, Loss : 0.628792, Accuracy: 0.964000, Test accuracy: 0.952200
Distillation: Epoch : 33, Loss : 0.646640, Accuracy: 0.944000, Test accuracy: 0.953100
Distillation: Epoch : 34, Loss : 0.634318, Accuracy: 0.956000, Test accuracy: 0.952900
Distillation: Epoch : 35, Loss : 0.647771, Accuracy: 0.953000, Test accuracy: 0.953100
Distillation: Epoch : 36, Loss : 0.636990, Accuracy: 0.948000, Test accuracy: 0.953800
Distillation: Epoch : 37, Loss : 0.662486, Accuracy: 0.941000, Test accuracy: 0.953900
Distillation: Epoch : 38, Loss : 0.626695, Accuracy: 0.962000, Test accuracy: 0.954600
Distillation: Epoch : 39, Loss : 0.645479, Accuracy: 0.949000, Test accuracy: 0.955100
Distillation: Epoch : 40, Loss : 0.640727, Accuracy: 0.944000, Test accuracy: 0.957000
Distillation: Epoch : 41, Loss : 0.613280, Accuracy: 0.953000, Test accuracy: 0.955500
Distillation: Epoch : 42, Loss : 0.649774, Accuracy: 0.958000, Test accuracy: 0.956100
Distillation: Epoch : 43, Loss : 0.639156, Accuracy: 0.951000, Test accuracy: 0.957200
Distillation: Epoch : 44, Loss : 0.620256, Accuracy: 0.958000, Test accuracy: 0.956300
Distillation: Epoch : 45, Loss : 0.590804, Accuracy: 0.963000, Test accuracy: 0.957200
Distillation: Epoch : 46, Loss : 0.613423, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 47, Loss : 0.602988, Accuracy: 0.950000, Test accuracy: 0.958200
Distillation: Epoch : 48, Loss : 0.635651, Accuracy: 0.958000, Test accuracy: 0.958000
Distillation: Epoch : 49, Loss : 0.610496, Accuracy: 0.964000, Test accuracy: 0.959000
Distillation: Epoch : 50, Loss : 0.627358, Accuracy: 0.962000, Test accuracy: 0.958700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9587
Generating confusion matrix for student4
[[ 968.    0.    9.    1.    0.    4.    6.    1.    8.    3.]
 [   0. 1119.    8.    2.    2.    1.    3.   11.    6.    8.]
 [   0.    2.  978.    9.    3.    1.    3.   14.    5.    0.]
 [   0.    3.    7.  944.    0.    7.    1.    3.    6.    2.]
 [   0.    1.    7.    0.  951.    1.    3.    5.    9.   17.]
 [   1.    0.    1.   19.    1.  849.    4.    2.    8.    7.]
 [   5.    4.    1.    2.    6.    9.  933.    0.    7.    2.]
 [   1.    0.   14.   19.    4.    6.    0.  975.    9.    6.]
 [   3.    6.    5.    7.    3.    6.    5.    0.  910.    4.]
 [   2.    0.    2.    7.   12.    8.    0.   17.    6.  960.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.416591, Accuracy: 0.775000, Test accuracy: 0.785100
Distillation: Epoch : 2, Loss : 1.000389, Accuracy: 0.869000, Test accuracy: 0.868600
Distillation: Epoch : 3, Loss : 0.969531, Accuracy: 0.884000, Test accuracy: 0.882100
Distillation: Epoch : 4, Loss : 0.983580, Accuracy: 0.864000, Test accuracy: 0.889700
Distillation: Epoch : 5, Loss : 0.941883, Accuracy: 0.881000, Test accuracy: 0.894100
Distillation: Epoch : 6, Loss : 0.936217, Accuracy: 0.887000, Test accuracy: 0.896600
Distillation: Epoch : 7, Loss : 0.940421, Accuracy: 0.899000, Test accuracy: 0.898400
Distillation: Epoch : 8, Loss : 0.946338, Accuracy: 0.887000, Test accuracy: 0.898600
Distillation: Epoch : 9, Loss : 0.930724, Accuracy: 0.886000, Test accuracy: 0.899800
Distillation: Epoch : 10, Loss : 0.911901, Accuracy: 0.894000, Test accuracy: 0.901000
Distillation: Epoch : 11, Loss : 0.941738, Accuracy: 0.893000, Test accuracy: 0.904000
Distillation: Epoch : 12, Loss : 0.921656, Accuracy: 0.896000, Test accuracy: 0.905000
Distillation: Epoch : 13, Loss : 0.914980, Accuracy: 0.908000, Test accuracy: 0.905100
Distillation: Epoch : 14, Loss : 0.912713, Accuracy: 0.904000, Test accuracy: 0.905100
Distillation: Epoch : 15, Loss : 0.913935, Accuracy: 0.903000, Test accuracy: 0.904500
Distillation: Epoch : 16, Loss : 0.922379, Accuracy: 0.899000, Test accuracy: 0.906200
Distillation: Epoch : 17, Loss : 0.903718, Accuracy: 0.911000, Test accuracy: 0.907200
Distillation: Epoch : 18, Loss : 0.902741, Accuracy: 0.910000, Test accuracy: 0.907600
Distillation: Epoch : 19, Loss : 0.912748, Accuracy: 0.903000, Test accuracy: 0.908700
Distillation: Epoch : 20, Loss : 0.923316, Accuracy: 0.917000, Test accuracy: 0.908700
Distillation: Epoch : 21, Loss : 0.902889, Accuracy: 0.908000, Test accuracy: 0.908200
Distillation: Epoch : 22, Loss : 0.895528, Accuracy: 0.917000, Test accuracy: 0.907300
Distillation: Epoch : 23, Loss : 0.885538, Accuracy: 0.900000, Test accuracy: 0.909700
Distillation: Epoch : 24, Loss : 0.880334, Accuracy: 0.908000, Test accuracy: 0.908800
Distillation: Epoch : 25, Loss : 0.895537, Accuracy: 0.917000, Test accuracy: 0.909700
Distillation: Epoch : 26, Loss : 0.948325, Accuracy: 0.897000, Test accuracy: 0.910800
Distillation: Epoch : 27, Loss : 0.944168, Accuracy: 0.890000, Test accuracy: 0.909300
Distillation: Epoch : 28, Loss : 0.934468, Accuracy: 0.898000, Test accuracy: 0.910400
Distillation: Epoch : 29, Loss : 0.888142, Accuracy: 0.912000, Test accuracy: 0.910000
Distillation: Epoch : 30, Loss : 0.922897, Accuracy: 0.916000, Test accuracy: 0.911800
Distillation: Epoch : 31, Loss : 0.946870, Accuracy: 0.884000, Test accuracy: 0.910700
Distillation: Epoch : 32, Loss : 0.890126, Accuracy: 0.902000, Test accuracy: 0.913800
Distillation: Epoch : 33, Loss : 0.863467, Accuracy: 0.918000, Test accuracy: 0.912800
Distillation: Epoch : 34, Loss : 0.900895, Accuracy: 0.913000, Test accuracy: 0.912600
Distillation: Epoch : 35, Loss : 0.907334, Accuracy: 0.906000, Test accuracy: 0.913700
Distillation: Epoch : 36, Loss : 0.900028, Accuracy: 0.915000, Test accuracy: 0.912700
Distillation: Epoch : 37, Loss : 0.871251, Accuracy: 0.927000, Test accuracy: 0.913600
Distillation: Epoch : 38, Loss : 0.908096, Accuracy: 0.906000, Test accuracy: 0.914100
Distillation: Epoch : 39, Loss : 0.874641, Accuracy: 0.913000, Test accuracy: 0.914700
Distillation: Epoch : 40, Loss : 0.866704, Accuracy: 0.913000, Test accuracy: 0.914100
Distillation: Epoch : 41, Loss : 0.894415, Accuracy: 0.917000, Test accuracy: 0.915000
Distillation: Epoch : 42, Loss : 0.876246, Accuracy: 0.930000, Test accuracy: 0.914900
Distillation: Epoch : 43, Loss : 0.911681, Accuracy: 0.906000, Test accuracy: 0.917400
Distillation: Epoch : 44, Loss : 0.896597, Accuracy: 0.906000, Test accuracy: 0.916200
Distillation: Epoch : 45, Loss : 0.882783, Accuracy: 0.910000, Test accuracy: 0.916700
Distillation: Epoch : 46, Loss : 0.858181, Accuracy: 0.921000, Test accuracy: 0.917100
Distillation: Epoch : 47, Loss : 0.883995, Accuracy: 0.913000, Test accuracy: 0.918100
Distillation: Epoch : 48, Loss : 0.858717, Accuracy: 0.924000, Test accuracy: 0.921300
Distillation: Epoch : 49, Loss : 0.872792, Accuracy: 0.931000, Test accuracy: 0.921500
Distillation: Epoch : 50, Loss : 0.885269, Accuracy: 0.906000, Test accuracy: 0.924700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9247
Generating confusion matrix for student4
[[ 963.    0.   10.    4.    1.    7.    8.    1.   10.    8.]
 [   0. 1103.   15.    3.    1.    5.    4.   18.   11.    6.]
 [   0.    3.  903.   15.    5.    1.    4.   14.    7.    1.]
 [   1.    3.   22.  927.    1.   24.    0.    3.   14.   12.]
 [   0.    1.   17.    2.  924.    4.    6.   11.   13.   43.]
 [   3.    2.    1.   22.    1.  801.   15.    1.   17.    7.]
 [   6.    5.   11.    2.    9.   15.  916.    0.   12.    0.]
 [   2.    1.   18.   13.    2.    6.    3.  942.    8.   26.]
 [   4.   17.   30.   16.    6.   22.    2.    1.  867.    5.]
 [   1.    0.    5.    6.   32.    7.    0.   37.   15.  901.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.577694, Accuracy: 0.791000, Test accuracy: 0.784200
Distillation: Epoch : 2, Loss : 1.209509, Accuracy: 0.841000, Test accuracy: 0.861900
Distillation: Epoch : 3, Loss : 1.167906, Accuracy: 0.859000, Test accuracy: 0.881900
Distillation: Epoch : 4, Loss : 1.096743, Accuracy: 0.893000, Test accuracy: 0.892000
Distillation: Epoch : 5, Loss : 1.077720, Accuracy: 0.907000, Test accuracy: 0.896300
Distillation: Epoch : 6, Loss : 1.086290, Accuracy: 0.902000, Test accuracy: 0.898500
Distillation: Epoch : 7, Loss : 1.095628, Accuracy: 0.883000, Test accuracy: 0.902000
Distillation: Epoch : 8, Loss : 1.078915, Accuracy: 0.900000, Test accuracy: 0.903700
Distillation: Epoch : 9, Loss : 1.065461, Accuracy: 0.899000, Test accuracy: 0.906700
Distillation: Epoch : 10, Loss : 1.067488, Accuracy: 0.893000, Test accuracy: 0.908000
Distillation: Epoch : 11, Loss : 1.088078, Accuracy: 0.901000, Test accuracy: 0.908700
Distillation: Epoch : 12, Loss : 1.076266, Accuracy: 0.903000, Test accuracy: 0.911200
Distillation: Epoch : 13, Loss : 1.017763, Accuracy: 0.918000, Test accuracy: 0.913000
Distillation: Epoch : 14, Loss : 1.028437, Accuracy: 0.928000, Test accuracy: 0.916300
Distillation: Epoch : 15, Loss : 1.041080, Accuracy: 0.919000, Test accuracy: 0.917400
Distillation: Epoch : 16, Loss : 1.048184, Accuracy: 0.915000, Test accuracy: 0.919200
Distillation: Epoch : 17, Loss : 1.046585, Accuracy: 0.915000, Test accuracy: 0.920700
Distillation: Epoch : 18, Loss : 1.021478, Accuracy: 0.926000, Test accuracy: 0.921900
Distillation: Epoch : 19, Loss : 1.026502, Accuracy: 0.909000, Test accuracy: 0.924100
Distillation: Epoch : 20, Loss : 1.006477, Accuracy: 0.933000, Test accuracy: 0.927600
Distillation: Epoch : 21, Loss : 1.027110, Accuracy: 0.918000, Test accuracy: 0.930700
Distillation: Epoch : 22, Loss : 1.019315, Accuracy: 0.929000, Test accuracy: 0.932200
Distillation: Epoch : 23, Loss : 1.015094, Accuracy: 0.934000, Test accuracy: 0.934100
Distillation: Epoch : 24, Loss : 1.023170, Accuracy: 0.919000, Test accuracy: 0.937000
Distillation: Epoch : 25, Loss : 0.987390, Accuracy: 0.941000, Test accuracy: 0.939200
Distillation: Epoch : 26, Loss : 1.023484, Accuracy: 0.928000, Test accuracy: 0.941000
Distillation: Epoch : 27, Loss : 0.986390, Accuracy: 0.939000, Test accuracy: 0.943000
Distillation: Epoch : 28, Loss : 1.003270, Accuracy: 0.934000, Test accuracy: 0.944000
Distillation: Epoch : 29, Loss : 0.966288, Accuracy: 0.939000, Test accuracy: 0.947700
Distillation: Epoch : 30, Loss : 0.976233, Accuracy: 0.947000, Test accuracy: 0.948700
Distillation: Epoch : 31, Loss : 0.996297, Accuracy: 0.944000, Test accuracy: 0.949900
Distillation: Epoch : 32, Loss : 0.949506, Accuracy: 0.951000, Test accuracy: 0.952000
Distillation: Epoch : 33, Loss : 0.963468, Accuracy: 0.939000, Test accuracy: 0.952500
Distillation: Epoch : 34, Loss : 0.941917, Accuracy: 0.962000, Test accuracy: 0.953000
Distillation: Epoch : 35, Loss : 0.948357, Accuracy: 0.955000, Test accuracy: 0.953300
Distillation: Epoch : 36, Loss : 0.972751, Accuracy: 0.955000, Test accuracy: 0.955000
Distillation: Epoch : 37, Loss : 0.964200, Accuracy: 0.945000, Test accuracy: 0.956100
Distillation: Epoch : 38, Loss : 0.961764, Accuracy: 0.940000, Test accuracy: 0.956100
Distillation: Epoch : 39, Loss : 0.974794, Accuracy: 0.952000, Test accuracy: 0.956800
Distillation: Epoch : 40, Loss : 0.961606, Accuracy: 0.947000, Test accuracy: 0.957300
Distillation: Epoch : 41, Loss : 0.956554, Accuracy: 0.957000, Test accuracy: 0.956700
Distillation: Epoch : 42, Loss : 0.955677, Accuracy: 0.964000, Test accuracy: 0.957200
Distillation: Epoch : 43, Loss : 0.968397, Accuracy: 0.952000, Test accuracy: 0.960100
Distillation: Epoch : 44, Loss : 0.948061, Accuracy: 0.957000, Test accuracy: 0.959100
Distillation: Epoch : 45, Loss : 0.967954, Accuracy: 0.947000, Test accuracy: 0.960500
Distillation: Epoch : 46, Loss : 0.969981, Accuracy: 0.954000, Test accuracy: 0.960600
Distillation: Epoch : 47, Loss : 0.967992, Accuracy: 0.961000, Test accuracy: 0.961000
Distillation: Epoch : 48, Loss : 0.939413, Accuracy: 0.958000, Test accuracy: 0.961800
Distillation: Epoch : 49, Loss : 0.951029, Accuracy: 0.950000, Test accuracy: 0.962200
Distillation: Epoch : 50, Loss : 0.939748, Accuracy: 0.958000, Test accuracy: 0.961400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9614
Generating confusion matrix for student4
[[ 969.    0.    5.    0.    1.    2.    7.    1.    9.    3.]
 [   1. 1119.    5.    1.    1.    1.    3.    7.   11.    8.]
 [   0.    2.  969.    6.    1.    1.    2.   13.    4.    0.]
 [   0.    2.   14.  969.    0.    8.    1.    4.    9.    2.]
 [   0.    1.    9.    1.  960.    1.    4.    7.    9.   18.]
 [   1.    0.    0.   10.    0.  859.    3.    0.    5.    5.]
 [   6.    5.    2.    0.    6.    9.  935.    0.    7.    1.]
 [   1.    0.   17.   14.    2.    2.    0.  973.   10.    7.]
 [   2.    6.   10.    5.    2.    2.    3.    2.  897.    1.]
 [   0.    0.    1.    4.    9.    7.    0.   21.   13.  964.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.245951, Accuracy: 0.276000, Test accuracy: 0.270000
Distillation: Epoch : 2, Loss : 1.535431, Accuracy: 0.807000, Test accuracy: 0.823600
Distillation: Epoch : 3, Loss : 1.275656, Accuracy: 0.863000, Test accuracy: 0.868600
Distillation: Epoch : 4, Loss : 1.222129, Accuracy: 0.895000, Test accuracy: 0.888200
Distillation: Epoch : 5, Loss : 1.216164, Accuracy: 0.911000, Test accuracy: 0.899200
Distillation: Epoch : 6, Loss : 1.195606, Accuracy: 0.900000, Test accuracy: 0.909100
Distillation: Epoch : 7, Loss : 1.209681, Accuracy: 0.907000, Test accuracy: 0.915800
Distillation: Epoch : 8, Loss : 1.208311, Accuracy: 0.908000, Test accuracy: 0.921400
Distillation: Epoch : 9, Loss : 1.182611, Accuracy: 0.907000, Test accuracy: 0.928300
Distillation: Epoch : 10, Loss : 1.179958, Accuracy: 0.915000, Test accuracy: 0.931300
Distillation: Epoch : 11, Loss : 1.166048, Accuracy: 0.925000, Test accuracy: 0.934900
Distillation: Epoch : 12, Loss : 1.170898, Accuracy: 0.920000, Test accuracy: 0.937200
Distillation: Epoch : 13, Loss : 1.156382, Accuracy: 0.931000, Test accuracy: 0.938800
Distillation: Epoch : 14, Loss : 1.144679, Accuracy: 0.933000, Test accuracy: 0.940300
Distillation: Epoch : 15, Loss : 1.155973, Accuracy: 0.926000, Test accuracy: 0.944700
Distillation: Epoch : 16, Loss : 1.180563, Accuracy: 0.934000, Test accuracy: 0.946300
Distillation: Epoch : 17, Loss : 1.153575, Accuracy: 0.941000, Test accuracy: 0.947700
Distillation: Epoch : 18, Loss : 1.130389, Accuracy: 0.946000, Test accuracy: 0.950500
Distillation: Epoch : 19, Loss : 1.158973, Accuracy: 0.930000, Test accuracy: 0.951900
Distillation: Epoch : 20, Loss : 1.121652, Accuracy: 0.944000, Test accuracy: 0.953200
Distillation: Epoch : 21, Loss : 1.161727, Accuracy: 0.951000, Test accuracy: 0.953900
Distillation: Epoch : 22, Loss : 1.124319, Accuracy: 0.963000, Test accuracy: 0.955000
Distillation: Epoch : 23, Loss : 1.120146, Accuracy: 0.944000, Test accuracy: 0.954700
Distillation: Epoch : 24, Loss : 1.117645, Accuracy: 0.947000, Test accuracy: 0.955800
Distillation: Epoch : 25, Loss : 1.122067, Accuracy: 0.947000, Test accuracy: 0.956600
Distillation: Epoch : 26, Loss : 1.120187, Accuracy: 0.952000, Test accuracy: 0.957400
Distillation: Epoch : 27, Loss : 1.107017, Accuracy: 0.958000, Test accuracy: 0.958200
Distillation: Epoch : 28, Loss : 1.118114, Accuracy: 0.954000, Test accuracy: 0.958300
Distillation: Epoch : 29, Loss : 1.118811, Accuracy: 0.953000, Test accuracy: 0.959600
Distillation: Epoch : 30, Loss : 1.094776, Accuracy: 0.958000, Test accuracy: 0.960400
Distillation: Epoch : 31, Loss : 1.121060, Accuracy: 0.966000, Test accuracy: 0.960600
Distillation: Epoch : 32, Loss : 1.119503, Accuracy: 0.953000, Test accuracy: 0.961600
Distillation: Epoch : 33, Loss : 1.114656, Accuracy: 0.955000, Test accuracy: 0.963000
Distillation: Epoch : 34, Loss : 1.107890, Accuracy: 0.959000, Test accuracy: 0.962500
Distillation: Epoch : 35, Loss : 1.098466, Accuracy: 0.954000, Test accuracy: 0.963700
Distillation: Epoch : 36, Loss : 1.106413, Accuracy: 0.944000, Test accuracy: 0.963700
Distillation: Epoch : 37, Loss : 1.096790, Accuracy: 0.970000, Test accuracy: 0.964400
Distillation: Epoch : 38, Loss : 1.096362, Accuracy: 0.963000, Test accuracy: 0.964900
Distillation: Epoch : 39, Loss : 1.120814, Accuracy: 0.953000, Test accuracy: 0.964500
Distillation: Epoch : 40, Loss : 1.131177, Accuracy: 0.967000, Test accuracy: 0.965600
Distillation: Epoch : 41, Loss : 1.098693, Accuracy: 0.967000, Test accuracy: 0.965800
Distillation: Epoch : 42, Loss : 1.118507, Accuracy: 0.960000, Test accuracy: 0.965700
Distillation: Epoch : 43, Loss : 1.123936, Accuracy: 0.960000, Test accuracy: 0.966100
Distillation: Epoch : 44, Loss : 1.127686, Accuracy: 0.957000, Test accuracy: 0.967100
Distillation: Epoch : 45, Loss : 1.094237, Accuracy: 0.968000, Test accuracy: 0.967000
Distillation: Epoch : 46, Loss : 1.122650, Accuracy: 0.970000, Test accuracy: 0.967600
Distillation: Epoch : 47, Loss : 1.089845, Accuracy: 0.966000, Test accuracy: 0.967300
Distillation: Epoch : 48, Loss : 1.096649, Accuracy: 0.971000, Test accuracy: 0.968500
Distillation: Epoch : 49, Loss : 1.096172, Accuracy: 0.964000, Test accuracy: 0.967400
Distillation: Epoch : 50, Loss : 1.112634, Accuracy: 0.965000, Test accuracy: 0.968400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9684
Generating confusion matrix for student4
[[ 972.    0.    5.    0.    1.    2.    8.    2.    9.    6.]
 [   0. 1123.    7.    0.    1.    1.    3.    5.    3.    6.]
 [   0.    3.  979.    5.    1.    0.    0.   12.    2.    1.]
 [   0.    1.    5.  979.    0.   10.    0.    3.    7.    4.]
 [   0.    1.    8.    1.  962.    1.    1.    2.    8.   22.]
 [   0.    0.    1.    7.    0.  865.    2.    0.    2.    2.]
 [   4.    3.    2.    0.    3.    4.  941.    0.    4.    0.]
 [   3.    0.   15.    7.    1.    2.    0.  988.    7.   11.]
 [   1.    4.    8.    6.    1.    3.    3.    0.  919.    1.]
 [   0.    0.    2.    5.   12.    4.    0.   16.   13.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.078494, Accuracy: 0.665000, Test accuracy: 0.671900
Distillation: Epoch : 2, Loss : 1.471511, Accuracy: 0.844000, Test accuracy: 0.850400
Distillation: Epoch : 3, Loss : 1.406960, Accuracy: 0.890000, Test accuracy: 0.878000
Distillation: Epoch : 4, Loss : 1.395262, Accuracy: 0.878000, Test accuracy: 0.888300
Distillation: Epoch : 5, Loss : 1.388699, Accuracy: 0.889000, Test accuracy: 0.893200
Distillation: Epoch : 6, Loss : 1.380155, Accuracy: 0.892000, Test accuracy: 0.899000
Distillation: Epoch : 7, Loss : 1.397958, Accuracy: 0.878000, Test accuracy: 0.904700
Distillation: Epoch : 8, Loss : 1.362604, Accuracy: 0.898000, Test accuracy: 0.909500
Distillation: Epoch : 9, Loss : 1.354161, Accuracy: 0.911000, Test accuracy: 0.912800
Distillation: Epoch : 10, Loss : 1.304116, Accuracy: 0.912000, Test accuracy: 0.918400
Distillation: Epoch : 11, Loss : 1.305496, Accuracy: 0.933000, Test accuracy: 0.921800
Distillation: Epoch : 12, Loss : 1.360642, Accuracy: 0.907000, Test accuracy: 0.925000
Distillation: Epoch : 13, Loss : 1.307457, Accuracy: 0.930000, Test accuracy: 0.929100
Distillation: Epoch : 14, Loss : 1.324349, Accuracy: 0.932000, Test accuracy: 0.931300
Distillation: Epoch : 15, Loss : 1.319426, Accuracy: 0.932000, Test accuracy: 0.933900
Distillation: Epoch : 16, Loss : 1.317436, Accuracy: 0.928000, Test accuracy: 0.937000
Distillation: Epoch : 17, Loss : 1.253983, Accuracy: 0.954000, Test accuracy: 0.940900
Distillation: Epoch : 18, Loss : 1.283334, Accuracy: 0.938000, Test accuracy: 0.942500
Distillation: Epoch : 19, Loss : 1.296740, Accuracy: 0.934000, Test accuracy: 0.944400
Distillation: Epoch : 20, Loss : 1.307665, Accuracy: 0.929000, Test accuracy: 0.946300
Distillation: Epoch : 21, Loss : 1.256324, Accuracy: 0.944000, Test accuracy: 0.948100
Distillation: Epoch : 22, Loss : 1.260330, Accuracy: 0.941000, Test accuracy: 0.950200
Distillation: Epoch : 23, Loss : 1.296233, Accuracy: 0.949000, Test accuracy: 0.951100
Distillation: Epoch : 24, Loss : 1.315708, Accuracy: 0.943000, Test accuracy: 0.952200
Distillation: Epoch : 25, Loss : 1.286912, Accuracy: 0.948000, Test accuracy: 0.952900
Distillation: Epoch : 26, Loss : 1.248375, Accuracy: 0.956000, Test accuracy: 0.954700
Distillation: Epoch : 27, Loss : 1.263055, Accuracy: 0.951000, Test accuracy: 0.954500
Distillation: Epoch : 28, Loss : 1.283110, Accuracy: 0.943000, Test accuracy: 0.955900
Distillation: Epoch : 29, Loss : 1.260091, Accuracy: 0.952000, Test accuracy: 0.957200
Distillation: Epoch : 30, Loss : 1.277709, Accuracy: 0.948000, Test accuracy: 0.956900
Distillation: Epoch : 31, Loss : 1.257593, Accuracy: 0.960000, Test accuracy: 0.957100
Distillation: Epoch : 32, Loss : 1.263443, Accuracy: 0.952000, Test accuracy: 0.958400
Distillation: Epoch : 33, Loss : 1.263700, Accuracy: 0.970000, Test accuracy: 0.957900
Distillation: Epoch : 34, Loss : 1.265684, Accuracy: 0.956000, Test accuracy: 0.958700
Distillation: Epoch : 35, Loss : 1.269346, Accuracy: 0.953000, Test accuracy: 0.959000
Distillation: Epoch : 36, Loss : 1.255921, Accuracy: 0.957000, Test accuracy: 0.959400
Distillation: Epoch : 37, Loss : 1.272514, Accuracy: 0.953000, Test accuracy: 0.959300
Distillation: Epoch : 38, Loss : 1.243595, Accuracy: 0.963000, Test accuracy: 0.959700
Distillation: Epoch : 39, Loss : 1.257381, Accuracy: 0.959000, Test accuracy: 0.959800
Distillation: Epoch : 40, Loss : 1.260578, Accuracy: 0.956000, Test accuracy: 0.959800
Distillation: Epoch : 41, Loss : 1.262978, Accuracy: 0.949000, Test accuracy: 0.960100
Distillation: Epoch : 42, Loss : 1.264051, Accuracy: 0.964000, Test accuracy: 0.960300
Distillation: Epoch : 43, Loss : 1.249308, Accuracy: 0.956000, Test accuracy: 0.961100
Distillation: Epoch : 44, Loss : 1.257239, Accuracy: 0.956000, Test accuracy: 0.960800
Distillation: Epoch : 45, Loss : 1.259635, Accuracy: 0.967000, Test accuracy: 0.961800
Distillation: Epoch : 46, Loss : 1.247838, Accuracy: 0.955000, Test accuracy: 0.961500
Distillation: Epoch : 47, Loss : 1.227393, Accuracy: 0.965000, Test accuracy: 0.961100
Distillation: Epoch : 48, Loss : 1.250313, Accuracy: 0.957000, Test accuracy: 0.961700
Distillation: Epoch : 49, Loss : 1.236484, Accuracy: 0.965000, Test accuracy: 0.961500
Distillation: Epoch : 50, Loss : 1.260235, Accuracy: 0.954000, Test accuracy: 0.961100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9611
Generating confusion matrix for student4
[[ 971.    0.    7.    1.    3.    2.   10.    1.    9.    3.]
 [   1. 1119.    8.    1.    2.    0.    3.    9.    8.    8.]
 [   0.    2.  972.    5.    1.    1.    1.   13.    8.    0.]
 [   0.    2.   10.  966.    0.    7.    1.    3.    5.    4.]
 [   2.    2.    7.    2.  957.    0.    3.    4.   11.   21.]
 [   1.    0.    1.    9.    0.  854.    5.    0.    3.    5.]
 [   2.    5.    2.    0.    3.    9.  933.    0.    5.    2.]
 [   0.    0.   17.   14.    1.    6.    0.  976.   10.    6.]
 [   2.    5.    6.    7.    5.    4.    2.    1.  905.    2.]
 [   1.    0.    2.    5.   10.    9.    0.   21.   10.  958.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.220925, Accuracy: 0.321000, Test accuracy: 0.324300
Distillation: Epoch : 2, Loss : 1.689681, Accuracy: 0.803000, Test accuracy: 0.817100
Distillation: Epoch : 3, Loss : 1.561928, Accuracy: 0.863000, Test accuracy: 0.862200
Distillation: Epoch : 4, Loss : 1.497175, Accuracy: 0.877000, Test accuracy: 0.885500
Distillation: Epoch : 5, Loss : 1.502462, Accuracy: 0.879000, Test accuracy: 0.899800
Distillation: Epoch : 6, Loss : 1.480099, Accuracy: 0.893000, Test accuracy: 0.909100
Distillation: Epoch : 7, Loss : 1.449054, Accuracy: 0.917000, Test accuracy: 0.915200
Distillation: Epoch : 8, Loss : 1.448501, Accuracy: 0.915000, Test accuracy: 0.920300
Distillation: Epoch : 9, Loss : 1.436624, Accuracy: 0.917000, Test accuracy: 0.923500
Distillation: Epoch : 10, Loss : 1.441908, Accuracy: 0.921000, Test accuracy: 0.928400
Distillation: Epoch : 11, Loss : 1.419832, Accuracy: 0.931000, Test accuracy: 0.931900
Distillation: Epoch : 12, Loss : 1.415736, Accuracy: 0.946000, Test accuracy: 0.936200
Distillation: Epoch : 13, Loss : 1.433794, Accuracy: 0.935000, Test accuracy: 0.939800
Distillation: Epoch : 14, Loss : 1.428310, Accuracy: 0.918000, Test accuracy: 0.943600
Distillation: Epoch : 15, Loss : 1.416660, Accuracy: 0.948000, Test accuracy: 0.945100
Distillation: Epoch : 16, Loss : 1.398295, Accuracy: 0.946000, Test accuracy: 0.949000
Distillation: Epoch : 17, Loss : 1.422171, Accuracy: 0.953000, Test accuracy: 0.950700
Distillation: Epoch : 18, Loss : 1.407231, Accuracy: 0.945000, Test accuracy: 0.951400
Distillation: Epoch : 19, Loss : 1.433237, Accuracy: 0.941000, Test accuracy: 0.953300
Distillation: Epoch : 20, Loss : 1.411733, Accuracy: 0.943000, Test accuracy: 0.953000
Distillation: Epoch : 21, Loss : 1.414298, Accuracy: 0.946000, Test accuracy: 0.954600
Distillation: Epoch : 22, Loss : 1.396361, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 23, Loss : 1.396198, Accuracy: 0.955000, Test accuracy: 0.957400
Distillation: Epoch : 24, Loss : 1.396633, Accuracy: 0.958000, Test accuracy: 0.958600
Distillation: Epoch : 25, Loss : 1.400624, Accuracy: 0.961000, Test accuracy: 0.959200
Distillation: Epoch : 26, Loss : 1.404846, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 27, Loss : 1.396630, Accuracy: 0.962000, Test accuracy: 0.961100
Distillation: Epoch : 28, Loss : 1.412905, Accuracy: 0.959000, Test accuracy: 0.961500
Distillation: Epoch : 29, Loss : 1.392954, Accuracy: 0.957000, Test accuracy: 0.961100
Distillation: Epoch : 30, Loss : 1.388497, Accuracy: 0.956000, Test accuracy: 0.960600
Distillation: Epoch : 31, Loss : 1.401453, Accuracy: 0.949000, Test accuracy: 0.962000
Distillation: Epoch : 32, Loss : 1.397005, Accuracy: 0.971000, Test accuracy: 0.961400
Distillation: Epoch : 33, Loss : 1.388288, Accuracy: 0.958000, Test accuracy: 0.961100
Distillation: Epoch : 34, Loss : 1.401483, Accuracy: 0.956000, Test accuracy: 0.962100
Distillation: Epoch : 35, Loss : 1.400739, Accuracy: 0.961000, Test accuracy: 0.963200
Distillation: Epoch : 36, Loss : 1.383046, Accuracy: 0.959000, Test accuracy: 0.962900
Distillation: Epoch : 37, Loss : 1.399435, Accuracy: 0.957000, Test accuracy: 0.963500
Distillation: Epoch : 38, Loss : 1.394390, Accuracy: 0.960000, Test accuracy: 0.963100
Distillation: Epoch : 39, Loss : 1.386607, Accuracy: 0.951000, Test accuracy: 0.963700
Distillation: Epoch : 40, Loss : 1.389076, Accuracy: 0.963000, Test accuracy: 0.963900
Distillation: Epoch : 41, Loss : 1.388338, Accuracy: 0.964000, Test accuracy: 0.962700
Distillation: Epoch : 42, Loss : 1.374323, Accuracy: 0.960000, Test accuracy: 0.963200
Distillation: Epoch : 43, Loss : 1.378958, Accuracy: 0.965000, Test accuracy: 0.963600
Distillation: Epoch : 44, Loss : 1.411097, Accuracy: 0.954000, Test accuracy: 0.963800
Distillation: Epoch : 45, Loss : 1.391681, Accuracy: 0.956000, Test accuracy: 0.963500
Distillation: Epoch : 46, Loss : 1.396800, Accuracy: 0.960000, Test accuracy: 0.964700
Distillation: Epoch : 47, Loss : 1.371622, Accuracy: 0.958000, Test accuracy: 0.964700
Distillation: Epoch : 48, Loss : 1.401411, Accuracy: 0.960000, Test accuracy: 0.963800
Distillation: Epoch : 49, Loss : 1.376922, Accuracy: 0.967000, Test accuracy: 0.964700
Distillation: Epoch : 50, Loss : 1.387331, Accuracy: 0.962000, Test accuracy: 0.964100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9641
Generating confusion matrix for student4
[[ 974.    0.    7.    2.    1.    2.    6.    2.   10.    5.]
 [   0. 1121.   10.    1.    2.    0.    3.    6.    6.    8.]
 [   0.    4.  968.    3.    1.    1.    1.   10.    8.    0.]
 [   0.    0.   10.  975.    0.   11.    0.    2.    2.    7.]
 [   0.    0.    6.    1.  967.    1.    4.    6.   10.   23.]
 [   0.    0.    1.    7.    0.  863.    6.    1.    4.    4.]
 [   3.    5.    5.    0.    3.    5.  934.    0.    4.    0.]
 [   1.    0.   14.   12.    0.    2.    0.  981.   12.   15.]
 [   2.    5.    9.    6.    2.    1.    4.    0.  911.    0.]
 [   0.    0.    2.    3.    6.    6.    0.   20.    7.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.031903, Accuracy: 0.767000, Test accuracy: 0.756700
Distillation: Epoch : 2, Loss : 1.830695, Accuracy: 0.842000, Test accuracy: 0.845900
Distillation: Epoch : 3, Loss : 1.787367, Accuracy: 0.875000, Test accuracy: 0.873600
Distillation: Epoch : 4, Loss : 1.781764, Accuracy: 0.860000, Test accuracy: 0.887200
Distillation: Epoch : 5, Loss : 1.757219, Accuracy: 0.900000, Test accuracy: 0.898400
Distillation: Epoch : 6, Loss : 1.755831, Accuracy: 0.909000, Test accuracy: 0.905800
Distillation: Epoch : 7, Loss : 1.726514, Accuracy: 0.925000, Test accuracy: 0.912400
Distillation: Epoch : 8, Loss : 1.738653, Accuracy: 0.915000, Test accuracy: 0.919000
Distillation: Epoch : 9, Loss : 1.739703, Accuracy: 0.916000, Test accuracy: 0.927800
Distillation: Epoch : 10, Loss : 1.705054, Accuracy: 0.916000, Test accuracy: 0.932200
Distillation: Epoch : 11, Loss : 1.723124, Accuracy: 0.916000, Test accuracy: 0.936800
Distillation: Epoch : 12, Loss : 1.711477, Accuracy: 0.940000, Test accuracy: 0.941600
Distillation: Epoch : 13, Loss : 1.697414, Accuracy: 0.945000, Test accuracy: 0.943800
Distillation: Epoch : 14, Loss : 1.713105, Accuracy: 0.943000, Test accuracy: 0.947600
Distillation: Epoch : 15, Loss : 1.718516, Accuracy: 0.940000, Test accuracy: 0.949700
Distillation: Epoch : 16, Loss : 1.703350, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 17, Loss : 1.721401, Accuracy: 0.947000, Test accuracy: 0.955100
Distillation: Epoch : 18, Loss : 1.697009, Accuracy: 0.948000, Test accuracy: 0.956300
Distillation: Epoch : 19, Loss : 1.698287, Accuracy: 0.956000, Test accuracy: 0.957100
Distillation: Epoch : 20, Loss : 1.724566, Accuracy: 0.949000, Test accuracy: 0.959000
Distillation: Epoch : 21, Loss : 1.691411, Accuracy: 0.949000, Test accuracy: 0.959400
Distillation: Epoch : 22, Loss : 1.711381, Accuracy: 0.954000, Test accuracy: 0.960000
Distillation: Epoch : 23, Loss : 1.703075, Accuracy: 0.954000, Test accuracy: 0.960900
Distillation: Epoch : 24, Loss : 1.691801, Accuracy: 0.964000, Test accuracy: 0.961800
Distillation: Epoch : 25, Loss : 1.699667, Accuracy: 0.963000, Test accuracy: 0.962300
Distillation: Epoch : 26, Loss : 1.674784, Accuracy: 0.960000, Test accuracy: 0.962200
Distillation: Epoch : 27, Loss : 1.704954, Accuracy: 0.947000, Test accuracy: 0.962800
Distillation: Epoch : 28, Loss : 1.698516, Accuracy: 0.964000, Test accuracy: 0.964000
Distillation: Epoch : 29, Loss : 1.691755, Accuracy: 0.959000, Test accuracy: 0.963300
Distillation: Epoch : 30, Loss : 1.683415, Accuracy: 0.961000, Test accuracy: 0.964600
Distillation: Epoch : 31, Loss : 1.686918, Accuracy: 0.953000, Test accuracy: 0.965600
Distillation: Epoch : 32, Loss : 1.686816, Accuracy: 0.957000, Test accuracy: 0.964700
Distillation: Epoch : 33, Loss : 1.680825, Accuracy: 0.957000, Test accuracy: 0.965200
Distillation: Epoch : 34, Loss : 1.691002, Accuracy: 0.961000, Test accuracy: 0.966100
Distillation: Epoch : 35, Loss : 1.675478, Accuracy: 0.963000, Test accuracy: 0.965800
Distillation: Epoch : 36, Loss : 1.699528, Accuracy: 0.971000, Test accuracy: 0.966900
Distillation: Epoch : 37, Loss : 1.677342, Accuracy: 0.964000, Test accuracy: 0.967100
Distillation: Epoch : 38, Loss : 1.684805, Accuracy: 0.965000, Test accuracy: 0.966700
Distillation: Epoch : 39, Loss : 1.689179, Accuracy: 0.961000, Test accuracy: 0.967800
Distillation: Epoch : 40, Loss : 1.692099, Accuracy: 0.959000, Test accuracy: 0.967000
Distillation: Epoch : 41, Loss : 1.696635, Accuracy: 0.964000, Test accuracy: 0.967700
Distillation: Epoch : 42, Loss : 1.675300, Accuracy: 0.971000, Test accuracy: 0.966500
Distillation: Epoch : 43, Loss : 1.699848, Accuracy: 0.960000, Test accuracy: 0.967900
Distillation: Epoch : 44, Loss : 1.681598, Accuracy: 0.968000, Test accuracy: 0.967600
Distillation: Epoch : 45, Loss : 1.685022, Accuracy: 0.975000, Test accuracy: 0.967900
Distillation: Epoch : 46, Loss : 1.670925, Accuracy: 0.970000, Test accuracy: 0.967500
Distillation: Epoch : 47, Loss : 1.690143, Accuracy: 0.962000, Test accuracy: 0.968000
Distillation: Epoch : 48, Loss : 1.690360, Accuracy: 0.968000, Test accuracy: 0.967900
Distillation: Epoch : 49, Loss : 1.676208, Accuracy: 0.968000, Test accuracy: 0.968000
Distillation: Epoch : 50, Loss : 1.683398, Accuracy: 0.969000, Test accuracy: 0.967800
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9678
Generating confusion matrix for student4
[[ 974.    0.    5.    0.    2.    2.    8.    1.    9.    6.]
 [   1. 1126.   10.    1.    0.    0.    4.    8.    3.    7.]
 [   1.    4.  970.    4.    1.    1.    0.   11.    7.    0.]
 [   0.    0.   11.  980.    0.   11.    0.    2.    4.    7.]
 [   0.    0.    6.    1.  968.    1.    3.    4.    6.   20.]
 [   0.    0.    0.    7.    0.  861.    7.    0.    2.    1.]
 [   3.    4.    2.    0.    2.    5.  933.    0.    3.    0.]
 [   1.    0.   15.   10.    0.    3.    0.  987.    8.    9.]
 [   0.    1.    9.    5.    2.    3.    3.    0.  922.    2.]
 [   0.    0.    4.    2.    7.    5.    0.   15.   10.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.146688, Accuracy: 0.768000, Test accuracy: 0.777300
Distillation: Epoch : 2, Loss : 2.052894, Accuracy: 0.848000, Test accuracy: 0.845400
Distillation: Epoch : 3, Loss : 2.034319, Accuracy: 0.849000, Test accuracy: 0.867500
Distillation: Epoch : 4, Loss : 2.021257, Accuracy: 0.864000, Test accuracy: 0.875700
Distillation: Epoch : 5, Loss : 2.037732, Accuracy: 0.861000, Test accuracy: 0.881900
Distillation: Epoch : 6, Loss : 2.015518, Accuracy: 0.894000, Test accuracy: 0.887600
Distillation: Epoch : 7, Loss : 2.019255, Accuracy: 0.882000, Test accuracy: 0.890900
Distillation: Epoch : 8, Loss : 2.011515, Accuracy: 0.881000, Test accuracy: 0.893700
Distillation: Epoch : 9, Loss : 2.010740, Accuracy: 0.885000, Test accuracy: 0.897700
Distillation: Epoch : 10, Loss : 1.996889, Accuracy: 0.907000, Test accuracy: 0.901400
Distillation: Epoch : 11, Loss : 2.013539, Accuracy: 0.896000, Test accuracy: 0.904000
Distillation: Epoch : 12, Loss : 2.009367, Accuracy: 0.905000, Test accuracy: 0.908400
Distillation: Epoch : 13, Loss : 2.002874, Accuracy: 0.900000, Test accuracy: 0.913100
Distillation: Epoch : 14, Loss : 1.999546, Accuracy: 0.913000, Test accuracy: 0.916300
Distillation: Epoch : 15, Loss : 1.998185, Accuracy: 0.902000, Test accuracy: 0.919500
Distillation: Epoch : 16, Loss : 2.003720, Accuracy: 0.906000, Test accuracy: 0.921800
Distillation: Epoch : 17, Loss : 1.993182, Accuracy: 0.909000, Test accuracy: 0.923300
Distillation: Epoch : 18, Loss : 1.997826, Accuracy: 0.904000, Test accuracy: 0.926300
Distillation: Epoch : 19, Loss : 1.991147, Accuracy: 0.910000, Test accuracy: 0.928300
Distillation: Epoch : 20, Loss : 1.980499, Accuracy: 0.933000, Test accuracy: 0.929600
Distillation: Epoch : 21, Loss : 1.977556, Accuracy: 0.922000, Test accuracy: 0.931600
Distillation: Epoch : 22, Loss : 1.986501, Accuracy: 0.928000, Test accuracy: 0.934700
Distillation: Epoch : 23, Loss : 1.985371, Accuracy: 0.926000, Test accuracy: 0.935700
Distillation: Epoch : 24, Loss : 1.988261, Accuracy: 0.935000, Test accuracy: 0.937200
Distillation: Epoch : 25, Loss : 1.979342, Accuracy: 0.940000, Test accuracy: 0.940300
Distillation: Epoch : 26, Loss : 1.982824, Accuracy: 0.936000, Test accuracy: 0.938800
Distillation: Epoch : 27, Loss : 1.984139, Accuracy: 0.931000, Test accuracy: 0.940500
Distillation: Epoch : 28, Loss : 1.991567, Accuracy: 0.939000, Test accuracy: 0.941100
Distillation: Epoch : 29, Loss : 1.976736, Accuracy: 0.935000, Test accuracy: 0.941700
Distillation: Epoch : 30, Loss : 1.988860, Accuracy: 0.947000, Test accuracy: 0.941900
Distillation: Epoch : 31, Loss : 1.986372, Accuracy: 0.931000, Test accuracy: 0.943200
Distillation: Epoch : 32, Loss : 1.986801, Accuracy: 0.937000, Test accuracy: 0.944100
Distillation: Epoch : 33, Loss : 1.971929, Accuracy: 0.951000, Test accuracy: 0.945600
Distillation: Epoch : 34, Loss : 1.985439, Accuracy: 0.939000, Test accuracy: 0.946000
Distillation: Epoch : 35, Loss : 1.982672, Accuracy: 0.935000, Test accuracy: 0.946800
Distillation: Epoch : 36, Loss : 1.973878, Accuracy: 0.937000, Test accuracy: 0.947500
Distillation: Epoch : 37, Loss : 1.981719, Accuracy: 0.928000, Test accuracy: 0.946900
Distillation: Epoch : 38, Loss : 1.976586, Accuracy: 0.943000, Test accuracy: 0.948000
Distillation: Epoch : 39, Loss : 1.986989, Accuracy: 0.938000, Test accuracy: 0.948100
Distillation: Epoch : 40, Loss : 1.980238, Accuracy: 0.939000, Test accuracy: 0.948700
Distillation: Epoch : 41, Loss : 1.973615, Accuracy: 0.941000, Test accuracy: 0.948400
Distillation: Epoch : 42, Loss : 1.973957, Accuracy: 0.948000, Test accuracy: 0.950500
Distillation: Epoch : 43, Loss : 1.983736, Accuracy: 0.925000, Test accuracy: 0.949600
Distillation: Epoch : 44, Loss : 1.989104, Accuracy: 0.916000, Test accuracy: 0.949200
Distillation: Epoch : 45, Loss : 1.976350, Accuracy: 0.951000, Test accuracy: 0.949600
Distillation: Epoch : 46, Loss : 1.966411, Accuracy: 0.951000, Test accuracy: 0.950300
Distillation: Epoch : 47, Loss : 1.975018, Accuracy: 0.951000, Test accuracy: 0.951500
Distillation: Epoch : 48, Loss : 1.979428, Accuracy: 0.950000, Test accuracy: 0.951000
Distillation: Epoch : 49, Loss : 1.980604, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 50, Loss : 1.977800, Accuracy: 0.951000, Test accuracy: 0.950400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9504
Generating confusion matrix for student4
[[ 970.    0.    6.    0.    2.    3.   11.    2.   11.    7.]
 [   1. 1113.   18.    3.    2.    1.    5.    8.   19.    7.]
 [   1.    4.  947.    3.    1.    0.    1.   16.    8.    0.]
 [   0.    0.   18.  974.    0.   11.    0.    2.    7.    6.]
 [   0.    2.   13.    1.  962.    1.    3.   10.   14.   40.]
 [   0.    0.    1.   11.    0.  854.    9.    0.    9.    3.]
 [   7.    4.    5.    0.    3.    8.  926.    0.    9.    0.]
 [   1.    1.   16.   10.    0.    3.    0.  955.   12.   14.]
 [   0.   11.    7.    5.    3.    3.    3.    0.  871.    0.]
 [   0.    0.    1.    3.    9.    8.    0.   35.   14.  932.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.841272, Accuracy: 0.786000, Test accuracy: 0.786000
Distillation: Epoch : 2, Loss : 0.553137, Accuracy: 0.838000, Test accuracy: 0.875600
Distillation: Epoch : 3, Loss : 0.399327, Accuracy: 0.882000, Test accuracy: 0.890600
Distillation: Epoch : 4, Loss : 0.357850, Accuracy: 0.895000, Test accuracy: 0.897700
Distillation: Epoch : 5, Loss : 0.378797, Accuracy: 0.889000, Test accuracy: 0.902000
Distillation: Epoch : 6, Loss : 0.371684, Accuracy: 0.900000, Test accuracy: 0.905300
Distillation: Epoch : 7, Loss : 0.317358, Accuracy: 0.918000, Test accuracy: 0.907000
Distillation: Epoch : 8, Loss : 0.272884, Accuracy: 0.906000, Test accuracy: 0.909600
Distillation: Epoch : 9, Loss : 0.363774, Accuracy: 0.899000, Test accuracy: 0.911200
Distillation: Epoch : 10, Loss : 0.304414, Accuracy: 0.906000, Test accuracy: 0.915100
Distillation: Epoch : 11, Loss : 0.303031, Accuracy: 0.899000, Test accuracy: 0.916100
Distillation: Epoch : 12, Loss : 0.277216, Accuracy: 0.920000, Test accuracy: 0.917300
Distillation: Epoch : 13, Loss : 0.274210, Accuracy: 0.910000, Test accuracy: 0.918500
Distillation: Epoch : 14, Loss : 0.309413, Accuracy: 0.913000, Test accuracy: 0.920000
Distillation: Epoch : 15, Loss : 0.256987, Accuracy: 0.931000, Test accuracy: 0.921700
Distillation: Epoch : 16, Loss : 0.256116, Accuracy: 0.922000, Test accuracy: 0.922100
Distillation: Epoch : 17, Loss : 0.268700, Accuracy: 0.914000, Test accuracy: 0.922700
Distillation: Epoch : 18, Loss : 0.269406, Accuracy: 0.925000, Test accuracy: 0.925600
Distillation: Epoch : 19, Loss : 0.297240, Accuracy: 0.920000, Test accuracy: 0.927700
Distillation: Epoch : 20, Loss : 0.282268, Accuracy: 0.916000, Test accuracy: 0.928400
Distillation: Epoch : 21, Loss : 0.271905, Accuracy: 0.923000, Test accuracy: 0.930700
Distillation: Epoch : 22, Loss : 0.213192, Accuracy: 0.935000, Test accuracy: 0.930700
Distillation: Epoch : 23, Loss : 0.233584, Accuracy: 0.936000, Test accuracy: 0.931700
Distillation: Epoch : 24, Loss : 0.263871, Accuracy: 0.923000, Test accuracy: 0.934100
Distillation: Epoch : 25, Loss : 0.218369, Accuracy: 0.943000, Test accuracy: 0.935300
Distillation: Epoch : 26, Loss : 0.246350, Accuracy: 0.929000, Test accuracy: 0.937000
Distillation: Epoch : 27, Loss : 0.217702, Accuracy: 0.942000, Test accuracy: 0.936800
Distillation: Epoch : 28, Loss : 0.197815, Accuracy: 0.945000, Test accuracy: 0.937000
Distillation: Epoch : 29, Loss : 0.250770, Accuracy: 0.931000, Test accuracy: 0.938100
Distillation: Epoch : 30, Loss : 0.188220, Accuracy: 0.944000, Test accuracy: 0.939100
Distillation: Epoch : 31, Loss : 0.224673, Accuracy: 0.936000, Test accuracy: 0.940000
Distillation: Epoch : 32, Loss : 0.224983, Accuracy: 0.935000, Test accuracy: 0.941600
Distillation: Epoch : 33, Loss : 0.182683, Accuracy: 0.943000, Test accuracy: 0.942300
Distillation: Epoch : 34, Loss : 0.234620, Accuracy: 0.931000, Test accuracy: 0.942700
Distillation: Epoch : 35, Loss : 0.194066, Accuracy: 0.948000, Test accuracy: 0.942700
Distillation: Epoch : 36, Loss : 0.194562, Accuracy: 0.947000, Test accuracy: 0.942600
Distillation: Epoch : 37, Loss : 0.189674, Accuracy: 0.946000, Test accuracy: 0.943600
Distillation: Epoch : 38, Loss : 0.183628, Accuracy: 0.952000, Test accuracy: 0.944000
Distillation: Epoch : 39, Loss : 0.180011, Accuracy: 0.953000, Test accuracy: 0.943400
Distillation: Epoch : 40, Loss : 0.167591, Accuracy: 0.948000, Test accuracy: 0.945000
Distillation: Epoch : 41, Loss : 0.211401, Accuracy: 0.933000, Test accuracy: 0.944700
Distillation: Epoch : 42, Loss : 0.192465, Accuracy: 0.940000, Test accuracy: 0.946600
Distillation: Epoch : 43, Loss : 0.172967, Accuracy: 0.955000, Test accuracy: 0.947200
Distillation: Epoch : 44, Loss : 0.227928, Accuracy: 0.943000, Test accuracy: 0.945800
Distillation: Epoch : 45, Loss : 0.171117, Accuracy: 0.946000, Test accuracy: 0.944000
Distillation: Epoch : 46, Loss : 0.170017, Accuracy: 0.949000, Test accuracy: 0.946400
Distillation: Epoch : 47, Loss : 0.154982, Accuracy: 0.954000, Test accuracy: 0.945900
Distillation: Epoch : 48, Loss : 0.155209, Accuracy: 0.952000, Test accuracy: 0.946500
Distillation: Epoch : 49, Loss : 0.169737, Accuracy: 0.949000, Test accuracy: 0.948700
Distillation: Epoch : 50, Loss : 0.188440, Accuracy: 0.940000, Test accuracy: 0.947900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9479
Generating confusion matrix for student5
[[ 966.    0.    5.    1.    1.    8.    9.    1.    8.    9.]
 [   0. 1121.    4.    0.    0.    3.    2.    6.    3.    7.]
 [   2.    3.  970.   12.    8.    2.    2.   17.    6.    1.]
 [   1.    2.    7.  952.    1.   17.    1.    9.   14.   11.]
 [   0.    1.   13.    0.  918.    4.    8.    5.    6.   13.]
 [   7.    1.    0.   11.    1.  815.    9.    2.   10.    5.]
 [   0.    0.    5.    1.    9.   11.  921.    0.    7.    0.]
 [   3.    1.    6.    8.    2.    4.    3.  957.    4.    6.]
 [   1.    6.   16.   16.    6.   25.    3.    1.  907.    5.]
 [   0.    0.    6.    9.   36.    3.    0.   30.    9.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.856623, Accuracy: 0.702000, Test accuracy: 0.690100
Distillation: Epoch : 2, Loss : 0.865706, Accuracy: 0.815000, Test accuracy: 0.815900
Distillation: Epoch : 3, Loss : 0.550471, Accuracy: 0.849000, Test accuracy: 0.854800
Distillation: Epoch : 4, Loss : 0.472116, Accuracy: 0.865000, Test accuracy: 0.875000
Distillation: Epoch : 5, Loss : 0.422261, Accuracy: 0.868000, Test accuracy: 0.889900
Distillation: Epoch : 6, Loss : 0.386063, Accuracy: 0.888000, Test accuracy: 0.897400
Distillation: Epoch : 7, Loss : 0.351518, Accuracy: 0.898000, Test accuracy: 0.903300
Distillation: Epoch : 8, Loss : 0.373761, Accuracy: 0.892000, Test accuracy: 0.909600
Distillation: Epoch : 9, Loss : 0.364348, Accuracy: 0.898000, Test accuracy: 0.910900
Distillation: Epoch : 10, Loss : 0.333206, Accuracy: 0.907000, Test accuracy: 0.914200
Distillation: Epoch : 11, Loss : 0.330653, Accuracy: 0.898000, Test accuracy: 0.918600
Distillation: Epoch : 12, Loss : 0.345460, Accuracy: 0.918000, Test accuracy: 0.919700
Distillation: Epoch : 13, Loss : 0.320092, Accuracy: 0.900000, Test accuracy: 0.921400
Distillation: Epoch : 14, Loss : 0.295185, Accuracy: 0.910000, Test accuracy: 0.923800
Distillation: Epoch : 15, Loss : 0.317258, Accuracy: 0.914000, Test accuracy: 0.923700
Distillation: Epoch : 16, Loss : 0.245294, Accuracy: 0.925000, Test accuracy: 0.927700
Distillation: Epoch : 17, Loss : 0.265471, Accuracy: 0.920000, Test accuracy: 0.929000
Distillation: Epoch : 18, Loss : 0.241216, Accuracy: 0.935000, Test accuracy: 0.932000
Distillation: Epoch : 19, Loss : 0.267729, Accuracy: 0.920000, Test accuracy: 0.932600
Distillation: Epoch : 20, Loss : 0.223138, Accuracy: 0.937000, Test accuracy: 0.934600
Distillation: Epoch : 21, Loss : 0.256179, Accuracy: 0.930000, Test accuracy: 0.934300
Distillation: Epoch : 22, Loss : 0.240293, Accuracy: 0.939000, Test accuracy: 0.937200
Distillation: Epoch : 23, Loss : 0.248204, Accuracy: 0.925000, Test accuracy: 0.938500
Distillation: Epoch : 24, Loss : 0.245748, Accuracy: 0.927000, Test accuracy: 0.939400
Distillation: Epoch : 25, Loss : 0.232664, Accuracy: 0.939000, Test accuracy: 0.941200
Distillation: Epoch : 26, Loss : 0.209133, Accuracy: 0.943000, Test accuracy: 0.943000
Distillation: Epoch : 27, Loss : 0.198944, Accuracy: 0.949000, Test accuracy: 0.944400
Distillation: Epoch : 28, Loss : 0.203713, Accuracy: 0.941000, Test accuracy: 0.944200
Distillation: Epoch : 29, Loss : 0.216576, Accuracy: 0.941000, Test accuracy: 0.946400
Distillation: Epoch : 30, Loss : 0.240858, Accuracy: 0.937000, Test accuracy: 0.947500
Distillation: Epoch : 31, Loss : 0.180635, Accuracy: 0.951000, Test accuracy: 0.946200
Distillation: Epoch : 32, Loss : 0.187325, Accuracy: 0.946000, Test accuracy: 0.949300
Distillation: Epoch : 33, Loss : 0.193573, Accuracy: 0.939000, Test accuracy: 0.949400
Distillation: Epoch : 34, Loss : 0.214692, Accuracy: 0.939000, Test accuracy: 0.950500
Distillation: Epoch : 35, Loss : 0.177087, Accuracy: 0.958000, Test accuracy: 0.952200
Distillation: Epoch : 36, Loss : 0.196604, Accuracy: 0.949000, Test accuracy: 0.952100
Distillation: Epoch : 37, Loss : 0.221193, Accuracy: 0.946000, Test accuracy: 0.952100
Distillation: Epoch : 38, Loss : 0.181227, Accuracy: 0.947000, Test accuracy: 0.953600
Distillation: Epoch : 39, Loss : 0.165982, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 40, Loss : 0.159581, Accuracy: 0.952000, Test accuracy: 0.955500
Distillation: Epoch : 41, Loss : 0.186022, Accuracy: 0.953000, Test accuracy: 0.955900
Distillation: Epoch : 42, Loss : 0.195495, Accuracy: 0.953000, Test accuracy: 0.954700
Distillation: Epoch : 43, Loss : 0.197946, Accuracy: 0.945000, Test accuracy: 0.956900
Distillation: Epoch : 44, Loss : 0.167963, Accuracy: 0.952000, Test accuracy: 0.956400
Distillation: Epoch : 45, Loss : 0.162786, Accuracy: 0.950000, Test accuracy: 0.957600
Distillation: Epoch : 46, Loss : 0.154748, Accuracy: 0.958000, Test accuracy: 0.957500
Distillation: Epoch : 47, Loss : 0.192967, Accuracy: 0.955000, Test accuracy: 0.958500
Distillation: Epoch : 48, Loss : 0.168309, Accuracy: 0.959000, Test accuracy: 0.959100
Distillation: Epoch : 49, Loss : 0.149143, Accuracy: 0.957000, Test accuracy: 0.957900
Distillation: Epoch : 50, Loss : 0.145695, Accuracy: 0.962000, Test accuracy: 0.959400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9594
Generating confusion matrix for student5
[[ 964.    0.    4.    2.    1.    2.    9.    1.    2.    6.]
 [   1. 1116.    4.    0.    0.    3.    2.    4.    1.    5.]
 [   2.    3.  989.    8.    3.    2.    0.   13.    3.    1.]
 [   1.    0.    7.  951.    6.   20.    0.   11.   11.   10.]
 [   0.    0.    3.    1.  949.    3.    2.    3.   10.   14.]
 [   1.    1.    1.   16.    1.  840.    3.    1.    4.    2.]
 [   6.    4.    3.    1.    9.    5.  933.    0.    3.    0.]
 [   1.    0.   12.   10.    2.    1.    2.  980.    8.   11.]
 [   2.   11.    9.   18.    3.   14.    7.    5.  923.   11.]
 [   2.    0.    0.    3.    8.    2.    0.   10.    9.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.486665, Accuracy: 0.710000, Test accuracy: 0.743100
Distillation: Epoch : 2, Loss : 0.785890, Accuracy: 0.827000, Test accuracy: 0.848100
Distillation: Epoch : 3, Loss : 0.671836, Accuracy: 0.863000, Test accuracy: 0.876100
Distillation: Epoch : 4, Loss : 0.650535, Accuracy: 0.891000, Test accuracy: 0.887400
Distillation: Epoch : 5, Loss : 0.622753, Accuracy: 0.895000, Test accuracy: 0.895900
Distillation: Epoch : 6, Loss : 0.589602, Accuracy: 0.894000, Test accuracy: 0.899900
Distillation: Epoch : 7, Loss : 0.635168, Accuracy: 0.896000, Test accuracy: 0.902200
Distillation: Epoch : 8, Loss : 0.570717, Accuracy: 0.913000, Test accuracy: 0.904600
Distillation: Epoch : 9, Loss : 0.614631, Accuracy: 0.892000, Test accuracy: 0.906700
Distillation: Epoch : 10, Loss : 0.624455, Accuracy: 0.886000, Test accuracy: 0.908800
Distillation: Epoch : 11, Loss : 0.596028, Accuracy: 0.907000, Test accuracy: 0.910000
Distillation: Epoch : 12, Loss : 0.595585, Accuracy: 0.913000, Test accuracy: 0.911700
Distillation: Epoch : 13, Loss : 0.581901, Accuracy: 0.913000, Test accuracy: 0.912300
Distillation: Epoch : 14, Loss : 0.589110, Accuracy: 0.913000, Test accuracy: 0.914100
Distillation: Epoch : 15, Loss : 0.575138, Accuracy: 0.906000, Test accuracy: 0.916100
Distillation: Epoch : 16, Loss : 0.628604, Accuracy: 0.897000, Test accuracy: 0.914600
Distillation: Epoch : 17, Loss : 0.586709, Accuracy: 0.915000, Test accuracy: 0.916700
Distillation: Epoch : 18, Loss : 0.603715, Accuracy: 0.895000, Test accuracy: 0.916300
Distillation: Epoch : 19, Loss : 0.621165, Accuracy: 0.899000, Test accuracy: 0.918300
Distillation: Epoch : 20, Loss : 0.563321, Accuracy: 0.912000, Test accuracy: 0.917800
Distillation: Epoch : 21, Loss : 0.574108, Accuracy: 0.904000, Test accuracy: 0.918400
Distillation: Epoch : 22, Loss : 0.610859, Accuracy: 0.898000, Test accuracy: 0.919100
Distillation: Epoch : 23, Loss : 0.559336, Accuracy: 0.917000, Test accuracy: 0.919500
Distillation: Epoch : 24, Loss : 0.564755, Accuracy: 0.908000, Test accuracy: 0.918800
Distillation: Epoch : 25, Loss : 0.573042, Accuracy: 0.915000, Test accuracy: 0.919900
Distillation: Epoch : 26, Loss : 0.543939, Accuracy: 0.945000, Test accuracy: 0.920900
Distillation: Epoch : 27, Loss : 0.527551, Accuracy: 0.934000, Test accuracy: 0.920700
Distillation: Epoch : 28, Loss : 0.564679, Accuracy: 0.907000, Test accuracy: 0.922100
Distillation: Epoch : 29, Loss : 0.603298, Accuracy: 0.909000, Test accuracy: 0.923100
Distillation: Epoch : 30, Loss : 0.551451, Accuracy: 0.920000, Test accuracy: 0.922300
Distillation: Epoch : 31, Loss : 0.575839, Accuracy: 0.914000, Test accuracy: 0.923500
Distillation: Epoch : 32, Loss : 0.543515, Accuracy: 0.929000, Test accuracy: 0.923300
Distillation: Epoch : 33, Loss : 0.554626, Accuracy: 0.920000, Test accuracy: 0.924600
Distillation: Epoch : 34, Loss : 0.563687, Accuracy: 0.915000, Test accuracy: 0.925000
Distillation: Epoch : 35, Loss : 0.549115, Accuracy: 0.921000, Test accuracy: 0.924600
Distillation: Epoch : 36, Loss : 0.536618, Accuracy: 0.926000, Test accuracy: 0.925600
Distillation: Epoch : 37, Loss : 0.553336, Accuracy: 0.929000, Test accuracy: 0.926100
Distillation: Epoch : 38, Loss : 0.581501, Accuracy: 0.909000, Test accuracy: 0.926600
Distillation: Epoch : 39, Loss : 0.551681, Accuracy: 0.926000, Test accuracy: 0.927200
Distillation: Epoch : 40, Loss : 0.547124, Accuracy: 0.920000, Test accuracy: 0.927600
Distillation: Epoch : 41, Loss : 0.515940, Accuracy: 0.940000, Test accuracy: 0.928500
Distillation: Epoch : 42, Loss : 0.609278, Accuracy: 0.907000, Test accuracy: 0.928200
Distillation: Epoch : 43, Loss : 0.534162, Accuracy: 0.941000, Test accuracy: 0.929700
Distillation: Epoch : 44, Loss : 0.500174, Accuracy: 0.935000, Test accuracy: 0.929800
Distillation: Epoch : 45, Loss : 0.545435, Accuracy: 0.929000, Test accuracy: 0.930200
Distillation: Epoch : 46, Loss : 0.540465, Accuracy: 0.928000, Test accuracy: 0.930500
Distillation: Epoch : 47, Loss : 0.549672, Accuracy: 0.923000, Test accuracy: 0.931100
Distillation: Epoch : 48, Loss : 0.541163, Accuracy: 0.922000, Test accuracy: 0.930600
Distillation: Epoch : 49, Loss : 0.563091, Accuracy: 0.933000, Test accuracy: 0.932000
Distillation: Epoch : 50, Loss : 0.528987, Accuracy: 0.932000, Test accuracy: 0.932700
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9327
Generating confusion matrix for student5
[[ 962.    0.   11.    5.    1.   10.    9.    2.    8.   10.]
 [   0. 1118.    8.    4.    1.    3.    3.   12.    5.    5.]
 [   0.    3.  933.   15.    6.    3.    4.   19.    7.    0.]
 [   1.    1.   15.  924.    1.   26.    0.    6.   17.    9.]
 [   1.    1.    9.    0.  937.    9.    9.    8.   12.   30.]
 [   4.    1.    1.   23.    0.  794.   15.    0.   25.    7.]
 [   8.    4.    8.    3.    8.   11.  913.    0.    7.    1.]
 [   2.    0.   16.   13.    2.    4.    3.  956.   13.   22.]
 [   2.    7.   25.   18.    5.   23.    2.    2.  873.    8.]
 [   0.    0.    6.    5.   21.    9.    0.   23.    7.  917.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.942896, Accuracy: 0.593000, Test accuracy: 0.602300
Distillation: Epoch : 2, Loss : 1.082808, Accuracy: 0.796000, Test accuracy: 0.791300
Distillation: Epoch : 3, Loss : 0.916074, Accuracy: 0.838000, Test accuracy: 0.844300
Distillation: Epoch : 4, Loss : 0.873973, Accuracy: 0.853000, Test accuracy: 0.866300
Distillation: Epoch : 5, Loss : 0.792281, Accuracy: 0.881000, Test accuracy: 0.882100
Distillation: Epoch : 6, Loss : 0.771948, Accuracy: 0.884000, Test accuracy: 0.891900
Distillation: Epoch : 7, Loss : 0.726058, Accuracy: 0.917000, Test accuracy: 0.899700
Distillation: Epoch : 8, Loss : 0.749640, Accuracy: 0.900000, Test accuracy: 0.905000
Distillation: Epoch : 9, Loss : 0.787334, Accuracy: 0.909000, Test accuracy: 0.910200
Distillation: Epoch : 10, Loss : 0.742490, Accuracy: 0.915000, Test accuracy: 0.916800
Distillation: Epoch : 11, Loss : 0.707361, Accuracy: 0.920000, Test accuracy: 0.918300
Distillation: Epoch : 12, Loss : 0.699698, Accuracy: 0.926000, Test accuracy: 0.924400
Distillation: Epoch : 13, Loss : 0.727689, Accuracy: 0.916000, Test accuracy: 0.926300
Distillation: Epoch : 14, Loss : 0.724510, Accuracy: 0.917000, Test accuracy: 0.929000
Distillation: Epoch : 15, Loss : 0.696995, Accuracy: 0.928000, Test accuracy: 0.932700
Distillation: Epoch : 16, Loss : 0.712814, Accuracy: 0.932000, Test accuracy: 0.933800
Distillation: Epoch : 17, Loss : 0.709390, Accuracy: 0.916000, Test accuracy: 0.936200
Distillation: Epoch : 18, Loss : 0.679283, Accuracy: 0.931000, Test accuracy: 0.938100
Distillation: Epoch : 19, Loss : 0.677905, Accuracy: 0.931000, Test accuracy: 0.938500
Distillation: Epoch : 20, Loss : 0.663274, Accuracy: 0.933000, Test accuracy: 0.940100
Distillation: Epoch : 21, Loss : 0.619578, Accuracy: 0.954000, Test accuracy: 0.941200
Distillation: Epoch : 22, Loss : 0.640828, Accuracy: 0.946000, Test accuracy: 0.941800
Distillation: Epoch : 23, Loss : 0.681710, Accuracy: 0.933000, Test accuracy: 0.942500
Distillation: Epoch : 24, Loss : 0.673560, Accuracy: 0.939000, Test accuracy: 0.944800
Distillation: Epoch : 25, Loss : 0.631648, Accuracy: 0.950000, Test accuracy: 0.945100
Distillation: Epoch : 26, Loss : 0.638514, Accuracy: 0.949000, Test accuracy: 0.945900
Distillation: Epoch : 27, Loss : 0.640609, Accuracy: 0.943000, Test accuracy: 0.947500
Distillation: Epoch : 28, Loss : 0.660905, Accuracy: 0.938000, Test accuracy: 0.947400
Distillation: Epoch : 29, Loss : 0.664866, Accuracy: 0.936000, Test accuracy: 0.949000
Distillation: Epoch : 30, Loss : 0.653838, Accuracy: 0.943000, Test accuracy: 0.949100
Distillation: Epoch : 31, Loss : 0.630457, Accuracy: 0.951000, Test accuracy: 0.950700
Distillation: Epoch : 32, Loss : 0.662799, Accuracy: 0.933000, Test accuracy: 0.951000
Distillation: Epoch : 33, Loss : 0.623579, Accuracy: 0.951000, Test accuracy: 0.951000
Distillation: Epoch : 34, Loss : 0.635824, Accuracy: 0.955000, Test accuracy: 0.952600
Distillation: Epoch : 35, Loss : 0.637919, Accuracy: 0.950000, Test accuracy: 0.953700
Distillation: Epoch : 36, Loss : 0.631830, Accuracy: 0.942000, Test accuracy: 0.954100
Distillation: Epoch : 37, Loss : 0.648343, Accuracy: 0.936000, Test accuracy: 0.953800
Distillation: Epoch : 38, Loss : 0.597802, Accuracy: 0.959000, Test accuracy: 0.954900
Distillation: Epoch : 39, Loss : 0.666196, Accuracy: 0.942000, Test accuracy: 0.955400
Distillation: Epoch : 40, Loss : 0.635246, Accuracy: 0.951000, Test accuracy: 0.955700
Distillation: Epoch : 41, Loss : 0.613763, Accuracy: 0.968000, Test accuracy: 0.957200
Distillation: Epoch : 42, Loss : 0.630595, Accuracy: 0.949000, Test accuracy: 0.956800
Distillation: Epoch : 43, Loss : 0.640817, Accuracy: 0.944000, Test accuracy: 0.957500
Distillation: Epoch : 44, Loss : 0.605800, Accuracy: 0.957000, Test accuracy: 0.957900
Distillation: Epoch : 45, Loss : 0.622021, Accuracy: 0.956000, Test accuracy: 0.958700
Distillation: Epoch : 46, Loss : 0.592274, Accuracy: 0.953000, Test accuracy: 0.959100
Distillation: Epoch : 47, Loss : 0.647894, Accuracy: 0.946000, Test accuracy: 0.958300
Distillation: Epoch : 48, Loss : 0.616783, Accuracy: 0.967000, Test accuracy: 0.959000
Distillation: Epoch : 49, Loss : 0.602927, Accuracy: 0.956000, Test accuracy: 0.958800
Distillation: Epoch : 50, Loss : 0.622189, Accuracy: 0.954000, Test accuracy: 0.958800
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9588
Generating confusion matrix for student5
[[ 973.    0.    6.    0.    1.    2.    8.    3.    7.    4.]
 [   0. 1118.    9.    1.    2.    1.    3.    8.    6.    7.]
 [   1.    4.  968.   10.    2.    0.    2.   14.    4.    1.]
 [   0.    1.    9.  963.    0.   11.    1.    3.    6.    7.]
 [   1.    0.   11.    1.  951.    2.    4.    4.    9.   20.]
 [   0.    0.    0.   12.    0.  855.    5.    0.    4.    4.]
 [   3.    3.    5.    0.    4.    7.  933.    0.    8.    1.]
 [   1.    1.   14.    9.    3.    3.    0.  971.    8.   13.]
 [   1.    8.    9.    8.    2.    3.    2.    2.  906.    2.]
 [   0.    0.    1.    6.   17.    8.    0.   23.   16.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.155943, Accuracy: 0.599000, Test accuracy: 0.608200
Distillation: Epoch : 2, Loss : 1.180527, Accuracy: 0.814000, Test accuracy: 0.826400
Distillation: Epoch : 3, Loss : 0.990376, Accuracy: 0.867000, Test accuracy: 0.868200
Distillation: Epoch : 4, Loss : 0.990395, Accuracy: 0.881000, Test accuracy: 0.883100
Distillation: Epoch : 5, Loss : 0.934597, Accuracy: 0.896000, Test accuracy: 0.892800
Distillation: Epoch : 6, Loss : 0.976987, Accuracy: 0.889000, Test accuracy: 0.896500
Distillation: Epoch : 7, Loss : 0.927420, Accuracy: 0.905000, Test accuracy: 0.904100
Distillation: Epoch : 8, Loss : 0.935486, Accuracy: 0.881000, Test accuracy: 0.907100
Distillation: Epoch : 9, Loss : 0.886645, Accuracy: 0.924000, Test accuracy: 0.911200
Distillation: Epoch : 10, Loss : 0.915123, Accuracy: 0.903000, Test accuracy: 0.915700
Distillation: Epoch : 11, Loss : 0.865483, Accuracy: 0.929000, Test accuracy: 0.919000
Distillation: Epoch : 12, Loss : 0.890856, Accuracy: 0.911000, Test accuracy: 0.924100
Distillation: Epoch : 13, Loss : 0.869302, Accuracy: 0.915000, Test accuracy: 0.926600
Distillation: Epoch : 14, Loss : 0.861058, Accuracy: 0.926000, Test accuracy: 0.931000
Distillation: Epoch : 15, Loss : 0.828421, Accuracy: 0.938000, Test accuracy: 0.935300
Distillation: Epoch : 16, Loss : 0.825026, Accuracy: 0.930000, Test accuracy: 0.937300
Distillation: Epoch : 17, Loss : 0.808987, Accuracy: 0.943000, Test accuracy: 0.938700
Distillation: Epoch : 18, Loss : 0.834264, Accuracy: 0.937000, Test accuracy: 0.941200
Distillation: Epoch : 19, Loss : 0.828231, Accuracy: 0.933000, Test accuracy: 0.943700
Distillation: Epoch : 20, Loss : 0.825726, Accuracy: 0.947000, Test accuracy: 0.946400
Distillation: Epoch : 21, Loss : 0.832237, Accuracy: 0.939000, Test accuracy: 0.946300
Distillation: Epoch : 22, Loss : 0.783723, Accuracy: 0.949000, Test accuracy: 0.948400
Distillation: Epoch : 23, Loss : 0.793912, Accuracy: 0.953000, Test accuracy: 0.949400
Distillation: Epoch : 24, Loss : 0.758725, Accuracy: 0.952000, Test accuracy: 0.951200
Distillation: Epoch : 25, Loss : 0.774502, Accuracy: 0.952000, Test accuracy: 0.951400
Distillation: Epoch : 26, Loss : 0.811114, Accuracy: 0.956000, Test accuracy: 0.952100
Distillation: Epoch : 27, Loss : 0.798471, Accuracy: 0.943000, Test accuracy: 0.953100
Distillation: Epoch : 28, Loss : 0.791364, Accuracy: 0.940000, Test accuracy: 0.954500
Distillation: Epoch : 29, Loss : 0.781253, Accuracy: 0.956000, Test accuracy: 0.954900
Distillation: Epoch : 30, Loss : 0.789714, Accuracy: 0.950000, Test accuracy: 0.955500
Distillation: Epoch : 31, Loss : 0.796511, Accuracy: 0.942000, Test accuracy: 0.955700
Distillation: Epoch : 32, Loss : 0.802763, Accuracy: 0.954000, Test accuracy: 0.956000
Distillation: Epoch : 33, Loss : 0.774182, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 34, Loss : 0.781891, Accuracy: 0.960000, Test accuracy: 0.957000
Distillation: Epoch : 35, Loss : 0.799727, Accuracy: 0.950000, Test accuracy: 0.957700
Distillation: Epoch : 36, Loss : 0.808998, Accuracy: 0.948000, Test accuracy: 0.958400
Distillation: Epoch : 37, Loss : 0.793103, Accuracy: 0.961000, Test accuracy: 0.958300
Distillation: Epoch : 38, Loss : 0.782053, Accuracy: 0.961000, Test accuracy: 0.957600
Distillation: Epoch : 39, Loss : 0.807816, Accuracy: 0.942000, Test accuracy: 0.959300
Distillation: Epoch : 40, Loss : 0.778515, Accuracy: 0.941000, Test accuracy: 0.959600
Distillation: Epoch : 41, Loss : 0.774774, Accuracy: 0.956000, Test accuracy: 0.959700
Distillation: Epoch : 42, Loss : 0.784841, Accuracy: 0.951000, Test accuracy: 0.959100
Distillation: Epoch : 43, Loss : 0.759645, Accuracy: 0.966000, Test accuracy: 0.959400
Distillation: Epoch : 44, Loss : 0.770655, Accuracy: 0.959000, Test accuracy: 0.960300
Distillation: Epoch : 45, Loss : 0.789004, Accuracy: 0.956000, Test accuracy: 0.959900
Distillation: Epoch : 46, Loss : 0.744638, Accuracy: 0.961000, Test accuracy: 0.959900
Distillation: Epoch : 47, Loss : 0.759211, Accuracy: 0.962000, Test accuracy: 0.959800
Distillation: Epoch : 48, Loss : 0.762061, Accuracy: 0.960000, Test accuracy: 0.959900
Distillation: Epoch : 49, Loss : 0.787020, Accuracy: 0.953000, Test accuracy: 0.961100
Distillation: Epoch : 50, Loss : 0.792998, Accuracy: 0.951000, Test accuracy: 0.960400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9604
Generating confusion matrix for student5
[[ 968.    0.    3.    2.    1.    4.    7.    1.   10.    8.]
 [   0. 1118.    6.    1.    2.    0.    2.    3.    6.    6.]
 [   0.    3.  982.    7.    1.    1.    0.   10.   10.    1.]
 [   0.    0.    4.  963.    0.   13.    0.    3.   10.    5.]
 [   1.    2.    4.    3.  958.    1.    4.    1.    7.   13.]
 [   2.    0.    1.    8.    0.  847.   19.    1.   10.    6.]
 [   5.    4.    3.    0.    3.    5.  925.    0.    2.    0.]
 [   3.    2.   12.    8.    0.    1.    0.  988.    9.    9.]
 [   1.    6.   16.   15.    2.   14.    1.    1.  896.    2.]
 [   0.    0.    1.    3.   15.    6.    0.   20.   14.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.130966, Accuracy: 0.650000, Test accuracy: 0.662100
Distillation: Epoch : 2, Loss : 1.324324, Accuracy: 0.802000, Test accuracy: 0.817700
Distillation: Epoch : 3, Loss : 1.182885, Accuracy: 0.860000, Test accuracy: 0.864700
Distillation: Epoch : 4, Loss : 1.135427, Accuracy: 0.859000, Test accuracy: 0.880700
Distillation: Epoch : 5, Loss : 1.102217, Accuracy: 0.880000, Test accuracy: 0.892800
Distillation: Epoch : 6, Loss : 1.067537, Accuracy: 0.899000, Test accuracy: 0.899400
Distillation: Epoch : 7, Loss : 1.055466, Accuracy: 0.900000, Test accuracy: 0.904100
Distillation: Epoch : 8, Loss : 1.047740, Accuracy: 0.907000, Test accuracy: 0.908200
Distillation: Epoch : 9, Loss : 1.033939, Accuracy: 0.912000, Test accuracy: 0.913000
Distillation: Epoch : 10, Loss : 1.077253, Accuracy: 0.899000, Test accuracy: 0.918400
Distillation: Epoch : 11, Loss : 1.015336, Accuracy: 0.909000, Test accuracy: 0.923200
Distillation: Epoch : 12, Loss : 0.976045, Accuracy: 0.933000, Test accuracy: 0.927200
Distillation: Epoch : 13, Loss : 1.011022, Accuracy: 0.929000, Test accuracy: 0.931900
Distillation: Epoch : 14, Loss : 1.027751, Accuracy: 0.927000, Test accuracy: 0.935300
Distillation: Epoch : 15, Loss : 1.022938, Accuracy: 0.942000, Test accuracy: 0.938100
Distillation: Epoch : 16, Loss : 0.970623, Accuracy: 0.937000, Test accuracy: 0.940300
Distillation: Epoch : 17, Loss : 0.981645, Accuracy: 0.935000, Test accuracy: 0.942800
Distillation: Epoch : 18, Loss : 0.984196, Accuracy: 0.933000, Test accuracy: 0.946600
Distillation: Epoch : 19, Loss : 0.980110, Accuracy: 0.948000, Test accuracy: 0.947100
Distillation: Epoch : 20, Loss : 0.981820, Accuracy: 0.953000, Test accuracy: 0.948800
Distillation: Epoch : 21, Loss : 0.972403, Accuracy: 0.946000, Test accuracy: 0.950500
Distillation: Epoch : 22, Loss : 0.937038, Accuracy: 0.951000, Test accuracy: 0.952400
Distillation: Epoch : 23, Loss : 0.967322, Accuracy: 0.943000, Test accuracy: 0.953900
Distillation: Epoch : 24, Loss : 0.960249, Accuracy: 0.945000, Test accuracy: 0.955300
Distillation: Epoch : 25, Loss : 0.981443, Accuracy: 0.942000, Test accuracy: 0.956300
Distillation: Epoch : 26, Loss : 0.959257, Accuracy: 0.955000, Test accuracy: 0.956800
Distillation: Epoch : 27, Loss : 0.959804, Accuracy: 0.952000, Test accuracy: 0.957100
Distillation: Epoch : 28, Loss : 0.954976, Accuracy: 0.956000, Test accuracy: 0.958200
Distillation: Epoch : 29, Loss : 0.949206, Accuracy: 0.949000, Test accuracy: 0.958700
Distillation: Epoch : 30, Loss : 0.974199, Accuracy: 0.952000, Test accuracy: 0.958100
Distillation: Epoch : 31, Loss : 0.958208, Accuracy: 0.944000, Test accuracy: 0.959500
Distillation: Epoch : 32, Loss : 0.975812, Accuracy: 0.943000, Test accuracy: 0.960400
Distillation: Epoch : 33, Loss : 0.950959, Accuracy: 0.959000, Test accuracy: 0.960500
Distillation: Epoch : 34, Loss : 0.960895, Accuracy: 0.953000, Test accuracy: 0.959300
Distillation: Epoch : 35, Loss : 0.976295, Accuracy: 0.955000, Test accuracy: 0.959900
Distillation: Epoch : 36, Loss : 0.941213, Accuracy: 0.965000, Test accuracy: 0.961000
Distillation: Epoch : 37, Loss : 0.950250, Accuracy: 0.965000, Test accuracy: 0.961100
Distillation: Epoch : 38, Loss : 0.939493, Accuracy: 0.960000, Test accuracy: 0.961400
Distillation: Epoch : 39, Loss : 0.931321, Accuracy: 0.960000, Test accuracy: 0.961200
Distillation: Epoch : 40, Loss : 0.965783, Accuracy: 0.952000, Test accuracy: 0.961600
Distillation: Epoch : 41, Loss : 0.930181, Accuracy: 0.959000, Test accuracy: 0.961500
Distillation: Epoch : 42, Loss : 0.932516, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 43, Loss : 0.948657, Accuracy: 0.950000, Test accuracy: 0.962000
Distillation: Epoch : 44, Loss : 0.966669, Accuracy: 0.956000, Test accuracy: 0.962300
Distillation: Epoch : 45, Loss : 0.953264, Accuracy: 0.953000, Test accuracy: 0.962000
Distillation: Epoch : 46, Loss : 0.984660, Accuracy: 0.959000, Test accuracy: 0.962100
Distillation: Epoch : 47, Loss : 0.924920, Accuracy: 0.973000, Test accuracy: 0.962000
Distillation: Epoch : 48, Loss : 0.937766, Accuracy: 0.951000, Test accuracy: 0.962500
Distillation: Epoch : 49, Loss : 0.948484, Accuracy: 0.955000, Test accuracy: 0.962100
Distillation: Epoch : 50, Loss : 0.960608, Accuracy: 0.950000, Test accuracy: 0.962800
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9628
Generating confusion matrix for student5
[[ 970.    0.    7.    1.    2.    2.    9.    2.    8.    8.]
 [   1. 1121.    7.    0.    1.    0.    3.    1.    2.    6.]
 [   0.    3.  965.    7.    1.    0.    1.   13.   13.    0.]
 [   0.    1.    9.  972.    0.   10.    0.    4.    5.    5.]
 [   0.    1.    7.    1.  963.    2.    4.    5.    5.   10.]
 [   1.    0.    0.    9.    0.  851.   10.    1.    7.    8.]
 [   4.    3.    4.    0.    4.    6.  930.    0.    5.    0.]
 [   3.    1.   10.    8.    1.    2.    0.  986.    8.   15.]
 [   1.    5.   22.    7.    2.   13.    1.    3.  915.    2.]
 [   0.    0.    1.    5.    8.    6.    0.   13.    6.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.172225, Accuracy: 0.520000, Test accuracy: 0.494900
Distillation: Epoch : 2, Loss : 1.413981, Accuracy: 0.827000, Test accuracy: 0.837100
Distillation: Epoch : 3, Loss : 1.307378, Accuracy: 0.866000, Test accuracy: 0.874100
Distillation: Epoch : 4, Loss : 1.283919, Accuracy: 0.869000, Test accuracy: 0.891800
Distillation: Epoch : 5, Loss : 1.264447, Accuracy: 0.889000, Test accuracy: 0.898300
Distillation: Epoch : 6, Loss : 1.258268, Accuracy: 0.894000, Test accuracy: 0.907700
Distillation: Epoch : 7, Loss : 1.229275, Accuracy: 0.907000, Test accuracy: 0.909700
Distillation: Epoch : 8, Loss : 1.210465, Accuracy: 0.901000, Test accuracy: 0.917200
Distillation: Epoch : 9, Loss : 1.197558, Accuracy: 0.910000, Test accuracy: 0.919800
Distillation: Epoch : 10, Loss : 1.175763, Accuracy: 0.916000, Test accuracy: 0.923100
Distillation: Epoch : 11, Loss : 1.171435, Accuracy: 0.921000, Test accuracy: 0.926900
Distillation: Epoch : 12, Loss : 1.194452, Accuracy: 0.922000, Test accuracy: 0.932700
Distillation: Epoch : 13, Loss : 1.172307, Accuracy: 0.925000, Test accuracy: 0.936100
Distillation: Epoch : 14, Loss : 1.174903, Accuracy: 0.932000, Test accuracy: 0.938700
Distillation: Epoch : 15, Loss : 1.137088, Accuracy: 0.941000, Test accuracy: 0.942100
Distillation: Epoch : 16, Loss : 1.145089, Accuracy: 0.941000, Test accuracy: 0.943800
Distillation: Epoch : 17, Loss : 1.150182, Accuracy: 0.943000, Test accuracy: 0.944200
Distillation: Epoch : 18, Loss : 1.151728, Accuracy: 0.944000, Test accuracy: 0.948300
Distillation: Epoch : 19, Loss : 1.146974, Accuracy: 0.949000, Test accuracy: 0.949100
Distillation: Epoch : 20, Loss : 1.113424, Accuracy: 0.936000, Test accuracy: 0.951900
Distillation: Epoch : 21, Loss : 1.162016, Accuracy: 0.938000, Test accuracy: 0.953200
Distillation: Epoch : 22, Loss : 1.107192, Accuracy: 0.943000, Test accuracy: 0.953800
Distillation: Epoch : 23, Loss : 1.125378, Accuracy: 0.933000, Test accuracy: 0.955400
Distillation: Epoch : 24, Loss : 1.143266, Accuracy: 0.947000, Test accuracy: 0.955600
Distillation: Epoch : 25, Loss : 1.091419, Accuracy: 0.960000, Test accuracy: 0.955700
Distillation: Epoch : 26, Loss : 1.118424, Accuracy: 0.961000, Test accuracy: 0.956500
Distillation: Epoch : 27, Loss : 1.115862, Accuracy: 0.954000, Test accuracy: 0.956200
Distillation: Epoch : 28, Loss : 1.124318, Accuracy: 0.954000, Test accuracy: 0.957400
Distillation: Epoch : 29, Loss : 1.124100, Accuracy: 0.952000, Test accuracy: 0.958600
Distillation: Epoch : 30, Loss : 1.120831, Accuracy: 0.950000, Test accuracy: 0.958300
Distillation: Epoch : 31, Loss : 1.116939, Accuracy: 0.943000, Test accuracy: 0.959700
Distillation: Epoch : 32, Loss : 1.139802, Accuracy: 0.945000, Test accuracy: 0.958900
Distillation: Epoch : 33, Loss : 1.118511, Accuracy: 0.954000, Test accuracy: 0.958800
Distillation: Epoch : 34, Loss : 1.114908, Accuracy: 0.958000, Test accuracy: 0.958200
Distillation: Epoch : 35, Loss : 1.134885, Accuracy: 0.948000, Test accuracy: 0.959700
Distillation: Epoch : 36, Loss : 1.103362, Accuracy: 0.964000, Test accuracy: 0.959000
Distillation: Epoch : 37, Loss : 1.128386, Accuracy: 0.949000, Test accuracy: 0.960100
Distillation: Epoch : 38, Loss : 1.113514, Accuracy: 0.954000, Test accuracy: 0.961100
Distillation: Epoch : 39, Loss : 1.147945, Accuracy: 0.954000, Test accuracy: 0.959100
Distillation: Epoch : 40, Loss : 1.130563, Accuracy: 0.957000, Test accuracy: 0.959800
Distillation: Epoch : 41, Loss : 1.111027, Accuracy: 0.966000, Test accuracy: 0.960500
Distillation: Epoch : 42, Loss : 1.122204, Accuracy: 0.951000, Test accuracy: 0.960500
Distillation: Epoch : 43, Loss : 1.106883, Accuracy: 0.960000, Test accuracy: 0.960700
Distillation: Epoch : 44, Loss : 1.093610, Accuracy: 0.956000, Test accuracy: 0.960000
Distillation: Epoch : 45, Loss : 1.126088, Accuracy: 0.953000, Test accuracy: 0.961100
Distillation: Epoch : 46, Loss : 1.118139, Accuracy: 0.953000, Test accuracy: 0.960500
Distillation: Epoch : 47, Loss : 1.108417, Accuracy: 0.951000, Test accuracy: 0.960500
Distillation: Epoch : 48, Loss : 1.118822, Accuracy: 0.953000, Test accuracy: 0.960700
Distillation: Epoch : 49, Loss : 1.110042, Accuracy: 0.955000, Test accuracy: 0.961100
Distillation: Epoch : 50, Loss : 1.105204, Accuracy: 0.954000, Test accuracy: 0.961100
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9611
Generating confusion matrix for student5
[[ 971.    0.    5.    0.    1.    3.    6.    1.    9.    5.]
 [   1. 1113.    8.    0.    0.    0.    3.    6.    4.    6.]
 [   0.    2.  967.    7.    0.    0.    0.    9.   11.    2.]
 [   0.    1.   10.  977.    0.   14.    0.    1.   17.    8.]
 [   0.    0.    5.    0.  964.    2.    2.    2.    7.   14.]
 [   1.    1.    0.    6.    0.  846.   11.    0.   10.    5.]
 [   4.    5.    3.    0.    4.    8.  934.    0.    1.    0.]
 [   2.    2.   12.   12.    3.    2.    0.  990.    7.   19.]
 [   0.   11.   22.    7.    1.   11.    2.    3.  900.    1.]
 [   1.    0.    0.    1.    9.    6.    0.   16.    8.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.189966, Accuracy: 0.571000, Test accuracy: 0.579700
Distillation: Epoch : 2, Loss : 1.552197, Accuracy: 0.811000, Test accuracy: 0.823900
Distillation: Epoch : 3, Loss : 1.432777, Accuracy: 0.855000, Test accuracy: 0.864500
Distillation: Epoch : 4, Loss : 1.431746, Accuracy: 0.846000, Test accuracy: 0.878100
Distillation: Epoch : 5, Loss : 1.409877, Accuracy: 0.875000, Test accuracy: 0.886600
Distillation: Epoch : 6, Loss : 1.403391, Accuracy: 0.869000, Test accuracy: 0.894000
Distillation: Epoch : 7, Loss : 1.381327, Accuracy: 0.886000, Test accuracy: 0.896100
Distillation: Epoch : 8, Loss : 1.337819, Accuracy: 0.909000, Test accuracy: 0.901300
Distillation: Epoch : 9, Loss : 1.344427, Accuracy: 0.904000, Test accuracy: 0.904200
Distillation: Epoch : 10, Loss : 1.359768, Accuracy: 0.890000, Test accuracy: 0.907000
Distillation: Epoch : 11, Loss : 1.345337, Accuracy: 0.910000, Test accuracy: 0.910300
Distillation: Epoch : 12, Loss : 1.365826, Accuracy: 0.898000, Test accuracy: 0.913900
Distillation: Epoch : 13, Loss : 1.325438, Accuracy: 0.917000, Test accuracy: 0.917800
Distillation: Epoch : 14, Loss : 1.343968, Accuracy: 0.900000, Test accuracy: 0.921000
Distillation: Epoch : 15, Loss : 1.324718, Accuracy: 0.905000, Test accuracy: 0.925000
Distillation: Epoch : 16, Loss : 1.348341, Accuracy: 0.911000, Test accuracy: 0.928500
Distillation: Epoch : 17, Loss : 1.315261, Accuracy: 0.918000, Test accuracy: 0.930700
Distillation: Epoch : 18, Loss : 1.317437, Accuracy: 0.932000, Test accuracy: 0.932300
Distillation: Epoch : 19, Loss : 1.280551, Accuracy: 0.935000, Test accuracy: 0.935900
Distillation: Epoch : 20, Loss : 1.302708, Accuracy: 0.942000, Test accuracy: 0.938000
Distillation: Epoch : 21, Loss : 1.301478, Accuracy: 0.933000, Test accuracy: 0.940300
Distillation: Epoch : 22, Loss : 1.290836, Accuracy: 0.933000, Test accuracy: 0.940800
Distillation: Epoch : 23, Loss : 1.296309, Accuracy: 0.923000, Test accuracy: 0.943700
Distillation: Epoch : 24, Loss : 1.287909, Accuracy: 0.939000, Test accuracy: 0.946000
Distillation: Epoch : 25, Loss : 1.283063, Accuracy: 0.934000, Test accuracy: 0.947800
Distillation: Epoch : 26, Loss : 1.265536, Accuracy: 0.948000, Test accuracy: 0.948900
Distillation: Epoch : 27, Loss : 1.250218, Accuracy: 0.953000, Test accuracy: 0.949600
Distillation: Epoch : 28, Loss : 1.284356, Accuracy: 0.943000, Test accuracy: 0.950500
Distillation: Epoch : 29, Loss : 1.276779, Accuracy: 0.945000, Test accuracy: 0.952200
Distillation: Epoch : 30, Loss : 1.275862, Accuracy: 0.943000, Test accuracy: 0.953100
Distillation: Epoch : 31, Loss : 1.277154, Accuracy: 0.938000, Test accuracy: 0.952800
Distillation: Epoch : 32, Loss : 1.273998, Accuracy: 0.944000, Test accuracy: 0.953900
Distillation: Epoch : 33, Loss : 1.255905, Accuracy: 0.936000, Test accuracy: 0.954300
Distillation: Epoch : 34, Loss : 1.274696, Accuracy: 0.949000, Test accuracy: 0.955000
Distillation: Epoch : 35, Loss : 1.254080, Accuracy: 0.963000, Test accuracy: 0.955400
Distillation: Epoch : 36, Loss : 1.266028, Accuracy: 0.954000, Test accuracy: 0.956100
Distillation: Epoch : 37, Loss : 1.275518, Accuracy: 0.956000, Test accuracy: 0.956800
Distillation: Epoch : 38, Loss : 1.257555, Accuracy: 0.963000, Test accuracy: 0.957000
Distillation: Epoch : 39, Loss : 1.288627, Accuracy: 0.939000, Test accuracy: 0.957500
Distillation: Epoch : 40, Loss : 1.253211, Accuracy: 0.950000, Test accuracy: 0.957500
Distillation: Epoch : 41, Loss : 1.262139, Accuracy: 0.950000, Test accuracy: 0.957800
Distillation: Epoch : 42, Loss : 1.259869, Accuracy: 0.956000, Test accuracy: 0.957600
Distillation: Epoch : 43, Loss : 1.267325, Accuracy: 0.950000, Test accuracy: 0.956800
Distillation: Epoch : 44, Loss : 1.260331, Accuracy: 0.943000, Test accuracy: 0.957900
Distillation: Epoch : 45, Loss : 1.279340, Accuracy: 0.944000, Test accuracy: 0.957600
Distillation: Epoch : 46, Loss : 1.271735, Accuracy: 0.947000, Test accuracy: 0.958400
Distillation: Epoch : 47, Loss : 1.280800, Accuracy: 0.947000, Test accuracy: 0.958300
Distillation: Epoch : 48, Loss : 1.274686, Accuracy: 0.945000, Test accuracy: 0.957900
Distillation: Epoch : 49, Loss : 1.263887, Accuracy: 0.955000, Test accuracy: 0.958300
Distillation: Epoch : 50, Loss : 1.274219, Accuracy: 0.940000, Test accuracy: 0.958600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9586
Generating confusion matrix for student5
[[ 968.    0.    9.    2.    1.    3.   10.    3.    8.    8.]
 [   1. 1124.    5.    0.    0.    1.    3.    2.    3.    6.]
 [   0.    1.  968.    4.    3.    1.    0.   10.   10.    0.]
 [   0.    2.    9.  961.    0.   20.    0.    8.    9.    7.]
 [   1.    1.    6.    2.  959.    3.    2.    2.   10.   16.]
 [   2.    0.    0.   11.    0.  839.   11.    1.    6.    8.]
 [   6.    3.    5.    0.    2.    7.  930.    0.    4.    0.]
 [   2.    1.   10.   10.    2.    2.    0.  986.    7.    9.]
 [   0.    3.   19.   13.    2.    8.    2.    1.  899.    3.]
 [   0.    0.    1.    7.   13.    8.    0.   15.   18.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.287172, Accuracy: 0.149000, Test accuracy: 0.150700
Distillation: Epoch : 2, Loss : 2.078317, Accuracy: 0.667000, Test accuracy: 0.672700
Distillation: Epoch : 3, Loss : 1.704479, Accuracy: 0.758000, Test accuracy: 0.780000
Distillation: Epoch : 4, Loss : 1.618876, Accuracy: 0.806000, Test accuracy: 0.824900
Distillation: Epoch : 5, Loss : 1.566674, Accuracy: 0.843000, Test accuracy: 0.848700
Distillation: Epoch : 6, Loss : 1.561115, Accuracy: 0.860000, Test accuracy: 0.864500
Distillation: Epoch : 7, Loss : 1.530221, Accuracy: 0.863000, Test accuracy: 0.877800
Distillation: Epoch : 8, Loss : 1.552253, Accuracy: 0.869000, Test accuracy: 0.888500
Distillation: Epoch : 9, Loss : 1.495512, Accuracy: 0.890000, Test accuracy: 0.896200
Distillation: Epoch : 10, Loss : 1.485567, Accuracy: 0.894000, Test accuracy: 0.905400
Distillation: Epoch : 11, Loss : 1.475142, Accuracy: 0.907000, Test accuracy: 0.910500
Distillation: Epoch : 12, Loss : 1.467651, Accuracy: 0.876000, Test accuracy: 0.914000
Distillation: Epoch : 13, Loss : 1.469126, Accuracy: 0.895000, Test accuracy: 0.918500
Distillation: Epoch : 14, Loss : 1.454545, Accuracy: 0.920000, Test accuracy: 0.921200
Distillation: Epoch : 15, Loss : 1.462215, Accuracy: 0.921000, Test accuracy: 0.924700
Distillation: Epoch : 16, Loss : 1.458623, Accuracy: 0.928000, Test accuracy: 0.928300
Distillation: Epoch : 17, Loss : 1.449952, Accuracy: 0.924000, Test accuracy: 0.928800
Distillation: Epoch : 18, Loss : 1.434416, Accuracy: 0.934000, Test accuracy: 0.930300
Distillation: Epoch : 19, Loss : 1.431404, Accuracy: 0.938000, Test accuracy: 0.933700
Distillation: Epoch : 20, Loss : 1.426930, Accuracy: 0.930000, Test accuracy: 0.936400
Distillation: Epoch : 21, Loss : 1.447325, Accuracy: 0.936000, Test accuracy: 0.937900
Distillation: Epoch : 22, Loss : 1.444783, Accuracy: 0.928000, Test accuracy: 0.938200
Distillation: Epoch : 23, Loss : 1.421161, Accuracy: 0.924000, Test accuracy: 0.938600
Distillation: Epoch : 24, Loss : 1.438793, Accuracy: 0.926000, Test accuracy: 0.940900
Distillation: Epoch : 25, Loss : 1.423269, Accuracy: 0.931000, Test accuracy: 0.940800
Distillation: Epoch : 26, Loss : 1.431623, Accuracy: 0.932000, Test accuracy: 0.943100
Distillation: Epoch : 27, Loss : 1.418448, Accuracy: 0.936000, Test accuracy: 0.943500
Distillation: Epoch : 28, Loss : 1.386065, Accuracy: 0.940000, Test accuracy: 0.945400
Distillation: Epoch : 29, Loss : 1.434321, Accuracy: 0.934000, Test accuracy: 0.946400
Distillation: Epoch : 30, Loss : 1.421223, Accuracy: 0.944000, Test accuracy: 0.947800
Distillation: Epoch : 31, Loss : 1.411905, Accuracy: 0.932000, Test accuracy: 0.947500
Distillation: Epoch : 32, Loss : 1.435555, Accuracy: 0.943000, Test accuracy: 0.948100
Distillation: Epoch : 33, Loss : 1.421060, Accuracy: 0.934000, Test accuracy: 0.949000
Distillation: Epoch : 34, Loss : 1.398533, Accuracy: 0.942000, Test accuracy: 0.949400
Distillation: Epoch : 35, Loss : 1.395953, Accuracy: 0.947000, Test accuracy: 0.950500
Distillation: Epoch : 36, Loss : 1.415733, Accuracy: 0.950000, Test accuracy: 0.950600
Distillation: Epoch : 37, Loss : 1.419798, Accuracy: 0.953000, Test accuracy: 0.950800
Distillation: Epoch : 38, Loss : 1.394589, Accuracy: 0.946000, Test accuracy: 0.951000
Distillation: Epoch : 39, Loss : 1.407348, Accuracy: 0.938000, Test accuracy: 0.950700
Distillation: Epoch : 40, Loss : 1.416116, Accuracy: 0.943000, Test accuracy: 0.950900
Distillation: Epoch : 41, Loss : 1.411996, Accuracy: 0.942000, Test accuracy: 0.951100
Distillation: Epoch : 42, Loss : 1.417241, Accuracy: 0.941000, Test accuracy: 0.951400
Distillation: Epoch : 43, Loss : 1.376833, Accuracy: 0.962000, Test accuracy: 0.952800
Distillation: Epoch : 44, Loss : 1.419960, Accuracy: 0.946000, Test accuracy: 0.952500
Distillation: Epoch : 45, Loss : 1.419785, Accuracy: 0.938000, Test accuracy: 0.953100
Distillation: Epoch : 46, Loss : 1.384998, Accuracy: 0.956000, Test accuracy: 0.953600
Distillation: Epoch : 47, Loss : 1.392665, Accuracy: 0.952000, Test accuracy: 0.953100
Distillation: Epoch : 48, Loss : 1.392441, Accuracy: 0.956000, Test accuracy: 0.952900
Distillation: Epoch : 49, Loss : 1.393822, Accuracy: 0.957000, Test accuracy: 0.953300
Distillation: Epoch : 50, Loss : 1.390783, Accuracy: 0.951000, Test accuracy: 0.954500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9545
Generating confusion matrix for student5
[[ 968.    0.    5.    0.    2.    3.   10.    2.   11.    6.]
 [   0. 1119.   17.    1.    2.    2.    4.   12.    9.    6.]
 [   0.    2.  948.    9.    0.    0.    1.   17.    8.    0.]
 [   0.    2.   12.  961.    0.    9.    0.    3.    5.    5.]
 [   1.    2.   13.    2.  964.    1.    4.    6.   12.   30.]
 [   0.    0.    0.   12.    0.  858.    6.    0.    3.    5.]
 [   6.    5.    2.    0.    4.    6.  928.    0.    9.    1.]
 [   1.    0.   16.   15.    2.    4.    0.  964.    8.   13.]
 [   3.    5.   18.    6.    2.    4.    5.    2.  893.    1.]
 [   1.    0.    1.    4.    6.    5.    0.   22.   16.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.165789, Accuracy: 0.640000, Test accuracy: 0.654100
Distillation: Epoch : 2, Loss : 1.857667, Accuracy: 0.824000, Test accuracy: 0.837400
Distillation: Epoch : 3, Loss : 1.809676, Accuracy: 0.855000, Test accuracy: 0.865500
Distillation: Epoch : 4, Loss : 1.798886, Accuracy: 0.875000, Test accuracy: 0.880300
Distillation: Epoch : 5, Loss : 1.779485, Accuracy: 0.876000, Test accuracy: 0.887900
Distillation: Epoch : 6, Loss : 1.791040, Accuracy: 0.885000, Test accuracy: 0.894400
Distillation: Epoch : 7, Loss : 1.784734, Accuracy: 0.880000, Test accuracy: 0.899500
Distillation: Epoch : 8, Loss : 1.740366, Accuracy: 0.902000, Test accuracy: 0.904800
Distillation: Epoch : 9, Loss : 1.770178, Accuracy: 0.902000, Test accuracy: 0.909600
Distillation: Epoch : 10, Loss : 1.754884, Accuracy: 0.882000, Test accuracy: 0.911100
Distillation: Epoch : 11, Loss : 1.751891, Accuracy: 0.898000, Test accuracy: 0.915500
Distillation: Epoch : 12, Loss : 1.760305, Accuracy: 0.905000, Test accuracy: 0.917800
Distillation: Epoch : 13, Loss : 1.712318, Accuracy: 0.928000, Test accuracy: 0.922500
Distillation: Epoch : 14, Loss : 1.733774, Accuracy: 0.923000, Test accuracy: 0.924600
Distillation: Epoch : 15, Loss : 1.730526, Accuracy: 0.920000, Test accuracy: 0.926000
Distillation: Epoch : 16, Loss : 1.719657, Accuracy: 0.923000, Test accuracy: 0.929700
Distillation: Epoch : 17, Loss : 1.720684, Accuracy: 0.919000, Test accuracy: 0.930800
Distillation: Epoch : 18, Loss : 1.728552, Accuracy: 0.931000, Test accuracy: 0.932000
Distillation: Epoch : 19, Loss : 1.721468, Accuracy: 0.920000, Test accuracy: 0.933900
Distillation: Epoch : 20, Loss : 1.727240, Accuracy: 0.940000, Test accuracy: 0.936100
Distillation: Epoch : 21, Loss : 1.699541, Accuracy: 0.942000, Test accuracy: 0.937100
Distillation: Epoch : 22, Loss : 1.729059, Accuracy: 0.919000, Test accuracy: 0.938800
Distillation: Epoch : 23, Loss : 1.723565, Accuracy: 0.922000, Test accuracy: 0.940500
Distillation: Epoch : 24, Loss : 1.709283, Accuracy: 0.929000, Test accuracy: 0.941900
Distillation: Epoch : 25, Loss : 1.714276, Accuracy: 0.940000, Test accuracy: 0.942300
Distillation: Epoch : 26, Loss : 1.719038, Accuracy: 0.936000, Test accuracy: 0.944100
Distillation: Epoch : 27, Loss : 1.717438, Accuracy: 0.940000, Test accuracy: 0.944000
Distillation: Epoch : 28, Loss : 1.713213, Accuracy: 0.953000, Test accuracy: 0.944800
Distillation: Epoch : 29, Loss : 1.704769, Accuracy: 0.949000, Test accuracy: 0.944200
Distillation: Epoch : 30, Loss : 1.693778, Accuracy: 0.940000, Test accuracy: 0.946200
Distillation: Epoch : 31, Loss : 1.712499, Accuracy: 0.937000, Test accuracy: 0.946400
Distillation: Epoch : 32, Loss : 1.708046, Accuracy: 0.917000, Test accuracy: 0.947600
Distillation: Epoch : 33, Loss : 1.713576, Accuracy: 0.928000, Test accuracy: 0.948200
Distillation: Epoch : 34, Loss : 1.706615, Accuracy: 0.952000, Test accuracy: 0.948500
Distillation: Epoch : 35, Loss : 1.685095, Accuracy: 0.939000, Test accuracy: 0.950300
Distillation: Epoch : 36, Loss : 1.706395, Accuracy: 0.953000, Test accuracy: 0.949800
Distillation: Epoch : 37, Loss : 1.699969, Accuracy: 0.956000, Test accuracy: 0.950000
Distillation: Epoch : 38, Loss : 1.714677, Accuracy: 0.948000, Test accuracy: 0.949800
Distillation: Epoch : 39, Loss : 1.713917, Accuracy: 0.951000, Test accuracy: 0.949300
Distillation: Epoch : 40, Loss : 1.683803, Accuracy: 0.941000, Test accuracy: 0.951400
Distillation: Epoch : 41, Loss : 1.719808, Accuracy: 0.933000, Test accuracy: 0.951300
Distillation: Epoch : 42, Loss : 1.683935, Accuracy: 0.953000, Test accuracy: 0.951600
Distillation: Epoch : 43, Loss : 1.702177, Accuracy: 0.950000, Test accuracy: 0.951500
Distillation: Epoch : 44, Loss : 1.703511, Accuracy: 0.946000, Test accuracy: 0.951600
Distillation: Epoch : 45, Loss : 1.695698, Accuracy: 0.963000, Test accuracy: 0.952500
Distillation: Epoch : 46, Loss : 1.704328, Accuracy: 0.946000, Test accuracy: 0.951900
Distillation: Epoch : 47, Loss : 1.691466, Accuracy: 0.952000, Test accuracy: 0.952200
Distillation: Epoch : 48, Loss : 1.712125, Accuracy: 0.944000, Test accuracy: 0.953500
Distillation: Epoch : 49, Loss : 1.709889, Accuracy: 0.944000, Test accuracy: 0.952600
Distillation: Epoch : 50, Loss : 1.709443, Accuracy: 0.953000, Test accuracy: 0.952800
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9528
Generating confusion matrix for student5
[[ 970.    0.    5.    0.    1.    1.   10.    3.   10.    8.]
 [   0. 1120.    8.    2.    4.    2.    4.    9.   16.    8.]
 [   1.    4.  959.    4.    0.    0.    1.   12.    8.    1.]
 [   0.    0.    8.  967.    0.   12.    0.    4.    7.    5.]
 [   1.    1.   12.    2.  961.    1.    6.    8.   17.   28.]
 [   0.    0.    1.   10.    0.  846.   11.    0.    9.    1.]
 [   6.    4.    2.    0.    3.    9.  923.    0.    8.    0.]
 [   1.    1.   12.   12.    0.    3.    0.  963.   12.   11.]
 [   1.    5.   22.    7.    3.    7.    3.    3.  872.    0.]
 [   0.    0.    3.    6.   10.   11.    0.   26.   15.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.195719, Accuracy: 0.677000, Test accuracy: 0.690400
Distillation: Epoch : 2, Loss : 2.057413, Accuracy: 0.803000, Test accuracy: 0.825700
Distillation: Epoch : 3, Loss : 2.052570, Accuracy: 0.830000, Test accuracy: 0.854600
Distillation: Epoch : 4, Loss : 2.030627, Accuracy: 0.850000, Test accuracy: 0.862800
Distillation: Epoch : 5, Loss : 2.027941, Accuracy: 0.849000, Test accuracy: 0.870400
Distillation: Epoch : 6, Loss : 2.014542, Accuracy: 0.866000, Test accuracy: 0.879100
Distillation: Epoch : 7, Loss : 2.027337, Accuracy: 0.877000, Test accuracy: 0.879900
Distillation: Epoch : 8, Loss : 2.017364, Accuracy: 0.882000, Test accuracy: 0.882700
Distillation: Epoch : 9, Loss : 2.023843, Accuracy: 0.870000, Test accuracy: 0.884900
Distillation: Epoch : 10, Loss : 2.020626, Accuracy: 0.888000, Test accuracy: 0.886800
Distillation: Epoch : 11, Loss : 2.021757, Accuracy: 0.869000, Test accuracy: 0.888100
Distillation: Epoch : 12, Loss : 2.015627, Accuracy: 0.887000, Test accuracy: 0.889000
Distillation: Epoch : 13, Loss : 2.021920, Accuracy: 0.867000, Test accuracy: 0.889800
Distillation: Epoch : 14, Loss : 2.018160, Accuracy: 0.878000, Test accuracy: 0.890300
Distillation: Epoch : 15, Loss : 2.006623, Accuracy: 0.894000, Test accuracy: 0.890300
Distillation: Epoch : 16, Loss : 2.021369, Accuracy: 0.879000, Test accuracy: 0.891200
Distillation: Epoch : 17, Loss : 2.019958, Accuracy: 0.887000, Test accuracy: 0.890900
Distillation: Epoch : 18, Loss : 2.008700, Accuracy: 0.912000, Test accuracy: 0.892300
Distillation: Epoch : 19, Loss : 2.014659, Accuracy: 0.874000, Test accuracy: 0.892700
Distillation: Epoch : 20, Loss : 2.016447, Accuracy: 0.897000, Test accuracy: 0.892200
Distillation: Epoch : 21, Loss : 2.013467, Accuracy: 0.877000, Test accuracy: 0.893200
Distillation: Epoch : 22, Loss : 2.009885, Accuracy: 0.895000, Test accuracy: 0.893500
Distillation: Epoch : 23, Loss : 2.006319, Accuracy: 0.894000, Test accuracy: 0.893100
Distillation: Epoch : 24, Loss : 1.998925, Accuracy: 0.897000, Test accuracy: 0.893700
Distillation: Epoch : 25, Loss : 2.006137, Accuracy: 0.901000, Test accuracy: 0.892700
Distillation: Epoch : 26, Loss : 2.011333, Accuracy: 0.883000, Test accuracy: 0.893900
Distillation: Epoch : 27, Loss : 2.008359, Accuracy: 0.878000, Test accuracy: 0.893500
Distillation: Epoch : 28, Loss : 2.012541, Accuracy: 0.889000, Test accuracy: 0.893000
Distillation: Epoch : 29, Loss : 2.012704, Accuracy: 0.877000, Test accuracy: 0.894700
Distillation: Epoch : 30, Loss : 2.017804, Accuracy: 0.876000, Test accuracy: 0.893700
Distillation: Epoch : 31, Loss : 2.007605, Accuracy: 0.904000, Test accuracy: 0.895000
Distillation: Epoch : 32, Loss : 2.002233, Accuracy: 0.906000, Test accuracy: 0.896000
Distillation: Epoch : 33, Loss : 2.007183, Accuracy: 0.877000, Test accuracy: 0.894700
Distillation: Epoch : 34, Loss : 2.008647, Accuracy: 0.893000, Test accuracy: 0.894700
Distillation: Epoch : 35, Loss : 2.016391, Accuracy: 0.882000, Test accuracy: 0.895000
Distillation: Epoch : 36, Loss : 2.008213, Accuracy: 0.891000, Test accuracy: 0.896200
Distillation: Epoch : 37, Loss : 2.021118, Accuracy: 0.896000, Test accuracy: 0.895000
Distillation: Epoch : 38, Loss : 2.006719, Accuracy: 0.906000, Test accuracy: 0.896500
Distillation: Epoch : 39, Loss : 2.014262, Accuracy: 0.884000, Test accuracy: 0.896500
Distillation: Epoch : 40, Loss : 2.015190, Accuracy: 0.881000, Test accuracy: 0.895300
Distillation: Epoch : 41, Loss : 2.007573, Accuracy: 0.887000, Test accuracy: 0.897200
Distillation: Epoch : 42, Loss : 2.008516, Accuracy: 0.894000, Test accuracy: 0.899300
Distillation: Epoch : 43, Loss : 1.999760, Accuracy: 0.893000, Test accuracy: 0.899200
Distillation: Epoch : 44, Loss : 2.002360, Accuracy: 0.896000, Test accuracy: 0.897200
Distillation: Epoch : 45, Loss : 2.011502, Accuracy: 0.884000, Test accuracy: 0.899000
Distillation: Epoch : 46, Loss : 1.999897, Accuracy: 0.890000, Test accuracy: 0.898400
Distillation: Epoch : 47, Loss : 2.003964, Accuracy: 0.891000, Test accuracy: 0.898400
Distillation: Epoch : 48, Loss : 2.000840, Accuracy: 0.901000, Test accuracy: 0.898100
Distillation: Epoch : 49, Loss : 2.000839, Accuracy: 0.901000, Test accuracy: 0.900300
Distillation: Epoch : 50, Loss : 2.012778, Accuracy: 0.881000, Test accuracy: 0.898800
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.8988
Generating confusion matrix for student5
[[ 955.    0.   16.   10.    1.   11.   12.    1.   10.   14.]
 [   0. 1106.   24.    4.    1.    4.    3.   22.   21.    6.]
 [   1.    3.  869.   13.    5.    1.    2.   13.    6.    1.]
 [   1.    3.   25.  896.    0.   32.    0.    8.   22.   13.]
 [   3.    3.   30.    3.  921.   18.    9.   29.   26.   92.]
 [   4.    3.    1.   32.    3.  768.   20.    1.   31.    4.]
 [   7.    4.   19.    5.   10.   17.  910.    1.   14.    0.]
 [   1.    0.   20.   23.    3.    6.    1.  888.    8.   22.]
 [   8.   13.   25.   14.    9.   19.    1.    1.  821.    3.]
 [   0.    0.    3.   10.   29.   16.    0.   64.   15.  854.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.685411, Accuracy: 0.812000, Test accuracy: 0.827500
Distillation: Epoch : 2, Loss : 0.410845, Accuracy: 0.870000, Test accuracy: 0.891600
Distillation: Epoch : 3, Loss : 0.328381, Accuracy: 0.895000, Test accuracy: 0.910100
Distillation: Epoch : 4, Loss : 0.319038, Accuracy: 0.903000, Test accuracy: 0.921500
Distillation: Epoch : 5, Loss : 0.252672, Accuracy: 0.923000, Test accuracy: 0.929000
Distillation: Epoch : 6, Loss : 0.196550, Accuracy: 0.944000, Test accuracy: 0.933700
Distillation: Epoch : 7, Loss : 0.217711, Accuracy: 0.937000, Test accuracy: 0.939700
Distillation: Epoch : 8, Loss : 0.278710, Accuracy: 0.931000, Test accuracy: 0.945900
Distillation: Epoch : 9, Loss : 0.185928, Accuracy: 0.944000, Test accuracy: 0.948600
Distillation: Epoch : 10, Loss : 0.157002, Accuracy: 0.953000, Test accuracy: 0.952300
Distillation: Epoch : 11, Loss : 0.151694, Accuracy: 0.962000, Test accuracy: 0.955100
Distillation: Epoch : 12, Loss : 0.137125, Accuracy: 0.953000, Test accuracy: 0.957400
Distillation: Epoch : 13, Loss : 0.163129, Accuracy: 0.951000, Test accuracy: 0.959900
Distillation: Epoch : 14, Loss : 0.134179, Accuracy: 0.961000, Test accuracy: 0.962000
Distillation: Epoch : 15, Loss : 0.141566, Accuracy: 0.955000, Test accuracy: 0.963900
Distillation: Epoch : 16, Loss : 0.147794, Accuracy: 0.955000, Test accuracy: 0.965400
Distillation: Epoch : 17, Loss : 0.131246, Accuracy: 0.960000, Test accuracy: 0.968100
Distillation: Epoch : 18, Loss : 0.074564, Accuracy: 0.978000, Test accuracy: 0.969100
Distillation: Epoch : 19, Loss : 0.103856, Accuracy: 0.972000, Test accuracy: 0.970700
Distillation: Epoch : 20, Loss : 0.107102, Accuracy: 0.966000, Test accuracy: 0.971400
Distillation: Epoch : 21, Loss : 0.086177, Accuracy: 0.973000, Test accuracy: 0.971500
Distillation: Epoch : 22, Loss : 0.077586, Accuracy: 0.975000, Test accuracy: 0.973100
Distillation: Epoch : 23, Loss : 0.086026, Accuracy: 0.975000, Test accuracy: 0.972600
Distillation: Epoch : 24, Loss : 0.086861, Accuracy: 0.971000, Test accuracy: 0.974200
Distillation: Epoch : 25, Loss : 0.091114, Accuracy: 0.972000, Test accuracy: 0.974900
Distillation: Epoch : 26, Loss : 0.081765, Accuracy: 0.977000, Test accuracy: 0.976600
Distillation: Epoch : 27, Loss : 0.090897, Accuracy: 0.978000, Test accuracy: 0.975900
Distillation: Epoch : 28, Loss : 0.077588, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 29, Loss : 0.103491, Accuracy: 0.970000, Test accuracy: 0.975600
Distillation: Epoch : 30, Loss : 0.063955, Accuracy: 0.981000, Test accuracy: 0.975700
Distillation: Epoch : 31, Loss : 0.095017, Accuracy: 0.975000, Test accuracy: 0.976300
Distillation: Epoch : 32, Loss : 0.107424, Accuracy: 0.967000, Test accuracy: 0.978500
Distillation: Epoch : 33, Loss : 0.082118, Accuracy: 0.976000, Test accuracy: 0.978300
Distillation: Epoch : 34, Loss : 0.076589, Accuracy: 0.972000, Test accuracy: 0.978500
Distillation: Epoch : 35, Loss : 0.075618, Accuracy: 0.977000, Test accuracy: 0.978100
Distillation: Epoch : 36, Loss : 0.088592, Accuracy: 0.968000, Test accuracy: 0.977800
Distillation: Epoch : 37, Loss : 0.076907, Accuracy: 0.973000, Test accuracy: 0.977700
Distillation: Epoch : 38, Loss : 0.058447, Accuracy: 0.985000, Test accuracy: 0.980200
Distillation: Epoch : 39, Loss : 0.077202, Accuracy: 0.976000, Test accuracy: 0.979100
Distillation: Epoch : 40, Loss : 0.069941, Accuracy: 0.980000, Test accuracy: 0.979400
Distillation: Epoch : 41, Loss : 0.075720, Accuracy: 0.975000, Test accuracy: 0.979600
Distillation: Epoch : 42, Loss : 0.071789, Accuracy: 0.980000, Test accuracy: 0.980500
Distillation: Epoch : 43, Loss : 0.066716, Accuracy: 0.977000, Test accuracy: 0.979900
Distillation: Epoch : 44, Loss : 0.066645, Accuracy: 0.981000, Test accuracy: 0.979900
Distillation: Epoch : 45, Loss : 0.089309, Accuracy: 0.975000, Test accuracy: 0.980300
Distillation: Epoch : 46, Loss : 0.094429, Accuracy: 0.969000, Test accuracy: 0.980500
Distillation: Epoch : 47, Loss : 0.049976, Accuracy: 0.986000, Test accuracy: 0.981200
Distillation: Epoch : 48, Loss : 0.060961, Accuracy: 0.980000, Test accuracy: 0.981400
Distillation: Epoch : 49, Loss : 0.070791, Accuracy: 0.978000, Test accuracy: 0.982400
Distillation: Epoch : 50, Loss : 0.058559, Accuracy: 0.978000, Test accuracy: 0.981500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9815
Generating confusion matrix for student
[[ 968.    0.    0.    1.    0.    1.    3.    0.    2.    2.]
 [   0. 1128.    4.    0.    0.    0.    3.    2.    0.    3.]
 [   1.    2. 1006.    3.    3.    1.    1.   11.    3.    0.]
 [   1.    1.    3.  992.    0.    7.    0.    5.    6.    4.]
 [   0.    1.    1.    0.  974.    0.    4.    0.    3.    8.]
 [   1.    0.    0.    4.    0.  877.    3.    1.    4.    3.]
 [   3.    0.    0.    0.    0.    2.  938.    0.    1.    1.]
 [   1.    1.    5.    3.    0.    1.    0. 1002.    3.    3.]
 [   4.    2.   13.    6.    1.    2.    6.    1.  948.    3.]
 [   1.    0.    0.    1.    4.    1.    0.    6.    4.  982.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.792987, Accuracy: 0.799000, Test accuracy: 0.802800
Distillation: Epoch : 2, Loss : 0.415402, Accuracy: 0.894000, Test accuracy: 0.882300
Distillation: Epoch : 3, Loss : 0.336321, Accuracy: 0.904000, Test accuracy: 0.904400
Distillation: Epoch : 4, Loss : 0.280968, Accuracy: 0.923000, Test accuracy: 0.915400
Distillation: Epoch : 5, Loss : 0.304157, Accuracy: 0.917000, Test accuracy: 0.923700
Distillation: Epoch : 6, Loss : 0.263318, Accuracy: 0.929000, Test accuracy: 0.930700
Distillation: Epoch : 7, Loss : 0.224441, Accuracy: 0.945000, Test accuracy: 0.936800
Distillation: Epoch : 8, Loss : 0.247636, Accuracy: 0.929000, Test accuracy: 0.942300
Distillation: Epoch : 9, Loss : 0.182240, Accuracy: 0.950000, Test accuracy: 0.945900
Distillation: Epoch : 10, Loss : 0.186482, Accuracy: 0.941000, Test accuracy: 0.949100
Distillation: Epoch : 11, Loss : 0.205390, Accuracy: 0.941000, Test accuracy: 0.952700
Distillation: Epoch : 12, Loss : 0.153828, Accuracy: 0.961000, Test accuracy: 0.955100
Distillation: Epoch : 13, Loss : 0.159679, Accuracy: 0.955000, Test accuracy: 0.957400
Distillation: Epoch : 14, Loss : 0.168270, Accuracy: 0.958000, Test accuracy: 0.960900
Distillation: Epoch : 15, Loss : 0.169748, Accuracy: 0.953000, Test accuracy: 0.962100
Distillation: Epoch : 16, Loss : 0.160367, Accuracy: 0.966000, Test accuracy: 0.964700
Distillation: Epoch : 17, Loss : 0.136688, Accuracy: 0.965000, Test accuracy: 0.965000
Distillation: Epoch : 18, Loss : 0.128751, Accuracy: 0.966000, Test accuracy: 0.965600
Distillation: Epoch : 19, Loss : 0.147580, Accuracy: 0.960000, Test accuracy: 0.968500
Distillation: Epoch : 20, Loss : 0.130126, Accuracy: 0.969000, Test accuracy: 0.969000
Distillation: Epoch : 21, Loss : 0.137079, Accuracy: 0.969000, Test accuracy: 0.970700
Distillation: Epoch : 22, Loss : 0.122266, Accuracy: 0.972000, Test accuracy: 0.970200
Distillation: Epoch : 23, Loss : 0.129788, Accuracy: 0.973000, Test accuracy: 0.970300
Distillation: Epoch : 24, Loss : 0.108015, Accuracy: 0.977000, Test accuracy: 0.971200
Distillation: Epoch : 25, Loss : 0.136224, Accuracy: 0.969000, Test accuracy: 0.971900
Distillation: Epoch : 26, Loss : 0.126452, Accuracy: 0.966000, Test accuracy: 0.972900
Distillation: Epoch : 27, Loss : 0.132298, Accuracy: 0.967000, Test accuracy: 0.972600
Distillation: Epoch : 28, Loss : 0.117141, Accuracy: 0.973000, Test accuracy: 0.973800
Distillation: Epoch : 29, Loss : 0.123894, Accuracy: 0.965000, Test accuracy: 0.974200
Distillation: Epoch : 30, Loss : 0.096108, Accuracy: 0.974000, Test accuracy: 0.974400
Distillation: Epoch : 31, Loss : 0.097319, Accuracy: 0.977000, Test accuracy: 0.975000
Distillation: Epoch : 32, Loss : 0.138496, Accuracy: 0.961000, Test accuracy: 0.975000
Distillation: Epoch : 33, Loss : 0.105529, Accuracy: 0.977000, Test accuracy: 0.975200
Distillation: Epoch : 34, Loss : 0.086958, Accuracy: 0.980000, Test accuracy: 0.975800
Distillation: Epoch : 35, Loss : 0.100892, Accuracy: 0.973000, Test accuracy: 0.975500
Distillation: Epoch : 36, Loss : 0.113011, Accuracy: 0.968000, Test accuracy: 0.976600
Distillation: Epoch : 37, Loss : 0.113748, Accuracy: 0.972000, Test accuracy: 0.976100
Distillation: Epoch : 38, Loss : 0.108064, Accuracy: 0.971000, Test accuracy: 0.976700
Distillation: Epoch : 39, Loss : 0.095872, Accuracy: 0.976000, Test accuracy: 0.976400
Distillation: Epoch : 40, Loss : 0.084450, Accuracy: 0.982000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 0.092729, Accuracy: 0.976000, Test accuracy: 0.977300
Distillation: Epoch : 42, Loss : 0.098189, Accuracy: 0.976000, Test accuracy: 0.976300
Distillation: Epoch : 43, Loss : 0.098168, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 44, Loss : 0.071909, Accuracy: 0.989000, Test accuracy: 0.978400
Distillation: Epoch : 45, Loss : 0.116235, Accuracy: 0.969000, Test accuracy: 0.976900
Distillation: Epoch : 46, Loss : 0.092462, Accuracy: 0.975000, Test accuracy: 0.977700
Distillation: Epoch : 47, Loss : 0.092336, Accuracy: 0.980000, Test accuracy: 0.977200
Distillation: Epoch : 48, Loss : 0.095179, Accuracy: 0.980000, Test accuracy: 0.978900
Distillation: Epoch : 49, Loss : 0.102518, Accuracy: 0.979000, Test accuracy: 0.979000
Distillation: Epoch : 50, Loss : 0.082582, Accuracy: 0.977000, Test accuracy: 0.979100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9791
Generating confusion matrix for student
[[ 974.    0.    5.    0.    2.    2.    8.    1.    6.    4.]
 [   0. 1125.    4.    0.    0.    0.    3.    3.    1.    6.]
 [   1.    3. 1006.    2.    3.    0.    1.    7.    4.    0.]
 [   0.    0.    3.  986.    0.    2.    0.    2.    6.    1.]
 [   0.    0.    3.    0.  962.    0.    5.    3.    3.    8.]
 [   0.    1.    0.   10.    0.  880.    3.    1.    4.    7.]
 [   2.    1.    0.    0.    1.    3.  935.    0.    0.    0.]
 [   0.    1.    5.    6.    3.    2.    0. 1005.    4.    4.]
 [   2.    4.    6.    5.    2.    2.    3.    1.  942.    3.]
 [   1.    0.    0.    1.    9.    1.    0.    5.    4.  976.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.150695, Accuracy: 0.759000, Test accuracy: 0.792000
Distillation: Epoch : 2, Loss : 0.734232, Accuracy: 0.841000, Test accuracy: 0.868100
Distillation: Epoch : 3, Loss : 0.645861, Accuracy: 0.891000, Test accuracy: 0.895100
Distillation: Epoch : 4, Loss : 0.604445, Accuracy: 0.909000, Test accuracy: 0.908500
Distillation: Epoch : 5, Loss : 0.571490, Accuracy: 0.923000, Test accuracy: 0.920700
Distillation: Epoch : 6, Loss : 0.552815, Accuracy: 0.931000, Test accuracy: 0.930100
Distillation: Epoch : 7, Loss : 0.529660, Accuracy: 0.920000, Test accuracy: 0.936300
Distillation: Epoch : 8, Loss : 0.472954, Accuracy: 0.954000, Test accuracy: 0.941400
Distillation: Epoch : 9, Loss : 0.484155, Accuracy: 0.949000, Test accuracy: 0.945300
Distillation: Epoch : 10, Loss : 0.474674, Accuracy: 0.943000, Test accuracy: 0.950600
Distillation: Epoch : 11, Loss : 0.475848, Accuracy: 0.951000, Test accuracy: 0.954100
Distillation: Epoch : 12, Loss : 0.461208, Accuracy: 0.951000, Test accuracy: 0.957900
Distillation: Epoch : 13, Loss : 0.449762, Accuracy: 0.957000, Test accuracy: 0.959800
Distillation: Epoch : 14, Loss : 0.471116, Accuracy: 0.945000, Test accuracy: 0.961200
Distillation: Epoch : 15, Loss : 0.468661, Accuracy: 0.951000, Test accuracy: 0.963200
Distillation: Epoch : 16, Loss : 0.437419, Accuracy: 0.975000, Test accuracy: 0.965000
Distillation: Epoch : 17, Loss : 0.428907, Accuracy: 0.971000, Test accuracy: 0.965000
Distillation: Epoch : 18, Loss : 0.443577, Accuracy: 0.961000, Test accuracy: 0.966400
Distillation: Epoch : 19, Loss : 0.414921, Accuracy: 0.969000, Test accuracy: 0.967400
Distillation: Epoch : 20, Loss : 0.410941, Accuracy: 0.979000, Test accuracy: 0.968700
Distillation: Epoch : 21, Loss : 0.419384, Accuracy: 0.963000, Test accuracy: 0.969500
Distillation: Epoch : 22, Loss : 0.434536, Accuracy: 0.972000, Test accuracy: 0.970700
Distillation: Epoch : 23, Loss : 0.432359, Accuracy: 0.963000, Test accuracy: 0.971900
Distillation: Epoch : 24, Loss : 0.432018, Accuracy: 0.961000, Test accuracy: 0.971300
Distillation: Epoch : 25, Loss : 0.434545, Accuracy: 0.971000, Test accuracy: 0.972600
Distillation: Epoch : 26, Loss : 0.396509, Accuracy: 0.978000, Test accuracy: 0.972600
Distillation: Epoch : 27, Loss : 0.428613, Accuracy: 0.972000, Test accuracy: 0.974300
Distillation: Epoch : 28, Loss : 0.398131, Accuracy: 0.975000, Test accuracy: 0.974300
Distillation: Epoch : 29, Loss : 0.426570, Accuracy: 0.967000, Test accuracy: 0.974600
Distillation: Epoch : 30, Loss : 0.390001, Accuracy: 0.985000, Test accuracy: 0.974800
Distillation: Epoch : 31, Loss : 0.410370, Accuracy: 0.979000, Test accuracy: 0.974900
Distillation: Epoch : 32, Loss : 0.433420, Accuracy: 0.969000, Test accuracy: 0.975300
Distillation: Epoch : 33, Loss : 0.385899, Accuracy: 0.980000, Test accuracy: 0.976600
Distillation: Epoch : 34, Loss : 0.392594, Accuracy: 0.978000, Test accuracy: 0.977000
Distillation: Epoch : 35, Loss : 0.414147, Accuracy: 0.965000, Test accuracy: 0.976400
Distillation: Epoch : 36, Loss : 0.392514, Accuracy: 0.981000, Test accuracy: 0.976900
Distillation: Epoch : 37, Loss : 0.401724, Accuracy: 0.980000, Test accuracy: 0.977500
Distillation: Epoch : 38, Loss : 0.415282, Accuracy: 0.972000, Test accuracy: 0.977000
Distillation: Epoch : 39, Loss : 0.405047, Accuracy: 0.974000, Test accuracy: 0.978100
Distillation: Epoch : 40, Loss : 0.415797, Accuracy: 0.977000, Test accuracy: 0.977900
Distillation: Epoch : 41, Loss : 0.394820, Accuracy: 0.971000, Test accuracy: 0.978400
Distillation: Epoch : 42, Loss : 0.395297, Accuracy: 0.981000, Test accuracy: 0.978800
Distillation: Epoch : 43, Loss : 0.393812, Accuracy: 0.982000, Test accuracy: 0.978700
Distillation: Epoch : 44, Loss : 0.400288, Accuracy: 0.974000, Test accuracy: 0.977300
Distillation: Epoch : 45, Loss : 0.414945, Accuracy: 0.977000, Test accuracy: 0.978600
Distillation: Epoch : 46, Loss : 0.390898, Accuracy: 0.983000, Test accuracy: 0.980200
Distillation: Epoch : 47, Loss : 0.387378, Accuracy: 0.979000, Test accuracy: 0.980000
Distillation: Epoch : 48, Loss : 0.399363, Accuracy: 0.973000, Test accuracy: 0.979600
Distillation: Epoch : 49, Loss : 0.418984, Accuracy: 0.975000, Test accuracy: 0.980200
Distillation: Epoch : 50, Loss : 0.403504, Accuracy: 0.974000, Test accuracy: 0.979600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9796
Generating confusion matrix for student
[[ 975.    0.    5.    0.    1.    2.    8.    0.    7.    4.]
 [   0. 1129.    1.    0.    0.    0.    3.    3.    1.    5.]
 [   0.    3. 1006.    4.    2.    0.    0.    5.    2.    0.]
 [   0.    1.    2.  980.    0.    6.    0.    2.    2.    4.]
 [   0.    1.    1.    0.  963.    0.    4.    3.    3.   10.]
 [   0.    0.    1.    5.    0.  879.    6.    0.    2.    3.]
 [   2.    1.    1.    0.    1.    2.  937.    0.    1.    0.]
 [   0.    0.    7.   10.    3.    1.    0. 1007.    5.    6.]
 [   2.    0.    8.    4.    2.    0.    0.    1.  944.    1.]
 [   1.    0.    0.    7.   10.    2.    0.    7.    7.  976.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.129604, Accuracy: 0.781000, Test accuracy: 0.786000
Distillation: Epoch : 2, Loss : 0.865646, Accuracy: 0.884000, Test accuracy: 0.877700
Distillation: Epoch : 3, Loss : 0.788783, Accuracy: 0.899000, Test accuracy: 0.897900
Distillation: Epoch : 4, Loss : 0.796619, Accuracy: 0.883000, Test accuracy: 0.911500
Distillation: Epoch : 5, Loss : 0.737273, Accuracy: 0.910000, Test accuracy: 0.920200
Distillation: Epoch : 6, Loss : 0.717194, Accuracy: 0.908000, Test accuracy: 0.924000
Distillation: Epoch : 7, Loss : 0.689697, Accuracy: 0.925000, Test accuracy: 0.928600
Distillation: Epoch : 8, Loss : 0.709265, Accuracy: 0.917000, Test accuracy: 0.935900
Distillation: Epoch : 9, Loss : 0.680807, Accuracy: 0.925000, Test accuracy: 0.937800
Distillation: Epoch : 10, Loss : 0.674860, Accuracy: 0.940000, Test accuracy: 0.942000
Distillation: Epoch : 11, Loss : 0.656754, Accuracy: 0.947000, Test accuracy: 0.945100
Distillation: Epoch : 12, Loss : 0.623985, Accuracy: 0.959000, Test accuracy: 0.947700
Distillation: Epoch : 13, Loss : 0.647376, Accuracy: 0.949000, Test accuracy: 0.949300
Distillation: Epoch : 14, Loss : 0.650422, Accuracy: 0.948000, Test accuracy: 0.953100
Distillation: Epoch : 15, Loss : 0.599751, Accuracy: 0.953000, Test accuracy: 0.955000
Distillation: Epoch : 16, Loss : 0.627886, Accuracy: 0.954000, Test accuracy: 0.957500
Distillation: Epoch : 17, Loss : 0.621362, Accuracy: 0.944000, Test accuracy: 0.957600
Distillation: Epoch : 18, Loss : 0.611283, Accuracy: 0.957000, Test accuracy: 0.960000
Distillation: Epoch : 19, Loss : 0.618891, Accuracy: 0.951000, Test accuracy: 0.960900
Distillation: Epoch : 20, Loss : 0.625480, Accuracy: 0.950000, Test accuracy: 0.963500
Distillation: Epoch : 21, Loss : 0.606343, Accuracy: 0.963000, Test accuracy: 0.963300
Distillation: Epoch : 22, Loss : 0.580115, Accuracy: 0.976000, Test accuracy: 0.964200
Distillation: Epoch : 23, Loss : 0.609439, Accuracy: 0.968000, Test accuracy: 0.965800
Distillation: Epoch : 24, Loss : 0.591024, Accuracy: 0.964000, Test accuracy: 0.966400
Distillation: Epoch : 25, Loss : 0.598987, Accuracy: 0.958000, Test accuracy: 0.967600
Distillation: Epoch : 26, Loss : 0.598313, Accuracy: 0.963000, Test accuracy: 0.968200
Distillation: Epoch : 27, Loss : 0.593946, Accuracy: 0.960000, Test accuracy: 0.969000
Distillation: Epoch : 28, Loss : 0.577283, Accuracy: 0.968000, Test accuracy: 0.969200
Distillation: Epoch : 29, Loss : 0.561767, Accuracy: 0.966000, Test accuracy: 0.970000
Distillation: Epoch : 30, Loss : 0.576058, Accuracy: 0.970000, Test accuracy: 0.970500
Distillation: Epoch : 31, Loss : 0.587747, Accuracy: 0.969000, Test accuracy: 0.971300
Distillation: Epoch : 32, Loss : 0.594773, Accuracy: 0.968000, Test accuracy: 0.971600
Distillation: Epoch : 33, Loss : 0.590800, Accuracy: 0.965000, Test accuracy: 0.973200
Distillation: Epoch : 34, Loss : 0.566736, Accuracy: 0.974000, Test accuracy: 0.971600
Distillation: Epoch : 35, Loss : 0.621802, Accuracy: 0.962000, Test accuracy: 0.973300
Distillation: Epoch : 36, Loss : 0.583982, Accuracy: 0.980000, Test accuracy: 0.973900
Distillation: Epoch : 37, Loss : 0.606849, Accuracy: 0.960000, Test accuracy: 0.974700
Distillation: Epoch : 38, Loss : 0.564472, Accuracy: 0.978000, Test accuracy: 0.976300
Distillation: Epoch : 39, Loss : 0.568633, Accuracy: 0.970000, Test accuracy: 0.976000
Distillation: Epoch : 40, Loss : 0.588382, Accuracy: 0.972000, Test accuracy: 0.975600
Distillation: Epoch : 41, Loss : 0.570622, Accuracy: 0.974000, Test accuracy: 0.976400
Distillation: Epoch : 42, Loss : 0.564960, Accuracy: 0.977000, Test accuracy: 0.976100
Distillation: Epoch : 43, Loss : 0.590665, Accuracy: 0.969000, Test accuracy: 0.977200
Distillation: Epoch : 44, Loss : 0.593295, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 45, Loss : 0.573604, Accuracy: 0.970000, Test accuracy: 0.976700
Distillation: Epoch : 46, Loss : 0.532638, Accuracy: 0.981000, Test accuracy: 0.977600
Distillation: Epoch : 47, Loss : 0.585888, Accuracy: 0.969000, Test accuracy: 0.976600
Distillation: Epoch : 48, Loss : 0.574576, Accuracy: 0.974000, Test accuracy: 0.976900
Distillation: Epoch : 49, Loss : 0.587211, Accuracy: 0.971000, Test accuracy: 0.978200
Distillation: Epoch : 50, Loss : 0.567131, Accuracy: 0.974000, Test accuracy: 0.977900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9779
Generating confusion matrix for student
[[ 973.    0.    5.    1.    1.    1.    4.    1.    7.    1.]
 [   0. 1126.    3.    0.    1.    0.    2.    6.    1.    6.]
 [   0.    3.  998.    0.    2.    0.    1.    7.    5.    1.]
 [   0.    0.    7.  992.    0.    5.    1.    3.    8.    6.]
 [   0.    1.    6.    0.  971.    0.    2.    2.    4.   13.]
 [   0.    0.    0.    5.    0.  877.    3.    0.    8.    2.]
 [   3.    3.    0.    0.    0.    4.  944.    0.    2.    0.]
 [   1.    1.    6.    7.    1.    1.    0. 1001.    4.    7.]
 [   3.    1.    6.    3.    1.    0.    1.    1.  925.    1.]
 [   0.    0.    1.    2.    5.    4.    0.    7.   10.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.281539, Accuracy: 0.747000, Test accuracy: 0.777200
Distillation: Epoch : 2, Loss : 1.043131, Accuracy: 0.838000, Test accuracy: 0.865100
Distillation: Epoch : 3, Loss : 0.948571, Accuracy: 0.897000, Test accuracy: 0.891900
Distillation: Epoch : 4, Loss : 0.889656, Accuracy: 0.925000, Test accuracy: 0.902600
Distillation: Epoch : 5, Loss : 0.894232, Accuracy: 0.914000, Test accuracy: 0.913300
Distillation: Epoch : 6, Loss : 0.892552, Accuracy: 0.915000, Test accuracy: 0.923600
Distillation: Epoch : 7, Loss : 0.857570, Accuracy: 0.921000, Test accuracy: 0.930000
Distillation: Epoch : 8, Loss : 0.835775, Accuracy: 0.937000, Test accuracy: 0.938400
Distillation: Epoch : 9, Loss : 0.820736, Accuracy: 0.950000, Test accuracy: 0.942600
Distillation: Epoch : 10, Loss : 0.786441, Accuracy: 0.940000, Test accuracy: 0.947200
Distillation: Epoch : 11, Loss : 0.788773, Accuracy: 0.957000, Test accuracy: 0.952500
Distillation: Epoch : 12, Loss : 0.823634, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 13, Loss : 0.807365, Accuracy: 0.947000, Test accuracy: 0.958000
Distillation: Epoch : 14, Loss : 0.799700, Accuracy: 0.951000, Test accuracy: 0.961600
Distillation: Epoch : 15, Loss : 0.785957, Accuracy: 0.959000, Test accuracy: 0.965500
Distillation: Epoch : 16, Loss : 0.788550, Accuracy: 0.951000, Test accuracy: 0.967300
Distillation: Epoch : 17, Loss : 0.778628, Accuracy: 0.965000, Test accuracy: 0.967000
Distillation: Epoch : 18, Loss : 0.783252, Accuracy: 0.974000, Test accuracy: 0.968600
Distillation: Epoch : 19, Loss : 0.784064, Accuracy: 0.963000, Test accuracy: 0.968900
Distillation: Epoch : 20, Loss : 0.746189, Accuracy: 0.972000, Test accuracy: 0.970000
Distillation: Epoch : 21, Loss : 0.730431, Accuracy: 0.979000, Test accuracy: 0.970800
Distillation: Epoch : 22, Loss : 0.777538, Accuracy: 0.965000, Test accuracy: 0.971700
Distillation: Epoch : 23, Loss : 0.738212, Accuracy: 0.969000, Test accuracy: 0.972100
Distillation: Epoch : 24, Loss : 0.755562, Accuracy: 0.968000, Test accuracy: 0.972800
Distillation: Epoch : 25, Loss : 0.763659, Accuracy: 0.965000, Test accuracy: 0.972600
Distillation: Epoch : 26, Loss : 0.767364, Accuracy: 0.972000, Test accuracy: 0.973900
Distillation: Epoch : 27, Loss : 0.769565, Accuracy: 0.970000, Test accuracy: 0.973900
Distillation: Epoch : 28, Loss : 0.749099, Accuracy: 0.957000, Test accuracy: 0.975200
Distillation: Epoch : 29, Loss : 0.757932, Accuracy: 0.967000, Test accuracy: 0.975100
Distillation: Epoch : 30, Loss : 0.770393, Accuracy: 0.977000, Test accuracy: 0.975300
Distillation: Epoch : 31, Loss : 0.744480, Accuracy: 0.973000, Test accuracy: 0.975800
Distillation: Epoch : 32, Loss : 0.734068, Accuracy: 0.975000, Test accuracy: 0.976100
Distillation: Epoch : 33, Loss : 0.750041, Accuracy: 0.973000, Test accuracy: 0.976400
Distillation: Epoch : 34, Loss : 0.739269, Accuracy: 0.978000, Test accuracy: 0.976500
Distillation: Epoch : 35, Loss : 0.751545, Accuracy: 0.971000, Test accuracy: 0.977000
Distillation: Epoch : 36, Loss : 0.758923, Accuracy: 0.975000, Test accuracy: 0.976800
Distillation: Epoch : 37, Loss : 0.748193, Accuracy: 0.973000, Test accuracy: 0.977300
Distillation: Epoch : 38, Loss : 0.731061, Accuracy: 0.973000, Test accuracy: 0.978200
Distillation: Epoch : 39, Loss : 0.765292, Accuracy: 0.976000, Test accuracy: 0.976600
Distillation: Epoch : 40, Loss : 0.756778, Accuracy: 0.972000, Test accuracy: 0.977800
Distillation: Epoch : 41, Loss : 0.741969, Accuracy: 0.982000, Test accuracy: 0.977700
Distillation: Epoch : 42, Loss : 0.736281, Accuracy: 0.985000, Test accuracy: 0.978200
Distillation: Epoch : 43, Loss : 0.731889, Accuracy: 0.977000, Test accuracy: 0.978500
Distillation: Epoch : 44, Loss : 0.735168, Accuracy: 0.972000, Test accuracy: 0.977900
Distillation: Epoch : 45, Loss : 0.752467, Accuracy: 0.968000, Test accuracy: 0.978100
Distillation: Epoch : 46, Loss : 0.727066, Accuracy: 0.981000, Test accuracy: 0.979000
Distillation: Epoch : 47, Loss : 0.706582, Accuracy: 0.980000, Test accuracy: 0.978700
Distillation: Epoch : 48, Loss : 0.737902, Accuracy: 0.971000, Test accuracy: 0.979100
Distillation: Epoch : 49, Loss : 0.742046, Accuracy: 0.971000, Test accuracy: 0.979200
Distillation: Epoch : 50, Loss : 0.731755, Accuracy: 0.982000, Test accuracy: 0.978700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9787
Generating confusion matrix for student
[[ 975.    0.    8.    1.    1.    2.    7.    0.    5.    2.]
 [   0. 1125.    2.    0.    1.    0.    3.    4.    2.    7.]
 [   0.    4. 1003.    1.    3.    0.    0.    7.    4.    1.]
 [   0.    0.    3.  996.    0.    5.    1.    2.    6.    7.]
 [   0.    0.    1.    0.  961.    1.    1.    2.    3.    6.]
 [   0.    0.    0.    2.    0.  877.    4.    0.    1.    1.]
 [   2.    3.    1.    0.    1.    4.  938.    0.    2.    0.]
 [   1.    0.    6.    6.    2.    2.    0.  999.    7.    4.]
 [   2.    3.    8.    3.    2.    1.    4.    2.  933.    1.]
 [   0.    0.    0.    1.   11.    0.    0.   12.   11.  980.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.417431, Accuracy: 0.760000, Test accuracy: 0.774500
Distillation: Epoch : 2, Loss : 1.152471, Accuracy: 0.872000, Test accuracy: 0.855000
Distillation: Epoch : 3, Loss : 1.125402, Accuracy: 0.875000, Test accuracy: 0.881000
Distillation: Epoch : 4, Loss : 1.110599, Accuracy: 0.871000, Test accuracy: 0.893800
Distillation: Epoch : 5, Loss : 1.096387, Accuracy: 0.888000, Test accuracy: 0.904500
Distillation: Epoch : 6, Loss : 1.072114, Accuracy: 0.900000, Test accuracy: 0.910000
Distillation: Epoch : 7, Loss : 1.042058, Accuracy: 0.921000, Test accuracy: 0.917600
Distillation: Epoch : 8, Loss : 1.018223, Accuracy: 0.931000, Test accuracy: 0.925200
Distillation: Epoch : 9, Loss : 1.037818, Accuracy: 0.921000, Test accuracy: 0.930900
Distillation: Epoch : 10, Loss : 1.013680, Accuracy: 0.921000, Test accuracy: 0.936600
Distillation: Epoch : 11, Loss : 0.998545, Accuracy: 0.946000, Test accuracy: 0.942800
Distillation: Epoch : 12, Loss : 0.997467, Accuracy: 0.944000, Test accuracy: 0.948500
Distillation: Epoch : 13, Loss : 0.975346, Accuracy: 0.955000, Test accuracy: 0.951400
Distillation: Epoch : 14, Loss : 0.996922, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 15, Loss : 0.939813, Accuracy: 0.956000, Test accuracy: 0.955600
Distillation: Epoch : 16, Loss : 0.979689, Accuracy: 0.957000, Test accuracy: 0.959000
Distillation: Epoch : 17, Loss : 0.960765, Accuracy: 0.961000, Test accuracy: 0.960900
Distillation: Epoch : 18, Loss : 0.963831, Accuracy: 0.955000, Test accuracy: 0.962300
Distillation: Epoch : 19, Loss : 0.961715, Accuracy: 0.966000, Test accuracy: 0.964100
Distillation: Epoch : 20, Loss : 0.940445, Accuracy: 0.964000, Test accuracy: 0.965500
Distillation: Epoch : 21, Loss : 0.945468, Accuracy: 0.965000, Test accuracy: 0.966600
Distillation: Epoch : 22, Loss : 0.938093, Accuracy: 0.960000, Test accuracy: 0.966500
Distillation: Epoch : 23, Loss : 0.918999, Accuracy: 0.968000, Test accuracy: 0.968400
Distillation: Epoch : 24, Loss : 0.920293, Accuracy: 0.964000, Test accuracy: 0.968600
Distillation: Epoch : 25, Loss : 0.938336, Accuracy: 0.968000, Test accuracy: 0.968800
Distillation: Epoch : 26, Loss : 0.927911, Accuracy: 0.970000, Test accuracy: 0.969400
Distillation: Epoch : 27, Loss : 0.932711, Accuracy: 0.962000, Test accuracy: 0.970800
Distillation: Epoch : 28, Loss : 0.926610, Accuracy: 0.967000, Test accuracy: 0.971700
Distillation: Epoch : 29, Loss : 0.932913, Accuracy: 0.971000, Test accuracy: 0.971400
Distillation: Epoch : 30, Loss : 0.941671, Accuracy: 0.964000, Test accuracy: 0.971700
Distillation: Epoch : 31, Loss : 0.915269, Accuracy: 0.964000, Test accuracy: 0.972400
Distillation: Epoch : 32, Loss : 0.943721, Accuracy: 0.976000, Test accuracy: 0.975200
Distillation: Epoch : 33, Loss : 0.924185, Accuracy: 0.969000, Test accuracy: 0.974800
Distillation: Epoch : 34, Loss : 0.901124, Accuracy: 0.976000, Test accuracy: 0.975000
Distillation: Epoch : 35, Loss : 0.930354, Accuracy: 0.968000, Test accuracy: 0.974100
Distillation: Epoch : 36, Loss : 0.934772, Accuracy: 0.968000, Test accuracy: 0.974700
Distillation: Epoch : 37, Loss : 0.922677, Accuracy: 0.966000, Test accuracy: 0.975100
Distillation: Epoch : 38, Loss : 0.914951, Accuracy: 0.974000, Test accuracy: 0.975900
Distillation: Epoch : 39, Loss : 0.919434, Accuracy: 0.967000, Test accuracy: 0.976400
Distillation: Epoch : 40, Loss : 0.927937, Accuracy: 0.972000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 0.938753, Accuracy: 0.981000, Test accuracy: 0.977100
Distillation: Epoch : 42, Loss : 0.918633, Accuracy: 0.975000, Test accuracy: 0.977000
Distillation: Epoch : 43, Loss : 0.915788, Accuracy: 0.979000, Test accuracy: 0.977800
Distillation: Epoch : 44, Loss : 0.933942, Accuracy: 0.975000, Test accuracy: 0.977300
Distillation: Epoch : 45, Loss : 0.923266, Accuracy: 0.978000, Test accuracy: 0.977300
Distillation: Epoch : 46, Loss : 0.936441, Accuracy: 0.971000, Test accuracy: 0.978200
Distillation: Epoch : 47, Loss : 0.890180, Accuracy: 0.984000, Test accuracy: 0.977700
Distillation: Epoch : 48, Loss : 0.920542, Accuracy: 0.973000, Test accuracy: 0.978000
Distillation: Epoch : 49, Loss : 0.910253, Accuracy: 0.970000, Test accuracy: 0.978700
Distillation: Epoch : 50, Loss : 0.928930, Accuracy: 0.970000, Test accuracy: 0.978500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9785
Generating confusion matrix for student
[[ 973.    0.    5.    1.    0.    2.    1.    2.    5.    3.]
 [   0. 1129.    1.    0.    0.    0.    2.    3.    1.    5.]
 [   0.    2.  996.    0.    2.    0.    0.   15.    4.    1.]
 [   0.    0.    3.  980.    0.    2.    0.    3.    3.    2.]
 [   0.    1.    3.    0.  965.    0.    4.    2.    3.   11.]
 [   0.    0.    1.    9.    0.  880.    2.    0.    3.    0.]
 [   4.    1.    2.    0.    3.    3.  945.    0.    1.    0.]
 [   1.    1.    9.    9.    0.    2.    0.  995.    4.    4.]
 [   2.    1.   12.    7.    2.    1.    4.    1.  943.    4.]
 [   0.    0.    0.    4.   10.    2.    0.    7.    7.  979.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.560950, Accuracy: 0.764000, Test accuracy: 0.778900
Distillation: Epoch : 2, Loss : 1.276208, Accuracy: 0.874000, Test accuracy: 0.874700
Distillation: Epoch : 3, Loss : 1.261101, Accuracy: 0.876000, Test accuracy: 0.896600
Distillation: Epoch : 4, Loss : 1.200372, Accuracy: 0.913000, Test accuracy: 0.906300
Distillation: Epoch : 5, Loss : 1.192786, Accuracy: 0.919000, Test accuracy: 0.916800
Distillation: Epoch : 6, Loss : 1.200286, Accuracy: 0.925000, Test accuracy: 0.925000
Distillation: Epoch : 7, Loss : 1.193412, Accuracy: 0.916000, Test accuracy: 0.931800
Distillation: Epoch : 8, Loss : 1.176187, Accuracy: 0.931000, Test accuracy: 0.935600
Distillation: Epoch : 9, Loss : 1.159778, Accuracy: 0.936000, Test accuracy: 0.940700
Distillation: Epoch : 10, Loss : 1.155063, Accuracy: 0.934000, Test accuracy: 0.945900
Distillation: Epoch : 11, Loss : 1.165872, Accuracy: 0.945000, Test accuracy: 0.949000
Distillation: Epoch : 12, Loss : 1.147965, Accuracy: 0.952000, Test accuracy: 0.953300
Distillation: Epoch : 13, Loss : 1.126255, Accuracy: 0.945000, Test accuracy: 0.955800
Distillation: Epoch : 14, Loss : 1.113054, Accuracy: 0.968000, Test accuracy: 0.959100
Distillation: Epoch : 15, Loss : 1.108745, Accuracy: 0.970000, Test accuracy: 0.962400
Distillation: Epoch : 16, Loss : 1.126936, Accuracy: 0.945000, Test accuracy: 0.963500
Distillation: Epoch : 17, Loss : 1.113004, Accuracy: 0.953000, Test accuracy: 0.963800
Distillation: Epoch : 18, Loss : 1.095752, Accuracy: 0.960000, Test accuracy: 0.966200
Distillation: Epoch : 19, Loss : 1.118431, Accuracy: 0.968000, Test accuracy: 0.966700
Distillation: Epoch : 20, Loss : 1.115719, Accuracy: 0.958000, Test accuracy: 0.968500
Distillation: Epoch : 21, Loss : 1.105462, Accuracy: 0.971000, Test accuracy: 0.968300
Distillation: Epoch : 22, Loss : 1.080427, Accuracy: 0.981000, Test accuracy: 0.970200
Distillation: Epoch : 23, Loss : 1.084838, Accuracy: 0.973000, Test accuracy: 0.971400
Distillation: Epoch : 24, Loss : 1.089654, Accuracy: 0.971000, Test accuracy: 0.971900
Distillation: Epoch : 25, Loss : 1.106890, Accuracy: 0.965000, Test accuracy: 0.971600
Distillation: Epoch : 26, Loss : 1.111109, Accuracy: 0.973000, Test accuracy: 0.972500
Distillation: Epoch : 27, Loss : 1.095763, Accuracy: 0.964000, Test accuracy: 0.972900
Distillation: Epoch : 28, Loss : 1.107849, Accuracy: 0.968000, Test accuracy: 0.974400
Distillation: Epoch : 29, Loss : 1.077549, Accuracy: 0.979000, Test accuracy: 0.974100
Distillation: Epoch : 30, Loss : 1.113732, Accuracy: 0.970000, Test accuracy: 0.974200
Distillation: Epoch : 31, Loss : 1.048099, Accuracy: 0.977000, Test accuracy: 0.975000
Distillation: Epoch : 32, Loss : 1.083699, Accuracy: 0.970000, Test accuracy: 0.974900
Distillation: Epoch : 33, Loss : 1.106295, Accuracy: 0.964000, Test accuracy: 0.975500
Distillation: Epoch : 34, Loss : 1.097626, Accuracy: 0.969000, Test accuracy: 0.976300
Distillation: Epoch : 35, Loss : 1.077764, Accuracy: 0.972000, Test accuracy: 0.976100
Distillation: Epoch : 36, Loss : 1.090770, Accuracy: 0.974000, Test accuracy: 0.976200
Distillation: Epoch : 37, Loss : 1.102694, Accuracy: 0.972000, Test accuracy: 0.977100
Distillation: Epoch : 38, Loss : 1.068847, Accuracy: 0.980000, Test accuracy: 0.977100
Distillation: Epoch : 39, Loss : 1.078596, Accuracy: 0.975000, Test accuracy: 0.977300
Distillation: Epoch : 40, Loss : 1.060974, Accuracy: 0.974000, Test accuracy: 0.977000
Distillation: Epoch : 41, Loss : 1.100121, Accuracy: 0.962000, Test accuracy: 0.977500
Distillation: Epoch : 42, Loss : 1.093870, Accuracy: 0.972000, Test accuracy: 0.977700
Distillation: Epoch : 43, Loss : 1.085249, Accuracy: 0.976000, Test accuracy: 0.978100
Distillation: Epoch : 44, Loss : 1.076384, Accuracy: 0.975000, Test accuracy: 0.977800
Distillation: Epoch : 45, Loss : 1.104895, Accuracy: 0.975000, Test accuracy: 0.977900
Distillation: Epoch : 46, Loss : 1.089308, Accuracy: 0.972000, Test accuracy: 0.977800
Distillation: Epoch : 47, Loss : 1.085714, Accuracy: 0.980000, Test accuracy: 0.978500
Distillation: Epoch : 48, Loss : 1.072905, Accuracy: 0.969000, Test accuracy: 0.978400
Distillation: Epoch : 49, Loss : 1.081494, Accuracy: 0.981000, Test accuracy: 0.979400
Distillation: Epoch : 50, Loss : 1.078339, Accuracy: 0.970000, Test accuracy: 0.978800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9788
Generating confusion matrix for student
[[ 971.    0.    3.    1.    1.    1.    4.    2.    7.    2.]
 [   1. 1129.    5.    0.    1.    0.    2.    7.    1.    7.]
 [   0.    3. 1000.    0.    1.    1.    0.   10.    5.    0.]
 [   0.    0.    4.  989.    0.    4.    1.    2.    3.    5.]
 [   0.    1.    5.    0.  973.    1.    2.    3.    4.   11.]
 [   1.    1.    0.    5.    0.  876.    4.    0.    6.    5.]
 [   3.    1.    1.    0.    0.    3.  945.    0.    1.    1.]
 [   1.    0.    4.    8.    0.    1.    0.  997.    2.    4.]
 [   2.    0.   10.    6.    2.    1.    0.    1.  935.    1.]
 [   1.    0.    0.    1.    4.    4.    0.    6.   10.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.699057, Accuracy: 0.745000, Test accuracy: 0.761400
Distillation: Epoch : 2, Loss : 1.455538, Accuracy: 0.849000, Test accuracy: 0.858900
Distillation: Epoch : 3, Loss : 1.394547, Accuracy: 0.899000, Test accuracy: 0.890000
Distillation: Epoch : 4, Loss : 1.394975, Accuracy: 0.903000, Test accuracy: 0.906800
Distillation: Epoch : 5, Loss : 1.341622, Accuracy: 0.911000, Test accuracy: 0.917700
Distillation: Epoch : 6, Loss : 1.323780, Accuracy: 0.930000, Test accuracy: 0.924600
Distillation: Epoch : 7, Loss : 1.327528, Accuracy: 0.920000, Test accuracy: 0.931500
Distillation: Epoch : 8, Loss : 1.312041, Accuracy: 0.933000, Test accuracy: 0.939800
Distillation: Epoch : 9, Loss : 1.270497, Accuracy: 0.957000, Test accuracy: 0.944900
Distillation: Epoch : 10, Loss : 1.274678, Accuracy: 0.945000, Test accuracy: 0.948300
Distillation: Epoch : 11, Loss : 1.281200, Accuracy: 0.955000, Test accuracy: 0.952200
Distillation: Epoch : 12, Loss : 1.297056, Accuracy: 0.957000, Test accuracy: 0.956000
Distillation: Epoch : 13, Loss : 1.262721, Accuracy: 0.968000, Test accuracy: 0.959300
Distillation: Epoch : 14, Loss : 1.256400, Accuracy: 0.956000, Test accuracy: 0.960500
Distillation: Epoch : 15, Loss : 1.262639, Accuracy: 0.968000, Test accuracy: 0.962800
Distillation: Epoch : 16, Loss : 1.268448, Accuracy: 0.952000, Test accuracy: 0.964400
Distillation: Epoch : 17, Loss : 1.269668, Accuracy: 0.963000, Test accuracy: 0.966000
Distillation: Epoch : 18, Loss : 1.266147, Accuracy: 0.965000, Test accuracy: 0.966400
Distillation: Epoch : 19, Loss : 1.255371, Accuracy: 0.955000, Test accuracy: 0.968300
Distillation: Epoch : 20, Loss : 1.282157, Accuracy: 0.965000, Test accuracy: 0.968900
Distillation: Epoch : 21, Loss : 1.247201, Accuracy: 0.972000, Test accuracy: 0.970000
Distillation: Epoch : 22, Loss : 1.278820, Accuracy: 0.957000, Test accuracy: 0.969700
Distillation: Epoch : 23, Loss : 1.234318, Accuracy: 0.967000, Test accuracy: 0.970100
Distillation: Epoch : 24, Loss : 1.274149, Accuracy: 0.970000, Test accuracy: 0.971200
Distillation: Epoch : 25, Loss : 1.241102, Accuracy: 0.978000, Test accuracy: 0.972400
Distillation: Epoch : 26, Loss : 1.240776, Accuracy: 0.977000, Test accuracy: 0.972400
Distillation: Epoch : 27, Loss : 1.256532, Accuracy: 0.963000, Test accuracy: 0.972600
Distillation: Epoch : 28, Loss : 1.269951, Accuracy: 0.967000, Test accuracy: 0.973400
Distillation: Epoch : 29, Loss : 1.233875, Accuracy: 0.975000, Test accuracy: 0.973500
Distillation: Epoch : 30, Loss : 1.250464, Accuracy: 0.969000, Test accuracy: 0.973100
Distillation: Epoch : 31, Loss : 1.225304, Accuracy: 0.963000, Test accuracy: 0.974200
Distillation: Epoch : 32, Loss : 1.230816, Accuracy: 0.975000, Test accuracy: 0.974800
Distillation: Epoch : 33, Loss : 1.212213, Accuracy: 0.973000, Test accuracy: 0.975100
Distillation: Epoch : 34, Loss : 1.232195, Accuracy: 0.971000, Test accuracy: 0.974800
Distillation: Epoch : 35, Loss : 1.232185, Accuracy: 0.977000, Test accuracy: 0.975400
Distillation: Epoch : 36, Loss : 1.240316, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 37, Loss : 1.228103, Accuracy: 0.972000, Test accuracy: 0.975600
Distillation: Epoch : 38, Loss : 1.240577, Accuracy: 0.975000, Test accuracy: 0.975700
Distillation: Epoch : 39, Loss : 1.229607, Accuracy: 0.971000, Test accuracy: 0.977000
Distillation: Epoch : 40, Loss : 1.250143, Accuracy: 0.971000, Test accuracy: 0.976400
Distillation: Epoch : 41, Loss : 1.242907, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 42, Loss : 1.231684, Accuracy: 0.965000, Test accuracy: 0.977000
Distillation: Epoch : 43, Loss : 1.225720, Accuracy: 0.974000, Test accuracy: 0.977600
Distillation: Epoch : 44, Loss : 1.215446, Accuracy: 0.981000, Test accuracy: 0.977600
Distillation: Epoch : 45, Loss : 1.235274, Accuracy: 0.971000, Test accuracy: 0.977600
Distillation: Epoch : 46, Loss : 1.249985, Accuracy: 0.969000, Test accuracy: 0.977400
Distillation: Epoch : 47, Loss : 1.232485, Accuracy: 0.977000, Test accuracy: 0.978100
Distillation: Epoch : 48, Loss : 1.237352, Accuracy: 0.973000, Test accuracy: 0.978200
Distillation: Epoch : 49, Loss : 1.230172, Accuracy: 0.978000, Test accuracy: 0.978800
Distillation: Epoch : 50, Loss : 1.222017, Accuracy: 0.977000, Test accuracy: 0.979100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9791
Generating confusion matrix for student
[[ 974.    0.    7.    2.    0.    3.    2.    0.    3.    5.]
 [   0. 1129.    1.    0.    1.    0.    3.    3.    1.    6.]
 [   0.    3.  997.    3.    1.    0.    0.    9.    5.    0.]
 [   0.    1.    5.  985.    0.    2.    0.    1.    3.    3.]
 [   0.    0.    3.    0.  967.    1.    3.    2.    4.    7.]
 [   0.    0.    0.    6.    0.  874.    5.    0.    2.    1.]
 [   4.    0.    3.    0.    0.    4.  942.    0.    3.    0.]
 [   1.    0.    6.    7.    2.    2.    0. 1004.    3.    7.]
 [   1.    2.   10.    5.    3.    3.    3.    1.  940.    1.]
 [   0.    0.    0.    2.    8.    3.    0.    8.   10.  979.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.720565, Accuracy: 0.781000, Test accuracy: 0.779500
Distillation: Epoch : 2, Loss : 1.559399, Accuracy: 0.829000, Test accuracy: 0.857000
Distillation: Epoch : 3, Loss : 1.567645, Accuracy: 0.852000, Test accuracy: 0.881900
Distillation: Epoch : 4, Loss : 1.472695, Accuracy: 0.889000, Test accuracy: 0.898200
Distillation: Epoch : 5, Loss : 1.475132, Accuracy: 0.915000, Test accuracy: 0.909800
Distillation: Epoch : 6, Loss : 1.452375, Accuracy: 0.911000, Test accuracy: 0.919600
Distillation: Epoch : 7, Loss : 1.439023, Accuracy: 0.915000, Test accuracy: 0.926900
Distillation: Epoch : 8, Loss : 1.439632, Accuracy: 0.915000, Test accuracy: 0.935300
Distillation: Epoch : 9, Loss : 1.420778, Accuracy: 0.946000, Test accuracy: 0.942200
Distillation: Epoch : 10, Loss : 1.427820, Accuracy: 0.932000, Test accuracy: 0.949000
Distillation: Epoch : 11, Loss : 1.394043, Accuracy: 0.949000, Test accuracy: 0.953100
Distillation: Epoch : 12, Loss : 1.411330, Accuracy: 0.951000, Test accuracy: 0.955600
Distillation: Epoch : 13, Loss : 1.373149, Accuracy: 0.957000, Test accuracy: 0.958600
Distillation: Epoch : 14, Loss : 1.394132, Accuracy: 0.961000, Test accuracy: 0.960600
Distillation: Epoch : 15, Loss : 1.418466, Accuracy: 0.952000, Test accuracy: 0.964700
Distillation: Epoch : 16, Loss : 1.378996, Accuracy: 0.964000, Test accuracy: 0.963600
Distillation: Epoch : 17, Loss : 1.383397, Accuracy: 0.956000, Test accuracy: 0.965100
Distillation: Epoch : 18, Loss : 1.403457, Accuracy: 0.961000, Test accuracy: 0.967000
Distillation: Epoch : 19, Loss : 1.414060, Accuracy: 0.957000, Test accuracy: 0.968200
Distillation: Epoch : 20, Loss : 1.383217, Accuracy: 0.971000, Test accuracy: 0.969200
Distillation: Epoch : 21, Loss : 1.383524, Accuracy: 0.967000, Test accuracy: 0.969500
Distillation: Epoch : 22, Loss : 1.407551, Accuracy: 0.966000, Test accuracy: 0.970800
Distillation: Epoch : 23, Loss : 1.386649, Accuracy: 0.966000, Test accuracy: 0.971500
Distillation: Epoch : 24, Loss : 1.379509, Accuracy: 0.965000, Test accuracy: 0.972100
Distillation: Epoch : 25, Loss : 1.381824, Accuracy: 0.968000, Test accuracy: 0.972700
Distillation: Epoch : 26, Loss : 1.398697, Accuracy: 0.962000, Test accuracy: 0.972800
Distillation: Epoch : 27, Loss : 1.351111, Accuracy: 0.975000, Test accuracy: 0.973900
Distillation: Epoch : 28, Loss : 1.395911, Accuracy: 0.954000, Test accuracy: 0.973000
Distillation: Epoch : 29, Loss : 1.345092, Accuracy: 0.973000, Test accuracy: 0.973800
Distillation: Epoch : 30, Loss : 1.350070, Accuracy: 0.972000, Test accuracy: 0.973600
Distillation: Epoch : 31, Loss : 1.393332, Accuracy: 0.964000, Test accuracy: 0.973900
Distillation: Epoch : 32, Loss : 1.383314, Accuracy: 0.968000, Test accuracy: 0.974200
Distillation: Epoch : 33, Loss : 1.376551, Accuracy: 0.970000, Test accuracy: 0.974600
Distillation: Epoch : 34, Loss : 1.373023, Accuracy: 0.974000, Test accuracy: 0.975300
Distillation: Epoch : 35, Loss : 1.389228, Accuracy: 0.972000, Test accuracy: 0.976300
Distillation: Epoch : 36, Loss : 1.373455, Accuracy: 0.969000, Test accuracy: 0.975800
Distillation: Epoch : 37, Loss : 1.379098, Accuracy: 0.973000, Test accuracy: 0.976600
Distillation: Epoch : 38, Loss : 1.356731, Accuracy: 0.973000, Test accuracy: 0.976500
Distillation: Epoch : 39, Loss : 1.376189, Accuracy: 0.977000, Test accuracy: 0.977300
Distillation: Epoch : 40, Loss : 1.386302, Accuracy: 0.970000, Test accuracy: 0.976900
Distillation: Epoch : 41, Loss : 1.362456, Accuracy: 0.977000, Test accuracy: 0.977400
Distillation: Epoch : 42, Loss : 1.374297, Accuracy: 0.974000, Test accuracy: 0.977500
Distillation: Epoch : 43, Loss : 1.380668, Accuracy: 0.971000, Test accuracy: 0.978000
Distillation: Epoch : 44, Loss : 1.369577, Accuracy: 0.977000, Test accuracy: 0.977600
Distillation: Epoch : 45, Loss : 1.361868, Accuracy: 0.977000, Test accuracy: 0.976900
Distillation: Epoch : 46, Loss : 1.372198, Accuracy: 0.969000, Test accuracy: 0.978000
Distillation: Epoch : 47, Loss : 1.371142, Accuracy: 0.971000, Test accuracy: 0.978100
Distillation: Epoch : 48, Loss : 1.343252, Accuracy: 0.982000, Test accuracy: 0.978600
Distillation: Epoch : 49, Loss : 1.380058, Accuracy: 0.972000, Test accuracy: 0.978600
Distillation: Epoch : 50, Loss : 1.358553, Accuracy: 0.987000, Test accuracy: 0.979100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9791
Generating confusion matrix for student
[[ 973.    0.    6.    1.    1.    1.    5.    0.    9.    2.]
 [   1. 1126.    3.    0.    0.    0.    3.    1.    0.    7.]
 [   0.    1. 1001.    3.    1.    1.    0.    8.    5.    0.]
 [   0.    2.    6.  991.    0.    6.    0.    2.    5.    5.]
 [   0.    0.    1.    0.  967.    1.    1.    3.    4.    8.]
 [   0.    0.    0.    5.    0.  875.    6.    0.    7.    2.]
 [   2.    4.    1.    0.    3.    3.  941.    0.    1.    0.]
 [   2.    0.    5.    6.    0.    1.    0. 1006.    4.    4.]
 [   2.    2.    8.    2.    1.    2.    2.    1.  932.    2.]
 [   0.    0.    1.    2.    9.    2.    0.    7.    7.  979.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.958637, Accuracy: 0.721000, Test accuracy: 0.727300
Distillation: Epoch : 2, Loss : 1.849012, Accuracy: 0.819000, Test accuracy: 0.830900
Distillation: Epoch : 3, Loss : 1.812238, Accuracy: 0.838000, Test accuracy: 0.857200
Distillation: Epoch : 4, Loss : 1.772750, Accuracy: 0.891000, Test accuracy: 0.880700
Distillation: Epoch : 5, Loss : 1.777208, Accuracy: 0.893000, Test accuracy: 0.895200
Distillation: Epoch : 6, Loss : 1.745989, Accuracy: 0.912000, Test accuracy: 0.908400
Distillation: Epoch : 7, Loss : 1.757027, Accuracy: 0.903000, Test accuracy: 0.920000
Distillation: Epoch : 8, Loss : 1.745842, Accuracy: 0.911000, Test accuracy: 0.927500
Distillation: Epoch : 9, Loss : 1.752250, Accuracy: 0.924000, Test accuracy: 0.932500
Distillation: Epoch : 10, Loss : 1.731043, Accuracy: 0.924000, Test accuracy: 0.936600
Distillation: Epoch : 11, Loss : 1.708355, Accuracy: 0.935000, Test accuracy: 0.940500
Distillation: Epoch : 12, Loss : 1.709275, Accuracy: 0.942000, Test accuracy: 0.946400
Distillation: Epoch : 13, Loss : 1.724468, Accuracy: 0.943000, Test accuracy: 0.948600
Distillation: Epoch : 14, Loss : 1.698787, Accuracy: 0.949000, Test accuracy: 0.951700
Distillation: Epoch : 15, Loss : 1.710026, Accuracy: 0.954000, Test accuracy: 0.953000
Distillation: Epoch : 16, Loss : 1.691111, Accuracy: 0.968000, Test accuracy: 0.954600
Distillation: Epoch : 17, Loss : 1.704216, Accuracy: 0.955000, Test accuracy: 0.956200
Distillation: Epoch : 18, Loss : 1.709821, Accuracy: 0.953000, Test accuracy: 0.957400
Distillation: Epoch : 19, Loss : 1.705378, Accuracy: 0.956000, Test accuracy: 0.958800
Distillation: Epoch : 20, Loss : 1.698920, Accuracy: 0.951000, Test accuracy: 0.959900
Distillation: Epoch : 21, Loss : 1.699309, Accuracy: 0.965000, Test accuracy: 0.962500
Distillation: Epoch : 22, Loss : 1.701735, Accuracy: 0.957000, Test accuracy: 0.963600
Distillation: Epoch : 23, Loss : 1.685571, Accuracy: 0.976000, Test accuracy: 0.964700
Distillation: Epoch : 24, Loss : 1.687073, Accuracy: 0.969000, Test accuracy: 0.965700
Distillation: Epoch : 25, Loss : 1.695883, Accuracy: 0.952000, Test accuracy: 0.965600
Distillation: Epoch : 26, Loss : 1.697893, Accuracy: 0.968000, Test accuracy: 0.966800
Distillation: Epoch : 27, Loss : 1.691674, Accuracy: 0.971000, Test accuracy: 0.968200
Distillation: Epoch : 28, Loss : 1.699613, Accuracy: 0.968000, Test accuracy: 0.967700
Distillation: Epoch : 29, Loss : 1.699494, Accuracy: 0.965000, Test accuracy: 0.968200
Distillation: Epoch : 30, Loss : 1.688773, Accuracy: 0.961000, Test accuracy: 0.968300
Distillation: Epoch : 31, Loss : 1.691748, Accuracy: 0.973000, Test accuracy: 0.969800
Distillation: Epoch : 32, Loss : 1.694765, Accuracy: 0.965000, Test accuracy: 0.969400
Distillation: Epoch : 33, Loss : 1.703003, Accuracy: 0.967000, Test accuracy: 0.969100
Distillation: Epoch : 34, Loss : 1.676634, Accuracy: 0.968000, Test accuracy: 0.970400
Distillation: Epoch : 35, Loss : 1.680854, Accuracy: 0.960000, Test accuracy: 0.970700
Distillation: Epoch : 36, Loss : 1.680027, Accuracy: 0.963000, Test accuracy: 0.969900
Distillation: Epoch : 37, Loss : 1.688391, Accuracy: 0.964000, Test accuracy: 0.971300
Distillation: Epoch : 38, Loss : 1.683026, Accuracy: 0.963000, Test accuracy: 0.971100
Distillation: Epoch : 39, Loss : 1.696232, Accuracy: 0.955000, Test accuracy: 0.972300
Distillation: Epoch : 40, Loss : 1.683680, Accuracy: 0.964000, Test accuracy: 0.971600
Distillation: Epoch : 41, Loss : 1.691004, Accuracy: 0.973000, Test accuracy: 0.971900
Distillation: Epoch : 42, Loss : 1.668308, Accuracy: 0.978000, Test accuracy: 0.972700
Distillation: Epoch : 43, Loss : 1.685861, Accuracy: 0.967000, Test accuracy: 0.971800
Distillation: Epoch : 44, Loss : 1.681619, Accuracy: 0.966000, Test accuracy: 0.972100
Distillation: Epoch : 45, Loss : 1.684679, Accuracy: 0.966000, Test accuracy: 0.973300
Distillation: Epoch : 46, Loss : 1.691464, Accuracy: 0.979000, Test accuracy: 0.973100
Distillation: Epoch : 47, Loss : 1.667835, Accuracy: 0.971000, Test accuracy: 0.973100
Distillation: Epoch : 48, Loss : 1.697355, Accuracy: 0.970000, Test accuracy: 0.973200
Distillation: Epoch : 49, Loss : 1.664124, Accuracy: 0.958000, Test accuracy: 0.973300
Distillation: Epoch : 50, Loss : 1.688083, Accuracy: 0.969000, Test accuracy: 0.973700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9737
Generating confusion matrix for student
[[ 973.    0.    8.    0.    1.    4.    7.    1.    7.    5.]
 [   0. 1125.    3.    0.    0.    0.    3.    5.    1.    6.]
 [   0.    3.  989.    1.    2.    0.    0.    8.    4.    0.]
 [   0.    1.    5.  986.    0.   10.    0.    0.   10.    8.]
 [   1.    0.    4.    0.  967.    0.    3.    2.    5.   11.]
 [   1.    0.    0.    5.    0.  867.   10.    0.    4.    1.]
 [   3.    4.    4.    0.    3.    4.  933.    0.    1.    1.]
 [   1.    0.    8.   10.    1.    2.    0. 1000.    4.    7.]
 [   1.    1.   11.    7.    1.    4.    2.    1.  930.    3.]
 [   0.    1.    0.    1.    7.    1.    0.   11.    8.  967.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.116304, Accuracy: 0.771000, Test accuracy: 0.798100
Distillation: Epoch : 2, Loss : 2.042902, Accuracy: 0.851000, Test accuracy: 0.858500
Distillation: Epoch : 3, Loss : 2.023060, Accuracy: 0.884000, Test accuracy: 0.890400
Distillation: Epoch : 4, Loss : 2.013798, Accuracy: 0.902000, Test accuracy: 0.910700
Distillation: Epoch : 5, Loss : 1.999912, Accuracy: 0.927000, Test accuracy: 0.924300
Distillation: Epoch : 6, Loss : 1.991199, Accuracy: 0.916000, Test accuracy: 0.931500
Distillation: Epoch : 7, Loss : 1.989009, Accuracy: 0.921000, Test accuracy: 0.939000
Distillation: Epoch : 8, Loss : 1.980530, Accuracy: 0.947000, Test accuracy: 0.941400
Distillation: Epoch : 9, Loss : 1.978822, Accuracy: 0.936000, Test accuracy: 0.946600
Distillation: Epoch : 10, Loss : 1.981707, Accuracy: 0.948000, Test accuracy: 0.949800
Distillation: Epoch : 11, Loss : 1.982420, Accuracy: 0.948000, Test accuracy: 0.952800
Distillation: Epoch : 12, Loss : 1.973621, Accuracy: 0.960000, Test accuracy: 0.955100
Distillation: Epoch : 13, Loss : 1.971177, Accuracy: 0.952000, Test accuracy: 0.957200
Distillation: Epoch : 14, Loss : 1.975442, Accuracy: 0.942000, Test accuracy: 0.958600
Distillation: Epoch : 15, Loss : 1.976395, Accuracy: 0.946000, Test accuracy: 0.960500
Distillation: Epoch : 16, Loss : 1.975238, Accuracy: 0.963000, Test accuracy: 0.962400
Distillation: Epoch : 17, Loss : 1.976491, Accuracy: 0.961000, Test accuracy: 0.965000
Distillation: Epoch : 18, Loss : 1.964860, Accuracy: 0.957000, Test accuracy: 0.965600
Distillation: Epoch : 19, Loss : 1.965397, Accuracy: 0.960000, Test accuracy: 0.966700
Distillation: Epoch : 20, Loss : 1.956937, Accuracy: 0.953000, Test accuracy: 0.967000
Distillation: Epoch : 21, Loss : 1.970311, Accuracy: 0.971000, Test accuracy: 0.967500
Distillation: Epoch : 22, Loss : 1.970371, Accuracy: 0.968000, Test accuracy: 0.968300
Distillation: Epoch : 23, Loss : 1.970120, Accuracy: 0.972000, Test accuracy: 0.968700
Distillation: Epoch : 24, Loss : 1.959852, Accuracy: 0.971000, Test accuracy: 0.970600
Distillation: Epoch : 25, Loss : 1.971916, Accuracy: 0.966000, Test accuracy: 0.970700
Distillation: Epoch : 26, Loss : 1.969262, Accuracy: 0.970000, Test accuracy: 0.971400
Distillation: Epoch : 27, Loss : 1.957717, Accuracy: 0.971000, Test accuracy: 0.971600
Distillation: Epoch : 28, Loss : 1.964418, Accuracy: 0.961000, Test accuracy: 0.972300
Distillation: Epoch : 29, Loss : 1.964384, Accuracy: 0.974000, Test accuracy: 0.971900
Distillation: Epoch : 30, Loss : 1.956445, Accuracy: 0.966000, Test accuracy: 0.973200
Distillation: Epoch : 31, Loss : 1.967474, Accuracy: 0.971000, Test accuracy: 0.973000
Distillation: Epoch : 32, Loss : 1.971927, Accuracy: 0.963000, Test accuracy: 0.973500
Distillation: Epoch : 33, Loss : 1.956692, Accuracy: 0.974000, Test accuracy: 0.973700
Distillation: Epoch : 34, Loss : 1.960279, Accuracy: 0.967000, Test accuracy: 0.973200
Distillation: Epoch : 35, Loss : 1.958636, Accuracy: 0.971000, Test accuracy: 0.974100
Distillation: Epoch : 36, Loss : 1.961881, Accuracy: 0.968000, Test accuracy: 0.974200
Distillation: Epoch : 37, Loss : 1.956662, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 38, Loss : 1.960534, Accuracy: 0.975000, Test accuracy: 0.975100
Distillation: Epoch : 39, Loss : 1.959585, Accuracy: 0.966000, Test accuracy: 0.975300
Distillation: Epoch : 40, Loss : 1.954812, Accuracy: 0.976000, Test accuracy: 0.975300
Distillation: Epoch : 41, Loss : 1.964897, Accuracy: 0.969000, Test accuracy: 0.975400
Distillation: Epoch : 42, Loss : 1.961737, Accuracy: 0.969000, Test accuracy: 0.975900
Distillation: Epoch : 43, Loss : 1.957110, Accuracy: 0.974000, Test accuracy: 0.975200
Distillation: Epoch : 44, Loss : 1.960078, Accuracy: 0.981000, Test accuracy: 0.975800
Distillation: Epoch : 45, Loss : 1.956356, Accuracy: 0.974000, Test accuracy: 0.975700
Distillation: Epoch : 46, Loss : 1.969476, Accuracy: 0.982000, Test accuracy: 0.976500
Distillation: Epoch : 47, Loss : 1.971661, Accuracy: 0.983000, Test accuracy: 0.976700
Distillation: Epoch : 48, Loss : 1.970281, Accuracy: 0.980000, Test accuracy: 0.976600
Distillation: Epoch : 49, Loss : 1.960398, Accuracy: 0.981000, Test accuracy: 0.976600
Distillation: Epoch : 50, Loss : 1.954954, Accuracy: 0.979000, Test accuracy: 0.976600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9766
Generating confusion matrix for student
[[ 973.    0.    9.    1.    1.    1.    7.    1.    5.    3.]
 [   0. 1127.    2.    0.    0.    0.    2.    6.    1.    5.]
 [   0.    2.  986.    1.    1.    0.    0.    9.    4.    0.]
 [   0.    1.    7.  984.    0.    5.    0.    2.    6.    3.]
 [   0.    0.    6.    0.  971.    1.    2.    2.    3.   13.]
 [   0.    0.    0.    8.    0.  876.   10.    0.    6.    2.]
 [   3.    3.    2.    0.    1.    5.  937.    0.    1.    0.]
 [   1.    1.    9.    8.    0.    1.    0. 1001.    4.    5.]
 [   3.    1.   11.    3.    2.    0.    0.    1.  934.    1.]
 [   0.    0.    0.    5.    6.    3.    0.    6.   10.  977.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.644225, Accuracy: 0.823000, Test accuracy: 0.842100
Distillation: Epoch : 2, Loss : 0.454853, Accuracy: 0.861000, Test accuracy: 0.882300
Distillation: Epoch : 3, Loss : 0.363755, Accuracy: 0.895000, Test accuracy: 0.896300
Distillation: Epoch : 4, Loss : 0.323102, Accuracy: 0.916000, Test accuracy: 0.901400
Distillation: Epoch : 5, Loss : 0.351770, Accuracy: 0.896000, Test accuracy: 0.906900
Distillation: Epoch : 6, Loss : 0.364132, Accuracy: 0.890000, Test accuracy: 0.907000
Distillation: Epoch : 7, Loss : 0.328189, Accuracy: 0.898000, Test accuracy: 0.909500
Distillation: Epoch : 8, Loss : 0.288976, Accuracy: 0.917000, Test accuracy: 0.911700
Distillation: Epoch : 9, Loss : 0.286280, Accuracy: 0.923000, Test accuracy: 0.914000
Distillation: Epoch : 10, Loss : 0.312889, Accuracy: 0.905000, Test accuracy: 0.914900
Distillation: Epoch : 11, Loss : 0.275670, Accuracy: 0.919000, Test accuracy: 0.913800
Distillation: Epoch : 12, Loss : 0.337080, Accuracy: 0.901000, Test accuracy: 0.916400
Distillation: Epoch : 13, Loss : 0.329882, Accuracy: 0.908000, Test accuracy: 0.918200
Distillation: Epoch : 14, Loss : 0.311090, Accuracy: 0.915000, Test accuracy: 0.918400
Distillation: Epoch : 15, Loss : 0.312005, Accuracy: 0.901000, Test accuracy: 0.920200
Distillation: Epoch : 16, Loss : 0.320844, Accuracy: 0.910000, Test accuracy: 0.921800
Distillation: Epoch : 17, Loss : 0.282469, Accuracy: 0.920000, Test accuracy: 0.921800
Distillation: Epoch : 18, Loss : 0.275776, Accuracy: 0.914000, Test accuracy: 0.921300
Distillation: Epoch : 19, Loss : 0.256085, Accuracy: 0.920000, Test accuracy: 0.923900
Distillation: Epoch : 20, Loss : 0.296456, Accuracy: 0.909000, Test accuracy: 0.924700
Distillation: Epoch : 21, Loss : 0.326837, Accuracy: 0.894000, Test accuracy: 0.925500
Distillation: Epoch : 22, Loss : 0.266388, Accuracy: 0.916000, Test accuracy: 0.925100
Distillation: Epoch : 23, Loss : 0.244218, Accuracy: 0.931000, Test accuracy: 0.926200
Distillation: Epoch : 24, Loss : 0.264477, Accuracy: 0.925000, Test accuracy: 0.929800
Distillation: Epoch : 25, Loss : 0.281648, Accuracy: 0.922000, Test accuracy: 0.929700
Distillation: Epoch : 26, Loss : 0.230433, Accuracy: 0.935000, Test accuracy: 0.929300
Distillation: Epoch : 27, Loss : 0.219822, Accuracy: 0.939000, Test accuracy: 0.931900
Distillation: Epoch : 28, Loss : 0.245413, Accuracy: 0.936000, Test accuracy: 0.932800
Distillation: Epoch : 29, Loss : 0.188070, Accuracy: 0.946000, Test accuracy: 0.933900
Distillation: Epoch : 30, Loss : 0.215586, Accuracy: 0.935000, Test accuracy: 0.934400
Distillation: Epoch : 31, Loss : 0.224607, Accuracy: 0.936000, Test accuracy: 0.935600
Distillation: Epoch : 32, Loss : 0.203378, Accuracy: 0.940000, Test accuracy: 0.937000
Distillation: Epoch : 33, Loss : 0.195368, Accuracy: 0.933000, Test accuracy: 0.937100
Distillation: Epoch : 34, Loss : 0.227832, Accuracy: 0.931000, Test accuracy: 0.939300
Distillation: Epoch : 35, Loss : 0.161382, Accuracy: 0.949000, Test accuracy: 0.940000
Distillation: Epoch : 36, Loss : 0.250696, Accuracy: 0.927000, Test accuracy: 0.941500
Distillation: Epoch : 37, Loss : 0.227598, Accuracy: 0.934000, Test accuracy: 0.943700
Distillation: Epoch : 38, Loss : 0.192162, Accuracy: 0.951000, Test accuracy: 0.943400
Distillation: Epoch : 39, Loss : 0.238254, Accuracy: 0.930000, Test accuracy: 0.944600
Distillation: Epoch : 40, Loss : 0.195155, Accuracy: 0.944000, Test accuracy: 0.944200
Distillation: Epoch : 41, Loss : 0.230256, Accuracy: 0.938000, Test accuracy: 0.945800
Distillation: Epoch : 42, Loss : 0.186528, Accuracy: 0.948000, Test accuracy: 0.946900
Distillation: Epoch : 43, Loss : 0.187107, Accuracy: 0.945000, Test accuracy: 0.947800
Distillation: Epoch : 44, Loss : 0.185113, Accuracy: 0.950000, Test accuracy: 0.948600
Distillation: Epoch : 45, Loss : 0.204725, Accuracy: 0.944000, Test accuracy: 0.948500
Distillation: Epoch : 46, Loss : 0.162709, Accuracy: 0.948000, Test accuracy: 0.949100
Distillation: Epoch : 47, Loss : 0.200211, Accuracy: 0.949000, Test accuracy: 0.950900
Distillation: Epoch : 48, Loss : 0.161977, Accuracy: 0.948000, Test accuracy: 0.950900
Distillation: Epoch : 49, Loss : 0.172367, Accuracy: 0.945000, Test accuracy: 0.952000
Distillation: Epoch : 50, Loss : 0.130936, Accuracy: 0.959000, Test accuracy: 0.951900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9519
Generating confusion matrix for student2
[[ 961.    0.    5.    0.    0.    7.    8.    1.    4.   10.]
 [   0. 1120.    2.    0.    0.    2.    3.    3.    3.    5.]
 [   5.    3.  976.   17.    5.    1.    4.   18.    7.    3.]
 [   1.    2.    9.  958.    1.    9.    1.    7.   15.    4.]
 [   0.    1.    8.    0.  931.    2.    7.    5.    7.   13.]
 [   6.    2.    0.   10.    1.  837.   11.    2.   15.    4.]
 [   4.    2.    2.    1.    7.    9.  916.    0.    2.    1.]
 [   2.    2.    7.    8.    3.    6.    3.  971.    6.   15.]
 [   1.    3.   18.   11.    7.   15.    5.    3.  906.   11.]
 [   0.    0.    5.    5.   27.    4.    0.   18.    9.  943.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.044102, Accuracy: 0.820000, Test accuracy: 0.816300
Distillation: Epoch : 2, Loss : 0.560729, Accuracy: 0.865000, Test accuracy: 0.867000
Distillation: Epoch : 3, Loss : 0.434513, Accuracy: 0.884000, Test accuracy: 0.890700
Distillation: Epoch : 4, Loss : 0.389693, Accuracy: 0.892000, Test accuracy: 0.901200
Distillation: Epoch : 5, Loss : 0.352302, Accuracy: 0.899000, Test accuracy: 0.908700
Distillation: Epoch : 6, Loss : 0.281829, Accuracy: 0.923000, Test accuracy: 0.915700
Distillation: Epoch : 7, Loss : 0.298816, Accuracy: 0.910000, Test accuracy: 0.918500
Distillation: Epoch : 8, Loss : 0.287075, Accuracy: 0.926000, Test accuracy: 0.921700
Distillation: Epoch : 9, Loss : 0.307369, Accuracy: 0.923000, Test accuracy: 0.924700
Distillation: Epoch : 10, Loss : 0.314588, Accuracy: 0.914000, Test accuracy: 0.925900
Distillation: Epoch : 11, Loss : 0.282135, Accuracy: 0.921000, Test accuracy: 0.928000
Distillation: Epoch : 12, Loss : 0.276958, Accuracy: 0.919000, Test accuracy: 0.929300
Distillation: Epoch : 13, Loss : 0.273161, Accuracy: 0.929000, Test accuracy: 0.930900
Distillation: Epoch : 14, Loss : 0.249388, Accuracy: 0.929000, Test accuracy: 0.933100
Distillation: Epoch : 15, Loss : 0.208498, Accuracy: 0.951000, Test accuracy: 0.935000
Distillation: Epoch : 16, Loss : 0.240789, Accuracy: 0.923000, Test accuracy: 0.936600
Distillation: Epoch : 17, Loss : 0.234609, Accuracy: 0.937000, Test accuracy: 0.937400
Distillation: Epoch : 18, Loss : 0.212436, Accuracy: 0.940000, Test accuracy: 0.939500
Distillation: Epoch : 19, Loss : 0.226039, Accuracy: 0.940000, Test accuracy: 0.940000
Distillation: Epoch : 20, Loss : 0.213999, Accuracy: 0.944000, Test accuracy: 0.943200
Distillation: Epoch : 21, Loss : 0.215697, Accuracy: 0.941000, Test accuracy: 0.942600
Distillation: Epoch : 22, Loss : 0.220991, Accuracy: 0.940000, Test accuracy: 0.944800
Distillation: Epoch : 23, Loss : 0.219878, Accuracy: 0.933000, Test accuracy: 0.945200
Distillation: Epoch : 24, Loss : 0.196440, Accuracy: 0.944000, Test accuracy: 0.947100
Distillation: Epoch : 25, Loss : 0.163732, Accuracy: 0.954000, Test accuracy: 0.946100
Distillation: Epoch : 26, Loss : 0.192373, Accuracy: 0.948000, Test accuracy: 0.947500
Distillation: Epoch : 27, Loss : 0.178225, Accuracy: 0.957000, Test accuracy: 0.948300
Distillation: Epoch : 28, Loss : 0.213384, Accuracy: 0.939000, Test accuracy: 0.948800
Distillation: Epoch : 29, Loss : 0.207703, Accuracy: 0.941000, Test accuracy: 0.949200
Distillation: Epoch : 30, Loss : 0.166447, Accuracy: 0.959000, Test accuracy: 0.950800
Distillation: Epoch : 31, Loss : 0.189274, Accuracy: 0.949000, Test accuracy: 0.950300
Distillation: Epoch : 32, Loss : 0.186799, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 33, Loss : 0.198281, Accuracy: 0.936000, Test accuracy: 0.952600
Distillation: Epoch : 34, Loss : 0.197781, Accuracy: 0.944000, Test accuracy: 0.953300
Distillation: Epoch : 35, Loss : 0.207310, Accuracy: 0.944000, Test accuracy: 0.951300
Distillation: Epoch : 36, Loss : 0.212150, Accuracy: 0.942000, Test accuracy: 0.954000
Distillation: Epoch : 37, Loss : 0.167898, Accuracy: 0.956000, Test accuracy: 0.953700
Distillation: Epoch : 38, Loss : 0.176224, Accuracy: 0.958000, Test accuracy: 0.952100
Distillation: Epoch : 39, Loss : 0.207553, Accuracy: 0.939000, Test accuracy: 0.954700
Distillation: Epoch : 40, Loss : 0.205367, Accuracy: 0.947000, Test accuracy: 0.955700
Distillation: Epoch : 41, Loss : 0.139735, Accuracy: 0.961000, Test accuracy: 0.956200
Distillation: Epoch : 42, Loss : 0.171648, Accuracy: 0.957000, Test accuracy: 0.954500
Distillation: Epoch : 43, Loss : 0.152887, Accuracy: 0.961000, Test accuracy: 0.956700
Distillation: Epoch : 44, Loss : 0.177060, Accuracy: 0.953000, Test accuracy: 0.956100
Distillation: Epoch : 45, Loss : 0.176329, Accuracy: 0.948000, Test accuracy: 0.956000
Distillation: Epoch : 46, Loss : 0.171027, Accuracy: 0.955000, Test accuracy: 0.957600
Distillation: Epoch : 47, Loss : 0.197367, Accuracy: 0.943000, Test accuracy: 0.956700
Distillation: Epoch : 48, Loss : 0.167230, Accuracy: 0.957000, Test accuracy: 0.958600
Distillation: Epoch : 49, Loss : 0.159103, Accuracy: 0.963000, Test accuracy: 0.958100
Distillation: Epoch : 50, Loss : 0.164629, Accuracy: 0.951000, Test accuracy: 0.957900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9579
Generating confusion matrix for student2
[[ 970.    0.    8.    3.    1.    5.   12.    1.    8.    8.]
 [   0. 1118.    4.    0.    3.    2.    3.    6.    2.    7.]
 [   1.    3.  965.    3.    5.    0.    3.   20.   13.    2.]
 [   1.    2.   14.  977.    1.   19.    0.    7.   15.   13.]
 [   1.    0.    4.    1.  948.    0.    2.    1.    9.    9.]
 [   1.    0.    0.    5.    0.  845.   10.    0.    4.    4.]
 [   2.    3.    6.    0.    2.    5.  924.    0.    4.    0.]
 [   3.    0.    8.   10.    2.    1.    1.  976.    6.   14.]
 [   1.    9.   20.    8.    3.   12.    3.    0.  906.    2.]
 [   0.    0.    3.    3.   17.    3.    0.   17.    7.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.677483, Accuracy: 0.763000, Test accuracy: 0.780600
Distillation: Epoch : 2, Loss : 0.957812, Accuracy: 0.818000, Test accuracy: 0.855200
Distillation: Epoch : 3, Loss : 0.702711, Accuracy: 0.881000, Test accuracy: 0.883100
Distillation: Epoch : 4, Loss : 0.658311, Accuracy: 0.889000, Test accuracy: 0.900900
Distillation: Epoch : 5, Loss : 0.583945, Accuracy: 0.916000, Test accuracy: 0.911700
Distillation: Epoch : 6, Loss : 0.591847, Accuracy: 0.903000, Test accuracy: 0.918000
Distillation: Epoch : 7, Loss : 0.528628, Accuracy: 0.923000, Test accuracy: 0.922000
Distillation: Epoch : 8, Loss : 0.555127, Accuracy: 0.909000, Test accuracy: 0.925600
Distillation: Epoch : 9, Loss : 0.535616, Accuracy: 0.936000, Test accuracy: 0.929700
Distillation: Epoch : 10, Loss : 0.519005, Accuracy: 0.921000, Test accuracy: 0.933000
Distillation: Epoch : 11, Loss : 0.503949, Accuracy: 0.933000, Test accuracy: 0.934800
Distillation: Epoch : 12, Loss : 0.495494, Accuracy: 0.928000, Test accuracy: 0.938100
Distillation: Epoch : 13, Loss : 0.488554, Accuracy: 0.949000, Test accuracy: 0.941400
Distillation: Epoch : 14, Loss : 0.498063, Accuracy: 0.934000, Test accuracy: 0.943300
Distillation: Epoch : 15, Loss : 0.461553, Accuracy: 0.948000, Test accuracy: 0.944600
Distillation: Epoch : 16, Loss : 0.474131, Accuracy: 0.949000, Test accuracy: 0.946800
Distillation: Epoch : 17, Loss : 0.488981, Accuracy: 0.942000, Test accuracy: 0.948700
Distillation: Epoch : 18, Loss : 0.456818, Accuracy: 0.949000, Test accuracy: 0.950300
Distillation: Epoch : 19, Loss : 0.484501, Accuracy: 0.950000, Test accuracy: 0.952500
Distillation: Epoch : 20, Loss : 0.456766, Accuracy: 0.938000, Test accuracy: 0.953200
Distillation: Epoch : 21, Loss : 0.463528, Accuracy: 0.936000, Test accuracy: 0.955100
Distillation: Epoch : 22, Loss : 0.436239, Accuracy: 0.962000, Test accuracy: 0.955800
Distillation: Epoch : 23, Loss : 0.481875, Accuracy: 0.947000, Test accuracy: 0.957100
Distillation: Epoch : 24, Loss : 0.472839, Accuracy: 0.947000, Test accuracy: 0.958400
Distillation: Epoch : 25, Loss : 0.439289, Accuracy: 0.958000, Test accuracy: 0.959200
Distillation: Epoch : 26, Loss : 0.475694, Accuracy: 0.953000, Test accuracy: 0.960200
Distillation: Epoch : 27, Loss : 0.462582, Accuracy: 0.959000, Test accuracy: 0.960600
Distillation: Epoch : 28, Loss : 0.440319, Accuracy: 0.964000, Test accuracy: 0.962000
Distillation: Epoch : 29, Loss : 0.457196, Accuracy: 0.955000, Test accuracy: 0.962700
Distillation: Epoch : 30, Loss : 0.448644, Accuracy: 0.957000, Test accuracy: 0.963900
Distillation: Epoch : 31, Loss : 0.452337, Accuracy: 0.963000, Test accuracy: 0.964300
Distillation: Epoch : 32, Loss : 0.458639, Accuracy: 0.955000, Test accuracy: 0.964600
Distillation: Epoch : 33, Loss : 0.432864, Accuracy: 0.967000, Test accuracy: 0.965400
Distillation: Epoch : 34, Loss : 0.460460, Accuracy: 0.956000, Test accuracy: 0.966400
Distillation: Epoch : 35, Loss : 0.413009, Accuracy: 0.965000, Test accuracy: 0.966000
Distillation: Epoch : 36, Loss : 0.422794, Accuracy: 0.969000, Test accuracy: 0.967600
Distillation: Epoch : 37, Loss : 0.434987, Accuracy: 0.962000, Test accuracy: 0.968100
Distillation: Epoch : 38, Loss : 0.401433, Accuracy: 0.971000, Test accuracy: 0.968100
Distillation: Epoch : 39, Loss : 0.427183, Accuracy: 0.966000, Test accuracy: 0.968700
Distillation: Epoch : 40, Loss : 0.417603, Accuracy: 0.959000, Test accuracy: 0.969200
Distillation: Epoch : 41, Loss : 0.410123, Accuracy: 0.970000, Test accuracy: 0.969000
Distillation: Epoch : 42, Loss : 0.418556, Accuracy: 0.977000, Test accuracy: 0.970300
Distillation: Epoch : 43, Loss : 0.437638, Accuracy: 0.962000, Test accuracy: 0.970200
Distillation: Epoch : 44, Loss : 0.425776, Accuracy: 0.959000, Test accuracy: 0.971000
Distillation: Epoch : 45, Loss : 0.418945, Accuracy: 0.964000, Test accuracy: 0.971100
Distillation: Epoch : 46, Loss : 0.448115, Accuracy: 0.961000, Test accuracy: 0.971500
Distillation: Epoch : 47, Loss : 0.426710, Accuracy: 0.966000, Test accuracy: 0.972300
Distillation: Epoch : 48, Loss : 0.429142, Accuracy: 0.974000, Test accuracy: 0.972600
Distillation: Epoch : 49, Loss : 0.441000, Accuracy: 0.964000, Test accuracy: 0.972500
Distillation: Epoch : 50, Loss : 0.413045, Accuracy: 0.964000, Test accuracy: 0.972500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9725
Generating confusion matrix for student2
[[ 973.    0.    4.    1.    1.    1.    4.    2.    8.    7.]
 [   0. 1123.    6.    0.    1.    1.    3.    4.    1.    5.]
 [   0.    2.  988.    4.    1.    0.    0.   17.    6.    1.]
 [   0.    2.    6.  983.    0.    4.    0.    2.    6.    3.]
 [   0.    0.    3.    0.  962.    0.    3.    1.    4.   14.]
 [   0.    1.    0.    7.    0.  875.    2.    0.    3.    2.]
 [   2.    3.    1.    0.    5.    3.  943.    0.    2.    0.]
 [   2.    0.   10.    8.    1.    3.    0.  988.    9.   12.]
 [   2.    4.   12.    5.    2.    2.    3.    2.  927.    2.]
 [   1.    0.    2.    2.    9.    3.    0.   12.    8.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.614787, Accuracy: 0.756000, Test accuracy: 0.770200
Distillation: Epoch : 2, Loss : 1.020885, Accuracy: 0.835000, Test accuracy: 0.836800
Distillation: Epoch : 3, Loss : 0.865628, Accuracy: 0.876000, Test accuracy: 0.867900
Distillation: Epoch : 4, Loss : 0.854982, Accuracy: 0.851000, Test accuracy: 0.886000
Distillation: Epoch : 5, Loss : 0.800925, Accuracy: 0.885000, Test accuracy: 0.896800
Distillation: Epoch : 6, Loss : 0.753684, Accuracy: 0.909000, Test accuracy: 0.908200
Distillation: Epoch : 7, Loss : 0.758424, Accuracy: 0.908000, Test accuracy: 0.913700
Distillation: Epoch : 8, Loss : 0.730619, Accuracy: 0.908000, Test accuracy: 0.919200
Distillation: Epoch : 9, Loss : 0.726767, Accuracy: 0.929000, Test accuracy: 0.924000
Distillation: Epoch : 10, Loss : 0.678876, Accuracy: 0.930000, Test accuracy: 0.927900
Distillation: Epoch : 11, Loss : 0.683878, Accuracy: 0.934000, Test accuracy: 0.930300
Distillation: Epoch : 12, Loss : 0.706021, Accuracy: 0.926000, Test accuracy: 0.934700
Distillation: Epoch : 13, Loss : 0.677147, Accuracy: 0.927000, Test accuracy: 0.939000
Distillation: Epoch : 14, Loss : 0.668530, Accuracy: 0.930000, Test accuracy: 0.941300
Distillation: Epoch : 15, Loss : 0.651496, Accuracy: 0.938000, Test accuracy: 0.943400
Distillation: Epoch : 16, Loss : 0.663789, Accuracy: 0.931000, Test accuracy: 0.946300
Distillation: Epoch : 17, Loss : 0.632923, Accuracy: 0.951000, Test accuracy: 0.948100
Distillation: Epoch : 18, Loss : 0.642554, Accuracy: 0.946000, Test accuracy: 0.949600
Distillation: Epoch : 19, Loss : 0.623285, Accuracy: 0.946000, Test accuracy: 0.951700
Distillation: Epoch : 20, Loss : 0.611061, Accuracy: 0.964000, Test accuracy: 0.953800
Distillation: Epoch : 21, Loss : 0.632191, Accuracy: 0.956000, Test accuracy: 0.953500
Distillation: Epoch : 22, Loss : 0.600120, Accuracy: 0.953000, Test accuracy: 0.955600
Distillation: Epoch : 23, Loss : 0.643285, Accuracy: 0.949000, Test accuracy: 0.956800
Distillation: Epoch : 24, Loss : 0.624521, Accuracy: 0.958000, Test accuracy: 0.956500
Distillation: Epoch : 25, Loss : 0.591558, Accuracy: 0.960000, Test accuracy: 0.957300
Distillation: Epoch : 26, Loss : 0.598505, Accuracy: 0.963000, Test accuracy: 0.958300
Distillation: Epoch : 27, Loss : 0.614918, Accuracy: 0.959000, Test accuracy: 0.958600
Distillation: Epoch : 28, Loss : 0.623529, Accuracy: 0.949000, Test accuracy: 0.959900
Distillation: Epoch : 29, Loss : 0.631816, Accuracy: 0.952000, Test accuracy: 0.959900
Distillation: Epoch : 30, Loss : 0.625004, Accuracy: 0.950000, Test accuracy: 0.961400
Distillation: Epoch : 31, Loss : 0.599186, Accuracy: 0.962000, Test accuracy: 0.961700
Distillation: Epoch : 32, Loss : 0.570181, Accuracy: 0.956000, Test accuracy: 0.962200
Distillation: Epoch : 33, Loss : 0.603710, Accuracy: 0.966000, Test accuracy: 0.962900
Distillation: Epoch : 34, Loss : 0.622820, Accuracy: 0.962000, Test accuracy: 0.962900
Distillation: Epoch : 35, Loss : 0.624738, Accuracy: 0.958000, Test accuracy: 0.963700
Distillation: Epoch : 36, Loss : 0.590616, Accuracy: 0.973000, Test accuracy: 0.963800
Distillation: Epoch : 37, Loss : 0.582226, Accuracy: 0.964000, Test accuracy: 0.963600
Distillation: Epoch : 38, Loss : 0.627209, Accuracy: 0.938000, Test accuracy: 0.964000
Distillation: Epoch : 39, Loss : 0.616817, Accuracy: 0.956000, Test accuracy: 0.964400
Distillation: Epoch : 40, Loss : 0.595007, Accuracy: 0.966000, Test accuracy: 0.964300
Distillation: Epoch : 41, Loss : 0.614528, Accuracy: 0.966000, Test accuracy: 0.965400
Distillation: Epoch : 42, Loss : 0.630043, Accuracy: 0.953000, Test accuracy: 0.965600
Distillation: Epoch : 43, Loss : 0.598082, Accuracy: 0.951000, Test accuracy: 0.965800
Distillation: Epoch : 44, Loss : 0.609557, Accuracy: 0.960000, Test accuracy: 0.966200
Distillation: Epoch : 45, Loss : 0.571907, Accuracy: 0.973000, Test accuracy: 0.966800
Distillation: Epoch : 46, Loss : 0.583477, Accuracy: 0.963000, Test accuracy: 0.966700
Distillation: Epoch : 47, Loss : 0.582182, Accuracy: 0.965000, Test accuracy: 0.966400
Distillation: Epoch : 48, Loss : 0.585368, Accuracy: 0.965000, Test accuracy: 0.966600
Distillation: Epoch : 49, Loss : 0.573246, Accuracy: 0.967000, Test accuracy: 0.967600
Distillation: Epoch : 50, Loss : 0.595808, Accuracy: 0.964000, Test accuracy: 0.967500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9675
Generating confusion matrix for student2
[[ 971.    0.    4.    0.    1.    2.    5.    2.   10.    5.]
 [   1. 1126.    6.    0.    2.    1.    4.    5.    4.    6.]
 [   0.    3.  979.    2.    1.    0.    0.   11.    7.    1.]
 [   0.    0.    5.  980.    0.    6.    0.    2.   11.    7.]
 [   2.    0.    5.    2.  964.    1.    4.    1.   10.   16.]
 [   0.    0.    0.    7.    0.  866.    6.    0.    6.    1.]
 [   2.    4.    2.    0.    3.    5.  935.    0.    1.    0.]
 [   3.    0.   14.    9.    1.    2.    0.  992.   11.   16.]
 [   1.    2.   14.    5.    3.    8.    4.    2.  905.    0.]
 [   0.    0.    3.    5.    7.    1.    0.   13.    9.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.704119, Accuracy: 0.756000, Test accuracy: 0.744300
Distillation: Epoch : 2, Loss : 1.170989, Accuracy: 0.808000, Test accuracy: 0.834900
Distillation: Epoch : 3, Loss : 1.050539, Accuracy: 0.854000, Test accuracy: 0.871900
Distillation: Epoch : 4, Loss : 0.977378, Accuracy: 0.895000, Test accuracy: 0.886500
Distillation: Epoch : 5, Loss : 0.924851, Accuracy: 0.890000, Test accuracy: 0.895300
Distillation: Epoch : 6, Loss : 0.940957, Accuracy: 0.895000, Test accuracy: 0.901300
Distillation: Epoch : 7, Loss : 0.921479, Accuracy: 0.909000, Test accuracy: 0.904800
Distillation: Epoch : 8, Loss : 0.913012, Accuracy: 0.899000, Test accuracy: 0.907900
Distillation: Epoch : 9, Loss : 0.869503, Accuracy: 0.917000, Test accuracy: 0.911200
Distillation: Epoch : 10, Loss : 0.907896, Accuracy: 0.900000, Test accuracy: 0.914000
Distillation: Epoch : 11, Loss : 0.901037, Accuracy: 0.916000, Test accuracy: 0.916100
Distillation: Epoch : 12, Loss : 0.914219, Accuracy: 0.899000, Test accuracy: 0.918700
Distillation: Epoch : 13, Loss : 0.864342, Accuracy: 0.933000, Test accuracy: 0.921300
Distillation: Epoch : 14, Loss : 0.871941, Accuracy: 0.925000, Test accuracy: 0.922500
Distillation: Epoch : 15, Loss : 0.883005, Accuracy: 0.905000, Test accuracy: 0.924200
Distillation: Epoch : 16, Loss : 0.901532, Accuracy: 0.903000, Test accuracy: 0.928000
Distillation: Epoch : 17, Loss : 0.859297, Accuracy: 0.924000, Test accuracy: 0.927700
Distillation: Epoch : 18, Loss : 0.819470, Accuracy: 0.931000, Test accuracy: 0.931600
Distillation: Epoch : 19, Loss : 0.839763, Accuracy: 0.926000, Test accuracy: 0.933100
Distillation: Epoch : 20, Loss : 0.832246, Accuracy: 0.939000, Test accuracy: 0.934400
Distillation: Epoch : 21, Loss : 0.821566, Accuracy: 0.945000, Test accuracy: 0.936100
Distillation: Epoch : 22, Loss : 0.829306, Accuracy: 0.937000, Test accuracy: 0.936800
Distillation: Epoch : 23, Loss : 0.820042, Accuracy: 0.932000, Test accuracy: 0.938200
Distillation: Epoch : 24, Loss : 0.853128, Accuracy: 0.927000, Test accuracy: 0.938400
Distillation: Epoch : 25, Loss : 0.816653, Accuracy: 0.938000, Test accuracy: 0.940500
Distillation: Epoch : 26, Loss : 0.826249, Accuracy: 0.942000, Test accuracy: 0.941600
Distillation: Epoch : 27, Loss : 0.821935, Accuracy: 0.933000, Test accuracy: 0.942300
Distillation: Epoch : 28, Loss : 0.825305, Accuracy: 0.943000, Test accuracy: 0.943400
Distillation: Epoch : 29, Loss : 0.849942, Accuracy: 0.928000, Test accuracy: 0.944700
Distillation: Epoch : 30, Loss : 0.811378, Accuracy: 0.949000, Test accuracy: 0.945200
Distillation: Epoch : 31, Loss : 0.835219, Accuracy: 0.924000, Test accuracy: 0.946500
Distillation: Epoch : 32, Loss : 0.776874, Accuracy: 0.955000, Test accuracy: 0.946900
Distillation: Epoch : 33, Loss : 0.807249, Accuracy: 0.944000, Test accuracy: 0.948400
Distillation: Epoch : 34, Loss : 0.826416, Accuracy: 0.944000, Test accuracy: 0.948800
Distillation: Epoch : 35, Loss : 0.819943, Accuracy: 0.945000, Test accuracy: 0.950700
Distillation: Epoch : 36, Loss : 0.838414, Accuracy: 0.936000, Test accuracy: 0.950000
Distillation: Epoch : 37, Loss : 0.812032, Accuracy: 0.946000, Test accuracy: 0.951200
Distillation: Epoch : 38, Loss : 0.793585, Accuracy: 0.949000, Test accuracy: 0.952700
Distillation: Epoch : 39, Loss : 0.801917, Accuracy: 0.956000, Test accuracy: 0.952600
Distillation: Epoch : 40, Loss : 0.814365, Accuracy: 0.957000, Test accuracy: 0.953800
Distillation: Epoch : 41, Loss : 0.790750, Accuracy: 0.946000, Test accuracy: 0.954100
Distillation: Epoch : 42, Loss : 0.779762, Accuracy: 0.957000, Test accuracy: 0.954800
Distillation: Epoch : 43, Loss : 0.791056, Accuracy: 0.958000, Test accuracy: 0.955200
Distillation: Epoch : 44, Loss : 0.798017, Accuracy: 0.951000, Test accuracy: 0.956500
Distillation: Epoch : 45, Loss : 0.780659, Accuracy: 0.954000, Test accuracy: 0.957800
Distillation: Epoch : 46, Loss : 0.823432, Accuracy: 0.947000, Test accuracy: 0.957800
Distillation: Epoch : 47, Loss : 0.786885, Accuracy: 0.949000, Test accuracy: 0.958000
Distillation: Epoch : 48, Loss : 0.786477, Accuracy: 0.958000, Test accuracy: 0.958700
Distillation: Epoch : 49, Loss : 0.755908, Accuracy: 0.962000, Test accuracy: 0.959100
Distillation: Epoch : 50, Loss : 0.774795, Accuracy: 0.958000, Test accuracy: 0.959900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9599
Generating confusion matrix for student2
[[ 971.    0.    6.    0.    0.    6.    7.    1.   10.    3.]
 [   0. 1125.    5.    1.    1.    0.    2.    5.    4.    5.]
 [   0.    1.  976.   10.    2.    0.    2.   14.    6.    0.]
 [   1.    2.    7.  953.    0.    7.    1.    2.   12.    5.]
 [   0.    1.    7.    2.  951.    1.    4.    7.    5.   20.]
 [   2.    1.    0.   17.    1.  850.    4.    1.    6.    7.]
 [   4.    5.    4.    1.    7.    8.  938.    0.    4.    1.]
 [   1.    0.   16.   18.    4.    7.    0.  978.   10.   11.]
 [   1.    0.    7.    6.    3.    5.    0.    1.  907.    7.]
 [   0.    0.    4.    2.   13.    8.    0.   19.   10.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.846277, Accuracy: 0.802000, Test accuracy: 0.791300
Distillation: Epoch : 2, Loss : 1.278990, Accuracy: 0.834000, Test accuracy: 0.839100
Distillation: Epoch : 3, Loss : 1.225325, Accuracy: 0.836000, Test accuracy: 0.867700
Distillation: Epoch : 4, Loss : 1.122881, Accuracy: 0.875000, Test accuracy: 0.885000
Distillation: Epoch : 5, Loss : 1.070818, Accuracy: 0.902000, Test accuracy: 0.896200
Distillation: Epoch : 6, Loss : 1.092153, Accuracy: 0.903000, Test accuracy: 0.906200
Distillation: Epoch : 7, Loss : 1.078948, Accuracy: 0.897000, Test accuracy: 0.912300
Distillation: Epoch : 8, Loss : 1.049454, Accuracy: 0.908000, Test accuracy: 0.916900
Distillation: Epoch : 9, Loss : 1.029604, Accuracy: 0.915000, Test accuracy: 0.921700
Distillation: Epoch : 10, Loss : 1.047359, Accuracy: 0.917000, Test accuracy: 0.926800
Distillation: Epoch : 11, Loss : 1.003064, Accuracy: 0.933000, Test accuracy: 0.930200
Distillation: Epoch : 12, Loss : 1.029567, Accuracy: 0.916000, Test accuracy: 0.933900
Distillation: Epoch : 13, Loss : 1.037928, Accuracy: 0.897000, Test accuracy: 0.938100
Distillation: Epoch : 14, Loss : 0.999547, Accuracy: 0.935000, Test accuracy: 0.941100
Distillation: Epoch : 15, Loss : 1.003374, Accuracy: 0.925000, Test accuracy: 0.943400
Distillation: Epoch : 16, Loss : 0.962480, Accuracy: 0.948000, Test accuracy: 0.946300
Distillation: Epoch : 17, Loss : 0.978084, Accuracy: 0.928000, Test accuracy: 0.948800
Distillation: Epoch : 18, Loss : 0.955462, Accuracy: 0.951000, Test accuracy: 0.950300
Distillation: Epoch : 19, Loss : 0.982678, Accuracy: 0.945000, Test accuracy: 0.951400
Distillation: Epoch : 20, Loss : 0.956005, Accuracy: 0.952000, Test accuracy: 0.952300
Distillation: Epoch : 21, Loss : 0.957513, Accuracy: 0.954000, Test accuracy: 0.952400
Distillation: Epoch : 22, Loss : 0.973756, Accuracy: 0.954000, Test accuracy: 0.955100
Distillation: Epoch : 23, Loss : 0.941270, Accuracy: 0.955000, Test accuracy: 0.955800
Distillation: Epoch : 24, Loss : 0.953162, Accuracy: 0.954000, Test accuracy: 0.956500
Distillation: Epoch : 25, Loss : 0.955270, Accuracy: 0.953000, Test accuracy: 0.957300
Distillation: Epoch : 26, Loss : 0.976365, Accuracy: 0.955000, Test accuracy: 0.958300
Distillation: Epoch : 27, Loss : 0.929454, Accuracy: 0.951000, Test accuracy: 0.958100
Distillation: Epoch : 28, Loss : 0.964156, Accuracy: 0.956000, Test accuracy: 0.959200
Distillation: Epoch : 29, Loss : 0.963529, Accuracy: 0.955000, Test accuracy: 0.960200
Distillation: Epoch : 30, Loss : 0.966606, Accuracy: 0.946000, Test accuracy: 0.959900
Distillation: Epoch : 31, Loss : 0.950003, Accuracy: 0.947000, Test accuracy: 0.961300
Distillation: Epoch : 32, Loss : 0.957151, Accuracy: 0.952000, Test accuracy: 0.960900
Distillation: Epoch : 33, Loss : 0.956708, Accuracy: 0.949000, Test accuracy: 0.961300
Distillation: Epoch : 34, Loss : 0.941208, Accuracy: 0.950000, Test accuracy: 0.961600
Distillation: Epoch : 35, Loss : 0.936978, Accuracy: 0.960000, Test accuracy: 0.961600
Distillation: Epoch : 36, Loss : 0.948614, Accuracy: 0.951000, Test accuracy: 0.963100
Distillation: Epoch : 37, Loss : 0.920410, Accuracy: 0.961000, Test accuracy: 0.963200
Distillation: Epoch : 38, Loss : 0.942530, Accuracy: 0.958000, Test accuracy: 0.963300
Distillation: Epoch : 39, Loss : 0.951095, Accuracy: 0.971000, Test accuracy: 0.962300
Distillation: Epoch : 40, Loss : 0.944978, Accuracy: 0.958000, Test accuracy: 0.963300
Distillation: Epoch : 41, Loss : 0.926064, Accuracy: 0.966000, Test accuracy: 0.962700
Distillation: Epoch : 42, Loss : 0.953442, Accuracy: 0.962000, Test accuracy: 0.963300
Distillation: Epoch : 43, Loss : 0.969601, Accuracy: 0.963000, Test accuracy: 0.963300
Distillation: Epoch : 44, Loss : 0.943694, Accuracy: 0.968000, Test accuracy: 0.964100
Distillation: Epoch : 45, Loss : 0.942823, Accuracy: 0.960000, Test accuracy: 0.964500
Distillation: Epoch : 46, Loss : 0.953711, Accuracy: 0.967000, Test accuracy: 0.963800
Distillation: Epoch : 47, Loss : 0.948379, Accuracy: 0.954000, Test accuracy: 0.964700
Distillation: Epoch : 48, Loss : 0.934802, Accuracy: 0.960000, Test accuracy: 0.965200
Distillation: Epoch : 49, Loss : 0.968668, Accuracy: 0.959000, Test accuracy: 0.965200
Distillation: Epoch : 50, Loss : 0.957662, Accuracy: 0.964000, Test accuracy: 0.965400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9654
Generating confusion matrix for student2
[[ 973.    0.    4.    0.    1.    3.    8.    2.    9.    5.]
 [   2. 1125.   10.    1.    3.    1.    3.    8.    3.    5.]
 [   0.    4.  971.    4.    1.    0.    0.   12.    9.    1.]
 [   0.    0.    7.  975.    0.    3.    1.    1.    8.    5.]
 [   0.    1.    7.    0.  963.    0.    4.    2.    9.   14.]
 [   0.    0.    0.   11.    0.  864.    5.    0.    7.    2.]
 [   3.    3.    3.    0.    2.    5.  935.    0.    6.    0.]
 [   2.    0.    8.    9.    1.    3.    0.  987.   10.   15.]
 [   0.    2.   19.    6.    2.    6.    2.    2.  900.    1.]
 [   0.    0.    3.    4.    9.    7.    0.   14.   13.  961.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.835538, Accuracy: 0.758000, Test accuracy: 0.779000
Distillation: Epoch : 2, Loss : 1.405220, Accuracy: 0.824000, Test accuracy: 0.843100
Distillation: Epoch : 3, Loss : 1.317836, Accuracy: 0.859000, Test accuracy: 0.868100
Distillation: Epoch : 4, Loss : 1.277018, Accuracy: 0.858000, Test accuracy: 0.883300
Distillation: Epoch : 5, Loss : 1.236594, Accuracy: 0.881000, Test accuracy: 0.890700
Distillation: Epoch : 6, Loss : 1.240427, Accuracy: 0.892000, Test accuracy: 0.897300
Distillation: Epoch : 7, Loss : 1.255145, Accuracy: 0.890000, Test accuracy: 0.900300
Distillation: Epoch : 8, Loss : 1.231290, Accuracy: 0.891000, Test accuracy: 0.906400
Distillation: Epoch : 9, Loss : 1.238877, Accuracy: 0.890000, Test accuracy: 0.909600
Distillation: Epoch : 10, Loss : 1.232374, Accuracy: 0.895000, Test accuracy: 0.911500
Distillation: Epoch : 11, Loss : 1.220761, Accuracy: 0.894000, Test accuracy: 0.915200
Distillation: Epoch : 12, Loss : 1.259680, Accuracy: 0.897000, Test accuracy: 0.918400
Distillation: Epoch : 13, Loss : 1.217744, Accuracy: 0.893000, Test accuracy: 0.920500
Distillation: Epoch : 14, Loss : 1.154359, Accuracy: 0.927000, Test accuracy: 0.922600
Distillation: Epoch : 15, Loss : 1.183165, Accuracy: 0.914000, Test accuracy: 0.924500
Distillation: Epoch : 16, Loss : 1.175681, Accuracy: 0.938000, Test accuracy: 0.926700
Distillation: Epoch : 17, Loss : 1.187085, Accuracy: 0.925000, Test accuracy: 0.929300
Distillation: Epoch : 18, Loss : 1.180623, Accuracy: 0.927000, Test accuracy: 0.933300
Distillation: Epoch : 19, Loss : 1.167682, Accuracy: 0.922000, Test accuracy: 0.935100
Distillation: Epoch : 20, Loss : 1.148575, Accuracy: 0.947000, Test accuracy: 0.937500
Distillation: Epoch : 21, Loss : 1.153494, Accuracy: 0.928000, Test accuracy: 0.939500
Distillation: Epoch : 22, Loss : 1.169817, Accuracy: 0.938000, Test accuracy: 0.941100
Distillation: Epoch : 23, Loss : 1.180450, Accuracy: 0.928000, Test accuracy: 0.942900
Distillation: Epoch : 24, Loss : 1.144570, Accuracy: 0.935000, Test accuracy: 0.944900
Distillation: Epoch : 25, Loss : 1.163713, Accuracy: 0.930000, Test accuracy: 0.946900
Distillation: Epoch : 26, Loss : 1.145225, Accuracy: 0.944000, Test accuracy: 0.949300
Distillation: Epoch : 27, Loss : 1.138815, Accuracy: 0.953000, Test accuracy: 0.951400
Distillation: Epoch : 28, Loss : 1.103693, Accuracy: 0.964000, Test accuracy: 0.952300
Distillation: Epoch : 29, Loss : 1.150640, Accuracy: 0.939000, Test accuracy: 0.953300
Distillation: Epoch : 30, Loss : 1.111011, Accuracy: 0.954000, Test accuracy: 0.954700
Distillation: Epoch : 31, Loss : 1.144217, Accuracy: 0.951000, Test accuracy: 0.954600
Distillation: Epoch : 32, Loss : 1.116360, Accuracy: 0.945000, Test accuracy: 0.954900
Distillation: Epoch : 33, Loss : 1.127002, Accuracy: 0.955000, Test accuracy: 0.957000
Distillation: Epoch : 34, Loss : 1.102141, Accuracy: 0.952000, Test accuracy: 0.956700
Distillation: Epoch : 35, Loss : 1.133550, Accuracy: 0.934000, Test accuracy: 0.958000
Distillation: Epoch : 36, Loss : 1.126458, Accuracy: 0.954000, Test accuracy: 0.958600
Distillation: Epoch : 37, Loss : 1.147661, Accuracy: 0.947000, Test accuracy: 0.957200
Distillation: Epoch : 38, Loss : 1.125376, Accuracy: 0.967000, Test accuracy: 0.958500
Distillation: Epoch : 39, Loss : 1.110049, Accuracy: 0.954000, Test accuracy: 0.959300
Distillation: Epoch : 40, Loss : 1.113765, Accuracy: 0.955000, Test accuracy: 0.958900
Distillation: Epoch : 41, Loss : 1.119557, Accuracy: 0.953000, Test accuracy: 0.959700
Distillation: Epoch : 42, Loss : 1.108986, Accuracy: 0.956000, Test accuracy: 0.960800
Distillation: Epoch : 43, Loss : 1.102814, Accuracy: 0.962000, Test accuracy: 0.960700
Distillation: Epoch : 44, Loss : 1.096491, Accuracy: 0.962000, Test accuracy: 0.960900
Distillation: Epoch : 45, Loss : 1.110560, Accuracy: 0.956000, Test accuracy: 0.961900
Distillation: Epoch : 46, Loss : 1.081797, Accuracy: 0.962000, Test accuracy: 0.962400
Distillation: Epoch : 47, Loss : 1.122482, Accuracy: 0.959000, Test accuracy: 0.963100
Distillation: Epoch : 48, Loss : 1.096834, Accuracy: 0.958000, Test accuracy: 0.962600
Distillation: Epoch : 49, Loss : 1.097369, Accuracy: 0.971000, Test accuracy: 0.962700
Distillation: Epoch : 50, Loss : 1.089920, Accuracy: 0.955000, Test accuracy: 0.963000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.963
Generating confusion matrix for student2
[[ 973.    0.    6.    1.    1.    2.    8.    2.   10.    6.]
 [   1. 1124.    6.    2.    2.    1.    3.    8.    5.    5.]
 [   0.    4.  983.    6.    2.    1.    0.   13.    9.    2.]
 [   0.    0.    8.  971.    0.    5.    1.    1.    5.    4.]
 [   1.    1.    8.    2.  958.    0.    4.    7.    8.   20.]
 [   0.    0.    1.   10.    0.  857.    5.    0.    7.    4.]
 [   2.    4.    2.    0.    7.    6.  934.    0.    6.    0.]
 [   2.    0.    9.    9.    1.    4.    0.  972.    6.    9.]
 [   1.    2.    7.    6.    3.    7.    3.    2.  900.    1.]
 [   0.    0.    2.    3.    8.    9.    0.   23.   18.  958.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.942433, Accuracy: 0.698000, Test accuracy: 0.718400
Distillation: Epoch : 2, Loss : 1.562870, Accuracy: 0.792000, Test accuracy: 0.821000
Distillation: Epoch : 3, Loss : 1.474533, Accuracy: 0.829000, Test accuracy: 0.858700
Distillation: Epoch : 4, Loss : 1.426733, Accuracy: 0.878000, Test accuracy: 0.874600
Distillation: Epoch : 5, Loss : 1.394624, Accuracy: 0.882000, Test accuracy: 0.883700
Distillation: Epoch : 6, Loss : 1.401952, Accuracy: 0.889000, Test accuracy: 0.888800
Distillation: Epoch : 7, Loss : 1.365143, Accuracy: 0.882000, Test accuracy: 0.894000
Distillation: Epoch : 8, Loss : 1.372076, Accuracy: 0.887000, Test accuracy: 0.901900
Distillation: Epoch : 9, Loss : 1.374528, Accuracy: 0.890000, Test accuracy: 0.905600
Distillation: Epoch : 10, Loss : 1.352890, Accuracy: 0.910000, Test accuracy: 0.907600
Distillation: Epoch : 11, Loss : 1.350163, Accuracy: 0.918000, Test accuracy: 0.910800
Distillation: Epoch : 12, Loss : 1.355971, Accuracy: 0.896000, Test accuracy: 0.914300
Distillation: Epoch : 13, Loss : 1.320430, Accuracy: 0.929000, Test accuracy: 0.918700
Distillation: Epoch : 14, Loss : 1.336974, Accuracy: 0.921000, Test accuracy: 0.921400
Distillation: Epoch : 15, Loss : 1.321959, Accuracy: 0.928000, Test accuracy: 0.924800
Distillation: Epoch : 16, Loss : 1.312591, Accuracy: 0.926000, Test accuracy: 0.927900
Distillation: Epoch : 17, Loss : 1.329370, Accuracy: 0.923000, Test accuracy: 0.931500
Distillation: Epoch : 18, Loss : 1.320776, Accuracy: 0.920000, Test accuracy: 0.935600
Distillation: Epoch : 19, Loss : 1.293193, Accuracy: 0.938000, Test accuracy: 0.937200
Distillation: Epoch : 20, Loss : 1.285829, Accuracy: 0.934000, Test accuracy: 0.940500
Distillation: Epoch : 21, Loss : 1.286425, Accuracy: 0.950000, Test accuracy: 0.942500
Distillation: Epoch : 22, Loss : 1.289464, Accuracy: 0.949000, Test accuracy: 0.944100
Distillation: Epoch : 23, Loss : 1.288189, Accuracy: 0.935000, Test accuracy: 0.946600
Distillation: Epoch : 24, Loss : 1.274987, Accuracy: 0.943000, Test accuracy: 0.947700
Distillation: Epoch : 25, Loss : 1.296757, Accuracy: 0.945000, Test accuracy: 0.949100
Distillation: Epoch : 26, Loss : 1.283082, Accuracy: 0.937000, Test accuracy: 0.951300
Distillation: Epoch : 27, Loss : 1.274978, Accuracy: 0.944000, Test accuracy: 0.952000
Distillation: Epoch : 28, Loss : 1.296387, Accuracy: 0.943000, Test accuracy: 0.952600
Distillation: Epoch : 29, Loss : 1.277055, Accuracy: 0.939000, Test accuracy: 0.954200
Distillation: Epoch : 30, Loss : 1.299596, Accuracy: 0.955000, Test accuracy: 0.954400
Distillation: Epoch : 31, Loss : 1.259997, Accuracy: 0.953000, Test accuracy: 0.955700
Distillation: Epoch : 32, Loss : 1.260096, Accuracy: 0.949000, Test accuracy: 0.956100
Distillation: Epoch : 33, Loss : 1.263919, Accuracy: 0.963000, Test accuracy: 0.956700
Distillation: Epoch : 34, Loss : 1.236801, Accuracy: 0.946000, Test accuracy: 0.957900
Distillation: Epoch : 35, Loss : 1.259609, Accuracy: 0.965000, Test accuracy: 0.958300
Distillation: Epoch : 36, Loss : 1.256546, Accuracy: 0.957000, Test accuracy: 0.958600
Distillation: Epoch : 37, Loss : 1.272388, Accuracy: 0.955000, Test accuracy: 0.959300
Distillation: Epoch : 38, Loss : 1.251959, Accuracy: 0.954000, Test accuracy: 0.960200
Distillation: Epoch : 39, Loss : 1.244888, Accuracy: 0.955000, Test accuracy: 0.960300
Distillation: Epoch : 40, Loss : 1.248962, Accuracy: 0.959000, Test accuracy: 0.961700
Distillation: Epoch : 41, Loss : 1.248840, Accuracy: 0.955000, Test accuracy: 0.962000
Distillation: Epoch : 42, Loss : 1.256561, Accuracy: 0.951000, Test accuracy: 0.961900
Distillation: Epoch : 43, Loss : 1.263504, Accuracy: 0.966000, Test accuracy: 0.962100
Distillation: Epoch : 44, Loss : 1.277197, Accuracy: 0.953000, Test accuracy: 0.962900
Distillation: Epoch : 45, Loss : 1.265433, Accuracy: 0.956000, Test accuracy: 0.963500
Distillation: Epoch : 46, Loss : 1.258065, Accuracy: 0.972000, Test accuracy: 0.964100
Distillation: Epoch : 47, Loss : 1.255071, Accuracy: 0.957000, Test accuracy: 0.964000
Distillation: Epoch : 48, Loss : 1.245683, Accuracy: 0.966000, Test accuracy: 0.963700
Distillation: Epoch : 49, Loss : 1.268032, Accuracy: 0.963000, Test accuracy: 0.964700
Distillation: Epoch : 50, Loss : 1.262429, Accuracy: 0.961000, Test accuracy: 0.963900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9639
Generating confusion matrix for student2
[[ 973.    0.    8.    1.    0.    1.    6.    3.    9.    6.]
 [   1. 1123.   10.    0.    0.    0.    3.    5.    4.    7.]
 [   0.    2.  972.    3.    5.    0.    0.   14.   14.    0.]
 [   0.    2.    7.  980.    0.    8.    0.    2.    7.    7.]
 [   0.    0.    6.    1.  955.    2.    1.    3.    5.   13.]
 [   2.    0.    0.    6.    0.  863.   11.    1.   11.    2.]
 [   3.    4.    3.    0.    4.    6.  935.    0.    3.    0.]
 [   1.    0.   10.    8.    3.    2.    0.  975.    8.   10.]
 [   0.    4.   15.    7.    2.    7.    2.    3.  900.    1.]
 [   0.    0.    1.    4.   13.    3.    0.   22.   13.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.903675, Accuracy: 0.773000, Test accuracy: 0.784900
Distillation: Epoch : 2, Loss : 1.626062, Accuracy: 0.816000, Test accuracy: 0.836300
Distillation: Epoch : 3, Loss : 1.561054, Accuracy: 0.858000, Test accuracy: 0.863900
Distillation: Epoch : 4, Loss : 1.542800, Accuracy: 0.870000, Test accuracy: 0.877700
Distillation: Epoch : 5, Loss : 1.521572, Accuracy: 0.867000, Test accuracy: 0.883300
Distillation: Epoch : 6, Loss : 1.520424, Accuracy: 0.872000, Test accuracy: 0.891900
Distillation: Epoch : 7, Loss : 1.491670, Accuracy: 0.894000, Test accuracy: 0.895900
Distillation: Epoch : 8, Loss : 1.506130, Accuracy: 0.892000, Test accuracy: 0.899800
Distillation: Epoch : 9, Loss : 1.477725, Accuracy: 0.902000, Test accuracy: 0.904200
Distillation: Epoch : 10, Loss : 1.492627, Accuracy: 0.895000, Test accuracy: 0.906800
Distillation: Epoch : 11, Loss : 1.451614, Accuracy: 0.917000, Test accuracy: 0.911800
Distillation: Epoch : 12, Loss : 1.456892, Accuracy: 0.910000, Test accuracy: 0.913300
Distillation: Epoch : 13, Loss : 1.462437, Accuracy: 0.917000, Test accuracy: 0.916400
Distillation: Epoch : 14, Loss : 1.464077, Accuracy: 0.906000, Test accuracy: 0.918600
Distillation: Epoch : 15, Loss : 1.454798, Accuracy: 0.916000, Test accuracy: 0.923000
Distillation: Epoch : 16, Loss : 1.435393, Accuracy: 0.915000, Test accuracy: 0.925600
Distillation: Epoch : 17, Loss : 1.440735, Accuracy: 0.924000, Test accuracy: 0.928400
Distillation: Epoch : 18, Loss : 1.429967, Accuracy: 0.918000, Test accuracy: 0.930200
Distillation: Epoch : 19, Loss : 1.421945, Accuracy: 0.930000, Test accuracy: 0.932700
Distillation: Epoch : 20, Loss : 1.448808, Accuracy: 0.923000, Test accuracy: 0.934700
Distillation: Epoch : 21, Loss : 1.454022, Accuracy: 0.923000, Test accuracy: 0.935200
Distillation: Epoch : 22, Loss : 1.433208, Accuracy: 0.934000, Test accuracy: 0.937600
Distillation: Epoch : 23, Loss : 1.419262, Accuracy: 0.938000, Test accuracy: 0.939400
Distillation: Epoch : 24, Loss : 1.415847, Accuracy: 0.942000, Test accuracy: 0.941300
Distillation: Epoch : 25, Loss : 1.396903, Accuracy: 0.942000, Test accuracy: 0.942300
Distillation: Epoch : 26, Loss : 1.415344, Accuracy: 0.948000, Test accuracy: 0.943100
Distillation: Epoch : 27, Loss : 1.423206, Accuracy: 0.941000, Test accuracy: 0.944200
Distillation: Epoch : 28, Loss : 1.412530, Accuracy: 0.931000, Test accuracy: 0.944700
Distillation: Epoch : 29, Loss : 1.412983, Accuracy: 0.939000, Test accuracy: 0.945500
Distillation: Epoch : 30, Loss : 1.402767, Accuracy: 0.949000, Test accuracy: 0.945900
Distillation: Epoch : 31, Loss : 1.391756, Accuracy: 0.939000, Test accuracy: 0.947000
Distillation: Epoch : 32, Loss : 1.430891, Accuracy: 0.938000, Test accuracy: 0.947600
Distillation: Epoch : 33, Loss : 1.405806, Accuracy: 0.942000, Test accuracy: 0.948400
Distillation: Epoch : 34, Loss : 1.430424, Accuracy: 0.931000, Test accuracy: 0.949400
Distillation: Epoch : 35, Loss : 1.398244, Accuracy: 0.942000, Test accuracy: 0.948600
Distillation: Epoch : 36, Loss : 1.410602, Accuracy: 0.937000, Test accuracy: 0.949900
Distillation: Epoch : 37, Loss : 1.399540, Accuracy: 0.958000, Test accuracy: 0.951700
Distillation: Epoch : 38, Loss : 1.400426, Accuracy: 0.956000, Test accuracy: 0.951300
Distillation: Epoch : 39, Loss : 1.393040, Accuracy: 0.949000, Test accuracy: 0.952800
Distillation: Epoch : 40, Loss : 1.387092, Accuracy: 0.955000, Test accuracy: 0.953000
Distillation: Epoch : 41, Loss : 1.412766, Accuracy: 0.937000, Test accuracy: 0.953300
Distillation: Epoch : 42, Loss : 1.406924, Accuracy: 0.945000, Test accuracy: 0.954700
Distillation: Epoch : 43, Loss : 1.395496, Accuracy: 0.953000, Test accuracy: 0.954900
Distillation: Epoch : 44, Loss : 1.400224, Accuracy: 0.954000, Test accuracy: 0.955200
Distillation: Epoch : 45, Loss : 1.392051, Accuracy: 0.951000, Test accuracy: 0.955800
Distillation: Epoch : 46, Loss : 1.404223, Accuracy: 0.948000, Test accuracy: 0.956000
Distillation: Epoch : 47, Loss : 1.379082, Accuracy: 0.959000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 1.398648, Accuracy: 0.957000, Test accuracy: 0.957000
Distillation: Epoch : 49, Loss : 1.405239, Accuracy: 0.951000, Test accuracy: 0.957800
Distillation: Epoch : 50, Loss : 1.389324, Accuracy: 0.955000, Test accuracy: 0.958600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9586
Generating confusion matrix for student2
[[ 968.    0.    9.    0.    3.    0.    9.    2.    9.    5.]
 [   0. 1123.    8.    1.    1.    1.    4.    8.    5.    6.]
 [   0.    2.  958.    4.    1.    1.    0.   16.   11.    1.]
 [   0.    2.    7.  972.    0.   13.    0.    2.   10.    6.]
 [   1.    1.   10.    3.  961.    0.    4.    3.   12.   26.]
 [   0.    0.    0.    8.    0.  859.   10.    2.    7.    4.]
 [   5.    4.    2.    0.    3.    5.  929.    0.    3.    0.]
 [   2.    1.   12.    7.    1.    3.    0.  973.    9.   10.]
 [   4.    2.   24.    9.    2.    4.    2.    3.  892.    0.]
 [   0.    0.    2.    6.   10.    6.    0.   19.   16.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.058800, Accuracy: 0.753000, Test accuracy: 0.764500
Distillation: Epoch : 2, Loss : 1.835260, Accuracy: 0.827000, Test accuracy: 0.837900
Distillation: Epoch : 3, Loss : 1.804094, Accuracy: 0.867000, Test accuracy: 0.864300
Distillation: Epoch : 4, Loss : 1.828827, Accuracy: 0.836000, Test accuracy: 0.874400
Distillation: Epoch : 5, Loss : 1.795532, Accuracy: 0.846000, Test accuracy: 0.881600
Distillation: Epoch : 6, Loss : 1.783207, Accuracy: 0.873000, Test accuracy: 0.888500
Distillation: Epoch : 7, Loss : 1.773139, Accuracy: 0.887000, Test accuracy: 0.891500
Distillation: Epoch : 8, Loss : 1.763045, Accuracy: 0.885000, Test accuracy: 0.896600
Distillation: Epoch : 9, Loss : 1.776548, Accuracy: 0.895000, Test accuracy: 0.899800
Distillation: Epoch : 10, Loss : 1.754242, Accuracy: 0.897000, Test accuracy: 0.902300
Distillation: Epoch : 11, Loss : 1.774527, Accuracy: 0.906000, Test accuracy: 0.905800
Distillation: Epoch : 12, Loss : 1.733398, Accuracy: 0.906000, Test accuracy: 0.906900
Distillation: Epoch : 13, Loss : 1.750161, Accuracy: 0.898000, Test accuracy: 0.908600
Distillation: Epoch : 14, Loss : 1.740016, Accuracy: 0.915000, Test accuracy: 0.912800
Distillation: Epoch : 15, Loss : 1.755680, Accuracy: 0.911000, Test accuracy: 0.915300
Distillation: Epoch : 16, Loss : 1.753002, Accuracy: 0.902000, Test accuracy: 0.915700
Distillation: Epoch : 17, Loss : 1.718035, Accuracy: 0.922000, Test accuracy: 0.919500
Distillation: Epoch : 18, Loss : 1.727334, Accuracy: 0.920000, Test accuracy: 0.923100
Distillation: Epoch : 19, Loss : 1.719338, Accuracy: 0.911000, Test accuracy: 0.925600
Distillation: Epoch : 20, Loss : 1.713420, Accuracy: 0.939000, Test accuracy: 0.928600
Distillation: Epoch : 21, Loss : 1.730755, Accuracy: 0.930000, Test accuracy: 0.931600
Distillation: Epoch : 22, Loss : 1.730282, Accuracy: 0.925000, Test accuracy: 0.934500
Distillation: Epoch : 23, Loss : 1.716131, Accuracy: 0.927000, Test accuracy: 0.936400
Distillation: Epoch : 24, Loss : 1.712114, Accuracy: 0.940000, Test accuracy: 0.938300
Distillation: Epoch : 25, Loss : 1.713337, Accuracy: 0.933000, Test accuracy: 0.940300
Distillation: Epoch : 26, Loss : 1.720638, Accuracy: 0.944000, Test accuracy: 0.943300
Distillation: Epoch : 27, Loss : 1.709749, Accuracy: 0.933000, Test accuracy: 0.944300
Distillation: Epoch : 28, Loss : 1.706239, Accuracy: 0.936000, Test accuracy: 0.945100
Distillation: Epoch : 29, Loss : 1.693106, Accuracy: 0.946000, Test accuracy: 0.946800
Distillation: Epoch : 30, Loss : 1.698834, Accuracy: 0.940000, Test accuracy: 0.947600
Distillation: Epoch : 31, Loss : 1.691400, Accuracy: 0.935000, Test accuracy: 0.948300
Distillation: Epoch : 32, Loss : 1.679943, Accuracy: 0.941000, Test accuracy: 0.950400
Distillation: Epoch : 33, Loss : 1.710982, Accuracy: 0.952000, Test accuracy: 0.951600
Distillation: Epoch : 34, Loss : 1.698686, Accuracy: 0.940000, Test accuracy: 0.953300
Distillation: Epoch : 35, Loss : 1.697840, Accuracy: 0.956000, Test accuracy: 0.954000
Distillation: Epoch : 36, Loss : 1.691065, Accuracy: 0.958000, Test accuracy: 0.955000
Distillation: Epoch : 37, Loss : 1.689777, Accuracy: 0.962000, Test accuracy: 0.955600
Distillation: Epoch : 38, Loss : 1.694614, Accuracy: 0.943000, Test accuracy: 0.957800
Distillation: Epoch : 39, Loss : 1.708670, Accuracy: 0.965000, Test accuracy: 0.958100
Distillation: Epoch : 40, Loss : 1.696414, Accuracy: 0.951000, Test accuracy: 0.958700
Distillation: Epoch : 41, Loss : 1.697267, Accuracy: 0.952000, Test accuracy: 0.959400
Distillation: Epoch : 42, Loss : 1.697127, Accuracy: 0.954000, Test accuracy: 0.960300
Distillation: Epoch : 43, Loss : 1.699684, Accuracy: 0.956000, Test accuracy: 0.959900
Distillation: Epoch : 44, Loss : 1.686098, Accuracy: 0.948000, Test accuracy: 0.960100
Distillation: Epoch : 45, Loss : 1.697389, Accuracy: 0.962000, Test accuracy: 0.960100
Distillation: Epoch : 46, Loss : 1.691213, Accuracy: 0.959000, Test accuracy: 0.961200
Distillation: Epoch : 47, Loss : 1.676774, Accuracy: 0.955000, Test accuracy: 0.961000
Distillation: Epoch : 48, Loss : 1.683121, Accuracy: 0.973000, Test accuracy: 0.961700
Distillation: Epoch : 49, Loss : 1.691527, Accuracy: 0.956000, Test accuracy: 0.961700
Distillation: Epoch : 50, Loss : 1.687499, Accuracy: 0.953000, Test accuracy: 0.962100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9621
Generating confusion matrix for student2
[[ 974.    0.    8.    0.    1.    2.    5.    2.    8.    6.]
 [   0. 1124.   10.    0.    0.    0.    4.   10.    8.    5.]
 [   1.    2.  963.    5.    2.    0.    0.   13.    7.    1.]
 [   0.    2.   14.  978.    0.    7.    0.    2.    8.    1.]
 [   0.    1.    9.    1.  964.    0.    3.   11.    7.   20.]
 [   2.    0.    0.   11.    0.  855.    9.    0.   13.    4.]
 [   2.    5.    4.    1.    4.    6.  934.    0.    5.    0.]
 [   1.    0.    8.   10.    1.    5.    0.  979.    8.   15.]
 [   0.    1.   14.    2.    2.    8.    3.    0.  898.    5.]
 [   0.    0.    2.    2.    8.    9.    0.   11.   12.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.164751, Accuracy: 0.751000, Test accuracy: 0.753700
Distillation: Epoch : 2, Loss : 2.070516, Accuracy: 0.811000, Test accuracy: 0.821900
Distillation: Epoch : 3, Loss : 2.043570, Accuracy: 0.848000, Test accuracy: 0.849900
Distillation: Epoch : 4, Loss : 2.041142, Accuracy: 0.855000, Test accuracy: 0.864600
Distillation: Epoch : 5, Loss : 2.026802, Accuracy: 0.861000, Test accuracy: 0.871200
Distillation: Epoch : 6, Loss : 2.029768, Accuracy: 0.864000, Test accuracy: 0.876100
Distillation: Epoch : 7, Loss : 2.022038, Accuracy: 0.868000, Test accuracy: 0.882800
Distillation: Epoch : 8, Loss : 2.017034, Accuracy: 0.871000, Test accuracy: 0.884800
Distillation: Epoch : 9, Loss : 2.023661, Accuracy: 0.883000, Test accuracy: 0.887700
Distillation: Epoch : 10, Loss : 2.026284, Accuracy: 0.879000, Test accuracy: 0.889000
Distillation: Epoch : 11, Loss : 2.014144, Accuracy: 0.879000, Test accuracy: 0.892700
Distillation: Epoch : 12, Loss : 2.013408, Accuracy: 0.873000, Test accuracy: 0.892900
Distillation: Epoch : 13, Loss : 2.013573, Accuracy: 0.898000, Test accuracy: 0.893400
Distillation: Epoch : 14, Loss : 2.022199, Accuracy: 0.873000, Test accuracy: 0.895500
Distillation: Epoch : 15, Loss : 2.009579, Accuracy: 0.890000, Test accuracy: 0.897400
Distillation: Epoch : 16, Loss : 2.005004, Accuracy: 0.892000, Test accuracy: 0.897200
Distillation: Epoch : 17, Loss : 1.995950, Accuracy: 0.906000, Test accuracy: 0.899300
Distillation: Epoch : 18, Loss : 2.009515, Accuracy: 0.885000, Test accuracy: 0.899700
Distillation: Epoch : 19, Loss : 2.005667, Accuracy: 0.911000, Test accuracy: 0.903900
Distillation: Epoch : 20, Loss : 2.003909, Accuracy: 0.909000, Test accuracy: 0.904900
Distillation: Epoch : 21, Loss : 2.000273, Accuracy: 0.891000, Test accuracy: 0.906700
Distillation: Epoch : 22, Loss : 1.998539, Accuracy: 0.905000, Test accuracy: 0.909400
Distillation: Epoch : 23, Loss : 1.995819, Accuracy: 0.902000, Test accuracy: 0.910100
Distillation: Epoch : 24, Loss : 2.008899, Accuracy: 0.901000, Test accuracy: 0.914100
Distillation: Epoch : 25, Loss : 2.001909, Accuracy: 0.910000, Test accuracy: 0.914600
Distillation: Epoch : 26, Loss : 1.988899, Accuracy: 0.904000, Test accuracy: 0.916800
Distillation: Epoch : 27, Loss : 1.997619, Accuracy: 0.913000, Test accuracy: 0.918700
Distillation: Epoch : 28, Loss : 1.994254, Accuracy: 0.930000, Test accuracy: 0.920400
Distillation: Epoch : 29, Loss : 1.988112, Accuracy: 0.919000, Test accuracy: 0.923900
Distillation: Epoch : 30, Loss : 1.995884, Accuracy: 0.921000, Test accuracy: 0.926700
Distillation: Epoch : 31, Loss : 1.985124, Accuracy: 0.924000, Test accuracy: 0.928900
Distillation: Epoch : 32, Loss : 1.988127, Accuracy: 0.934000, Test accuracy: 0.932400
Distillation: Epoch : 33, Loss : 1.987287, Accuracy: 0.932000, Test accuracy: 0.934500
Distillation: Epoch : 34, Loss : 1.985638, Accuracy: 0.927000, Test accuracy: 0.938600
Distillation: Epoch : 35, Loss : 1.984814, Accuracy: 0.946000, Test accuracy: 0.939700
Distillation: Epoch : 36, Loss : 1.984574, Accuracy: 0.930000, Test accuracy: 0.942500
Distillation: Epoch : 37, Loss : 1.982393, Accuracy: 0.944000, Test accuracy: 0.946000
Distillation: Epoch : 38, Loss : 1.989597, Accuracy: 0.924000, Test accuracy: 0.946800
Distillation: Epoch : 39, Loss : 1.983137, Accuracy: 0.927000, Test accuracy: 0.948600
Distillation: Epoch : 40, Loss : 1.981453, Accuracy: 0.943000, Test accuracy: 0.950500
Distillation: Epoch : 41, Loss : 1.975550, Accuracy: 0.942000, Test accuracy: 0.951900
Distillation: Epoch : 42, Loss : 1.969393, Accuracy: 0.944000, Test accuracy: 0.953200
Distillation: Epoch : 43, Loss : 1.966838, Accuracy: 0.952000, Test accuracy: 0.954400
Distillation: Epoch : 44, Loss : 1.978160, Accuracy: 0.947000, Test accuracy: 0.955200
Distillation: Epoch : 45, Loss : 1.974727, Accuracy: 0.953000, Test accuracy: 0.956300
Distillation: Epoch : 46, Loss : 1.966515, Accuracy: 0.950000, Test accuracy: 0.956400
Distillation: Epoch : 47, Loss : 1.973824, Accuracy: 0.943000, Test accuracy: 0.958700
Distillation: Epoch : 48, Loss : 1.972535, Accuracy: 0.962000, Test accuracy: 0.958200
Distillation: Epoch : 49, Loss : 1.961886, Accuracy: 0.961000, Test accuracy: 0.959000
Distillation: Epoch : 50, Loss : 1.970350, Accuracy: 0.958000, Test accuracy: 0.959800
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9598
Generating confusion matrix for student2
[[ 970.    0.   10.    1.    1.    2.    6.    4.   10.    7.]
 [   0. 1124.    9.    1.    2.    1.    3.    9.    5.    5.]
 [   1.    2.  959.    1.    4.    1.    1.   13.    9.    0.]
 [   0.    1.    5.  976.    0.    2.    1.    0.    9.    6.]
 [   1.    2.   11.    1.  955.    0.    6.    9.    9.   25.]
 [   1.    1.    1.    8.    0.  870.   15.    1.    8.    1.]
 [   5.    4.    4.    1.    4.    7.  924.    0.    5.    0.]
 [   1.    1.   15.   11.    2.    3.    0.  973.   10.   14.]
 [   1.    0.   17.    5.    2.    2.    2.    1.  899.    3.]
 [   0.    0.    1.    5.   12.    4.    0.   18.   10.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.098372, Accuracy: 0.747000, Test accuracy: 0.757000
Distillation: Epoch : 2, Loss : 0.528834, Accuracy: 0.858000, Test accuracy: 0.857300
Distillation: Epoch : 3, Loss : 0.439056, Accuracy: 0.874000, Test accuracy: 0.888700
Distillation: Epoch : 4, Loss : 0.372549, Accuracy: 0.886000, Test accuracy: 0.904200
Distillation: Epoch : 5, Loss : 0.336080, Accuracy: 0.904000, Test accuracy: 0.913900
Distillation: Epoch : 6, Loss : 0.300447, Accuracy: 0.910000, Test accuracy: 0.918800
Distillation: Epoch : 7, Loss : 0.253132, Accuracy: 0.911000, Test accuracy: 0.924300
Distillation: Epoch : 8, Loss : 0.247381, Accuracy: 0.926000, Test accuracy: 0.929800
Distillation: Epoch : 9, Loss : 0.247825, Accuracy: 0.930000, Test accuracy: 0.931800
Distillation: Epoch : 10, Loss : 0.191307, Accuracy: 0.937000, Test accuracy: 0.934400
Distillation: Epoch : 11, Loss : 0.255990, Accuracy: 0.921000, Test accuracy: 0.935300
Distillation: Epoch : 12, Loss : 0.223380, Accuracy: 0.938000, Test accuracy: 0.938900
Distillation: Epoch : 13, Loss : 0.239431, Accuracy: 0.933000, Test accuracy: 0.940100
Distillation: Epoch : 14, Loss : 0.229639, Accuracy: 0.928000, Test accuracy: 0.941600
Distillation: Epoch : 15, Loss : 0.178058, Accuracy: 0.945000, Test accuracy: 0.942700
Distillation: Epoch : 16, Loss : 0.182068, Accuracy: 0.952000, Test accuracy: 0.944500
Distillation: Epoch : 17, Loss : 0.208780, Accuracy: 0.940000, Test accuracy: 0.946600
Distillation: Epoch : 18, Loss : 0.173318, Accuracy: 0.949000, Test accuracy: 0.946600
Distillation: Epoch : 19, Loss : 0.171914, Accuracy: 0.951000, Test accuracy: 0.949500
Distillation: Epoch : 20, Loss : 0.175641, Accuracy: 0.948000, Test accuracy: 0.949100
Distillation: Epoch : 21, Loss : 0.171602, Accuracy: 0.949000, Test accuracy: 0.950300
Distillation: Epoch : 22, Loss : 0.168662, Accuracy: 0.954000, Test accuracy: 0.952200
Distillation: Epoch : 23, Loss : 0.196889, Accuracy: 0.944000, Test accuracy: 0.953200
Distillation: Epoch : 24, Loss : 0.173591, Accuracy: 0.943000, Test accuracy: 0.953900
Distillation: Epoch : 25, Loss : 0.179788, Accuracy: 0.946000, Test accuracy: 0.953300
Distillation: Epoch : 26, Loss : 0.180971, Accuracy: 0.946000, Test accuracy: 0.954200
Distillation: Epoch : 27, Loss : 0.134072, Accuracy: 0.957000, Test accuracy: 0.955200
Distillation: Epoch : 28, Loss : 0.145057, Accuracy: 0.953000, Test accuracy: 0.954900
Distillation: Epoch : 29, Loss : 0.162066, Accuracy: 0.952000, Test accuracy: 0.956400
Distillation: Epoch : 30, Loss : 0.172609, Accuracy: 0.946000, Test accuracy: 0.957100
Distillation: Epoch : 31, Loss : 0.151687, Accuracy: 0.953000, Test accuracy: 0.956700
Distillation: Epoch : 32, Loss : 0.163027, Accuracy: 0.948000, Test accuracy: 0.956800
Distillation: Epoch : 33, Loss : 0.166412, Accuracy: 0.952000, Test accuracy: 0.957100
Distillation: Epoch : 34, Loss : 0.110345, Accuracy: 0.961000, Test accuracy: 0.958100
Distillation: Epoch : 35, Loss : 0.146312, Accuracy: 0.954000, Test accuracy: 0.957600
Distillation: Epoch : 36, Loss : 0.171571, Accuracy: 0.955000, Test accuracy: 0.958800
Distillation: Epoch : 37, Loss : 0.170051, Accuracy: 0.941000, Test accuracy: 0.958900
Distillation: Epoch : 38, Loss : 0.148670, Accuracy: 0.948000, Test accuracy: 0.959000
Distillation: Epoch : 39, Loss : 0.106575, Accuracy: 0.966000, Test accuracy: 0.959500
Distillation: Epoch : 40, Loss : 0.147222, Accuracy: 0.954000, Test accuracy: 0.959700
Distillation: Epoch : 41, Loss : 0.148397, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 42, Loss : 0.112339, Accuracy: 0.961000, Test accuracy: 0.959700
Distillation: Epoch : 43, Loss : 0.126667, Accuracy: 0.960000, Test accuracy: 0.959100
Distillation: Epoch : 44, Loss : 0.141476, Accuracy: 0.959000, Test accuracy: 0.960400
Distillation: Epoch : 45, Loss : 0.147496, Accuracy: 0.955000, Test accuracy: 0.959800
Distillation: Epoch : 46, Loss : 0.135580, Accuracy: 0.951000, Test accuracy: 0.960800
Distillation: Epoch : 47, Loss : 0.124030, Accuracy: 0.958000, Test accuracy: 0.960800
Distillation: Epoch : 48, Loss : 0.129881, Accuracy: 0.960000, Test accuracy: 0.960500
Distillation: Epoch : 49, Loss : 0.141597, Accuracy: 0.968000, Test accuracy: 0.960200
Distillation: Epoch : 50, Loss : 0.142064, Accuracy: 0.953000, Test accuracy: 0.960900
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9609
Generating confusion matrix for student3
[[ 969.    0.    6.    1.    2.    3.   13.    0.    6.    9.]
 [   0. 1120.    3.    0.    1.    2.    3.    3.    4.    5.]
 [   1.    2.  976.    6.    7.    1.    7.   18.    8.    2.]
 [   0.    1.   11.  978.    0.   18.    0.    7.   10.   11.]
 [   0.    0.    3.    0.  946.    0.    2.    2.    5.    6.]
 [   2.    1.    0.    5.    0.  847.    8.    1.    5.    4.]
 [   5.    3.    3.    0.    2.    4.  921.    0.    3.    0.]
 [   2.    0.    6.    6.    4.    1.    1.  982.    6.   17.]
 [   0.    8.   24.   10.    3.   13.    3.    2.  918.    3.]
 [   1.    0.    0.    4.   17.    3.    0.   13.    9.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.330779, Accuracy: 0.778000, Test accuracy: 0.786600
Distillation: Epoch : 2, Loss : 0.718201, Accuracy: 0.825000, Test accuracy: 0.847000
Distillation: Epoch : 3, Loss : 0.556575, Accuracy: 0.840000, Test accuracy: 0.873700
Distillation: Epoch : 4, Loss : 0.440409, Accuracy: 0.876000, Test accuracy: 0.887300
Distillation: Epoch : 5, Loss : 0.424691, Accuracy: 0.891000, Test accuracy: 0.895600
Distillation: Epoch : 6, Loss : 0.373935, Accuracy: 0.905000, Test accuracy: 0.900400
Distillation: Epoch : 7, Loss : 0.380039, Accuracy: 0.878000, Test accuracy: 0.904100
Distillation: Epoch : 8, Loss : 0.331243, Accuracy: 0.907000, Test accuracy: 0.907200
Distillation: Epoch : 9, Loss : 0.367599, Accuracy: 0.910000, Test accuracy: 0.909300
Distillation: Epoch : 10, Loss : 0.366268, Accuracy: 0.901000, Test accuracy: 0.911000
Distillation: Epoch : 11, Loss : 0.356897, Accuracy: 0.911000, Test accuracy: 0.912600
Distillation: Epoch : 12, Loss : 0.286318, Accuracy: 0.929000, Test accuracy: 0.914000
Distillation: Epoch : 13, Loss : 0.291303, Accuracy: 0.913000, Test accuracy: 0.916000
Distillation: Epoch : 14, Loss : 0.269091, Accuracy: 0.927000, Test accuracy: 0.916000
Distillation: Epoch : 15, Loss : 0.299155, Accuracy: 0.925000, Test accuracy: 0.918300
Distillation: Epoch : 16, Loss : 0.269161, Accuracy: 0.924000, Test accuracy: 0.918300
Distillation: Epoch : 17, Loss : 0.311325, Accuracy: 0.928000, Test accuracy: 0.919300
Distillation: Epoch : 18, Loss : 0.280148, Accuracy: 0.909000, Test accuracy: 0.919800
Distillation: Epoch : 19, Loss : 0.299035, Accuracy: 0.926000, Test accuracy: 0.921700
Distillation: Epoch : 20, Loss : 0.306321, Accuracy: 0.923000, Test accuracy: 0.923900
Distillation: Epoch : 21, Loss : 0.267445, Accuracy: 0.923000, Test accuracy: 0.924700
Distillation: Epoch : 22, Loss : 0.307111, Accuracy: 0.921000, Test accuracy: 0.925000
Distillation: Epoch : 23, Loss : 0.265213, Accuracy: 0.928000, Test accuracy: 0.927100
Distillation: Epoch : 24, Loss : 0.281442, Accuracy: 0.929000, Test accuracy: 0.927400
Distillation: Epoch : 25, Loss : 0.287383, Accuracy: 0.923000, Test accuracy: 0.929200
Distillation: Epoch : 26, Loss : 0.316625, Accuracy: 0.928000, Test accuracy: 0.930800
Distillation: Epoch : 27, Loss : 0.297924, Accuracy: 0.923000, Test accuracy: 0.931600
Distillation: Epoch : 28, Loss : 0.232119, Accuracy: 0.939000, Test accuracy: 0.932300
Distillation: Epoch : 29, Loss : 0.239595, Accuracy: 0.937000, Test accuracy: 0.934300
Distillation: Epoch : 30, Loss : 0.269763, Accuracy: 0.928000, Test accuracy: 0.935300
Distillation: Epoch : 31, Loss : 0.244067, Accuracy: 0.928000, Test accuracy: 0.937100
Distillation: Epoch : 32, Loss : 0.216214, Accuracy: 0.941000, Test accuracy: 0.938100
Distillation: Epoch : 33, Loss : 0.254493, Accuracy: 0.932000, Test accuracy: 0.938600
Distillation: Epoch : 34, Loss : 0.218776, Accuracy: 0.939000, Test accuracy: 0.940200
Distillation: Epoch : 35, Loss : 0.243308, Accuracy: 0.943000, Test accuracy: 0.942100
Distillation: Epoch : 36, Loss : 0.219424, Accuracy: 0.938000, Test accuracy: 0.942100
Distillation: Epoch : 37, Loss : 0.207140, Accuracy: 0.952000, Test accuracy: 0.943000
Distillation: Epoch : 38, Loss : 0.235581, Accuracy: 0.933000, Test accuracy: 0.943700
Distillation: Epoch : 39, Loss : 0.223838, Accuracy: 0.941000, Test accuracy: 0.944600
Distillation: Epoch : 40, Loss : 0.205576, Accuracy: 0.950000, Test accuracy: 0.945500
Distillation: Epoch : 41, Loss : 0.201954, Accuracy: 0.946000, Test accuracy: 0.947600
Distillation: Epoch : 42, Loss : 0.208661, Accuracy: 0.950000, Test accuracy: 0.947600
Distillation: Epoch : 43, Loss : 0.187140, Accuracy: 0.951000, Test accuracy: 0.948300
Distillation: Epoch : 44, Loss : 0.178998, Accuracy: 0.947000, Test accuracy: 0.948500
Distillation: Epoch : 45, Loss : 0.204218, Accuracy: 0.947000, Test accuracy: 0.950300
Distillation: Epoch : 46, Loss : 0.208665, Accuracy: 0.938000, Test accuracy: 0.950600
Distillation: Epoch : 47, Loss : 0.195199, Accuracy: 0.946000, Test accuracy: 0.952500
Distillation: Epoch : 48, Loss : 0.207841, Accuracy: 0.947000, Test accuracy: 0.951900
Distillation: Epoch : 49, Loss : 0.164504, Accuracy: 0.963000, Test accuracy: 0.952600
Distillation: Epoch : 50, Loss : 0.185804, Accuracy: 0.948000, Test accuracy: 0.953300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9533
Generating confusion matrix for student3
[[ 966.    0.    4.    0.    1.    5.    9.    1.    7.    6.]
 [   0. 1124.    8.    0.    2.    1.    4.    6.    4.    6.]
 [   2.    3.  958.    8.    3.    0.    1.   17.    7.    1.]
 [   0.    1.   15.  969.    0.   11.    1.    3.   14.   11.]
 [   0.    0.    6.    0.  951.    2.    9.    3.    7.   18.]
 [   3.    1.    1.   11.    0.  844.    6.    2.   16.    8.]
 [   6.    4.    5.    1.    5.    6.  921.    0.    7.    0.]
 [   1.    0.    9.    5.    2.    4.    1.  973.   11.   19.]
 [   2.    2.   23.   10.    2.   15.    6.    3.  892.    5.]
 [   0.    0.    3.    6.   16.    4.    0.   20.    9.  935.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.512936, Accuracy: 0.711000, Test accuracy: 0.738600
Distillation: Epoch : 2, Loss : 0.950523, Accuracy: 0.802000, Test accuracy: 0.825600
Distillation: Epoch : 3, Loss : 0.819503, Accuracy: 0.833000, Test accuracy: 0.861100
Distillation: Epoch : 4, Loss : 0.727139, Accuracy: 0.858000, Test accuracy: 0.876100
Distillation: Epoch : 5, Loss : 0.675975, Accuracy: 0.879000, Test accuracy: 0.886200
Distillation: Epoch : 6, Loss : 0.690122, Accuracy: 0.885000, Test accuracy: 0.893400
Distillation: Epoch : 7, Loss : 0.577741, Accuracy: 0.909000, Test accuracy: 0.896600
Distillation: Epoch : 8, Loss : 0.646964, Accuracy: 0.889000, Test accuracy: 0.900300
Distillation: Epoch : 9, Loss : 0.649277, Accuracy: 0.894000, Test accuracy: 0.901800
Distillation: Epoch : 10, Loss : 0.638645, Accuracy: 0.879000, Test accuracy: 0.902100
Distillation: Epoch : 11, Loss : 0.665258, Accuracy: 0.877000, Test accuracy: 0.904500
Distillation: Epoch : 12, Loss : 0.582273, Accuracy: 0.907000, Test accuracy: 0.905100
Distillation: Epoch : 13, Loss : 0.603291, Accuracy: 0.906000, Test accuracy: 0.905500
Distillation: Epoch : 14, Loss : 0.620354, Accuracy: 0.897000, Test accuracy: 0.907300
Distillation: Epoch : 15, Loss : 0.663298, Accuracy: 0.884000, Test accuracy: 0.907900
Distillation: Epoch : 16, Loss : 0.605163, Accuracy: 0.900000, Test accuracy: 0.907500
Distillation: Epoch : 17, Loss : 0.598469, Accuracy: 0.905000, Test accuracy: 0.908200
Distillation: Epoch : 18, Loss : 0.604684, Accuracy: 0.892000, Test accuracy: 0.909600
Distillation: Epoch : 19, Loss : 0.614715, Accuracy: 0.904000, Test accuracy: 0.908200
Distillation: Epoch : 20, Loss : 0.626204, Accuracy: 0.896000, Test accuracy: 0.910000
Distillation: Epoch : 21, Loss : 0.618527, Accuracy: 0.910000, Test accuracy: 0.910900
Distillation: Epoch : 22, Loss : 0.585100, Accuracy: 0.899000, Test accuracy: 0.911900
Distillation: Epoch : 23, Loss : 0.584423, Accuracy: 0.900000, Test accuracy: 0.912300
Distillation: Epoch : 24, Loss : 0.537910, Accuracy: 0.930000, Test accuracy: 0.911900
Distillation: Epoch : 25, Loss : 0.589932, Accuracy: 0.898000, Test accuracy: 0.913200
Distillation: Epoch : 26, Loss : 0.596067, Accuracy: 0.917000, Test accuracy: 0.913300
Distillation: Epoch : 27, Loss : 0.555320, Accuracy: 0.911000, Test accuracy: 0.914600
Distillation: Epoch : 28, Loss : 0.601246, Accuracy: 0.905000, Test accuracy: 0.915400
Distillation: Epoch : 29, Loss : 0.570435, Accuracy: 0.915000, Test accuracy: 0.915300
Distillation: Epoch : 30, Loss : 0.587805, Accuracy: 0.915000, Test accuracy: 0.916600
Distillation: Epoch : 31, Loss : 0.568821, Accuracy: 0.911000, Test accuracy: 0.915000
Distillation: Epoch : 32, Loss : 0.556320, Accuracy: 0.922000, Test accuracy: 0.915900
Distillation: Epoch : 33, Loss : 0.574404, Accuracy: 0.921000, Test accuracy: 0.917000
Distillation: Epoch : 34, Loss : 0.584149, Accuracy: 0.913000, Test accuracy: 0.917500
Distillation: Epoch : 35, Loss : 0.570241, Accuracy: 0.913000, Test accuracy: 0.918400
Distillation: Epoch : 36, Loss : 0.573169, Accuracy: 0.911000, Test accuracy: 0.918200
Distillation: Epoch : 37, Loss : 0.587014, Accuracy: 0.907000, Test accuracy: 0.917800
Distillation: Epoch : 38, Loss : 0.587527, Accuracy: 0.912000, Test accuracy: 0.918500
Distillation: Epoch : 39, Loss : 0.606311, Accuracy: 0.898000, Test accuracy: 0.918600
Distillation: Epoch : 40, Loss : 0.572547, Accuracy: 0.915000, Test accuracy: 0.919000
Distillation: Epoch : 41, Loss : 0.587953, Accuracy: 0.906000, Test accuracy: 0.920300
Distillation: Epoch : 42, Loss : 0.535825, Accuracy: 0.919000, Test accuracy: 0.920900
Distillation: Epoch : 43, Loss : 0.570367, Accuracy: 0.920000, Test accuracy: 0.920100
Distillation: Epoch : 44, Loss : 0.579866, Accuracy: 0.911000, Test accuracy: 0.921900
Distillation: Epoch : 45, Loss : 0.510644, Accuracy: 0.935000, Test accuracy: 0.920400
Distillation: Epoch : 46, Loss : 0.567698, Accuracy: 0.907000, Test accuracy: 0.922100
Distillation: Epoch : 47, Loss : 0.563051, Accuracy: 0.915000, Test accuracy: 0.921600
Distillation: Epoch : 48, Loss : 0.544124, Accuracy: 0.927000, Test accuracy: 0.923800
Distillation: Epoch : 49, Loss : 0.568883, Accuracy: 0.924000, Test accuracy: 0.923100
Distillation: Epoch : 50, Loss : 0.561786, Accuracy: 0.923000, Test accuracy: 0.924200
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9242
Generating confusion matrix for student3
[[ 963.    0.   11.    4.    0.    8.    9.    2.    8.    9.]
 [   0. 1116.   12.    2.    4.    3.    3.   18.    9.    7.]
 [   1.    2.  914.   16.    5.    2.    4.   19.    9.    1.]
 [   2.    2.   20.  930.    1.   33.    2.    3.   21.   10.]
 [   0.    0.   12.    2.  929.   10.    9.   11.   12.   38.]
 [   4.    3.    1.   17.    1.  777.   15.    0.   30.    5.]
 [   7.    4.   10.    3.    7.   14.  913.    0.   10.    0.]
 [   1.    1.   13.   12.    2.    7.    2.  941.   10.   25.]
 [   2.    7.   33.   16.    5.   30.    1.    0.  852.    7.]
 [   0.    0.    6.    8.   28.    8.    0.   34.   13.  907.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.781640, Accuracy: 0.717000, Test accuracy: 0.735500
Distillation: Epoch : 2, Loss : 1.166421, Accuracy: 0.803000, Test accuracy: 0.823900
Distillation: Epoch : 3, Loss : 0.943309, Accuracy: 0.828000, Test accuracy: 0.863600
Distillation: Epoch : 4, Loss : 0.838991, Accuracy: 0.882000, Test accuracy: 0.882700
Distillation: Epoch : 5, Loss : 0.793082, Accuracy: 0.897000, Test accuracy: 0.894800
Distillation: Epoch : 6, Loss : 0.755583, Accuracy: 0.896000, Test accuracy: 0.904000
Distillation: Epoch : 7, Loss : 0.730694, Accuracy: 0.917000, Test accuracy: 0.908900
Distillation: Epoch : 8, Loss : 0.767399, Accuracy: 0.899000, Test accuracy: 0.914700
Distillation: Epoch : 9, Loss : 0.747781, Accuracy: 0.911000, Test accuracy: 0.916900
Distillation: Epoch : 10, Loss : 0.734026, Accuracy: 0.912000, Test accuracy: 0.919400
Distillation: Epoch : 11, Loss : 0.705833, Accuracy: 0.920000, Test accuracy: 0.922200
Distillation: Epoch : 12, Loss : 0.707244, Accuracy: 0.927000, Test accuracy: 0.925300
Distillation: Epoch : 13, Loss : 0.680127, Accuracy: 0.925000, Test accuracy: 0.927800
Distillation: Epoch : 14, Loss : 0.705271, Accuracy: 0.924000, Test accuracy: 0.928600
Distillation: Epoch : 15, Loss : 0.714323, Accuracy: 0.922000, Test accuracy: 0.932200
Distillation: Epoch : 16, Loss : 0.704056, Accuracy: 0.913000, Test accuracy: 0.932500
Distillation: Epoch : 17, Loss : 0.662176, Accuracy: 0.937000, Test accuracy: 0.935000
Distillation: Epoch : 18, Loss : 0.655560, Accuracy: 0.940000, Test accuracy: 0.937000
Distillation: Epoch : 19, Loss : 0.672073, Accuracy: 0.927000, Test accuracy: 0.938300
Distillation: Epoch : 20, Loss : 0.673560, Accuracy: 0.937000, Test accuracy: 0.939500
Distillation: Epoch : 21, Loss : 0.644666, Accuracy: 0.933000, Test accuracy: 0.941000
Distillation: Epoch : 22, Loss : 0.646351, Accuracy: 0.937000, Test accuracy: 0.942700
Distillation: Epoch : 23, Loss : 0.647530, Accuracy: 0.941000, Test accuracy: 0.944400
Distillation: Epoch : 24, Loss : 0.638469, Accuracy: 0.963000, Test accuracy: 0.945000
Distillation: Epoch : 25, Loss : 0.610215, Accuracy: 0.955000, Test accuracy: 0.946900
Distillation: Epoch : 26, Loss : 0.623065, Accuracy: 0.951000, Test accuracy: 0.947200
Distillation: Epoch : 27, Loss : 0.655274, Accuracy: 0.928000, Test accuracy: 0.948000
Distillation: Epoch : 28, Loss : 0.660068, Accuracy: 0.940000, Test accuracy: 0.949000
Distillation: Epoch : 29, Loss : 0.655901, Accuracy: 0.934000, Test accuracy: 0.949800
Distillation: Epoch : 30, Loss : 0.635625, Accuracy: 0.950000, Test accuracy: 0.950500
Distillation: Epoch : 31, Loss : 0.649649, Accuracy: 0.941000, Test accuracy: 0.950700
Distillation: Epoch : 32, Loss : 0.625460, Accuracy: 0.941000, Test accuracy: 0.953000
Distillation: Epoch : 33, Loss : 0.633343, Accuracy: 0.944000, Test accuracy: 0.952500
Distillation: Epoch : 34, Loss : 0.614418, Accuracy: 0.950000, Test accuracy: 0.953600
Distillation: Epoch : 35, Loss : 0.625735, Accuracy: 0.956000, Test accuracy: 0.954700
Distillation: Epoch : 36, Loss : 0.615374, Accuracy: 0.951000, Test accuracy: 0.954700
Distillation: Epoch : 37, Loss : 0.612175, Accuracy: 0.956000, Test accuracy: 0.955600
Distillation: Epoch : 38, Loss : 0.669381, Accuracy: 0.936000, Test accuracy: 0.955300
Distillation: Epoch : 39, Loss : 0.622708, Accuracy: 0.958000, Test accuracy: 0.955700
Distillation: Epoch : 40, Loss : 0.614462, Accuracy: 0.957000, Test accuracy: 0.956700
Distillation: Epoch : 41, Loss : 0.660640, Accuracy: 0.934000, Test accuracy: 0.955800
Distillation: Epoch : 42, Loss : 0.635187, Accuracy: 0.958000, Test accuracy: 0.955700
Distillation: Epoch : 43, Loss : 0.603247, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 44, Loss : 0.655788, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 45, Loss : 0.607370, Accuracy: 0.966000, Test accuracy: 0.957000
Distillation: Epoch : 46, Loss : 0.619242, Accuracy: 0.950000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 0.636984, Accuracy: 0.949000, Test accuracy: 0.956400
Distillation: Epoch : 48, Loss : 0.606882, Accuracy: 0.961000, Test accuracy: 0.957800
Distillation: Epoch : 49, Loss : 0.586093, Accuracy: 0.955000, Test accuracy: 0.957300
Distillation: Epoch : 50, Loss : 0.611825, Accuracy: 0.943000, Test accuracy: 0.958000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.958
Generating confusion matrix for student3
[[ 973.    0.    5.    1.    1.    2.    3.    2.   10.    5.]
 [   0. 1124.    7.    0.    3.    1.    3.   10.    5.    7.]
 [   1.    3.  966.    4.    3.    0.    1.   13.    8.    0.]
 [   0.    1.   10.  972.    0.    7.    1.    3.   11.    6.]
 [   0.    1.    8.    2.  954.    0.    7.    6.    6.   24.]
 [   1.    0.    0.   10.    0.  856.    6.    0.    6.    4.]
 [   2.    3.    4.    0.    5.    6.  934.    0.    7.    0.]
 [   1.    0.   13.    8.    2.    3.    0.  963.   13.   19.]
 [   2.    3.   16.    7.    4.   11.    3.    3.  898.    4.]
 [   0.    0.    3.    6.   10.    6.    0.   28.   10.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.884055, Accuracy: 0.728000, Test accuracy: 0.742300
Distillation: Epoch : 2, Loss : 1.279677, Accuracy: 0.793000, Test accuracy: 0.816100
Distillation: Epoch : 3, Loss : 1.059208, Accuracy: 0.844000, Test accuracy: 0.850500
Distillation: Epoch : 4, Loss : 1.023490, Accuracy: 0.860000, Test accuracy: 0.869700
Distillation: Epoch : 5, Loss : 0.972050, Accuracy: 0.877000, Test accuracy: 0.881700
Distillation: Epoch : 6, Loss : 0.949916, Accuracy: 0.873000, Test accuracy: 0.890300
Distillation: Epoch : 7, Loss : 0.970168, Accuracy: 0.896000, Test accuracy: 0.895600
Distillation: Epoch : 8, Loss : 0.934762, Accuracy: 0.896000, Test accuracy: 0.899400
Distillation: Epoch : 9, Loss : 0.938912, Accuracy: 0.889000, Test accuracy: 0.903600
Distillation: Epoch : 10, Loss : 0.921904, Accuracy: 0.905000, Test accuracy: 0.906500
Distillation: Epoch : 11, Loss : 0.892238, Accuracy: 0.904000, Test accuracy: 0.909200
Distillation: Epoch : 12, Loss : 0.913143, Accuracy: 0.906000, Test accuracy: 0.911500
Distillation: Epoch : 13, Loss : 0.908913, Accuracy: 0.914000, Test accuracy: 0.915000
Distillation: Epoch : 14, Loss : 0.911578, Accuracy: 0.909000, Test accuracy: 0.916900
Distillation: Epoch : 15, Loss : 0.927454, Accuracy: 0.901000, Test accuracy: 0.918500
Distillation: Epoch : 16, Loss : 0.864834, Accuracy: 0.921000, Test accuracy: 0.921500
Distillation: Epoch : 17, Loss : 0.885850, Accuracy: 0.900000, Test accuracy: 0.922400
Distillation: Epoch : 18, Loss : 0.828862, Accuracy: 0.934000, Test accuracy: 0.924900
Distillation: Epoch : 19, Loss : 0.854649, Accuracy: 0.930000, Test accuracy: 0.926000
Distillation: Epoch : 20, Loss : 0.852583, Accuracy: 0.930000, Test accuracy: 0.928600
Distillation: Epoch : 21, Loss : 0.847620, Accuracy: 0.926000, Test accuracy: 0.929600
Distillation: Epoch : 22, Loss : 0.854409, Accuracy: 0.925000, Test accuracy: 0.933200
Distillation: Epoch : 23, Loss : 0.898951, Accuracy: 0.907000, Test accuracy: 0.935900
Distillation: Epoch : 24, Loss : 0.847445, Accuracy: 0.926000, Test accuracy: 0.937500
Distillation: Epoch : 25, Loss : 0.823229, Accuracy: 0.932000, Test accuracy: 0.939200
Distillation: Epoch : 26, Loss : 0.836216, Accuracy: 0.933000, Test accuracy: 0.941300
Distillation: Epoch : 27, Loss : 0.845917, Accuracy: 0.927000, Test accuracy: 0.942300
Distillation: Epoch : 28, Loss : 0.792445, Accuracy: 0.938000, Test accuracy: 0.944300
Distillation: Epoch : 29, Loss : 0.812836, Accuracy: 0.930000, Test accuracy: 0.946100
Distillation: Epoch : 30, Loss : 0.820547, Accuracy: 0.936000, Test accuracy: 0.947900
Distillation: Epoch : 31, Loss : 0.815512, Accuracy: 0.948000, Test accuracy: 0.949000
Distillation: Epoch : 32, Loss : 0.799262, Accuracy: 0.943000, Test accuracy: 0.949600
Distillation: Epoch : 33, Loss : 0.810571, Accuracy: 0.946000, Test accuracy: 0.949800
Distillation: Epoch : 34, Loss : 0.824481, Accuracy: 0.942000, Test accuracy: 0.950500
Distillation: Epoch : 35, Loss : 0.816466, Accuracy: 0.938000, Test accuracy: 0.951200
Distillation: Epoch : 36, Loss : 0.815599, Accuracy: 0.945000, Test accuracy: 0.952700
Distillation: Epoch : 37, Loss : 0.790168, Accuracy: 0.958000, Test accuracy: 0.953000
Distillation: Epoch : 38, Loss : 0.774310, Accuracy: 0.953000, Test accuracy: 0.953900
Distillation: Epoch : 39, Loss : 0.806148, Accuracy: 0.941000, Test accuracy: 0.953900
Distillation: Epoch : 40, Loss : 0.790167, Accuracy: 0.955000, Test accuracy: 0.955100
Distillation: Epoch : 41, Loss : 0.802763, Accuracy: 0.967000, Test accuracy: 0.955500
Distillation: Epoch : 42, Loss : 0.812175, Accuracy: 0.942000, Test accuracy: 0.956200
Distillation: Epoch : 43, Loss : 0.756584, Accuracy: 0.949000, Test accuracy: 0.956800
Distillation: Epoch : 44, Loss : 0.803998, Accuracy: 0.945000, Test accuracy: 0.957300
Distillation: Epoch : 45, Loss : 0.792404, Accuracy: 0.944000, Test accuracy: 0.958000
Distillation: Epoch : 46, Loss : 0.768673, Accuracy: 0.964000, Test accuracy: 0.957600
Distillation: Epoch : 47, Loss : 0.764755, Accuracy: 0.956000, Test accuracy: 0.958600
Distillation: Epoch : 48, Loss : 0.805179, Accuracy: 0.948000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 0.782407, Accuracy: 0.960000, Test accuracy: 0.958600
Distillation: Epoch : 50, Loss : 0.756950, Accuracy: 0.960000, Test accuracy: 0.959200
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9592
Generating confusion matrix for student3
[[ 970.    0.    7.    0.    3.    2.    7.    2.    8.    6.]
 [   1. 1125.    9.    0.    3.    1.    2.    7.    7.    5.]
 [   0.    3.  969.    3.    2.    0.    0.   19.    7.    1.]
 [   0.    1.    9.  973.    0.    9.    1.    3.   12.    7.]
 [   1.    0.    5.    1.  949.    0.    4.    2.    7.   20.]
 [   1.    1.    0.    8.    0.  856.    5.    0.    9.    3.]
 [   3.    3.    3.    0.    4.    6.  937.    0.    4.    0.]
 [   2.    0.   12.    5.    1.    3.    0.  965.   10.   12.]
 [   2.    2.   15.   14.    2.    8.    2.    2.  895.    2.]
 [   0.    0.    3.    6.   18.    7.    0.   28.   15.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.940324, Accuracy: 0.700000, Test accuracy: 0.718000
Distillation: Epoch : 2, Loss : 1.421208, Accuracy: 0.778000, Test accuracy: 0.810200
Distillation: Epoch : 3, Loss : 1.249767, Accuracy: 0.835000, Test accuracy: 0.851400
Distillation: Epoch : 4, Loss : 1.163188, Accuracy: 0.866000, Test accuracy: 0.874600
Distillation: Epoch : 5, Loss : 1.124521, Accuracy: 0.878000, Test accuracy: 0.883100
Distillation: Epoch : 6, Loss : 1.103812, Accuracy: 0.891000, Test accuracy: 0.892100
Distillation: Epoch : 7, Loss : 1.070346, Accuracy: 0.897000, Test accuracy: 0.898600
Distillation: Epoch : 8, Loss : 1.099754, Accuracy: 0.896000, Test accuracy: 0.904200
Distillation: Epoch : 9, Loss : 1.058930, Accuracy: 0.912000, Test accuracy: 0.908900
Distillation: Epoch : 10, Loss : 1.052129, Accuracy: 0.904000, Test accuracy: 0.909500
Distillation: Epoch : 11, Loss : 1.050080, Accuracy: 0.916000, Test accuracy: 0.913200
Distillation: Epoch : 12, Loss : 1.054865, Accuracy: 0.918000, Test accuracy: 0.915800
Distillation: Epoch : 13, Loss : 1.031334, Accuracy: 0.924000, Test accuracy: 0.918200
Distillation: Epoch : 14, Loss : 1.039231, Accuracy: 0.916000, Test accuracy: 0.919700
Distillation: Epoch : 15, Loss : 1.005418, Accuracy: 0.911000, Test accuracy: 0.923200
Distillation: Epoch : 16, Loss : 1.029584, Accuracy: 0.914000, Test accuracy: 0.924700
Distillation: Epoch : 17, Loss : 1.054273, Accuracy: 0.907000, Test accuracy: 0.927900
Distillation: Epoch : 18, Loss : 1.004246, Accuracy: 0.926000, Test accuracy: 0.930100
Distillation: Epoch : 19, Loss : 1.004690, Accuracy: 0.931000, Test accuracy: 0.930300
Distillation: Epoch : 20, Loss : 1.014866, Accuracy: 0.921000, Test accuracy: 0.932600
Distillation: Epoch : 21, Loss : 1.016489, Accuracy: 0.928000, Test accuracy: 0.934200
Distillation: Epoch : 22, Loss : 1.016984, Accuracy: 0.932000, Test accuracy: 0.934300
Distillation: Epoch : 23, Loss : 0.995158, Accuracy: 0.933000, Test accuracy: 0.936300
Distillation: Epoch : 24, Loss : 0.995241, Accuracy: 0.944000, Test accuracy: 0.937400
Distillation: Epoch : 25, Loss : 0.998129, Accuracy: 0.926000, Test accuracy: 0.937700
Distillation: Epoch : 26, Loss : 1.006738, Accuracy: 0.931000, Test accuracy: 0.938400
Distillation: Epoch : 27, Loss : 0.968990, Accuracy: 0.948000, Test accuracy: 0.938800
Distillation: Epoch : 28, Loss : 1.000003, Accuracy: 0.927000, Test accuracy: 0.939400
Distillation: Epoch : 29, Loss : 0.992881, Accuracy: 0.926000, Test accuracy: 0.941500
Distillation: Epoch : 30, Loss : 1.003418, Accuracy: 0.927000, Test accuracy: 0.940900
Distillation: Epoch : 31, Loss : 0.993389, Accuracy: 0.938000, Test accuracy: 0.942000
Distillation: Epoch : 32, Loss : 0.990957, Accuracy: 0.926000, Test accuracy: 0.942900
Distillation: Epoch : 33, Loss : 0.982973, Accuracy: 0.935000, Test accuracy: 0.943300
Distillation: Epoch : 34, Loss : 0.977305, Accuracy: 0.947000, Test accuracy: 0.944100
Distillation: Epoch : 35, Loss : 0.998473, Accuracy: 0.924000, Test accuracy: 0.944100
Distillation: Epoch : 36, Loss : 0.985630, Accuracy: 0.947000, Test accuracy: 0.944800
Distillation: Epoch : 37, Loss : 0.989556, Accuracy: 0.942000, Test accuracy: 0.945200
Distillation: Epoch : 38, Loss : 0.990998, Accuracy: 0.944000, Test accuracy: 0.945500
Distillation: Epoch : 39, Loss : 0.978393, Accuracy: 0.951000, Test accuracy: 0.946500
Distillation: Epoch : 40, Loss : 0.988042, Accuracy: 0.943000, Test accuracy: 0.946800
Distillation: Epoch : 41, Loss : 0.976030, Accuracy: 0.932000, Test accuracy: 0.947400
Distillation: Epoch : 42, Loss : 0.984405, Accuracy: 0.946000, Test accuracy: 0.947200
Distillation: Epoch : 43, Loss : 0.992331, Accuracy: 0.936000, Test accuracy: 0.947600
Distillation: Epoch : 44, Loss : 0.986443, Accuracy: 0.954000, Test accuracy: 0.947900
Distillation: Epoch : 45, Loss : 1.000232, Accuracy: 0.938000, Test accuracy: 0.948600
Distillation: Epoch : 46, Loss : 0.976255, Accuracy: 0.956000, Test accuracy: 0.949900
Distillation: Epoch : 47, Loss : 0.996406, Accuracy: 0.929000, Test accuracy: 0.949000
Distillation: Epoch : 48, Loss : 0.973743, Accuracy: 0.950000, Test accuracy: 0.948800
Distillation: Epoch : 49, Loss : 0.952552, Accuracy: 0.942000, Test accuracy: 0.949500
Distillation: Epoch : 50, Loss : 0.968341, Accuracy: 0.955000, Test accuracy: 0.949900
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9499
Generating confusion matrix for student3
[[ 970.    0.    9.    2.    1.    2.   10.    2.    8.    6.]
 [   0. 1110.    7.    1.    0.    1.    3.    8.    6.    6.]
 [   0.    3.  951.    6.    3.    0.    3.   11.   12.    1.]
 [   0.    1.   16.  972.    0.   25.    0.    3.   16.    8.]
 [   1.    0.    8.    2.  956.    2.    1.    4.    9.   19.]
 [   1.    2.    1.    7.    1.  820.   10.    1.   17.    7.]
 [   3.    4.    9.    0.    3.   11.  926.    0.    7.    0.]
 [   3.    1.    9.    9.    2.    4.    1.  972.    8.   15.]
 [   2.   14.   22.    7.    2.   20.    4.    2.  881.    6.]
 [   0.    0.    0.    4.   14.    7.    0.   25.   10.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.935576, Accuracy: 0.701000, Test accuracy: 0.720800
Distillation: Epoch : 2, Loss : 1.467052, Accuracy: 0.796000, Test accuracy: 0.802900
Distillation: Epoch : 3, Loss : 1.335681, Accuracy: 0.835000, Test accuracy: 0.845200
Distillation: Epoch : 4, Loss : 1.317476, Accuracy: 0.858000, Test accuracy: 0.865100
Distillation: Epoch : 5, Loss : 1.295662, Accuracy: 0.854000, Test accuracy: 0.875600
Distillation: Epoch : 6, Loss : 1.274044, Accuracy: 0.883000, Test accuracy: 0.882900
Distillation: Epoch : 7, Loss : 1.276456, Accuracy: 0.878000, Test accuracy: 0.887200
Distillation: Epoch : 8, Loss : 1.257997, Accuracy: 0.879000, Test accuracy: 0.890200
Distillation: Epoch : 9, Loss : 1.261748, Accuracy: 0.874000, Test accuracy: 0.894500
Distillation: Epoch : 10, Loss : 1.264591, Accuracy: 0.886000, Test accuracy: 0.897300
Distillation: Epoch : 11, Loss : 1.238986, Accuracy: 0.904000, Test accuracy: 0.896800
Distillation: Epoch : 12, Loss : 1.241362, Accuracy: 0.899000, Test accuracy: 0.899700
Distillation: Epoch : 13, Loss : 1.237424, Accuracy: 0.897000, Test accuracy: 0.900100
Distillation: Epoch : 14, Loss : 1.211353, Accuracy: 0.901000, Test accuracy: 0.902200
Distillation: Epoch : 15, Loss : 1.257355, Accuracy: 0.894000, Test accuracy: 0.903600
Distillation: Epoch : 16, Loss : 1.209046, Accuracy: 0.899000, Test accuracy: 0.905600
Distillation: Epoch : 17, Loss : 1.203703, Accuracy: 0.913000, Test accuracy: 0.904200
Distillation: Epoch : 18, Loss : 1.231300, Accuracy: 0.908000, Test accuracy: 0.906800
Distillation: Epoch : 19, Loss : 1.208751, Accuracy: 0.913000, Test accuracy: 0.907700
Distillation: Epoch : 20, Loss : 1.221485, Accuracy: 0.893000, Test accuracy: 0.907600
Distillation: Epoch : 21, Loss : 1.227476, Accuracy: 0.895000, Test accuracy: 0.909900
Distillation: Epoch : 22, Loss : 1.198692, Accuracy: 0.908000, Test accuracy: 0.911400
Distillation: Epoch : 23, Loss : 1.221754, Accuracy: 0.903000, Test accuracy: 0.913700
Distillation: Epoch : 24, Loss : 1.193434, Accuracy: 0.911000, Test accuracy: 0.912500
Distillation: Epoch : 25, Loss : 1.224377, Accuracy: 0.911000, Test accuracy: 0.915800
Distillation: Epoch : 26, Loss : 1.218101, Accuracy: 0.903000, Test accuracy: 0.916600
Distillation: Epoch : 27, Loss : 1.186590, Accuracy: 0.907000, Test accuracy: 0.920000
Distillation: Epoch : 28, Loss : 1.206467, Accuracy: 0.894000, Test accuracy: 0.919800
Distillation: Epoch : 29, Loss : 1.182934, Accuracy: 0.930000, Test accuracy: 0.922400
Distillation: Epoch : 30, Loss : 1.193145, Accuracy: 0.914000, Test accuracy: 0.925300
Distillation: Epoch : 31, Loss : 1.185090, Accuracy: 0.921000, Test accuracy: 0.926300
Distillation: Epoch : 32, Loss : 1.149591, Accuracy: 0.936000, Test accuracy: 0.928400
Distillation: Epoch : 33, Loss : 1.172080, Accuracy: 0.929000, Test accuracy: 0.930100
Distillation: Epoch : 34, Loss : 1.159364, Accuracy: 0.934000, Test accuracy: 0.931300
Distillation: Epoch : 35, Loss : 1.147026, Accuracy: 0.934000, Test accuracy: 0.932400
Distillation: Epoch : 36, Loss : 1.118577, Accuracy: 0.944000, Test accuracy: 0.934600
Distillation: Epoch : 37, Loss : 1.151129, Accuracy: 0.931000, Test accuracy: 0.936000
Distillation: Epoch : 38, Loss : 1.137618, Accuracy: 0.934000, Test accuracy: 0.937700
Distillation: Epoch : 39, Loss : 1.134713, Accuracy: 0.941000, Test accuracy: 0.938000
Distillation: Epoch : 40, Loss : 1.164881, Accuracy: 0.927000, Test accuracy: 0.939900
Distillation: Epoch : 41, Loss : 1.144024, Accuracy: 0.943000, Test accuracy: 0.940700
Distillation: Epoch : 42, Loss : 1.142852, Accuracy: 0.945000, Test accuracy: 0.942700
Distillation: Epoch : 43, Loss : 1.128105, Accuracy: 0.947000, Test accuracy: 0.944900
Distillation: Epoch : 44, Loss : 1.139317, Accuracy: 0.931000, Test accuracy: 0.944400
Distillation: Epoch : 45, Loss : 1.142543, Accuracy: 0.941000, Test accuracy: 0.946200
Distillation: Epoch : 46, Loss : 1.162704, Accuracy: 0.931000, Test accuracy: 0.945800
Distillation: Epoch : 47, Loss : 1.130183, Accuracy: 0.943000, Test accuracy: 0.947200
Distillation: Epoch : 48, Loss : 1.120827, Accuracy: 0.945000, Test accuracy: 0.947900
Distillation: Epoch : 49, Loss : 1.132802, Accuracy: 0.956000, Test accuracy: 0.948500
Distillation: Epoch : 50, Loss : 1.142738, Accuracy: 0.943000, Test accuracy: 0.949500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9495
Generating confusion matrix for student3
[[ 968.    0.   12.    0.    2.    1.    7.    3.   10.    9.]
 [   1. 1121.   11.    1.    1.    1.    4.    7.    7.    5.]
 [   0.    2.  939.    2.    2.    1.    0.   14.   10.    1.]
 [   0.    2.    8.  969.    0.   21.    0.    3.   16.   10.]
 [   2.    2.   10.    4.  956.    0.    5.    6.    9.   29.]
 [   0.    0.    0.   11.    0.  836.   14.    2.   18.    4.]
 [   6.    4.    6.    1.    5.    7.  926.    0.    1.    0.]
 [   2.    1.   16.    6.    2.    2.    0.  964.   10.   10.]
 [   1.    3.   29.   11.    2.   13.    2.    3.  876.    1.]
 [   0.    0.    1.    5.   12.   10.    0.   26.   17.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.077034, Accuracy: 0.698000, Test accuracy: 0.695800
Distillation: Epoch : 2, Loss : 1.639907, Accuracy: 0.791000, Test accuracy: 0.805200
Distillation: Epoch : 3, Loss : 1.518355, Accuracy: 0.814000, Test accuracy: 0.837400
Distillation: Epoch : 4, Loss : 1.455443, Accuracy: 0.852000, Test accuracy: 0.864400
Distillation: Epoch : 5, Loss : 1.424118, Accuracy: 0.863000, Test accuracy: 0.877200
Distillation: Epoch : 6, Loss : 1.413400, Accuracy: 0.859000, Test accuracy: 0.885200
Distillation: Epoch : 7, Loss : 1.401111, Accuracy: 0.870000, Test accuracy: 0.891000
Distillation: Epoch : 8, Loss : 1.359555, Accuracy: 0.903000, Test accuracy: 0.895300
Distillation: Epoch : 9, Loss : 1.368601, Accuracy: 0.894000, Test accuracy: 0.898600
Distillation: Epoch : 10, Loss : 1.350950, Accuracy: 0.878000, Test accuracy: 0.901000
Distillation: Epoch : 11, Loss : 1.363717, Accuracy: 0.906000, Test accuracy: 0.902500
Distillation: Epoch : 12, Loss : 1.354931, Accuracy: 0.902000, Test accuracy: 0.904300
Distillation: Epoch : 13, Loss : 1.359294, Accuracy: 0.898000, Test accuracy: 0.906200
Distillation: Epoch : 14, Loss : 1.337155, Accuracy: 0.894000, Test accuracy: 0.907600
Distillation: Epoch : 15, Loss : 1.331650, Accuracy: 0.916000, Test accuracy: 0.910000
Distillation: Epoch : 16, Loss : 1.343037, Accuracy: 0.905000, Test accuracy: 0.911400
Distillation: Epoch : 17, Loss : 1.346704, Accuracy: 0.903000, Test accuracy: 0.913600
Distillation: Epoch : 18, Loss : 1.322123, Accuracy: 0.918000, Test accuracy: 0.915000
Distillation: Epoch : 19, Loss : 1.334941, Accuracy: 0.907000, Test accuracy: 0.916200
Distillation: Epoch : 20, Loss : 1.343340, Accuracy: 0.903000, Test accuracy: 0.918500
Distillation: Epoch : 21, Loss : 1.326936, Accuracy: 0.919000, Test accuracy: 0.919700
Distillation: Epoch : 22, Loss : 1.307412, Accuracy: 0.918000, Test accuracy: 0.919600
Distillation: Epoch : 23, Loss : 1.318556, Accuracy: 0.904000, Test accuracy: 0.922000
Distillation: Epoch : 24, Loss : 1.363545, Accuracy: 0.902000, Test accuracy: 0.922800
Distillation: Epoch : 25, Loss : 1.325781, Accuracy: 0.926000, Test accuracy: 0.924500
Distillation: Epoch : 26, Loss : 1.355725, Accuracy: 0.917000, Test accuracy: 0.925600
Distillation: Epoch : 27, Loss : 1.330698, Accuracy: 0.910000, Test accuracy: 0.926600
Distillation: Epoch : 28, Loss : 1.307832, Accuracy: 0.914000, Test accuracy: 0.927400
Distillation: Epoch : 29, Loss : 1.340339, Accuracy: 0.914000, Test accuracy: 0.928800
Distillation: Epoch : 30, Loss : 1.306250, Accuracy: 0.916000, Test accuracy: 0.929600
Distillation: Epoch : 31, Loss : 1.322018, Accuracy: 0.918000, Test accuracy: 0.931400
Distillation: Epoch : 32, Loss : 1.326761, Accuracy: 0.916000, Test accuracy: 0.932200
Distillation: Epoch : 33, Loss : 1.321620, Accuracy: 0.928000, Test accuracy: 0.933100
Distillation: Epoch : 34, Loss : 1.328164, Accuracy: 0.939000, Test accuracy: 0.934600
Distillation: Epoch : 35, Loss : 1.300654, Accuracy: 0.937000, Test accuracy: 0.933600
Distillation: Epoch : 36, Loss : 1.305381, Accuracy: 0.928000, Test accuracy: 0.935700
Distillation: Epoch : 37, Loss : 1.331832, Accuracy: 0.923000, Test accuracy: 0.936300
Distillation: Epoch : 38, Loss : 1.297822, Accuracy: 0.931000, Test accuracy: 0.936600
Distillation: Epoch : 39, Loss : 1.302684, Accuracy: 0.928000, Test accuracy: 0.937100
Distillation: Epoch : 40, Loss : 1.315107, Accuracy: 0.923000, Test accuracy: 0.937700
Distillation: Epoch : 41, Loss : 1.305915, Accuracy: 0.922000, Test accuracy: 0.938200
Distillation: Epoch : 42, Loss : 1.294462, Accuracy: 0.940000, Test accuracy: 0.939000
Distillation: Epoch : 43, Loss : 1.307231, Accuracy: 0.930000, Test accuracy: 0.938800
Distillation: Epoch : 44, Loss : 1.305496, Accuracy: 0.933000, Test accuracy: 0.938700
Distillation: Epoch : 45, Loss : 1.300657, Accuracy: 0.929000, Test accuracy: 0.939400
Distillation: Epoch : 46, Loss : 1.281949, Accuracy: 0.937000, Test accuracy: 0.941000
Distillation: Epoch : 47, Loss : 1.285140, Accuracy: 0.938000, Test accuracy: 0.941500
Distillation: Epoch : 48, Loss : 1.299406, Accuracy: 0.940000, Test accuracy: 0.941400
Distillation: Epoch : 49, Loss : 1.299317, Accuracy: 0.937000, Test accuracy: 0.942400
Distillation: Epoch : 50, Loss : 1.303405, Accuracy: 0.933000, Test accuracy: 0.942500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9425
Generating confusion matrix for student3
[[ 969.    0.   13.    5.    0.    7.    6.    2.   10.    7.]
 [   0. 1121.   15.    2.    0.    2.    4.    9.   10.    5.]
 [   0.    2.  947.    2.    6.    0.    1.   15.    9.    2.]
 [   1.    1.   10.  941.    0.   10.    0.    1.   23.    5.]
 [   1.    1.   18.    5.  949.    4.    5.   15.   17.   25.]
 [   3.    0.    1.   15.    0.  830.   18.    1.   14.    5.]
 [   2.    5.    5.    2.    7.    8.  923.    0.    1.    0.]
 [   1.    1.   11.   20.    3.    7.    1.  942.   10.   18.]
 [   2.    4.   11.   13.    4.   16.    0.    2.  864.    3.]
 [   1.    0.    1.    5.   13.    8.    0.   41.   16.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.071344, Accuracy: 0.691000, Test accuracy: 0.704000
Distillation: Epoch : 2, Loss : 1.728084, Accuracy: 0.774000, Test accuracy: 0.801200
Distillation: Epoch : 3, Loss : 1.617980, Accuracy: 0.816000, Test accuracy: 0.844500
Distillation: Epoch : 4, Loss : 1.552925, Accuracy: 0.854000, Test accuracy: 0.865200
Distillation: Epoch : 5, Loss : 1.538002, Accuracy: 0.861000, Test accuracy: 0.876700
Distillation: Epoch : 6, Loss : 1.507967, Accuracy: 0.876000, Test accuracy: 0.882000
Distillation: Epoch : 7, Loss : 1.526666, Accuracy: 0.879000, Test accuracy: 0.886300
Distillation: Epoch : 8, Loss : 1.508611, Accuracy: 0.880000, Test accuracy: 0.889800
Distillation: Epoch : 9, Loss : 1.518260, Accuracy: 0.881000, Test accuracy: 0.893200
Distillation: Epoch : 10, Loss : 1.514992, Accuracy: 0.887000, Test accuracy: 0.894300
Distillation: Epoch : 11, Loss : 1.480977, Accuracy: 0.890000, Test accuracy: 0.896600
Distillation: Epoch : 12, Loss : 1.512374, Accuracy: 0.895000, Test accuracy: 0.899700
Distillation: Epoch : 13, Loss : 1.497508, Accuracy: 0.893000, Test accuracy: 0.898900
Distillation: Epoch : 14, Loss : 1.512650, Accuracy: 0.890000, Test accuracy: 0.901200
Distillation: Epoch : 15, Loss : 1.495924, Accuracy: 0.890000, Test accuracy: 0.902400
Distillation: Epoch : 16, Loss : 1.473202, Accuracy: 0.904000, Test accuracy: 0.903400
Distillation: Epoch : 17, Loss : 1.486097, Accuracy: 0.891000, Test accuracy: 0.904400
Distillation: Epoch : 18, Loss : 1.447076, Accuracy: 0.903000, Test accuracy: 0.907300
Distillation: Epoch : 19, Loss : 1.478620, Accuracy: 0.900000, Test accuracy: 0.907700
Distillation: Epoch : 20, Loss : 1.485592, Accuracy: 0.897000, Test accuracy: 0.908700
Distillation: Epoch : 21, Loss : 1.478611, Accuracy: 0.895000, Test accuracy: 0.909200
Distillation: Epoch : 22, Loss : 1.472110, Accuracy: 0.907000, Test accuracy: 0.910800
Distillation: Epoch : 23, Loss : 1.461597, Accuracy: 0.908000, Test accuracy: 0.912800
Distillation: Epoch : 24, Loss : 1.471069, Accuracy: 0.910000, Test accuracy: 0.914500
Distillation: Epoch : 25, Loss : 1.443655, Accuracy: 0.934000, Test accuracy: 0.915600
Distillation: Epoch : 26, Loss : 1.459810, Accuracy: 0.908000, Test accuracy: 0.916900
Distillation: Epoch : 27, Loss : 1.447345, Accuracy: 0.932000, Test accuracy: 0.918200
Distillation: Epoch : 28, Loss : 1.466524, Accuracy: 0.920000, Test accuracy: 0.919800
Distillation: Epoch : 29, Loss : 1.445820, Accuracy: 0.907000, Test accuracy: 0.921300
Distillation: Epoch : 30, Loss : 1.458152, Accuracy: 0.913000, Test accuracy: 0.924300
Distillation: Epoch : 31, Loss : 1.457512, Accuracy: 0.921000, Test accuracy: 0.926400
Distillation: Epoch : 32, Loss : 1.447623, Accuracy: 0.927000, Test accuracy: 0.927800
Distillation: Epoch : 33, Loss : 1.446338, Accuracy: 0.923000, Test accuracy: 0.930900
Distillation: Epoch : 34, Loss : 1.427645, Accuracy: 0.917000, Test accuracy: 0.932900
Distillation: Epoch : 35, Loss : 1.424256, Accuracy: 0.930000, Test accuracy: 0.933300
Distillation: Epoch : 36, Loss : 1.428619, Accuracy: 0.925000, Test accuracy: 0.935700
Distillation: Epoch : 37, Loss : 1.454734, Accuracy: 0.926000, Test accuracy: 0.936800
Distillation: Epoch : 38, Loss : 1.431069, Accuracy: 0.912000, Test accuracy: 0.938200
Distillation: Epoch : 39, Loss : 1.418545, Accuracy: 0.937000, Test accuracy: 0.939400
Distillation: Epoch : 40, Loss : 1.430579, Accuracy: 0.934000, Test accuracy: 0.940300
Distillation: Epoch : 41, Loss : 1.440318, Accuracy: 0.930000, Test accuracy: 0.942200
Distillation: Epoch : 42, Loss : 1.430437, Accuracy: 0.927000, Test accuracy: 0.943200
Distillation: Epoch : 43, Loss : 1.394995, Accuracy: 0.954000, Test accuracy: 0.944300
Distillation: Epoch : 44, Loss : 1.400890, Accuracy: 0.941000, Test accuracy: 0.946400
Distillation: Epoch : 45, Loss : 1.392972, Accuracy: 0.946000, Test accuracy: 0.946800
Distillation: Epoch : 46, Loss : 1.400969, Accuracy: 0.944000, Test accuracy: 0.947200
Distillation: Epoch : 47, Loss : 1.396186, Accuracy: 0.945000, Test accuracy: 0.948000
Distillation: Epoch : 48, Loss : 1.401070, Accuracy: 0.941000, Test accuracy: 0.949000
Distillation: Epoch : 49, Loss : 1.430063, Accuracy: 0.927000, Test accuracy: 0.949100
Distillation: Epoch : 50, Loss : 1.409489, Accuracy: 0.942000, Test accuracy: 0.949800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9498
Generating confusion matrix for student3
[[ 968.    0.   10.    1.    1.    2.    9.    3.   10.    5.]
 [   0. 1123.    9.    1.    1.    1.    5.   11.    7.    5.]
 [   0.    4.  941.    1.    2.    1.    1.    9.    9.    0.]
 [   0.    0.   14.  967.    0.   10.    1.    3.   13.   12.]
 [   2.    0.    9.    2.  959.    1.    9.    8.   16.   28.]
 [   2.    0.    0.   14.    0.  853.   15.    2.   10.    4.]
 [   5.    4.    9.    2.    3.    7.  916.    0.    8.    0.]
 [   1.    0.   15.    9.    0.    4.    0.  959.   11.   18.]
 [   2.    4.   22.    9.    3.    9.    2.    2.  876.    1.]
 [   0.    0.    3.    4.   13.    4.    0.   31.   14.  936.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.099732, Accuracy: 0.677000, Test accuracy: 0.702100
Distillation: Epoch : 2, Loss : 1.874445, Accuracy: 0.806000, Test accuracy: 0.797700
Distillation: Epoch : 3, Loss : 1.838405, Accuracy: 0.830000, Test accuracy: 0.841000
Distillation: Epoch : 4, Loss : 1.812188, Accuracy: 0.852000, Test accuracy: 0.854800
Distillation: Epoch : 5, Loss : 1.807668, Accuracy: 0.855000, Test accuracy: 0.866100
Distillation: Epoch : 6, Loss : 1.798376, Accuracy: 0.871000, Test accuracy: 0.871700
Distillation: Epoch : 7, Loss : 1.795113, Accuracy: 0.873000, Test accuracy: 0.876400
Distillation: Epoch : 8, Loss : 1.768963, Accuracy: 0.889000, Test accuracy: 0.880600
Distillation: Epoch : 9, Loss : 1.802210, Accuracy: 0.873000, Test accuracy: 0.885400
Distillation: Epoch : 10, Loss : 1.811030, Accuracy: 0.865000, Test accuracy: 0.886400
Distillation: Epoch : 11, Loss : 1.767189, Accuracy: 0.876000, Test accuracy: 0.889900
Distillation: Epoch : 12, Loss : 1.779647, Accuracy: 0.881000, Test accuracy: 0.890800
Distillation: Epoch : 13, Loss : 1.782111, Accuracy: 0.883000, Test accuracy: 0.892100
Distillation: Epoch : 14, Loss : 1.780264, Accuracy: 0.871000, Test accuracy: 0.893100
Distillation: Epoch : 15, Loss : 1.769752, Accuracy: 0.877000, Test accuracy: 0.893100
Distillation: Epoch : 16, Loss : 1.769293, Accuracy: 0.893000, Test accuracy: 0.894800
Distillation: Epoch : 17, Loss : 1.768177, Accuracy: 0.873000, Test accuracy: 0.895900
Distillation: Epoch : 18, Loss : 1.777442, Accuracy: 0.873000, Test accuracy: 0.896900
Distillation: Epoch : 19, Loss : 1.744684, Accuracy: 0.908000, Test accuracy: 0.897400
Distillation: Epoch : 20, Loss : 1.763566, Accuracy: 0.888000, Test accuracy: 0.898400
Distillation: Epoch : 21, Loss : 1.756266, Accuracy: 0.892000, Test accuracy: 0.899500
Distillation: Epoch : 22, Loss : 1.739823, Accuracy: 0.900000, Test accuracy: 0.898300
Distillation: Epoch : 23, Loss : 1.751459, Accuracy: 0.894000, Test accuracy: 0.900800
Distillation: Epoch : 24, Loss : 1.767673, Accuracy: 0.906000, Test accuracy: 0.902900
Distillation: Epoch : 25, Loss : 1.730330, Accuracy: 0.898000, Test accuracy: 0.903400
Distillation: Epoch : 26, Loss : 1.754850, Accuracy: 0.903000, Test accuracy: 0.903100
Distillation: Epoch : 27, Loss : 1.740779, Accuracy: 0.879000, Test accuracy: 0.904800
Distillation: Epoch : 28, Loss : 1.740176, Accuracy: 0.910000, Test accuracy: 0.905400
Distillation: Epoch : 29, Loss : 1.758229, Accuracy: 0.903000, Test accuracy: 0.906500
Distillation: Epoch : 30, Loss : 1.748005, Accuracy: 0.903000, Test accuracy: 0.906900
Distillation: Epoch : 31, Loss : 1.769275, Accuracy: 0.911000, Test accuracy: 0.909300
Distillation: Epoch : 32, Loss : 1.761887, Accuracy: 0.897000, Test accuracy: 0.909700
Distillation: Epoch : 33, Loss : 1.734867, Accuracy: 0.906000, Test accuracy: 0.910200
Distillation: Epoch : 34, Loss : 1.741538, Accuracy: 0.901000, Test accuracy: 0.911400
Distillation: Epoch : 35, Loss : 1.751876, Accuracy: 0.911000, Test accuracy: 0.913600
Distillation: Epoch : 36, Loss : 1.749805, Accuracy: 0.896000, Test accuracy: 0.915800
Distillation: Epoch : 37, Loss : 1.740067, Accuracy: 0.910000, Test accuracy: 0.917600
Distillation: Epoch : 38, Loss : 1.725701, Accuracy: 0.918000, Test accuracy: 0.918900
Distillation: Epoch : 39, Loss : 1.749963, Accuracy: 0.909000, Test accuracy: 0.921000
Distillation: Epoch : 40, Loss : 1.758779, Accuracy: 0.912000, Test accuracy: 0.921900
Distillation: Epoch : 41, Loss : 1.737188, Accuracy: 0.913000, Test accuracy: 0.923200
Distillation: Epoch : 42, Loss : 1.739148, Accuracy: 0.908000, Test accuracy: 0.925300
Distillation: Epoch : 43, Loss : 1.725423, Accuracy: 0.932000, Test accuracy: 0.927600
Distillation: Epoch : 44, Loss : 1.731290, Accuracy: 0.916000, Test accuracy: 0.929100
Distillation: Epoch : 45, Loss : 1.714137, Accuracy: 0.940000, Test accuracy: 0.930100
Distillation: Epoch : 46, Loss : 1.749694, Accuracy: 0.928000, Test accuracy: 0.931400
Distillation: Epoch : 47, Loss : 1.737893, Accuracy: 0.933000, Test accuracy: 0.933000
Distillation: Epoch : 48, Loss : 1.724636, Accuracy: 0.922000, Test accuracy: 0.933700
Distillation: Epoch : 49, Loss : 1.720084, Accuracy: 0.920000, Test accuracy: 0.935400
Distillation: Epoch : 50, Loss : 1.724206, Accuracy: 0.904000, Test accuracy: 0.936800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9368
Generating confusion matrix for student3
[[ 963.    0.   13.    5.    0.    5.   10.    0.    8.    8.]
 [   0. 1114.   23.    3.    1.    1.    5.   15.    7.    6.]
 [   1.    2.  912.    7.    4.    0.    1.   12.    9.    0.]
 [   1.    2.    9.  950.    0.   21.    0.    5.   11.   10.]
 [   2.    1.   19.    3.  947.   11.    7.   15.   29.   46.]
 [   3.    3.    0.   16.    0.  827.   14.    1.   17.    5.]
 [   7.    4.   12.    5.    6.    9.  920.    0.    7.    0.]
 [   1.    0.   19.    8.    0.    2.    0.  948.    7.    8.]
 [   2.    9.   23.    8.    3.   11.    1.    2.  862.    1.]
 [   0.    0.    2.    5.   21.    5.    0.   30.   17.  925.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.221177, Accuracy: 0.657000, Test accuracy: 0.683100
Distillation: Epoch : 2, Loss : 2.093675, Accuracy: 0.769000, Test accuracy: 0.788000
Distillation: Epoch : 3, Loss : 2.061898, Accuracy: 0.792000, Test accuracy: 0.824500
Distillation: Epoch : 4, Loss : 2.038811, Accuracy: 0.845000, Test accuracy: 0.850500
Distillation: Epoch : 5, Loss : 2.029998, Accuracy: 0.865000, Test accuracy: 0.861400
Distillation: Epoch : 6, Loss : 2.022918, Accuracy: 0.867000, Test accuracy: 0.868400
Distillation: Epoch : 7, Loss : 2.029500, Accuracy: 0.873000, Test accuracy: 0.872100
Distillation: Epoch : 8, Loss : 2.036638, Accuracy: 0.849000, Test accuracy: 0.875200
Distillation: Epoch : 9, Loss : 2.018376, Accuracy: 0.876000, Test accuracy: 0.879500
Distillation: Epoch : 10, Loss : 2.020125, Accuracy: 0.871000, Test accuracy: 0.882700
Distillation: Epoch : 11, Loss : 2.014482, Accuracy: 0.873000, Test accuracy: 0.883300
Distillation: Epoch : 12, Loss : 2.019698, Accuracy: 0.881000, Test accuracy: 0.884500
Distillation: Epoch : 13, Loss : 2.015227, Accuracy: 0.885000, Test accuracy: 0.886000
Distillation: Epoch : 14, Loss : 2.003235, Accuracy: 0.893000, Test accuracy: 0.886100
Distillation: Epoch : 15, Loss : 2.010887, Accuracy: 0.890000, Test accuracy: 0.890200
Distillation: Epoch : 16, Loss : 2.021560, Accuracy: 0.879000, Test accuracy: 0.891700
Distillation: Epoch : 17, Loss : 2.003524, Accuracy: 0.902000, Test accuracy: 0.890400
Distillation: Epoch : 18, Loss : 2.017197, Accuracy: 0.866000, Test accuracy: 0.892600
Distillation: Epoch : 19, Loss : 2.012676, Accuracy: 0.885000, Test accuracy: 0.892900
Distillation: Epoch : 20, Loss : 2.006645, Accuracy: 0.882000, Test accuracy: 0.894700
Distillation: Epoch : 21, Loss : 2.011404, Accuracy: 0.893000, Test accuracy: 0.896100
Distillation: Epoch : 22, Loss : 2.003649, Accuracy: 0.904000, Test accuracy: 0.895300
Distillation: Epoch : 23, Loss : 2.005400, Accuracy: 0.883000, Test accuracy: 0.898100
Distillation: Epoch : 24, Loss : 2.019918, Accuracy: 0.878000, Test accuracy: 0.898500
Distillation: Epoch : 25, Loss : 2.018169, Accuracy: 0.894000, Test accuracy: 0.899400
Distillation: Epoch : 26, Loss : 2.012612, Accuracy: 0.907000, Test accuracy: 0.901100
Distillation: Epoch : 27, Loss : 1.999614, Accuracy: 0.896000, Test accuracy: 0.903000
Distillation: Epoch : 28, Loss : 2.002437, Accuracy: 0.903000, Test accuracy: 0.903000
Distillation: Epoch : 29, Loss : 2.006333, Accuracy: 0.906000, Test accuracy: 0.904300
Distillation: Epoch : 30, Loss : 2.008852, Accuracy: 0.902000, Test accuracy: 0.907200
Distillation: Epoch : 31, Loss : 2.002704, Accuracy: 0.902000, Test accuracy: 0.906100
Distillation: Epoch : 32, Loss : 2.014627, Accuracy: 0.893000, Test accuracy: 0.908200
Distillation: Epoch : 33, Loss : 2.003456, Accuracy: 0.901000, Test accuracy: 0.910800
Distillation: Epoch : 34, Loss : 1.997534, Accuracy: 0.903000, Test accuracy: 0.911700
Distillation: Epoch : 35, Loss : 1.993903, Accuracy: 0.906000, Test accuracy: 0.912900
Distillation: Epoch : 36, Loss : 1.987662, Accuracy: 0.925000, Test accuracy: 0.913800
Distillation: Epoch : 37, Loss : 1.998135, Accuracy: 0.908000, Test accuracy: 0.917000
Distillation: Epoch : 38, Loss : 1.994095, Accuracy: 0.901000, Test accuracy: 0.916900
Distillation: Epoch : 39, Loss : 2.004772, Accuracy: 0.914000, Test accuracy: 0.918200
Distillation: Epoch : 40, Loss : 1.986533, Accuracy: 0.917000, Test accuracy: 0.921500
Distillation: Epoch : 41, Loss : 1.988390, Accuracy: 0.910000, Test accuracy: 0.923200
Distillation: Epoch : 42, Loss : 1.989456, Accuracy: 0.923000, Test accuracy: 0.923400
Distillation: Epoch : 43, Loss : 1.991478, Accuracy: 0.921000, Test accuracy: 0.925800
Distillation: Epoch : 44, Loss : 1.998455, Accuracy: 0.908000, Test accuracy: 0.925800
Distillation: Epoch : 45, Loss : 1.978565, Accuracy: 0.921000, Test accuracy: 0.927100
Distillation: Epoch : 46, Loss : 1.992700, Accuracy: 0.925000, Test accuracy: 0.929200
Distillation: Epoch : 47, Loss : 1.981031, Accuracy: 0.929000, Test accuracy: 0.929600
Distillation: Epoch : 48, Loss : 1.979779, Accuracy: 0.928000, Test accuracy: 0.929900
Distillation: Epoch : 49, Loss : 1.985229, Accuracy: 0.924000, Test accuracy: 0.931500
Distillation: Epoch : 50, Loss : 1.989995, Accuracy: 0.924000, Test accuracy: 0.931700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9317
Generating confusion matrix for student3
[[ 965.    0.   15.    4.    0.    6.    7.    2.    8.    9.]
 [   0. 1113.   30.    2.    2.    1.    3.   21.   13.    7.]
 [   0.    2.  909.    6.    6.    0.    1.   16.    6.    2.]
 [   2.    3.    9.  948.    0.    9.    1.    3.   23.   11.]
 [   1.    2.   23.    2.  937.    8.    6.   23.   20.   48.]
 [   4.    2.    0.   13.    0.  841.   18.    1.   25.    4.]
 [   6.    5.    6.    4.    6.   15.  921.    0.    4.    0.]
 [   1.    2.   24.   15.    2.    2.    0.  924.    9.   20.]
 [   1.    6.   13.   11.    6.    6.    1.    2.  853.    2.]
 [   0.    0.    3.    5.   23.    4.    0.   36.   13.  906.]]
</confusion_matrix>
