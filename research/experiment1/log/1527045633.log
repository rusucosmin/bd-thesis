Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.086903, Accuracy: 0.976000, Test accuracy: 0.965800
Starting training epoch 1
Epoch : 2, Loss : 0.079858, Accuracy: 0.968000, Test accuracy: 0.976100
Starting training epoch 2
Epoch : 3, Loss : 0.050965, Accuracy: 0.980000, Test accuracy: 0.983400
Starting training epoch 3
Epoch : 4, Loss : 0.029229, Accuracy: 0.992000, Test accuracy: 0.986500
Starting training epoch 4
Epoch : 5, Loss : 0.015638, Accuracy: 0.996000, Test accuracy: 0.986700
Starting training epoch 5
Epoch : 6, Loss : 0.031400, Accuracy: 0.988000, Test accuracy: 0.988600
Starting training epoch 6
Epoch : 7, Loss : 0.018549, Accuracy: 0.988000, Test accuracy: 0.988700
Starting training epoch 7
Epoch : 8, Loss : 0.024747, Accuracy: 0.992000, Test accuracy: 0.989500
Starting training epoch 8
Epoch : 9, Loss : 0.006076, Accuracy: 1.000000, Test accuracy: 0.988500
Starting training epoch 9
Epoch : 10, Loss : 0.002343, Accuracy: 1.000000, Test accuracy: 0.991000
Starting training epoch 10
Epoch : 11, Loss : 0.015949, Accuracy: 0.992000, Test accuracy: 0.990400
Starting training epoch 11
Epoch : 12, Loss : 0.016420, Accuracy: 0.992000, Test accuracy: 0.991500
Starting training epoch 12
Epoch : 13, Loss : 0.004593, Accuracy: 1.000000, Test accuracy: 0.991200
Starting training epoch 13
Epoch : 14, Loss : 0.001288, Accuracy: 1.000000, Test accuracy: 0.991200
Starting training epoch 14
Epoch : 15, Loss : 0.002811, Accuracy: 1.000000, Test accuracy: 0.991700
Starting training epoch 15
Epoch : 16, Loss : 0.000966, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 16
Epoch : 17, Loss : 0.000573, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 17
Epoch : 18, Loss : 0.004201, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 18
Epoch : 19, Loss : 0.001716, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 19
Epoch : 20, Loss : 0.000412, Accuracy: 1.000000, Test accuracy: 0.992200
Starting training epoch 20
Epoch : 21, Loss : 0.001213, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 21
Epoch : 22, Loss : 0.000558, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 22
Epoch : 23, Loss : 0.000774, Accuracy: 1.000000, Test accuracy: 0.992200
Starting training epoch 23
Epoch : 24, Loss : 0.006868, Accuracy: 0.996000, Test accuracy: 0.993100
Starting training epoch 24
Epoch : 25, Loss : 0.001075, Accuracy: 1.000000, Test accuracy: 0.991900
Starting training epoch 25
Epoch : 26, Loss : 0.000333, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 26
Epoch : 27, Loss : 0.000039, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 27
Epoch : 28, Loss : 0.005841, Accuracy: 0.996000, Test accuracy: 0.992200
Starting training epoch 28
Epoch : 29, Loss : 0.000406, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 29
Epoch : 30, Loss : 0.000170, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 30
Epoch : 31, Loss : 0.000730, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 31
Epoch : 32, Loss : 0.000093, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 32
Epoch : 33, Loss : 0.000091, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 33
Epoch : 34, Loss : 0.008863, Accuracy: 0.996000, Test accuracy: 0.992500
Starting training epoch 34
Epoch : 35, Loss : 0.007276, Accuracy: 0.996000, Test accuracy: 0.992800
Starting training epoch 35
Epoch : 36, Loss : 0.000110, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 36
Epoch : 37, Loss : 0.000030, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 37
Epoch : 38, Loss : 0.000668, Accuracy: 1.000000, Test accuracy: 0.991900
Starting training epoch 38
Epoch : 39, Loss : 0.000028, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 39
Epoch : 40, Loss : 0.000567, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 40
Epoch : 41, Loss : 0.000005, Accuracy: 1.000000, Test accuracy: 0.994000
Starting training epoch 41
Epoch : 42, Loss : 0.000344, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 42
Epoch : 43, Loss : 0.004388, Accuracy: 0.996000, Test accuracy: 0.993500
Starting training epoch 43
Epoch : 44, Loss : 0.000136, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 44
Epoch : 45, Loss : 0.000069, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 45
Epoch : 46, Loss : 0.000039, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 46
Epoch : 47, Loss : 0.000053, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 47
Epoch : 48, Loss : 0.000008, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 48
Epoch : 49, Loss : 0.000102, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 49
Epoch : 50, Loss : 0.000137, Accuracy: 1.000000, Test accuracy: 0.994200
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 1.523251, Accuracy: 0.780000, Test accuracy: 0.738700
Starting training epoch 1
Epoch : 2, Loss : 0.845730, Accuracy: 0.800000, Test accuracy: 0.819700
Starting training epoch 2
Epoch : 3, Loss : 0.618414, Accuracy: 0.852000, Test accuracy: 0.854900
Starting training epoch 3
Epoch : 4, Loss : 0.539461, Accuracy: 0.836000, Test accuracy: 0.875000
Starting training epoch 4
Epoch : 5, Loss : 0.419627, Accuracy: 0.888000, Test accuracy: 0.887600
Starting training epoch 5
Epoch : 6, Loss : 0.377134, Accuracy: 0.868000, Test accuracy: 0.895700
Starting training epoch 6
Epoch : 7, Loss : 0.402592, Accuracy: 0.884000, Test accuracy: 0.901800
Starting training epoch 7
Epoch : 8, Loss : 0.317577, Accuracy: 0.908000, Test accuracy: 0.906700
Starting training epoch 8
Epoch : 9, Loss : 0.246500, Accuracy: 0.924000, Test accuracy: 0.910200
Starting training epoch 9
Epoch : 10, Loss : 0.304605, Accuracy: 0.916000, Test accuracy: 0.913400
Starting training epoch 10
Epoch : 11, Loss : 0.281051, Accuracy: 0.924000, Test accuracy: 0.917000
Starting training epoch 11
Epoch : 12, Loss : 0.380791, Accuracy: 0.880000, Test accuracy: 0.919800
Starting training epoch 12
Epoch : 13, Loss : 0.284973, Accuracy: 0.904000, Test accuracy: 0.921900
Starting training epoch 13
Epoch : 14, Loss : 0.343089, Accuracy: 0.896000, Test accuracy: 0.925000
Starting training epoch 14
Epoch : 15, Loss : 0.307310, Accuracy: 0.904000, Test accuracy: 0.926300
Starting training epoch 15
Epoch : 16, Loss : 0.194525, Accuracy: 0.948000, Test accuracy: 0.927800
Starting training epoch 16
Epoch : 17, Loss : 0.341049, Accuracy: 0.896000, Test accuracy: 0.929500
Starting training epoch 17
Epoch : 18, Loss : 0.235198, Accuracy: 0.920000, Test accuracy: 0.931300
Starting training epoch 18
Epoch : 19, Loss : 0.258377, Accuracy: 0.928000, Test accuracy: 0.931300
Starting training epoch 19
Epoch : 20, Loss : 0.292057, Accuracy: 0.928000, Test accuracy: 0.932700
Starting training epoch 20
Epoch : 21, Loss : 0.186420, Accuracy: 0.948000, Test accuracy: 0.933300
Starting training epoch 21
Epoch : 22, Loss : 0.250568, Accuracy: 0.932000, Test accuracy: 0.934300
Starting training epoch 22
Epoch : 23, Loss : 0.229420, Accuracy: 0.924000, Test accuracy: 0.934300
Starting training epoch 23
Epoch : 24, Loss : 0.162032, Accuracy: 0.952000, Test accuracy: 0.936000
Starting training epoch 24
Epoch : 25, Loss : 0.199067, Accuracy: 0.936000, Test accuracy: 0.936300
Starting training epoch 25
Epoch : 26, Loss : 0.211500, Accuracy: 0.924000, Test accuracy: 0.937900
Starting training epoch 26
Epoch : 27, Loss : 0.221566, Accuracy: 0.924000, Test accuracy: 0.937700
Starting training epoch 27
Epoch : 28, Loss : 0.176167, Accuracy: 0.936000, Test accuracy: 0.939000
Starting training epoch 28
Epoch : 29, Loss : 0.252295, Accuracy: 0.924000, Test accuracy: 0.939800
Starting training epoch 29
Epoch : 30, Loss : 0.251807, Accuracy: 0.920000, Test accuracy: 0.940900
Starting training epoch 30
Epoch : 31, Loss : 0.253106, Accuracy: 0.936000, Test accuracy: 0.941500
Starting training epoch 31
Epoch : 32, Loss : 0.217549, Accuracy: 0.952000, Test accuracy: 0.941700
Starting training epoch 32
Epoch : 33, Loss : 0.354139, Accuracy: 0.908000, Test accuracy: 0.942400
Starting training epoch 33
Epoch : 34, Loss : 0.173473, Accuracy: 0.940000, Test accuracy: 0.942800
Starting training epoch 34
Epoch : 35, Loss : 0.284629, Accuracy: 0.932000, Test accuracy: 0.943000
Starting training epoch 35
Epoch : 36, Loss : 0.153682, Accuracy: 0.956000, Test accuracy: 0.944900
Starting training epoch 36
Epoch : 37, Loss : 0.175002, Accuracy: 0.944000, Test accuracy: 0.945000
Starting training epoch 37
Epoch : 38, Loss : 0.215980, Accuracy: 0.928000, Test accuracy: 0.944800
Starting training epoch 38
Epoch : 39, Loss : 0.177477, Accuracy: 0.944000, Test accuracy: 0.945600
Starting training epoch 39
Epoch : 40, Loss : 0.164590, Accuracy: 0.944000, Test accuracy: 0.945800
Starting training epoch 40
Epoch : 41, Loss : 0.113022, Accuracy: 0.964000, Test accuracy: 0.946400
Starting training epoch 41
Epoch : 42, Loss : 0.210951, Accuracy: 0.940000, Test accuracy: 0.948000
Starting training epoch 42
Epoch : 43, Loss : 0.219475, Accuracy: 0.916000, Test accuracy: 0.947600
Starting training epoch 43
Epoch : 44, Loss : 0.112282, Accuracy: 0.964000, Test accuracy: 0.948800
Starting training epoch 44
Epoch : 45, Loss : 0.187201, Accuracy: 0.940000, Test accuracy: 0.949800
Starting training epoch 45
Epoch : 46, Loss : 0.155649, Accuracy: 0.968000, Test accuracy: 0.950000
Starting training epoch 46
Epoch : 47, Loss : 0.177922, Accuracy: 0.936000, Test accuracy: 0.949600
Starting training epoch 47
Epoch : 48, Loss : 0.190464, Accuracy: 0.948000, Test accuracy: 0.950600
Starting training epoch 48
Epoch : 49, Loss : 0.202139, Accuracy: 0.932000, Test accuracy: 0.951500
Starting training epoch 49
Epoch : 50, Loss : 0.329948, Accuracy: 0.896000, Test accuracy: 0.951800
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 1.171946, Accuracy: 0.764000, Test accuracy: 0.721100
Starting training opoch 1
Epoch : 2, Loss : 0.637224, Accuracy: 0.824000, Test accuracy: 0.833500
Starting training opoch 2
Epoch : 3, Loss : 0.461228, Accuracy: 0.848000, Test accuracy: 0.868600
Starting training opoch 3
Epoch : 4, Loss : 0.421510, Accuracy: 0.896000, Test accuracy: 0.884700
Starting training opoch 4
Epoch : 5, Loss : 0.381453, Accuracy: 0.884000, Test accuracy: 0.894000
Starting training opoch 5
Epoch : 6, Loss : 0.435255, Accuracy: 0.852000, Test accuracy: 0.899600
Starting training opoch 6
Epoch : 7, Loss : 0.317938, Accuracy: 0.912000, Test accuracy: 0.906200
Starting training opoch 7
Epoch : 8, Loss : 0.276155, Accuracy: 0.936000, Test accuracy: 0.908400
Starting training opoch 8
Epoch : 9, Loss : 0.262266, Accuracy: 0.940000, Test accuracy: 0.912500
Starting training opoch 9
Epoch : 10, Loss : 0.237443, Accuracy: 0.936000, Test accuracy: 0.915800
Starting training opoch 10
Epoch : 11, Loss : 0.289877, Accuracy: 0.916000, Test accuracy: 0.917400
Starting training opoch 11
Epoch : 12, Loss : 0.273915, Accuracy: 0.928000, Test accuracy: 0.921000
Starting training opoch 12
Epoch : 13, Loss : 0.341813, Accuracy: 0.936000, Test accuracy: 0.922300
Starting training opoch 13
Epoch : 14, Loss : 0.215361, Accuracy: 0.928000, Test accuracy: 0.925100
Starting training opoch 14
Epoch : 15, Loss : 0.291706, Accuracy: 0.916000, Test accuracy: 0.926200
Starting training opoch 15
Epoch : 16, Loss : 0.208149, Accuracy: 0.960000, Test accuracy: 0.929400
Starting training opoch 16
Epoch : 17, Loss : 0.240194, Accuracy: 0.928000, Test accuracy: 0.929300
Starting training opoch 17
Epoch : 18, Loss : 0.254731, Accuracy: 0.932000, Test accuracy: 0.931600
Starting training opoch 18
Epoch : 19, Loss : 0.204470, Accuracy: 0.952000, Test accuracy: 0.933800
Starting training opoch 19
Epoch : 20, Loss : 0.195680, Accuracy: 0.940000, Test accuracy: 0.935500
Starting training opoch 20
Epoch : 21, Loss : 0.153877, Accuracy: 0.948000, Test accuracy: 0.936700
Starting training opoch 21
Epoch : 22, Loss : 0.208810, Accuracy: 0.944000, Test accuracy: 0.937000
Starting training opoch 22
Epoch : 23, Loss : 0.252818, Accuracy: 0.928000, Test accuracy: 0.939100
Starting training opoch 23
Epoch : 24, Loss : 0.164925, Accuracy: 0.956000, Test accuracy: 0.935700
Starting training opoch 24
Epoch : 25, Loss : 0.264516, Accuracy: 0.932000, Test accuracy: 0.940400
Starting training opoch 25
Epoch : 26, Loss : 0.226770, Accuracy: 0.924000, Test accuracy: 0.941900
Starting training opoch 26
Epoch : 27, Loss : 0.181171, Accuracy: 0.952000, Test accuracy: 0.942400
Starting training opoch 27
Epoch : 28, Loss : 0.259764, Accuracy: 0.904000, Test accuracy: 0.941800
Starting training opoch 28
Epoch : 29, Loss : 0.179782, Accuracy: 0.948000, Test accuracy: 0.942100
Starting training opoch 29
Epoch : 30, Loss : 0.167600, Accuracy: 0.940000, Test accuracy: 0.943300
Starting training opoch 30
Epoch : 31, Loss : 0.152793, Accuracy: 0.952000, Test accuracy: 0.944700
Starting training opoch 31
Epoch : 32, Loss : 0.150043, Accuracy: 0.956000, Test accuracy: 0.946700
Starting training opoch 32
Epoch : 33, Loss : 0.143611, Accuracy: 0.964000, Test accuracy: 0.945900
Starting training opoch 33
Epoch : 34, Loss : 0.154791, Accuracy: 0.960000, Test accuracy: 0.948200
Starting training opoch 34
Epoch : 35, Loss : 0.137494, Accuracy: 0.964000, Test accuracy: 0.947900
Starting training opoch 35
Epoch : 36, Loss : 0.187718, Accuracy: 0.948000, Test accuracy: 0.948800
Starting training opoch 36
Epoch : 37, Loss : 0.119230, Accuracy: 0.972000, Test accuracy: 0.950200
Starting training opoch 37
Epoch : 38, Loss : 0.198564, Accuracy: 0.932000, Test accuracy: 0.949100
Starting training opoch 38
Epoch : 39, Loss : 0.189478, Accuracy: 0.924000, Test accuracy: 0.950100
Starting training opoch 39
Epoch : 40, Loss : 0.148827, Accuracy: 0.952000, Test accuracy: 0.950100
Starting training opoch 40
Epoch : 41, Loss : 0.166750, Accuracy: 0.940000, Test accuracy: 0.952800
Starting training opoch 41
Epoch : 42, Loss : 0.119705, Accuracy: 0.952000, Test accuracy: 0.952000
Starting training opoch 42
Epoch : 43, Loss : 0.106450, Accuracy: 0.968000, Test accuracy: 0.952700
Starting training opoch 43
Epoch : 44, Loss : 0.196514, Accuracy: 0.948000, Test accuracy: 0.954900
Starting training opoch 44
Epoch : 45, Loss : 0.125301, Accuracy: 0.968000, Test accuracy: 0.953600
Starting training opoch 45
Epoch : 46, Loss : 0.167447, Accuracy: 0.940000, Test accuracy: 0.954700
Starting training opoch 46
Epoch : 47, Loss : 0.219947, Accuracy: 0.924000, Test accuracy: 0.955600
Starting training opoch 47
Epoch : 48, Loss : 0.122781, Accuracy: 0.952000, Test accuracy: 0.955900
Starting training opoch 48
Epoch : 49, Loss : 0.074979, Accuracy: 0.980000, Test accuracy: 0.956400
Starting training opoch 49
Epoch : 50, Loss : 0.165243, Accuracy: 0.952000, Test accuracy: 0.955800
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.558360, Accuracy: 0.840000, Test accuracy: 0.842200
Starting training epoch 1
Epoch : 2, Loss : 0.407964, Accuracy: 0.876000, Test accuracy: 0.888600
Starting training epoch 2
Epoch : 3, Loss : 0.356461, Accuracy: 0.884000, Test accuracy: 0.906400
Starting training epoch 3
Epoch : 4, Loss : 0.307506, Accuracy: 0.900000, Test accuracy: 0.914800
Starting training epoch 4
Epoch : 5, Loss : 0.401325, Accuracy: 0.908000, Test accuracy: 0.922300
Starting training epoch 5
Epoch : 6, Loss : 0.249438, Accuracy: 0.928000, Test accuracy: 0.929300
Starting training epoch 6
Epoch : 7, Loss : 0.179118, Accuracy: 0.952000, Test accuracy: 0.934200
Starting training epoch 7
Epoch : 8, Loss : 0.203425, Accuracy: 0.948000, Test accuracy: 0.938600
Starting training epoch 8
Epoch : 9, Loss : 0.165120, Accuracy: 0.944000, Test accuracy: 0.942900
Starting training epoch 9
Epoch : 10, Loss : 0.201265, Accuracy: 0.936000, Test accuracy: 0.945800
Starting training epoch 10
Epoch : 11, Loss : 0.193430, Accuracy: 0.944000, Test accuracy: 0.948600
Starting training epoch 11
Epoch : 12, Loss : 0.229516, Accuracy: 0.944000, Test accuracy: 0.952000
Starting training epoch 12
Epoch : 13, Loss : 0.134084, Accuracy: 0.952000, Test accuracy: 0.953800
Starting training epoch 13
Epoch : 14, Loss : 0.197544, Accuracy: 0.960000, Test accuracy: 0.953900
Starting training epoch 14
Epoch : 15, Loss : 0.098739, Accuracy: 0.972000, Test accuracy: 0.955400
Starting training epoch 15
Epoch : 16, Loss : 0.101552, Accuracy: 0.968000, Test accuracy: 0.957800
Starting training epoch 16
Epoch : 17, Loss : 0.087032, Accuracy: 0.968000, Test accuracy: 0.960700
Starting training epoch 17
Epoch : 18, Loss : 0.128852, Accuracy: 0.952000, Test accuracy: 0.961600
Starting training epoch 18
Epoch : 19, Loss : 0.140673, Accuracy: 0.948000, Test accuracy: 0.962900
Starting training epoch 19
Epoch : 20, Loss : 0.116534, Accuracy: 0.964000, Test accuracy: 0.964500
Starting training epoch 20
Epoch : 21, Loss : 0.119057, Accuracy: 0.964000, Test accuracy: 0.964600
Starting training epoch 21
Epoch : 22, Loss : 0.146205, Accuracy: 0.960000, Test accuracy: 0.967200
Starting training epoch 22
Epoch : 23, Loss : 0.151483, Accuracy: 0.964000, Test accuracy: 0.966900
Starting training epoch 23
Epoch : 24, Loss : 0.129851, Accuracy: 0.948000, Test accuracy: 0.967800
Starting training epoch 24
Epoch : 25, Loss : 0.117634, Accuracy: 0.948000, Test accuracy: 0.969400
Starting training epoch 25
Epoch : 26, Loss : 0.084283, Accuracy: 0.964000, Test accuracy: 0.970700
Starting training epoch 26
Epoch : 27, Loss : 0.178490, Accuracy: 0.956000, Test accuracy: 0.970700
Starting training epoch 27
Epoch : 28, Loss : 0.080680, Accuracy: 0.968000, Test accuracy: 0.970500
Starting training epoch 28
Epoch : 29, Loss : 0.097972, Accuracy: 0.976000, Test accuracy: 0.971400
Starting training epoch 29
Epoch : 30, Loss : 0.125930, Accuracy: 0.952000, Test accuracy: 0.971300
Starting training epoch 30
Epoch : 31, Loss : 0.114936, Accuracy: 0.972000, Test accuracy: 0.970600
Starting training epoch 31
Epoch : 32, Loss : 0.127700, Accuracy: 0.976000, Test accuracy: 0.973000
Starting training epoch 32
Epoch : 33, Loss : 0.122058, Accuracy: 0.964000, Test accuracy: 0.972900
Starting training epoch 33
Epoch : 34, Loss : 0.101546, Accuracy: 0.972000, Test accuracy: 0.973200
Starting training epoch 34
Epoch : 35, Loss : 0.069052, Accuracy: 0.984000, Test accuracy: 0.974100
Starting training epoch 35
Epoch : 36, Loss : 0.083436, Accuracy: 0.972000, Test accuracy: 0.974100
Starting training epoch 36
Epoch : 37, Loss : 0.092462, Accuracy: 0.960000, Test accuracy: 0.974300
Starting training epoch 37
Epoch : 38, Loss : 0.052605, Accuracy: 0.984000, Test accuracy: 0.975700
Starting training epoch 38
Epoch : 39, Loss : 0.096899, Accuracy: 0.972000, Test accuracy: 0.975500
Starting training epoch 39
Epoch : 40, Loss : 0.046112, Accuracy: 0.992000, Test accuracy: 0.975200
Starting training epoch 40
Epoch : 41, Loss : 0.075147, Accuracy: 0.972000, Test accuracy: 0.976800
Starting training epoch 41
Epoch : 42, Loss : 0.074184, Accuracy: 0.984000, Test accuracy: 0.976400
Starting training epoch 42
Epoch : 43, Loss : 0.070963, Accuracy: 0.972000, Test accuracy: 0.976800
Starting training epoch 43
Epoch : 44, Loss : 0.030245, Accuracy: 0.988000, Test accuracy: 0.974800
Starting training epoch 44
Epoch : 45, Loss : 0.068586, Accuracy: 0.984000, Test accuracy: 0.977400
Starting training epoch 45
Epoch : 46, Loss : 0.076593, Accuracy: 0.980000, Test accuracy: 0.977300
Starting training epoch 46
Epoch : 47, Loss : 0.097008, Accuracy: 0.968000, Test accuracy: 0.977100
Starting training epoch 47
Epoch : 48, Loss : 0.044053, Accuracy: 0.988000, Test accuracy: 0.976800
Starting training epoch 48
Epoch : 49, Loss : 0.095836, Accuracy: 0.968000, Test accuracy: 0.977100
Starting training epoch 49
Epoch : 50, Loss : 0.070619, Accuracy: 0.972000, Test accuracy: 0.978200
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.711817, Accuracy: 0.828000, Test accuracy: 0.839700
Starting training opoch 1
Epoch : 2, Loss : 0.346652, Accuracy: 0.884000, Test accuracy: 0.893400
Starting training opoch 2
Epoch : 3, Loss : 0.357683, Accuracy: 0.900000, Test accuracy: 0.910600
Starting training opoch 3
Epoch : 4, Loss : 0.299076, Accuracy: 0.896000, Test accuracy: 0.920200
Starting training opoch 4
Epoch : 5, Loss : 0.299221, Accuracy: 0.912000, Test accuracy: 0.926600
Starting training opoch 5
Epoch : 6, Loss : 0.322526, Accuracy: 0.884000, Test accuracy: 0.929600
Starting training opoch 6
Epoch : 7, Loss : 0.238846, Accuracy: 0.932000, Test accuracy: 0.934800
Starting training opoch 7
Epoch : 8, Loss : 0.223636, Accuracy: 0.924000, Test accuracy: 0.939000
Starting training opoch 8
Epoch : 9, Loss : 0.212622, Accuracy: 0.932000, Test accuracy: 0.941000
Starting training opoch 9
Epoch : 10, Loss : 0.192804, Accuracy: 0.944000, Test accuracy: 0.942100
Starting training opoch 10
Epoch : 11, Loss : 0.134216, Accuracy: 0.968000, Test accuracy: 0.946000
Starting training opoch 11
Epoch : 12, Loss : 0.344777, Accuracy: 0.892000, Test accuracy: 0.948600
Starting training opoch 12
Epoch : 13, Loss : 0.239432, Accuracy: 0.924000, Test accuracy: 0.950700
Starting training opoch 13
Epoch : 14, Loss : 0.218850, Accuracy: 0.940000, Test accuracy: 0.952600
Starting training opoch 14
Epoch : 15, Loss : 0.205427, Accuracy: 0.944000, Test accuracy: 0.953600
Starting training opoch 15
Epoch : 16, Loss : 0.156540, Accuracy: 0.960000, Test accuracy: 0.955500
Starting training opoch 16
Epoch : 17, Loss : 0.193094, Accuracy: 0.936000, Test accuracy: 0.955800
Starting training opoch 17
Epoch : 18, Loss : 0.128600, Accuracy: 0.964000, Test accuracy: 0.958300
Starting training opoch 18
Epoch : 19, Loss : 0.113831, Accuracy: 0.980000, Test accuracy: 0.959300
Starting training opoch 19
Epoch : 20, Loss : 0.195412, Accuracy: 0.952000, Test accuracy: 0.961600
Starting training opoch 20
Epoch : 21, Loss : 0.075779, Accuracy: 0.984000, Test accuracy: 0.961800
Starting training opoch 21
Epoch : 22, Loss : 0.135486, Accuracy: 0.960000, Test accuracy: 0.963300
Starting training opoch 22
Epoch : 23, Loss : 0.134488, Accuracy: 0.968000, Test accuracy: 0.963400
Starting training opoch 23
Epoch : 24, Loss : 0.097211, Accuracy: 0.964000, Test accuracy: 0.963100
Starting training opoch 24
Epoch : 25, Loss : 0.062883, Accuracy: 0.988000, Test accuracy: 0.963800
Starting training opoch 25
Epoch : 26, Loss : 0.154303, Accuracy: 0.964000, Test accuracy: 0.966200
Starting training opoch 26
Epoch : 27, Loss : 0.087990, Accuracy: 0.968000, Test accuracy: 0.965700
Starting training opoch 27
Epoch : 28, Loss : 0.073970, Accuracy: 0.988000, Test accuracy: 0.966300
Starting training opoch 28
Epoch : 29, Loss : 0.057630, Accuracy: 0.988000, Test accuracy: 0.966300
Starting training opoch 29
Epoch : 30, Loss : 0.103153, Accuracy: 0.960000, Test accuracy: 0.967100
Starting training opoch 30
Epoch : 31, Loss : 0.130846, Accuracy: 0.964000, Test accuracy: 0.968000
Starting training opoch 31
Epoch : 32, Loss : 0.069497, Accuracy: 0.988000, Test accuracy: 0.968300
Starting training opoch 32
Epoch : 33, Loss : 0.194826, Accuracy: 0.956000, Test accuracy: 0.969000
Starting training opoch 33
Epoch : 34, Loss : 0.119570, Accuracy: 0.952000, Test accuracy: 0.968800
Starting training opoch 34
Epoch : 35, Loss : 0.062731, Accuracy: 0.984000, Test accuracy: 0.969300
Starting training opoch 35
Epoch : 36, Loss : 0.095708, Accuracy: 0.968000, Test accuracy: 0.970200
Starting training opoch 36
Epoch : 37, Loss : 0.166961, Accuracy: 0.948000, Test accuracy: 0.968500
Starting training opoch 37
Epoch : 38, Loss : 0.065182, Accuracy: 0.976000, Test accuracy: 0.971100
Starting training opoch 38
Epoch : 39, Loss : 0.114594, Accuracy: 0.948000, Test accuracy: 0.970700
Starting training opoch 39
Epoch : 40, Loss : 0.087927, Accuracy: 0.972000, Test accuracy: 0.970700
Starting training opoch 40
Epoch : 41, Loss : 0.087177, Accuracy: 0.964000, Test accuracy: 0.970300
Starting training opoch 41
Epoch : 42, Loss : 0.119484, Accuracy: 0.968000, Test accuracy: 0.970500
Starting training opoch 42
Epoch : 43, Loss : 0.073644, Accuracy: 0.980000, Test accuracy: 0.971800
Starting training opoch 43
Epoch : 44, Loss : 0.093616, Accuracy: 0.968000, Test accuracy: 0.971700
Starting training opoch 44
Epoch : 45, Loss : 0.124757, Accuracy: 0.960000, Test accuracy: 0.971600
Starting training opoch 45
Epoch : 46, Loss : 0.090114, Accuracy: 0.968000, Test accuracy: 0.971200
Starting training opoch 46
Epoch : 47, Loss : 0.054971, Accuracy: 0.984000, Test accuracy: 0.972300
Starting training opoch 47
Epoch : 48, Loss : 0.101992, Accuracy: 0.968000, Test accuracy: 0.971300
Starting training opoch 48
Epoch : 49, Loss : 0.088109, Accuracy: 0.968000, Test accuracy: 0.972600
Starting training opoch 49
Epoch : 50, Loss : 0.069558, Accuracy: 0.980000, Test accuracy: 0.971900
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 1.223863, Accuracy: 0.832000, Test accuracy: 0.808000
Starting training opoch 1
Epoch : 2, Loss : 0.579005, Accuracy: 0.844000, Test accuracy: 0.881200
Starting training opoch 2
Epoch : 3, Loss : 0.366311, Accuracy: 0.904000, Test accuracy: 0.910300
Starting training opoch 3
Epoch : 4, Loss : 0.309141, Accuracy: 0.932000, Test accuracy: 0.923400
Starting training opoch 4
Epoch : 5, Loss : 0.233191, Accuracy: 0.936000, Test accuracy: 0.931900
Starting training opoch 5
Epoch : 6, Loss : 0.216621, Accuracy: 0.932000, Test accuracy: 0.936700
Starting training opoch 6
Epoch : 7, Loss : 0.202935, Accuracy: 0.940000, Test accuracy: 0.939900
Starting training opoch 7
Epoch : 8, Loss : 0.233867, Accuracy: 0.940000, Test accuracy: 0.942200
Starting training opoch 8
Epoch : 9, Loss : 0.249887, Accuracy: 0.920000, Test accuracy: 0.946400
Starting training opoch 9
Epoch : 10, Loss : 0.293224, Accuracy: 0.916000, Test accuracy: 0.948600
Starting training opoch 10
Epoch : 11, Loss : 0.218098, Accuracy: 0.940000, Test accuracy: 0.949500
Starting training opoch 11
Epoch : 12, Loss : 0.129928, Accuracy: 0.960000, Test accuracy: 0.950500
Starting training opoch 12
Epoch : 13, Loss : 0.195504, Accuracy: 0.944000, Test accuracy: 0.951500
Starting training opoch 13
Epoch : 14, Loss : 0.217035, Accuracy: 0.952000, Test accuracy: 0.954000
Starting training opoch 14
Epoch : 15, Loss : 0.124521, Accuracy: 0.952000, Test accuracy: 0.954500
Starting training opoch 15
Epoch : 16, Loss : 0.163388, Accuracy: 0.964000, Test accuracy: 0.956400
Starting training opoch 16
Epoch : 17, Loss : 0.163579, Accuracy: 0.960000, Test accuracy: 0.956300
Starting training opoch 17
Epoch : 18, Loss : 0.135325, Accuracy: 0.956000, Test accuracy: 0.956700
Starting training opoch 18
Epoch : 19, Loss : 0.149193, Accuracy: 0.956000, Test accuracy: 0.957100
Starting training opoch 19
Epoch : 20, Loss : 0.111048, Accuracy: 0.952000, Test accuracy: 0.957900
Starting training opoch 20
Epoch : 21, Loss : 0.121680, Accuracy: 0.976000, Test accuracy: 0.959400
Starting training opoch 21
Epoch : 22, Loss : 0.091511, Accuracy: 0.984000, Test accuracy: 0.959700
Starting training opoch 22
Epoch : 23, Loss : 0.154446, Accuracy: 0.968000, Test accuracy: 0.959400
Starting training opoch 23
Epoch : 24, Loss : 0.130381, Accuracy: 0.952000, Test accuracy: 0.960800
Starting training opoch 24
Epoch : 25, Loss : 0.117605, Accuracy: 0.972000, Test accuracy: 0.962000
Starting training opoch 25
Epoch : 26, Loss : 0.083007, Accuracy: 0.972000, Test accuracy: 0.961200
Starting training opoch 26
Epoch : 27, Loss : 0.130809, Accuracy: 0.952000, Test accuracy: 0.962300
Starting training opoch 27
Epoch : 28, Loss : 0.176068, Accuracy: 0.940000, Test accuracy: 0.961500
Starting training opoch 28
Epoch : 29, Loss : 0.086226, Accuracy: 0.976000, Test accuracy: 0.963400
Starting training opoch 29
Epoch : 30, Loss : 0.108274, Accuracy: 0.960000, Test accuracy: 0.962300
Starting training opoch 30
Epoch : 31, Loss : 0.080169, Accuracy: 0.980000, Test accuracy: 0.963600
Starting training opoch 31
Epoch : 32, Loss : 0.137156, Accuracy: 0.964000, Test accuracy: 0.963600
Starting training opoch 32
Epoch : 33, Loss : 0.110809, Accuracy: 0.968000, Test accuracy: 0.964200
Starting training opoch 33
Epoch : 34, Loss : 0.106189, Accuracy: 0.960000, Test accuracy: 0.963500
Starting training opoch 34
Epoch : 35, Loss : 0.134163, Accuracy: 0.952000, Test accuracy: 0.964000
Starting training opoch 35
Epoch : 36, Loss : 0.132187, Accuracy: 0.948000, Test accuracy: 0.964700
Starting training opoch 36
Epoch : 37, Loss : 0.087396, Accuracy: 0.976000, Test accuracy: 0.964700
Starting training opoch 37
Epoch : 38, Loss : 0.101358, Accuracy: 0.968000, Test accuracy: 0.966100
Starting training opoch 38
Epoch : 39, Loss : 0.094110, Accuracy: 0.980000, Test accuracy: 0.965600
Starting training opoch 39
Epoch : 40, Loss : 0.127271, Accuracy: 0.964000, Test accuracy: 0.966300
Starting training opoch 40
Epoch : 41, Loss : 0.103973, Accuracy: 0.972000, Test accuracy: 0.965700
Starting training opoch 41
Epoch : 42, Loss : 0.104911, Accuracy: 0.964000, Test accuracy: 0.965300
Starting training opoch 42
Epoch : 43, Loss : 0.066309, Accuracy: 0.980000, Test accuracy: 0.966000
Starting training opoch 43
Epoch : 44, Loss : 0.146101, Accuracy: 0.968000, Test accuracy: 0.965900
Starting training opoch 44
Epoch : 45, Loss : 0.087351, Accuracy: 0.976000, Test accuracy: 0.966400
Starting training opoch 45
Epoch : 46, Loss : 0.163691, Accuracy: 0.972000, Test accuracy: 0.965600
Starting training opoch 46
Epoch : 47, Loss : 0.118985, Accuracy: 0.972000, Test accuracy: 0.967600
Starting training opoch 47
Epoch : 48, Loss : 0.070127, Accuracy: 0.972000, Test accuracy: 0.966600
Starting training opoch 48
Epoch : 49, Loss : 0.152106, Accuracy: 0.964000, Test accuracy: 0.966700
Starting training opoch 49
Epoch : 50, Loss : 0.128938, Accuracy: 0.964000, Test accuracy: 0.967500
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9942
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.562781, Accuracy: 0.843000, Test accuracy: 0.850700
Distillation: Epoch : 2, Loss : 0.459932, Accuracy: 0.868000, Test accuracy: 0.890000
Distillation: Epoch : 3, Loss : 0.380837, Accuracy: 0.885000, Test accuracy: 0.901900
Distillation: Epoch : 4, Loss : 0.348651, Accuracy: 0.901000, Test accuracy: 0.906900
Distillation: Epoch : 5, Loss : 0.276066, Accuracy: 0.918000, Test accuracy: 0.912200
Distillation: Epoch : 6, Loss : 0.329103, Accuracy: 0.901000, Test accuracy: 0.913800
Distillation: Epoch : 7, Loss : 0.284065, Accuracy: 0.918000, Test accuracy: 0.916600
Distillation: Epoch : 8, Loss : 0.286735, Accuracy: 0.908000, Test accuracy: 0.920300
Distillation: Epoch : 9, Loss : 0.255458, Accuracy: 0.918000, Test accuracy: 0.923400
Distillation: Epoch : 10, Loss : 0.266967, Accuracy: 0.926000, Test accuracy: 0.925200
Distillation: Epoch : 11, Loss : 0.263677, Accuracy: 0.934000, Test accuracy: 0.928200
Distillation: Epoch : 12, Loss : 0.292458, Accuracy: 0.915000, Test accuracy: 0.929800
Distillation: Epoch : 13, Loss : 0.241061, Accuracy: 0.931000, Test accuracy: 0.932200
Distillation: Epoch : 14, Loss : 0.183133, Accuracy: 0.941000, Test accuracy: 0.934800
Distillation: Epoch : 15, Loss : 0.242514, Accuracy: 0.935000, Test accuracy: 0.936100
Distillation: Epoch : 16, Loss : 0.239736, Accuracy: 0.936000, Test accuracy: 0.940900
Distillation: Epoch : 17, Loss : 0.230116, Accuracy: 0.934000, Test accuracy: 0.942000
Distillation: Epoch : 18, Loss : 0.187804, Accuracy: 0.946000, Test accuracy: 0.944200
Distillation: Epoch : 19, Loss : 0.211343, Accuracy: 0.939000, Test accuracy: 0.946800
Distillation: Epoch : 20, Loss : 0.168226, Accuracy: 0.954000, Test accuracy: 0.947400
Distillation: Epoch : 21, Loss : 0.176726, Accuracy: 0.950000, Test accuracy: 0.949800
Distillation: Epoch : 22, Loss : 0.175314, Accuracy: 0.951000, Test accuracy: 0.950200
Distillation: Epoch : 23, Loss : 0.214790, Accuracy: 0.935000, Test accuracy: 0.951300
Distillation: Epoch : 24, Loss : 0.200789, Accuracy: 0.936000, Test accuracy: 0.952100
Distillation: Epoch : 25, Loss : 0.183274, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 26, Loss : 0.190714, Accuracy: 0.953000, Test accuracy: 0.955400
Distillation: Epoch : 27, Loss : 0.166791, Accuracy: 0.952000, Test accuracy: 0.955300
Distillation: Epoch : 28, Loss : 0.143252, Accuracy: 0.955000, Test accuracy: 0.957500
Distillation: Epoch : 29, Loss : 0.166755, Accuracy: 0.950000, Test accuracy: 0.957200
Distillation: Epoch : 30, Loss : 0.136248, Accuracy: 0.955000, Test accuracy: 0.958800
Distillation: Epoch : 31, Loss : 0.138276, Accuracy: 0.960000, Test accuracy: 0.960300
Distillation: Epoch : 32, Loss : 0.151239, Accuracy: 0.953000, Test accuracy: 0.959200
Distillation: Epoch : 33, Loss : 0.148697, Accuracy: 0.960000, Test accuracy: 0.959700
Distillation: Epoch : 34, Loss : 0.147264, Accuracy: 0.963000, Test accuracy: 0.961000
Distillation: Epoch : 35, Loss : 0.189109, Accuracy: 0.943000, Test accuracy: 0.960500
Distillation: Epoch : 36, Loss : 0.140195, Accuracy: 0.954000, Test accuracy: 0.960900
Distillation: Epoch : 37, Loss : 0.129357, Accuracy: 0.965000, Test accuracy: 0.963000
Distillation: Epoch : 38, Loss : 0.151554, Accuracy: 0.955000, Test accuracy: 0.963200
Distillation: Epoch : 39, Loss : 0.146574, Accuracy: 0.957000, Test accuracy: 0.963300
Distillation: Epoch : 40, Loss : 0.129624, Accuracy: 0.965000, Test accuracy: 0.963700
Distillation: Epoch : 41, Loss : 0.119813, Accuracy: 0.970000, Test accuracy: 0.965200
Distillation: Epoch : 42, Loss : 0.112835, Accuracy: 0.966000, Test accuracy: 0.965500
Distillation: Epoch : 43, Loss : 0.120040, Accuracy: 0.960000, Test accuracy: 0.965400
Distillation: Epoch : 44, Loss : 0.115769, Accuracy: 0.971000, Test accuracy: 0.966100
Distillation: Epoch : 45, Loss : 0.138294, Accuracy: 0.963000, Test accuracy: 0.966500
Distillation: Epoch : 46, Loss : 0.125062, Accuracy: 0.966000, Test accuracy: 0.966100
Distillation: Epoch : 47, Loss : 0.113832, Accuracy: 0.964000, Test accuracy: 0.966700
Distillation: Epoch : 48, Loss : 0.124422, Accuracy: 0.966000, Test accuracy: 0.967100
Distillation: Epoch : 49, Loss : 0.101102, Accuracy: 0.969000, Test accuracy: 0.965300
Distillation: Epoch : 50, Loss : 0.142244, Accuracy: 0.964000, Test accuracy: 0.966900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9669
Generating confusion matrix for student4
[[ 973.    0.    3.    1.    1.    3.    6.    1.    6.    5.]
 [   0. 1122.    7.    0.    1.    3.    3.    8.    4.    7.]
 [   0.    2.  989.    4.    2.    0.    3.   16.    4.    1.]
 [   1.    2.   11.  985.    0.   20.    1.    7.   10.    9.]
 [   0.    0.    4.    1.  957.    2.    3.    0.    7.   14.]
 [   0.    0.    0.    5.    0.  849.    3.    1.    3.    9.]
 [   2.    2.    0.    0.    4.    6.  933.    0.    7.    0.]
 [   1.    1.    7.    7.    2.    5.    0.  987.    8.    6.]
 [   3.    6.   10.    5.    3.    1.    6.    0.  920.    4.]
 [   0.    0.    1.    2.   12.    3.    0.    8.    5.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.924911, Accuracy: 0.787000, Test accuracy: 0.786200
Distillation: Epoch : 2, Loss : 0.473823, Accuracy: 0.863000, Test accuracy: 0.868600
Distillation: Epoch : 3, Loss : 0.414057, Accuracy: 0.877000, Test accuracy: 0.888300
Distillation: Epoch : 4, Loss : 0.362723, Accuracy: 0.899000, Test accuracy: 0.897300
Distillation: Epoch : 5, Loss : 0.395875, Accuracy: 0.882000, Test accuracy: 0.904000
Distillation: Epoch : 6, Loss : 0.357010, Accuracy: 0.892000, Test accuracy: 0.907000
Distillation: Epoch : 7, Loss : 0.360892, Accuracy: 0.897000, Test accuracy: 0.910700
Distillation: Epoch : 8, Loss : 0.350159, Accuracy: 0.903000, Test accuracy: 0.913900
Distillation: Epoch : 9, Loss : 0.348576, Accuracy: 0.898000, Test accuracy: 0.917800
Distillation: Epoch : 10, Loss : 0.307206, Accuracy: 0.906000, Test accuracy: 0.919900
Distillation: Epoch : 11, Loss : 0.270305, Accuracy: 0.923000, Test accuracy: 0.919600
Distillation: Epoch : 12, Loss : 0.300858, Accuracy: 0.916000, Test accuracy: 0.924000
Distillation: Epoch : 13, Loss : 0.256604, Accuracy: 0.930000, Test accuracy: 0.925800
Distillation: Epoch : 14, Loss : 0.277855, Accuracy: 0.930000, Test accuracy: 0.929600
Distillation: Epoch : 15, Loss : 0.231778, Accuracy: 0.939000, Test accuracy: 0.932000
Distillation: Epoch : 16, Loss : 0.217833, Accuracy: 0.944000, Test accuracy: 0.934300
Distillation: Epoch : 17, Loss : 0.200234, Accuracy: 0.954000, Test accuracy: 0.937200
Distillation: Epoch : 18, Loss : 0.271122, Accuracy: 0.939000, Test accuracy: 0.939000
Distillation: Epoch : 19, Loss : 0.209566, Accuracy: 0.948000, Test accuracy: 0.942200
Distillation: Epoch : 20, Loss : 0.279931, Accuracy: 0.925000, Test accuracy: 0.942300
Distillation: Epoch : 21, Loss : 0.257314, Accuracy: 0.937000, Test accuracy: 0.944200
Distillation: Epoch : 22, Loss : 0.223957, Accuracy: 0.948000, Test accuracy: 0.945900
Distillation: Epoch : 23, Loss : 0.219549, Accuracy: 0.933000, Test accuracy: 0.948900
Distillation: Epoch : 24, Loss : 0.204920, Accuracy: 0.947000, Test accuracy: 0.950000
Distillation: Epoch : 25, Loss : 0.184295, Accuracy: 0.947000, Test accuracy: 0.951400
Distillation: Epoch : 26, Loss : 0.193685, Accuracy: 0.945000, Test accuracy: 0.953900
Distillation: Epoch : 27, Loss : 0.179835, Accuracy: 0.953000, Test accuracy: 0.955000
Distillation: Epoch : 28, Loss : 0.179224, Accuracy: 0.954000, Test accuracy: 0.956300
Distillation: Epoch : 29, Loss : 0.166536, Accuracy: 0.954000, Test accuracy: 0.955700
Distillation: Epoch : 30, Loss : 0.187960, Accuracy: 0.952000, Test accuracy: 0.956900
Distillation: Epoch : 31, Loss : 0.176929, Accuracy: 0.955000, Test accuracy: 0.957700
Distillation: Epoch : 32, Loss : 0.182655, Accuracy: 0.952000, Test accuracy: 0.957200
Distillation: Epoch : 33, Loss : 0.166836, Accuracy: 0.960000, Test accuracy: 0.959600
Distillation: Epoch : 34, Loss : 0.163340, Accuracy: 0.958000, Test accuracy: 0.959600
Distillation: Epoch : 35, Loss : 0.148387, Accuracy: 0.961000, Test accuracy: 0.959800
Distillation: Epoch : 36, Loss : 0.156601, Accuracy: 0.958000, Test accuracy: 0.960500
Distillation: Epoch : 37, Loss : 0.157830, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 38, Loss : 0.205758, Accuracy: 0.950000, Test accuracy: 0.961900
Distillation: Epoch : 39, Loss : 0.126887, Accuracy: 0.976000, Test accuracy: 0.962300
Distillation: Epoch : 40, Loss : 0.138392, Accuracy: 0.970000, Test accuracy: 0.962300
Distillation: Epoch : 41, Loss : 0.178247, Accuracy: 0.962000, Test accuracy: 0.964100
Distillation: Epoch : 42, Loss : 0.137659, Accuracy: 0.967000, Test accuracy: 0.963500
Distillation: Epoch : 43, Loss : 0.150706, Accuracy: 0.962000, Test accuracy: 0.963800
Distillation: Epoch : 44, Loss : 0.140801, Accuracy: 0.966000, Test accuracy: 0.963700
Distillation: Epoch : 45, Loss : 0.151710, Accuracy: 0.963000, Test accuracy: 0.963600
Distillation: Epoch : 46, Loss : 0.140251, Accuracy: 0.973000, Test accuracy: 0.965200
Distillation: Epoch : 47, Loss : 0.160090, Accuracy: 0.964000, Test accuracy: 0.965600
Distillation: Epoch : 48, Loss : 0.163163, Accuracy: 0.955000, Test accuracy: 0.965800
Distillation: Epoch : 49, Loss : 0.137617, Accuracy: 0.968000, Test accuracy: 0.966300
Distillation: Epoch : 50, Loss : 0.147863, Accuracy: 0.960000, Test accuracy: 0.965900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9659
Generating confusion matrix for student4
[[ 963.    0.    3.    0.    1.    5.    5.    2.    5.    7.]
 [   0. 1118.    4.    0.    0.    2.    2.    3.    4.    5.]
 [   3.    3.  991.    6.    3.    0.    3.   20.    6.    1.]
 [   0.    0.    4.  984.    0.   13.    1.    3.    6.    9.]
 [   0.    0.    2.    1.  949.    0.    2.    0.    3.    9.]
 [   2.    1.    0.    4.    0.  847.    5.    1.    4.    4.]
 [   6.    2.    3.    0.    5.    6.  937.    0.    2.    0.]
 [   4.    1.    4.    6.    2.    2.    0.  979.    3.   12.]
 [   2.   10.   21.    7.    2.   12.    3.    2.  936.    7.]
 [   0.    0.    0.    2.   20.    5.    0.   18.    5.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.111527, Accuracy: 0.762000, Test accuracy: 0.797200
Distillation: Epoch : 2, Loss : 0.782947, Accuracy: 0.863000, Test accuracy: 0.873100
Distillation: Epoch : 3, Loss : 0.748948, Accuracy: 0.874000, Test accuracy: 0.890400
Distillation: Epoch : 4, Loss : 0.689334, Accuracy: 0.881000, Test accuracy: 0.898200
Distillation: Epoch : 5, Loss : 0.707230, Accuracy: 0.888000, Test accuracy: 0.899600
Distillation: Epoch : 6, Loss : 0.686350, Accuracy: 0.881000, Test accuracy: 0.903400
Distillation: Epoch : 7, Loss : 0.655206, Accuracy: 0.910000, Test accuracy: 0.906000
Distillation: Epoch : 8, Loss : 0.655271, Accuracy: 0.913000, Test accuracy: 0.906000
Distillation: Epoch : 9, Loss : 0.666162, Accuracy: 0.881000, Test accuracy: 0.906700
Distillation: Epoch : 10, Loss : 0.633036, Accuracy: 0.903000, Test accuracy: 0.905800
Distillation: Epoch : 11, Loss : 0.662386, Accuracy: 0.887000, Test accuracy: 0.908800
Distillation: Epoch : 12, Loss : 0.695055, Accuracy: 0.900000, Test accuracy: 0.908600
Distillation: Epoch : 13, Loss : 0.640812, Accuracy: 0.907000, Test accuracy: 0.909500
Distillation: Epoch : 14, Loss : 0.687084, Accuracy: 0.896000, Test accuracy: 0.910100
Distillation: Epoch : 15, Loss : 0.665787, Accuracy: 0.896000, Test accuracy: 0.910300
Distillation: Epoch : 16, Loss : 0.633675, Accuracy: 0.912000, Test accuracy: 0.910400
Distillation: Epoch : 17, Loss : 0.589944, Accuracy: 0.925000, Test accuracy: 0.911700
Distillation: Epoch : 18, Loss : 0.632247, Accuracy: 0.903000, Test accuracy: 0.912100
Distillation: Epoch : 19, Loss : 0.625943, Accuracy: 0.904000, Test accuracy: 0.911800
Distillation: Epoch : 20, Loss : 0.632869, Accuracy: 0.913000, Test accuracy: 0.912100
Distillation: Epoch : 21, Loss : 0.636945, Accuracy: 0.919000, Test accuracy: 0.913800
Distillation: Epoch : 22, Loss : 0.674674, Accuracy: 0.903000, Test accuracy: 0.912900
Distillation: Epoch : 23, Loss : 0.624567, Accuracy: 0.917000, Test accuracy: 0.913800
Distillation: Epoch : 24, Loss : 0.656252, Accuracy: 0.903000, Test accuracy: 0.914800
Distillation: Epoch : 25, Loss : 0.649437, Accuracy: 0.912000, Test accuracy: 0.914900
Distillation: Epoch : 26, Loss : 0.673589, Accuracy: 0.899000, Test accuracy: 0.916800
Distillation: Epoch : 27, Loss : 0.677915, Accuracy: 0.901000, Test accuracy: 0.915000
Distillation: Epoch : 28, Loss : 0.625038, Accuracy: 0.909000, Test accuracy: 0.915900
Distillation: Epoch : 29, Loss : 0.640688, Accuracy: 0.907000, Test accuracy: 0.917600
Distillation: Epoch : 30, Loss : 0.603676, Accuracy: 0.917000, Test accuracy: 0.916100
Distillation: Epoch : 31, Loss : 0.628197, Accuracy: 0.914000, Test accuracy: 0.918700
Distillation: Epoch : 32, Loss : 0.625157, Accuracy: 0.913000, Test accuracy: 0.918200
Distillation: Epoch : 33, Loss : 0.619739, Accuracy: 0.919000, Test accuracy: 0.918000
Distillation: Epoch : 34, Loss : 0.648671, Accuracy: 0.899000, Test accuracy: 0.918200
Distillation: Epoch : 35, Loss : 0.639214, Accuracy: 0.916000, Test accuracy: 0.917000
Distillation: Epoch : 36, Loss : 0.629897, Accuracy: 0.903000, Test accuracy: 0.917800
Distillation: Epoch : 37, Loss : 0.624571, Accuracy: 0.912000, Test accuracy: 0.918100
Distillation: Epoch : 38, Loss : 0.655800, Accuracy: 0.912000, Test accuracy: 0.917500
Distillation: Epoch : 39, Loss : 0.622549, Accuracy: 0.913000, Test accuracy: 0.920000
Distillation: Epoch : 40, Loss : 0.647335, Accuracy: 0.911000, Test accuracy: 0.919200
Distillation: Epoch : 41, Loss : 0.669215, Accuracy: 0.911000, Test accuracy: 0.920200
Distillation: Epoch : 42, Loss : 0.611895, Accuracy: 0.913000, Test accuracy: 0.919700
Distillation: Epoch : 43, Loss : 0.642173, Accuracy: 0.913000, Test accuracy: 0.920100
Distillation: Epoch : 44, Loss : 0.648303, Accuracy: 0.903000, Test accuracy: 0.920000
Distillation: Epoch : 45, Loss : 0.593613, Accuracy: 0.930000, Test accuracy: 0.920700
Distillation: Epoch : 46, Loss : 0.635793, Accuracy: 0.907000, Test accuracy: 0.919300
Distillation: Epoch : 47, Loss : 0.613543, Accuracy: 0.913000, Test accuracy: 0.919800
Distillation: Epoch : 48, Loss : 0.615661, Accuracy: 0.907000, Test accuracy: 0.919200
Distillation: Epoch : 49, Loss : 0.669962, Accuracy: 0.893000, Test accuracy: 0.919700
Distillation: Epoch : 50, Loss : 0.585021, Accuracy: 0.933000, Test accuracy: 0.922100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9221
Generating confusion matrix for student4
[[ 959.    0.    8.    2.    0.    6.    8.    2.   10.    9.]
 [   0. 1110.    8.    2.    4.    3.    4.   15.   12.    6.]
 [   1.    3.  911.   13.    4.    2.    5.   15.    6.    2.]
 [   1.    3.   23.  930.    1.   39.    0.    6.   20.   13.]
 [   1.    0.   11.    3.  912.    8.    7.    8.   11.   35.]
 [   5.    3.    1.   21.    2.  778.    9.    1.   37.    8.]
 [   9.    4.   12.    4.   12.   18.  923.    0.   15.    0.]
 [   2.    1.   13.   12.    3.    5.    2.  943.    9.   23.]
 [   2.   11.   39.   19.    6.   27.    0.    0.  846.    4.]
 [   0.    0.    6.    4.   38.    6.    0.   38.    8.  909.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.519464, Accuracy: 0.775000, Test accuracy: 0.774800
Distillation: Epoch : 2, Loss : 0.939272, Accuracy: 0.853000, Test accuracy: 0.869300
Distillation: Epoch : 3, Loss : 0.885229, Accuracy: 0.895000, Test accuracy: 0.891300
Distillation: Epoch : 4, Loss : 0.865972, Accuracy: 0.887000, Test accuracy: 0.899300
Distillation: Epoch : 5, Loss : 0.813680, Accuracy: 0.910000, Test accuracy: 0.905200
Distillation: Epoch : 6, Loss : 0.797663, Accuracy: 0.916000, Test accuracy: 0.910800
Distillation: Epoch : 7, Loss : 0.800654, Accuracy: 0.908000, Test accuracy: 0.914400
Distillation: Epoch : 8, Loss : 0.741430, Accuracy: 0.939000, Test accuracy: 0.917600
Distillation: Epoch : 9, Loss : 0.799085, Accuracy: 0.916000, Test accuracy: 0.921100
Distillation: Epoch : 10, Loss : 0.753714, Accuracy: 0.923000, Test accuracy: 0.925000
Distillation: Epoch : 11, Loss : 0.763334, Accuracy: 0.917000, Test accuracy: 0.928900
Distillation: Epoch : 12, Loss : 0.743833, Accuracy: 0.942000, Test accuracy: 0.932900
Distillation: Epoch : 13, Loss : 0.757107, Accuracy: 0.918000, Test accuracy: 0.935800
Distillation: Epoch : 14, Loss : 0.746061, Accuracy: 0.933000, Test accuracy: 0.939300
Distillation: Epoch : 15, Loss : 0.710832, Accuracy: 0.944000, Test accuracy: 0.941300
Distillation: Epoch : 16, Loss : 0.714212, Accuracy: 0.941000, Test accuracy: 0.942900
Distillation: Epoch : 17, Loss : 0.737812, Accuracy: 0.936000, Test accuracy: 0.943600
Distillation: Epoch : 18, Loss : 0.711727, Accuracy: 0.941000, Test accuracy: 0.947400
Distillation: Epoch : 19, Loss : 0.702659, Accuracy: 0.941000, Test accuracy: 0.949700
Distillation: Epoch : 20, Loss : 0.713796, Accuracy: 0.956000, Test accuracy: 0.949900
Distillation: Epoch : 21, Loss : 0.706878, Accuracy: 0.955000, Test accuracy: 0.952700
Distillation: Epoch : 22, Loss : 0.688999, Accuracy: 0.955000, Test accuracy: 0.953600
Distillation: Epoch : 23, Loss : 0.675417, Accuracy: 0.952000, Test accuracy: 0.954900
Distillation: Epoch : 24, Loss : 0.703438, Accuracy: 0.953000, Test accuracy: 0.957200
Distillation: Epoch : 25, Loss : 0.653113, Accuracy: 0.964000, Test accuracy: 0.956100
Distillation: Epoch : 26, Loss : 0.666886, Accuracy: 0.962000, Test accuracy: 0.957900
Distillation: Epoch : 27, Loss : 0.686638, Accuracy: 0.961000, Test accuracy: 0.959400
Distillation: Epoch : 28, Loss : 0.660282, Accuracy: 0.955000, Test accuracy: 0.960000
Distillation: Epoch : 29, Loss : 0.682905, Accuracy: 0.958000, Test accuracy: 0.960500
Distillation: Epoch : 30, Loss : 0.658283, Accuracy: 0.966000, Test accuracy: 0.961300
Distillation: Epoch : 31, Loss : 0.683251, Accuracy: 0.959000, Test accuracy: 0.961800
Distillation: Epoch : 32, Loss : 0.675427, Accuracy: 0.958000, Test accuracy: 0.962300
Distillation: Epoch : 33, Loss : 0.703804, Accuracy: 0.954000, Test accuracy: 0.962700
Distillation: Epoch : 34, Loss : 0.656778, Accuracy: 0.964000, Test accuracy: 0.963200
Distillation: Epoch : 35, Loss : 0.642161, Accuracy: 0.966000, Test accuracy: 0.963800
Distillation: Epoch : 36, Loss : 0.664066, Accuracy: 0.960000, Test accuracy: 0.963300
Distillation: Epoch : 37, Loss : 0.667775, Accuracy: 0.954000, Test accuracy: 0.963700
Distillation: Epoch : 38, Loss : 0.640183, Accuracy: 0.969000, Test accuracy: 0.964500
Distillation: Epoch : 39, Loss : 0.653964, Accuracy: 0.961000, Test accuracy: 0.965200
Distillation: Epoch : 40, Loss : 0.662851, Accuracy: 0.962000, Test accuracy: 0.964000
Distillation: Epoch : 41, Loss : 0.682246, Accuracy: 0.970000, Test accuracy: 0.965500
Distillation: Epoch : 42, Loss : 0.654295, Accuracy: 0.966000, Test accuracy: 0.965000
Distillation: Epoch : 43, Loss : 0.636244, Accuracy: 0.975000, Test accuracy: 0.966600
Distillation: Epoch : 44, Loss : 0.665820, Accuracy: 0.968000, Test accuracy: 0.966300
Distillation: Epoch : 45, Loss : 0.656825, Accuracy: 0.959000, Test accuracy: 0.965900
Distillation: Epoch : 46, Loss : 0.675204, Accuracy: 0.954000, Test accuracy: 0.967200
Distillation: Epoch : 47, Loss : 0.664413, Accuracy: 0.958000, Test accuracy: 0.968300
Distillation: Epoch : 48, Loss : 0.664078, Accuracy: 0.964000, Test accuracy: 0.968000
Distillation: Epoch : 49, Loss : 0.652371, Accuracy: 0.975000, Test accuracy: 0.968300
Distillation: Epoch : 50, Loss : 0.687328, Accuracy: 0.954000, Test accuracy: 0.968400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9684
Generating confusion matrix for student4
[[ 971.    0.    5.    0.    1.    2.    6.    1.    6.    4.]
 [   0. 1121.    8.    0.    1.    0.    3.   10.    3.    7.]
 [   1.    4.  994.    9.    5.    1.    2.   14.    5.    0.]
 [   0.    2.    8.  977.    1.   16.    1.    2.    7.    6.]
 [   0.    0.    3.    0.  950.    0.    3.    0.    8.   14.]
 [   0.    0.    1.    6.    0.  863.    2.    0.    5.    7.]
 [   2.    3.    1.    0.    1.    4.  938.    0.   10.    0.]
 [   0.    0.    6.   12.    3.    4.    0.  992.    9.    7.]
 [   3.    5.    5.    6.    3.    0.    3.    1.  915.    1.]
 [   3.    0.    1.    0.   17.    2.    0.    8.    6.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.951461, Accuracy: 0.705000, Test accuracy: 0.743500
Distillation: Epoch : 2, Loss : 1.169406, Accuracy: 0.842000, Test accuracy: 0.844100
Distillation: Epoch : 3, Loss : 1.067529, Accuracy: 0.864000, Test accuracy: 0.879600
Distillation: Epoch : 4, Loss : 1.032599, Accuracy: 0.902000, Test accuracy: 0.896600
Distillation: Epoch : 5, Loss : 1.005022, Accuracy: 0.884000, Test accuracy: 0.909100
Distillation: Epoch : 6, Loss : 0.973387, Accuracy: 0.909000, Test accuracy: 0.914400
Distillation: Epoch : 7, Loss : 0.997660, Accuracy: 0.900000, Test accuracy: 0.921800
Distillation: Epoch : 8, Loss : 0.953268, Accuracy: 0.921000, Test accuracy: 0.926700
Distillation: Epoch : 9, Loss : 0.975334, Accuracy: 0.913000, Test accuracy: 0.932600
Distillation: Epoch : 10, Loss : 0.913197, Accuracy: 0.927000, Test accuracy: 0.935500
Distillation: Epoch : 11, Loss : 0.909044, Accuracy: 0.926000, Test accuracy: 0.938700
Distillation: Epoch : 12, Loss : 0.915345, Accuracy: 0.938000, Test accuracy: 0.942100
Distillation: Epoch : 13, Loss : 0.901993, Accuracy: 0.941000, Test accuracy: 0.944600
Distillation: Epoch : 14, Loss : 0.884591, Accuracy: 0.941000, Test accuracy: 0.947700
Distillation: Epoch : 15, Loss : 0.886977, Accuracy: 0.934000, Test accuracy: 0.949700
Distillation: Epoch : 16, Loss : 0.889050, Accuracy: 0.944000, Test accuracy: 0.950900
Distillation: Epoch : 17, Loss : 0.868804, Accuracy: 0.964000, Test accuracy: 0.952000
Distillation: Epoch : 18, Loss : 0.868701, Accuracy: 0.951000, Test accuracy: 0.955200
Distillation: Epoch : 19, Loss : 0.856403, Accuracy: 0.956000, Test accuracy: 0.955200
Distillation: Epoch : 20, Loss : 0.879905, Accuracy: 0.942000, Test accuracy: 0.956800
Distillation: Epoch : 21, Loss : 0.868105, Accuracy: 0.962000, Test accuracy: 0.957200
Distillation: Epoch : 22, Loss : 0.862562, Accuracy: 0.967000, Test accuracy: 0.958400
Distillation: Epoch : 23, Loss : 0.831739, Accuracy: 0.958000, Test accuracy: 0.959000
Distillation: Epoch : 24, Loss : 0.854470, Accuracy: 0.958000, Test accuracy: 0.960300
Distillation: Epoch : 25, Loss : 0.847207, Accuracy: 0.956000, Test accuracy: 0.961300
Distillation: Epoch : 26, Loss : 0.857950, Accuracy: 0.956000, Test accuracy: 0.962900
Distillation: Epoch : 27, Loss : 0.858180, Accuracy: 0.952000, Test accuracy: 0.962900
Distillation: Epoch : 28, Loss : 0.804545, Accuracy: 0.958000, Test accuracy: 0.964200
Distillation: Epoch : 29, Loss : 0.868910, Accuracy: 0.961000, Test accuracy: 0.964100
Distillation: Epoch : 30, Loss : 0.874237, Accuracy: 0.954000, Test accuracy: 0.964900
Distillation: Epoch : 31, Loss : 0.850565, Accuracy: 0.960000, Test accuracy: 0.965000
Distillation: Epoch : 32, Loss : 0.844960, Accuracy: 0.964000, Test accuracy: 0.966200
Distillation: Epoch : 33, Loss : 0.830767, Accuracy: 0.973000, Test accuracy: 0.965700
Distillation: Epoch : 34, Loss : 0.858827, Accuracy: 0.965000, Test accuracy: 0.966800
Distillation: Epoch : 35, Loss : 0.820225, Accuracy: 0.977000, Test accuracy: 0.966800
Distillation: Epoch : 36, Loss : 0.829677, Accuracy: 0.961000, Test accuracy: 0.966400
Distillation: Epoch : 37, Loss : 0.845907, Accuracy: 0.963000, Test accuracy: 0.967300
Distillation: Epoch : 38, Loss : 0.849237, Accuracy: 0.951000, Test accuracy: 0.967200
Distillation: Epoch : 39, Loss : 0.836296, Accuracy: 0.966000, Test accuracy: 0.967300
Distillation: Epoch : 40, Loss : 0.802845, Accuracy: 0.979000, Test accuracy: 0.967700
Distillation: Epoch : 41, Loss : 0.826969, Accuracy: 0.969000, Test accuracy: 0.967500
Distillation: Epoch : 42, Loss : 0.834671, Accuracy: 0.966000, Test accuracy: 0.968000
Distillation: Epoch : 43, Loss : 0.820457, Accuracy: 0.967000, Test accuracy: 0.968300
Distillation: Epoch : 44, Loss : 0.830330, Accuracy: 0.968000, Test accuracy: 0.968700
Distillation: Epoch : 45, Loss : 0.823319, Accuracy: 0.974000, Test accuracy: 0.968700
Distillation: Epoch : 46, Loss : 0.859198, Accuracy: 0.960000, Test accuracy: 0.969000
Distillation: Epoch : 47, Loss : 0.810035, Accuracy: 0.968000, Test accuracy: 0.968900
Distillation: Epoch : 48, Loss : 0.825619, Accuracy: 0.968000, Test accuracy: 0.968900
Distillation: Epoch : 49, Loss : 0.830164, Accuracy: 0.962000, Test accuracy: 0.969500
Distillation: Epoch : 50, Loss : 0.813151, Accuracy: 0.972000, Test accuracy: 0.970200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9702
Generating confusion matrix for student4
[[ 974.    0.    3.    0.    0.    1.    7.    2.    8.    5.]
 [   0. 1126.    6.    1.    2.    0.    3.   11.    1.    5.]
 [   1.    4.  994.    2.    4.    0.    2.   12.    6.    1.]
 [   0.    1.    8.  983.    0.   14.    1.    3.    9.    8.]
 [   0.    0.    3.    0.  957.    0.    1.    1.    4.   13.]
 [   0.    0.    1.    5.    0.  868.    1.    0.    4.    6.]
 [   2.    3.    0.    0.    3.    4.  942.    0.    8.    1.]
 [   1.    0.   11.    9.    2.    0.    0.  984.    9.   10.]
 [   2.    1.    6.    8.    2.    2.    1.    2.  916.    2.]
 [   0.    0.    0.    2.   12.    3.    0.   13.    9.  958.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.441565, Accuracy: 0.779000, Test accuracy: 0.799100
Distillation: Epoch : 2, Loss : 1.261107, Accuracy: 0.845000, Test accuracy: 0.866600
Distillation: Epoch : 3, Loss : 1.238158, Accuracy: 0.863000, Test accuracy: 0.882800
Distillation: Epoch : 4, Loss : 1.213168, Accuracy: 0.874000, Test accuracy: 0.890000
Distillation: Epoch : 5, Loss : 1.189250, Accuracy: 0.881000, Test accuracy: 0.896700
Distillation: Epoch : 6, Loss : 1.191927, Accuracy: 0.891000, Test accuracy: 0.898800
Distillation: Epoch : 7, Loss : 1.173862, Accuracy: 0.895000, Test accuracy: 0.899400
Distillation: Epoch : 8, Loss : 1.181340, Accuracy: 0.882000, Test accuracy: 0.900600
Distillation: Epoch : 9, Loss : 1.143597, Accuracy: 0.901000, Test accuracy: 0.901400
Distillation: Epoch : 10, Loss : 1.181878, Accuracy: 0.896000, Test accuracy: 0.903900
Distillation: Epoch : 11, Loss : 1.185976, Accuracy: 0.890000, Test accuracy: 0.904100
Distillation: Epoch : 12, Loss : 1.168958, Accuracy: 0.894000, Test accuracy: 0.904500
Distillation: Epoch : 13, Loss : 1.174516, Accuracy: 0.906000, Test accuracy: 0.906300
Distillation: Epoch : 14, Loss : 1.174429, Accuracy: 0.891000, Test accuracy: 0.905900
Distillation: Epoch : 15, Loss : 1.175136, Accuracy: 0.887000, Test accuracy: 0.906000
Distillation: Epoch : 16, Loss : 1.166482, Accuracy: 0.900000, Test accuracy: 0.906400
Distillation: Epoch : 17, Loss : 1.171981, Accuracy: 0.900000, Test accuracy: 0.907400
Distillation: Epoch : 18, Loss : 1.184994, Accuracy: 0.891000, Test accuracy: 0.908600
Distillation: Epoch : 19, Loss : 1.167855, Accuracy: 0.891000, Test accuracy: 0.908600
Distillation: Epoch : 20, Loss : 1.162632, Accuracy: 0.901000, Test accuracy: 0.910600
Distillation: Epoch : 21, Loss : 1.151027, Accuracy: 0.894000, Test accuracy: 0.911900
Distillation: Epoch : 22, Loss : 1.153454, Accuracy: 0.895000, Test accuracy: 0.913400
Distillation: Epoch : 23, Loss : 1.153376, Accuracy: 0.907000, Test accuracy: 0.914200
Distillation: Epoch : 24, Loss : 1.147364, Accuracy: 0.904000, Test accuracy: 0.917700
Distillation: Epoch : 25, Loss : 1.118116, Accuracy: 0.919000, Test accuracy: 0.919300
Distillation: Epoch : 26, Loss : 1.140236, Accuracy: 0.917000, Test accuracy: 0.923800
Distillation: Epoch : 27, Loss : 1.124372, Accuracy: 0.915000, Test accuracy: 0.925100
Distillation: Epoch : 28, Loss : 1.107524, Accuracy: 0.925000, Test accuracy: 0.929000
Distillation: Epoch : 29, Loss : 1.103430, Accuracy: 0.918000, Test accuracy: 0.932500
Distillation: Epoch : 30, Loss : 1.116390, Accuracy: 0.922000, Test accuracy: 0.935200
Distillation: Epoch : 31, Loss : 1.092000, Accuracy: 0.934000, Test accuracy: 0.937200
Distillation: Epoch : 32, Loss : 1.113738, Accuracy: 0.935000, Test accuracy: 0.940500
Distillation: Epoch : 33, Loss : 1.060726, Accuracy: 0.948000, Test accuracy: 0.944000
Distillation: Epoch : 34, Loss : 1.068571, Accuracy: 0.945000, Test accuracy: 0.945000
Distillation: Epoch : 35, Loss : 1.055045, Accuracy: 0.941000, Test accuracy: 0.947300
Distillation: Epoch : 36, Loss : 1.055686, Accuracy: 0.945000, Test accuracy: 0.949300
Distillation: Epoch : 37, Loss : 1.065208, Accuracy: 0.946000, Test accuracy: 0.949300
Distillation: Epoch : 38, Loss : 1.057595, Accuracy: 0.939000, Test accuracy: 0.951500
Distillation: Epoch : 39, Loss : 1.097347, Accuracy: 0.936000, Test accuracy: 0.952400
Distillation: Epoch : 40, Loss : 1.041473, Accuracy: 0.953000, Test accuracy: 0.953700
Distillation: Epoch : 41, Loss : 1.058642, Accuracy: 0.948000, Test accuracy: 0.954500
Distillation: Epoch : 42, Loss : 1.052006, Accuracy: 0.943000, Test accuracy: 0.956300
Distillation: Epoch : 43, Loss : 1.043434, Accuracy: 0.960000, Test accuracy: 0.956600
Distillation: Epoch : 44, Loss : 1.036994, Accuracy: 0.949000, Test accuracy: 0.956200
Distillation: Epoch : 45, Loss : 1.049112, Accuracy: 0.945000, Test accuracy: 0.957700
Distillation: Epoch : 46, Loss : 1.028702, Accuracy: 0.957000, Test accuracy: 0.957900
Distillation: Epoch : 47, Loss : 1.045864, Accuracy: 0.956000, Test accuracy: 0.956700
Distillation: Epoch : 48, Loss : 1.037230, Accuracy: 0.949000, Test accuracy: 0.957800
Distillation: Epoch : 49, Loss : 1.062275, Accuracy: 0.944000, Test accuracy: 0.957500
Distillation: Epoch : 50, Loss : 1.048808, Accuracy: 0.950000, Test accuracy: 0.959200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9592
Generating confusion matrix for student4
[[ 969.    0.    6.    0.    0.    3.    6.    3.    7.    5.]
 [   0. 1110.    7.    0.    1.    0.    3.   11.    5.    5.]
 [   0.    3.  980.    6.    2.    0.    1.   10.   15.    1.]
 [   0.    0.   10.  985.    0.   19.    0.    4.   19.   14.]
 [   0.    1.    3.    2.  956.    0.    1.    1.    7.   11.]
 [   2.    1.    1.    3.    0.  851.   11.    1.   19.    9.]
 [   3.    5.    2.    0.    6.    7.  935.    0.    6.    0.]
 [   3.    0.    6.    8.    1.    2.    0.  974.    3.   15.]
 [   2.   15.   17.    5.    1.    8.    1.    2.  885.    2.]
 [   1.    0.    0.    1.   15.    2.    0.   22.    8.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.729462, Accuracy: 0.756000, Test accuracy: 0.767700
Distillation: Epoch : 2, Loss : 1.398620, Accuracy: 0.856000, Test accuracy: 0.855400
Distillation: Epoch : 3, Loss : 1.371398, Accuracy: 0.870000, Test accuracy: 0.882900
Distillation: Epoch : 4, Loss : 1.366719, Accuracy: 0.872000, Test accuracy: 0.895200
Distillation: Epoch : 5, Loss : 1.342487, Accuracy: 0.882000, Test accuracy: 0.902800
Distillation: Epoch : 6, Loss : 1.289444, Accuracy: 0.912000, Test accuracy: 0.910200
Distillation: Epoch : 7, Loss : 1.315553, Accuracy: 0.910000, Test accuracy: 0.915900
Distillation: Epoch : 8, Loss : 1.296700, Accuracy: 0.911000, Test accuracy: 0.922700
Distillation: Epoch : 9, Loss : 1.268558, Accuracy: 0.919000, Test accuracy: 0.928400
Distillation: Epoch : 10, Loss : 1.267232, Accuracy: 0.917000, Test accuracy: 0.936200
Distillation: Epoch : 11, Loss : 1.234610, Accuracy: 0.928000, Test accuracy: 0.940400
Distillation: Epoch : 12, Loss : 1.236637, Accuracy: 0.937000, Test accuracy: 0.945600
Distillation: Epoch : 13, Loss : 1.207069, Accuracy: 0.938000, Test accuracy: 0.947700
Distillation: Epoch : 14, Loss : 1.224093, Accuracy: 0.940000, Test accuracy: 0.950600
Distillation: Epoch : 15, Loss : 1.233401, Accuracy: 0.936000, Test accuracy: 0.952300
Distillation: Epoch : 16, Loss : 1.215579, Accuracy: 0.941000, Test accuracy: 0.954500
Distillation: Epoch : 17, Loss : 1.233407, Accuracy: 0.948000, Test accuracy: 0.955500
Distillation: Epoch : 18, Loss : 1.193975, Accuracy: 0.956000, Test accuracy: 0.956000
Distillation: Epoch : 19, Loss : 1.207642, Accuracy: 0.956000, Test accuracy: 0.957300
Distillation: Epoch : 20, Loss : 1.186005, Accuracy: 0.968000, Test accuracy: 0.957800
Distillation: Epoch : 21, Loss : 1.207295, Accuracy: 0.968000, Test accuracy: 0.958600
Distillation: Epoch : 22, Loss : 1.206631, Accuracy: 0.963000, Test accuracy: 0.960100
Distillation: Epoch : 23, Loss : 1.184121, Accuracy: 0.956000, Test accuracy: 0.961400
Distillation: Epoch : 24, Loss : 1.197288, Accuracy: 0.947000, Test accuracy: 0.961100
Distillation: Epoch : 25, Loss : 1.192904, Accuracy: 0.952000, Test accuracy: 0.963100
Distillation: Epoch : 26, Loss : 1.181138, Accuracy: 0.964000, Test accuracy: 0.963900
Distillation: Epoch : 27, Loss : 1.185507, Accuracy: 0.957000, Test accuracy: 0.963900
Distillation: Epoch : 28, Loss : 1.189833, Accuracy: 0.952000, Test accuracy: 0.963100
Distillation: Epoch : 29, Loss : 1.201324, Accuracy: 0.953000, Test accuracy: 0.963200
Distillation: Epoch : 30, Loss : 1.201119, Accuracy: 0.956000, Test accuracy: 0.964000
Distillation: Epoch : 31, Loss : 1.188609, Accuracy: 0.959000, Test accuracy: 0.964200
Distillation: Epoch : 32, Loss : 1.184556, Accuracy: 0.961000, Test accuracy: 0.965000
Distillation: Epoch : 33, Loss : 1.200759, Accuracy: 0.956000, Test accuracy: 0.963800
Distillation: Epoch : 34, Loss : 1.181594, Accuracy: 0.957000, Test accuracy: 0.965800
Distillation: Epoch : 35, Loss : 1.200037, Accuracy: 0.957000, Test accuracy: 0.965700
Distillation: Epoch : 36, Loss : 1.191628, Accuracy: 0.968000, Test accuracy: 0.965400
Distillation: Epoch : 37, Loss : 1.169435, Accuracy: 0.959000, Test accuracy: 0.965600
Distillation: Epoch : 38, Loss : 1.189964, Accuracy: 0.958000, Test accuracy: 0.965900
Distillation: Epoch : 39, Loss : 1.158807, Accuracy: 0.962000, Test accuracy: 0.965300
Distillation: Epoch : 40, Loss : 1.206915, Accuracy: 0.964000, Test accuracy: 0.965800
Distillation: Epoch : 41, Loss : 1.198170, Accuracy: 0.967000, Test accuracy: 0.966500
Distillation: Epoch : 42, Loss : 1.169666, Accuracy: 0.964000, Test accuracy: 0.966100
Distillation: Epoch : 43, Loss : 1.177780, Accuracy: 0.962000, Test accuracy: 0.966200
Distillation: Epoch : 44, Loss : 1.182979, Accuracy: 0.960000, Test accuracy: 0.966500
Distillation: Epoch : 45, Loss : 1.174163, Accuracy: 0.964000, Test accuracy: 0.966400
Distillation: Epoch : 46, Loss : 1.154003, Accuracy: 0.969000, Test accuracy: 0.966800
Distillation: Epoch : 47, Loss : 1.206269, Accuracy: 0.965000, Test accuracy: 0.967600
Distillation: Epoch : 48, Loss : 1.162069, Accuracy: 0.967000, Test accuracy: 0.966700
Distillation: Epoch : 49, Loss : 1.176447, Accuracy: 0.961000, Test accuracy: 0.967100
Distillation: Epoch : 50, Loss : 1.205803, Accuracy: 0.965000, Test accuracy: 0.967400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9674
Generating confusion matrix for student4
[[ 966.    0.    1.    0.    1.    1.    8.    2.    8.    6.]
 [   1. 1118.    8.    0.    3.    1.    3.    8.    3.    6.]
 [   1.    5.  993.    3.    2.    1.    0.   10.   12.    1.]
 [   0.    0.    6.  990.    0.   11.    0.    3.   11.    9.]
 [   0.    0.    3.    0.  957.    0.    3.    1.    5.   10.]
 [   1.    0.    0.    4.    0.  864.    3.    1.    2.    2.]
 [   9.    4.    1.    0.    3.    6.  938.    0.   11.    0.]
 [   1.    1.    8.    7.    0.    2.    0.  983.    7.   14.]
 [   1.    7.   10.    3.    2.    2.    3.    3.  905.    1.]
 [   0.    0.    2.    3.   14.    4.    0.   17.   10.  960.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.834503, Accuracy: 0.741000, Test accuracy: 0.772100
Distillation: Epoch : 2, Loss : 1.556830, Accuracy: 0.834000, Test accuracy: 0.853800
Distillation: Epoch : 3, Loss : 1.498921, Accuracy: 0.860000, Test accuracy: 0.877000
Distillation: Epoch : 4, Loss : 1.478486, Accuracy: 0.872000, Test accuracy: 0.886400
Distillation: Epoch : 5, Loss : 1.441396, Accuracy: 0.882000, Test accuracy: 0.892400
Distillation: Epoch : 6, Loss : 1.447921, Accuracy: 0.874000, Test accuracy: 0.898100
Distillation: Epoch : 7, Loss : 1.447890, Accuracy: 0.899000, Test accuracy: 0.906400
Distillation: Epoch : 8, Loss : 1.422873, Accuracy: 0.916000, Test accuracy: 0.911000
Distillation: Epoch : 9, Loss : 1.397431, Accuracy: 0.921000, Test accuracy: 0.916700
Distillation: Epoch : 10, Loss : 1.409708, Accuracy: 0.910000, Test accuracy: 0.920200
Distillation: Epoch : 11, Loss : 1.423190, Accuracy: 0.917000, Test accuracy: 0.923100
Distillation: Epoch : 12, Loss : 1.392012, Accuracy: 0.914000, Test accuracy: 0.926400
Distillation: Epoch : 13, Loss : 1.401862, Accuracy: 0.927000, Test accuracy: 0.930900
Distillation: Epoch : 14, Loss : 1.401087, Accuracy: 0.932000, Test accuracy: 0.932400
Distillation: Epoch : 15, Loss : 1.401277, Accuracy: 0.921000, Test accuracy: 0.936600
Distillation: Epoch : 16, Loss : 1.396674, Accuracy: 0.926000, Test accuracy: 0.939500
Distillation: Epoch : 17, Loss : 1.355772, Accuracy: 0.943000, Test accuracy: 0.940800
Distillation: Epoch : 18, Loss : 1.346953, Accuracy: 0.950000, Test accuracy: 0.942800
Distillation: Epoch : 19, Loss : 1.362913, Accuracy: 0.945000, Test accuracy: 0.944300
Distillation: Epoch : 20, Loss : 1.380547, Accuracy: 0.945000, Test accuracy: 0.946200
Distillation: Epoch : 21, Loss : 1.345825, Accuracy: 0.949000, Test accuracy: 0.948100
Distillation: Epoch : 22, Loss : 1.368401, Accuracy: 0.939000, Test accuracy: 0.949500
Distillation: Epoch : 23, Loss : 1.337030, Accuracy: 0.940000, Test accuracy: 0.951200
Distillation: Epoch : 24, Loss : 1.366583, Accuracy: 0.949000, Test accuracy: 0.953000
Distillation: Epoch : 25, Loss : 1.329657, Accuracy: 0.958000, Test accuracy: 0.953800
Distillation: Epoch : 26, Loss : 1.353815, Accuracy: 0.951000, Test accuracy: 0.955300
Distillation: Epoch : 27, Loss : 1.325329, Accuracy: 0.962000, Test accuracy: 0.957300
Distillation: Epoch : 28, Loss : 1.332866, Accuracy: 0.967000, Test accuracy: 0.958200
Distillation: Epoch : 29, Loss : 1.340169, Accuracy: 0.950000, Test accuracy: 0.959000
Distillation: Epoch : 30, Loss : 1.341022, Accuracy: 0.956000, Test accuracy: 0.961500
Distillation: Epoch : 31, Loss : 1.338704, Accuracy: 0.950000, Test accuracy: 0.961800
Distillation: Epoch : 32, Loss : 1.340990, Accuracy: 0.957000, Test accuracy: 0.962000
Distillation: Epoch : 33, Loss : 1.357775, Accuracy: 0.960000, Test accuracy: 0.963200
Distillation: Epoch : 34, Loss : 1.329879, Accuracy: 0.958000, Test accuracy: 0.964200
Distillation: Epoch : 35, Loss : 1.313532, Accuracy: 0.966000, Test accuracy: 0.964700
Distillation: Epoch : 36, Loss : 1.349301, Accuracy: 0.963000, Test accuracy: 0.965400
Distillation: Epoch : 37, Loss : 1.322295, Accuracy: 0.950000, Test accuracy: 0.966000
Distillation: Epoch : 38, Loss : 1.308978, Accuracy: 0.971000, Test accuracy: 0.966000
Distillation: Epoch : 39, Loss : 1.322760, Accuracy: 0.962000, Test accuracy: 0.965800
Distillation: Epoch : 40, Loss : 1.327823, Accuracy: 0.964000, Test accuracy: 0.966100
Distillation: Epoch : 41, Loss : 1.338989, Accuracy: 0.971000, Test accuracy: 0.966900
Distillation: Epoch : 42, Loss : 1.317646, Accuracy: 0.969000, Test accuracy: 0.966700
Distillation: Epoch : 43, Loss : 1.321132, Accuracy: 0.964000, Test accuracy: 0.967300
Distillation: Epoch : 44, Loss : 1.346348, Accuracy: 0.968000, Test accuracy: 0.966600
Distillation: Epoch : 45, Loss : 1.328376, Accuracy: 0.965000, Test accuracy: 0.967800
Distillation: Epoch : 46, Loss : 1.316736, Accuracy: 0.969000, Test accuracy: 0.967700
Distillation: Epoch : 47, Loss : 1.316267, Accuracy: 0.964000, Test accuracy: 0.967800
Distillation: Epoch : 48, Loss : 1.316801, Accuracy: 0.970000, Test accuracy: 0.967700
Distillation: Epoch : 49, Loss : 1.299501, Accuracy: 0.974000, Test accuracy: 0.968500
Distillation: Epoch : 50, Loss : 1.336544, Accuracy: 0.966000, Test accuracy: 0.968600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9686
Generating confusion matrix for student4
[[ 972.    0.    3.    1.    1.    1.    6.    2.    7.    3.]
 [   1. 1122.    5.    0.    2.    0.    3.   11.    3.    5.]
 [   1.    1.  994.    3.    3.    0.    2.    7.    8.    0.]
 [   0.    3.    8.  977.    0.   14.    0.    4.    9.    5.]
 [   0.    0.    6.    0.  953.    0.    3.    3.    5.   12.]
 [   2.    0.    1.   13.    0.  861.    3.    0.    6.    8.]
 [   2.    5.    2.    0.    2.    8.  940.    0.    8.    1.]
 [   1.    0.    8.   12.    3.    2.    0.  994.    5.    3.]
 [   1.    4.    4.    4.    3.    3.    1.    1.  907.    6.]
 [   0.    0.    1.    0.   15.    3.    0.    6.   16.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.959216, Accuracy: 0.774000, Test accuracy: 0.785100
Distillation: Epoch : 2, Loss : 1.617749, Accuracy: 0.839000, Test accuracy: 0.867900
Distillation: Epoch : 3, Loss : 1.601759, Accuracy: 0.891000, Test accuracy: 0.896300
Distillation: Epoch : 4, Loss : 1.584411, Accuracy: 0.883000, Test accuracy: 0.908600
Distillation: Epoch : 5, Loss : 1.535316, Accuracy: 0.908000, Test accuracy: 0.917000
Distillation: Epoch : 6, Loss : 1.530650, Accuracy: 0.914000, Test accuracy: 0.924600
Distillation: Epoch : 7, Loss : 1.515989, Accuracy: 0.922000, Test accuracy: 0.930600
Distillation: Epoch : 8, Loss : 1.511580, Accuracy: 0.934000, Test accuracy: 0.935600
Distillation: Epoch : 9, Loss : 1.492833, Accuracy: 0.938000, Test accuracy: 0.939500
Distillation: Epoch : 10, Loss : 1.484502, Accuracy: 0.935000, Test accuracy: 0.944600
Distillation: Epoch : 11, Loss : 1.484232, Accuracy: 0.952000, Test accuracy: 0.947300
Distillation: Epoch : 12, Loss : 1.499546, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 13, Loss : 1.479946, Accuracy: 0.952000, Test accuracy: 0.952000
Distillation: Epoch : 14, Loss : 1.468104, Accuracy: 0.958000, Test accuracy: 0.955200
Distillation: Epoch : 15, Loss : 1.496847, Accuracy: 0.952000, Test accuracy: 0.956800
Distillation: Epoch : 16, Loss : 1.460093, Accuracy: 0.954000, Test accuracy: 0.958600
Distillation: Epoch : 17, Loss : 1.464381, Accuracy: 0.962000, Test accuracy: 0.960200
Distillation: Epoch : 18, Loss : 1.461178, Accuracy: 0.963000, Test accuracy: 0.960900
Distillation: Epoch : 19, Loss : 1.466242, Accuracy: 0.964000, Test accuracy: 0.962000
Distillation: Epoch : 20, Loss : 1.479720, Accuracy: 0.955000, Test accuracy: 0.961900
Distillation: Epoch : 21, Loss : 1.472453, Accuracy: 0.965000, Test accuracy: 0.963300
Distillation: Epoch : 22, Loss : 1.460621, Accuracy: 0.957000, Test accuracy: 0.963500
Distillation: Epoch : 23, Loss : 1.487873, Accuracy: 0.960000, Test accuracy: 0.965000
Distillation: Epoch : 24, Loss : 1.462441, Accuracy: 0.972000, Test accuracy: 0.964900
Distillation: Epoch : 25, Loss : 1.467654, Accuracy: 0.956000, Test accuracy: 0.966100
Distillation: Epoch : 26, Loss : 1.465961, Accuracy: 0.955000, Test accuracy: 0.966500
Distillation: Epoch : 27, Loss : 1.466640, Accuracy: 0.959000, Test accuracy: 0.966800
Distillation: Epoch : 28, Loss : 1.469685, Accuracy: 0.969000, Test accuracy: 0.967400
Distillation: Epoch : 29, Loss : 1.469461, Accuracy: 0.964000, Test accuracy: 0.967700
Distillation: Epoch : 30, Loss : 1.440485, Accuracy: 0.963000, Test accuracy: 0.968700
Distillation: Epoch : 31, Loss : 1.442943, Accuracy: 0.969000, Test accuracy: 0.968800
Distillation: Epoch : 32, Loss : 1.470704, Accuracy: 0.952000, Test accuracy: 0.968300
Distillation: Epoch : 33, Loss : 1.436025, Accuracy: 0.965000, Test accuracy: 0.968700
Distillation: Epoch : 34, Loss : 1.464290, Accuracy: 0.971000, Test accuracy: 0.969700
Distillation: Epoch : 35, Loss : 1.448386, Accuracy: 0.966000, Test accuracy: 0.969600
Distillation: Epoch : 36, Loss : 1.460309, Accuracy: 0.965000, Test accuracy: 0.970400
Distillation: Epoch : 37, Loss : 1.458105, Accuracy: 0.957000, Test accuracy: 0.970600
Distillation: Epoch : 38, Loss : 1.442669, Accuracy: 0.968000, Test accuracy: 0.971300
Distillation: Epoch : 39, Loss : 1.456860, Accuracy: 0.968000, Test accuracy: 0.971400
Distillation: Epoch : 40, Loss : 1.451154, Accuracy: 0.974000, Test accuracy: 0.971900
Distillation: Epoch : 41, Loss : 1.448632, Accuracy: 0.967000, Test accuracy: 0.971200
Distillation: Epoch : 42, Loss : 1.449857, Accuracy: 0.972000, Test accuracy: 0.972600
Distillation: Epoch : 43, Loss : 1.446982, Accuracy: 0.963000, Test accuracy: 0.972700
Distillation: Epoch : 44, Loss : 1.438489, Accuracy: 0.972000, Test accuracy: 0.972800
Distillation: Epoch : 45, Loss : 1.438536, Accuracy: 0.969000, Test accuracy: 0.972700
Distillation: Epoch : 46, Loss : 1.446913, Accuracy: 0.976000, Test accuracy: 0.973200
Distillation: Epoch : 47, Loss : 1.456581, Accuracy: 0.977000, Test accuracy: 0.973400
Distillation: Epoch : 48, Loss : 1.442738, Accuracy: 0.962000, Test accuracy: 0.973900
Distillation: Epoch : 49, Loss : 1.442167, Accuracy: 0.967000, Test accuracy: 0.973700
Distillation: Epoch : 50, Loss : 1.460455, Accuracy: 0.964000, Test accuracy: 0.973300
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9733
Generating confusion matrix for student4
[[ 973.    0.    2.    1.    1.    2.    5.    1.    8.    7.]
 [   1. 1122.    4.    0.    0.    0.    3.    3.    1.    4.]
 [   2.    5.  997.    3.    1.    0.    0.   16.    6.    1.]
 [   0.    0.   11.  988.    0.   18.    0.    3.    6.    7.]
 [   0.    0.    4.    0.  957.    1.    3.    2.    2.    4.]
 [   1.    0.    1.    4.    0.  863.    2.    0.    3.    5.]
 [   2.    4.    0.    0.    4.    5.  943.    0.    5.    1.]
 [   1.    0.    6.    8.    3.    1.    0.  989.    2.    4.]
 [   0.    4.    5.    5.    2.    0.    2.    2.  929.    4.]
 [   0.    0.    2.    1.   14.    2.    0.   12.   12.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.009987, Accuracy: 0.729000, Test accuracy: 0.760800
Distillation: Epoch : 2, Loss : 1.884756, Accuracy: 0.836000, Test accuracy: 0.852200
Distillation: Epoch : 3, Loss : 1.846527, Accuracy: 0.881000, Test accuracy: 0.875700
Distillation: Epoch : 4, Loss : 1.832312, Accuracy: 0.874000, Test accuracy: 0.885300
Distillation: Epoch : 5, Loss : 1.828533, Accuracy: 0.893000, Test accuracy: 0.897500
Distillation: Epoch : 6, Loss : 1.835851, Accuracy: 0.863000, Test accuracy: 0.902900
Distillation: Epoch : 7, Loss : 1.820394, Accuracy: 0.906000, Test accuracy: 0.909500
Distillation: Epoch : 8, Loss : 1.793205, Accuracy: 0.920000, Test accuracy: 0.916300
Distillation: Epoch : 9, Loss : 1.799984, Accuracy: 0.921000, Test accuracy: 0.920100
Distillation: Epoch : 10, Loss : 1.799793, Accuracy: 0.921000, Test accuracy: 0.923100
Distillation: Epoch : 11, Loss : 1.794987, Accuracy: 0.919000, Test accuracy: 0.928100
Distillation: Epoch : 12, Loss : 1.809686, Accuracy: 0.930000, Test accuracy: 0.931200
Distillation: Epoch : 13, Loss : 1.778447, Accuracy: 0.925000, Test accuracy: 0.934600
Distillation: Epoch : 14, Loss : 1.773528, Accuracy: 0.934000, Test accuracy: 0.937500
Distillation: Epoch : 15, Loss : 1.772136, Accuracy: 0.934000, Test accuracy: 0.940800
Distillation: Epoch : 16, Loss : 1.770396, Accuracy: 0.929000, Test accuracy: 0.942000
Distillation: Epoch : 17, Loss : 1.782231, Accuracy: 0.928000, Test accuracy: 0.942800
Distillation: Epoch : 18, Loss : 1.766618, Accuracy: 0.932000, Test accuracy: 0.944400
Distillation: Epoch : 19, Loss : 1.773606, Accuracy: 0.934000, Test accuracy: 0.944900
Distillation: Epoch : 20, Loss : 1.770491, Accuracy: 0.939000, Test accuracy: 0.944800
Distillation: Epoch : 21, Loss : 1.759701, Accuracy: 0.954000, Test accuracy: 0.945700
Distillation: Epoch : 22, Loss : 1.773053, Accuracy: 0.934000, Test accuracy: 0.946800
Distillation: Epoch : 23, Loss : 1.759995, Accuracy: 0.951000, Test accuracy: 0.947400
Distillation: Epoch : 24, Loss : 1.767516, Accuracy: 0.946000, Test accuracy: 0.948000
Distillation: Epoch : 25, Loss : 1.758686, Accuracy: 0.952000, Test accuracy: 0.948900
Distillation: Epoch : 26, Loss : 1.774348, Accuracy: 0.941000, Test accuracy: 0.949900
Distillation: Epoch : 27, Loss : 1.762520, Accuracy: 0.940000, Test accuracy: 0.950400
Distillation: Epoch : 28, Loss : 1.767022, Accuracy: 0.943000, Test accuracy: 0.950800
Distillation: Epoch : 29, Loss : 1.767059, Accuracy: 0.938000, Test accuracy: 0.951600
Distillation: Epoch : 30, Loss : 1.769989, Accuracy: 0.939000, Test accuracy: 0.951600
Distillation: Epoch : 31, Loss : 1.757022, Accuracy: 0.943000, Test accuracy: 0.952100
Distillation: Epoch : 32, Loss : 1.758636, Accuracy: 0.943000, Test accuracy: 0.952200
Distillation: Epoch : 33, Loss : 1.750850, Accuracy: 0.945000, Test accuracy: 0.952600
Distillation: Epoch : 34, Loss : 1.761739, Accuracy: 0.958000, Test accuracy: 0.953700
Distillation: Epoch : 35, Loss : 1.751637, Accuracy: 0.959000, Test accuracy: 0.953900
Distillation: Epoch : 36, Loss : 1.760113, Accuracy: 0.945000, Test accuracy: 0.953500
Distillation: Epoch : 37, Loss : 1.762491, Accuracy: 0.945000, Test accuracy: 0.953600
Distillation: Epoch : 38, Loss : 1.764868, Accuracy: 0.956000, Test accuracy: 0.954800
Distillation: Epoch : 39, Loss : 1.761226, Accuracy: 0.941000, Test accuracy: 0.954100
Distillation: Epoch : 40, Loss : 1.749313, Accuracy: 0.943000, Test accuracy: 0.955000
Distillation: Epoch : 41, Loss : 1.748850, Accuracy: 0.950000, Test accuracy: 0.954400
Distillation: Epoch : 42, Loss : 1.765282, Accuracy: 0.951000, Test accuracy: 0.955900
Distillation: Epoch : 43, Loss : 1.752905, Accuracy: 0.959000, Test accuracy: 0.955400
Distillation: Epoch : 44, Loss : 1.751391, Accuracy: 0.943000, Test accuracy: 0.956300
Distillation: Epoch : 45, Loss : 1.766847, Accuracy: 0.964000, Test accuracy: 0.955800
Distillation: Epoch : 46, Loss : 1.754728, Accuracy: 0.953000, Test accuracy: 0.956100
Distillation: Epoch : 47, Loss : 1.756075, Accuracy: 0.955000, Test accuracy: 0.956200
Distillation: Epoch : 48, Loss : 1.751419, Accuracy: 0.958000, Test accuracy: 0.956700
Distillation: Epoch : 49, Loss : 1.747991, Accuracy: 0.946000, Test accuracy: 0.957200
Distillation: Epoch : 50, Loss : 1.758620, Accuracy: 0.954000, Test accuracy: 0.957000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.957
Generating confusion matrix for student4
[[ 968.    0.    2.    0.    1.    2.   11.    2.   10.    8.]
 [   1. 1110.   11.    1.    3.    1.    3.   11.   10.    7.]
 [   2.    5.  978.    3.    2.    0.    1.   15.    8.    1.]
 [   0.    3.   11.  987.    0.   22.    0.    4.    9.   12.]
 [   1.    0.    7.    1.  946.    0.    3.    3.    8.   20.]
 [   0.    0.    0.    5.    0.  854.    6.    1.    8.    5.]
 [   7.    1.    2.    0.    5.    6.  931.    0.   12.    1.]
 [   1.    1.   13.    7.    1.    2.    0.  965.    7.   14.]
 [   0.   15.    7.    4.    2.    2.    3.    3.  892.    2.]
 [   0.    0.    1.    2.   22.    3.    0.   24.   10.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.154657, Accuracy: 0.782000, Test accuracy: 0.771100
Distillation: Epoch : 2, Loss : 2.078206, Accuracy: 0.825000, Test accuracy: 0.850500
Distillation: Epoch : 3, Loss : 2.067770, Accuracy: 0.861000, Test accuracy: 0.871500
Distillation: Epoch : 4, Loss : 2.055907, Accuracy: 0.885000, Test accuracy: 0.880900
Distillation: Epoch : 5, Loss : 2.051902, Accuracy: 0.869000, Test accuracy: 0.887600
Distillation: Epoch : 6, Loss : 2.055947, Accuracy: 0.876000, Test accuracy: 0.890900
Distillation: Epoch : 7, Loss : 2.050558, Accuracy: 0.879000, Test accuracy: 0.895900
Distillation: Epoch : 8, Loss : 2.037070, Accuracy: 0.896000, Test accuracy: 0.900900
Distillation: Epoch : 9, Loss : 2.049064, Accuracy: 0.884000, Test accuracy: 0.905300
Distillation: Epoch : 10, Loss : 2.041140, Accuracy: 0.902000, Test accuracy: 0.909700
Distillation: Epoch : 11, Loss : 2.036926, Accuracy: 0.900000, Test accuracy: 0.912100
Distillation: Epoch : 12, Loss : 2.029172, Accuracy: 0.912000, Test accuracy: 0.915800
Distillation: Epoch : 13, Loss : 2.031118, Accuracy: 0.917000, Test accuracy: 0.920000
Distillation: Epoch : 14, Loss : 2.034959, Accuracy: 0.908000, Test accuracy: 0.924300
Distillation: Epoch : 15, Loss : 2.028214, Accuracy: 0.910000, Test accuracy: 0.930000
Distillation: Epoch : 16, Loss : 2.025414, Accuracy: 0.932000, Test accuracy: 0.933700
Distillation: Epoch : 17, Loss : 2.027843, Accuracy: 0.936000, Test accuracy: 0.935600
Distillation: Epoch : 18, Loss : 2.027945, Accuracy: 0.921000, Test accuracy: 0.939500
Distillation: Epoch : 19, Loss : 2.013435, Accuracy: 0.939000, Test accuracy: 0.941700
Distillation: Epoch : 20, Loss : 2.018932, Accuracy: 0.928000, Test accuracy: 0.942400
Distillation: Epoch : 21, Loss : 2.014396, Accuracy: 0.940000, Test accuracy: 0.944700
Distillation: Epoch : 22, Loss : 2.008911, Accuracy: 0.949000, Test accuracy: 0.945900
Distillation: Epoch : 23, Loss : 2.017633, Accuracy: 0.941000, Test accuracy: 0.946500
Distillation: Epoch : 24, Loss : 2.008768, Accuracy: 0.944000, Test accuracy: 0.948700
Distillation: Epoch : 25, Loss : 2.008055, Accuracy: 0.934000, Test accuracy: 0.948700
Distillation: Epoch : 26, Loss : 2.004767, Accuracy: 0.944000, Test accuracy: 0.949500
Distillation: Epoch : 27, Loss : 2.002128, Accuracy: 0.955000, Test accuracy: 0.949900
Distillation: Epoch : 28, Loss : 2.003832, Accuracy: 0.939000, Test accuracy: 0.950300
Distillation: Epoch : 29, Loss : 2.010826, Accuracy: 0.951000, Test accuracy: 0.950300
Distillation: Epoch : 30, Loss : 2.003952, Accuracy: 0.948000, Test accuracy: 0.950500
Distillation: Epoch : 31, Loss : 2.015123, Accuracy: 0.947000, Test accuracy: 0.950900
Distillation: Epoch : 32, Loss : 2.011539, Accuracy: 0.955000, Test accuracy: 0.952400
Distillation: Epoch : 33, Loss : 2.011421, Accuracy: 0.938000, Test accuracy: 0.952800
Distillation: Epoch : 34, Loss : 1.999128, Accuracy: 0.962000, Test accuracy: 0.953100
Distillation: Epoch : 35, Loss : 2.011135, Accuracy: 0.955000, Test accuracy: 0.954100
Distillation: Epoch : 36, Loss : 2.001937, Accuracy: 0.963000, Test accuracy: 0.954700
Distillation: Epoch : 37, Loss : 2.011984, Accuracy: 0.959000, Test accuracy: 0.954000
Distillation: Epoch : 38, Loss : 2.012222, Accuracy: 0.963000, Test accuracy: 0.954800
Distillation: Epoch : 39, Loss : 2.013657, Accuracy: 0.956000, Test accuracy: 0.954600
Distillation: Epoch : 40, Loss : 1.999159, Accuracy: 0.952000, Test accuracy: 0.955500
Distillation: Epoch : 41, Loss : 2.010504, Accuracy: 0.946000, Test accuracy: 0.955200
Distillation: Epoch : 42, Loss : 2.005055, Accuracy: 0.953000, Test accuracy: 0.955200
Distillation: Epoch : 43, Loss : 2.011213, Accuracy: 0.957000, Test accuracy: 0.956100
Distillation: Epoch : 44, Loss : 2.006639, Accuracy: 0.952000, Test accuracy: 0.955600
Distillation: Epoch : 45, Loss : 2.011573, Accuracy: 0.957000, Test accuracy: 0.956300
Distillation: Epoch : 46, Loss : 2.002877, Accuracy: 0.957000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 2.007874, Accuracy: 0.960000, Test accuracy: 0.957800
Distillation: Epoch : 48, Loss : 2.002542, Accuracy: 0.944000, Test accuracy: 0.958100
Distillation: Epoch : 49, Loss : 2.004829, Accuracy: 0.962000, Test accuracy: 0.958100
Distillation: Epoch : 50, Loss : 2.003603, Accuracy: 0.971000, Test accuracy: 0.957800
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9578
Generating confusion matrix for student4
[[ 972.    0.    3.    0.    1.    2.   13.    4.    8.    4.]
 [   1. 1111.    6.    0.    1.    1.    2.   13.   10.    9.]
 [   0.    3.  981.    6.    1.    1.    1.   13.    8.    2.]
 [   0.    0.   13.  978.    1.   24.    1.    2.    9.   12.]
 [   0.    1.    5.    1.  947.    0.    3.    5.    9.   18.]
 [   1.    0.    1.    7.    0.  854.    7.    1.    8.   10.]
 [   3.    5.    0.    0.    7.    5.  929.    0.   11.    1.]
 [   0.    0.   12.   11.    2.    2.    0.  967.    7.    6.]
 [   2.   15.   10.    6.    4.    2.    2.    2.  893.    1.]
 [   1.    0.    1.    1.   18.    1.    0.   21.   11.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.908094, Accuracy: 0.754000, Test accuracy: 0.781900
Distillation: Epoch : 2, Loss : 0.510109, Accuracy: 0.858000, Test accuracy: 0.866100
Distillation: Epoch : 3, Loss : 0.436298, Accuracy: 0.874000, Test accuracy: 0.887100
Distillation: Epoch : 4, Loss : 0.436875, Accuracy: 0.876000, Test accuracy: 0.896900
Distillation: Epoch : 5, Loss : 0.311264, Accuracy: 0.907000, Test accuracy: 0.901000
Distillation: Epoch : 6, Loss : 0.348414, Accuracy: 0.895000, Test accuracy: 0.906700
Distillation: Epoch : 7, Loss : 0.328287, Accuracy: 0.903000, Test accuracy: 0.908800
Distillation: Epoch : 8, Loss : 0.322922, Accuracy: 0.901000, Test accuracy: 0.912900
Distillation: Epoch : 9, Loss : 0.253333, Accuracy: 0.922000, Test accuracy: 0.917000
Distillation: Epoch : 10, Loss : 0.271210, Accuracy: 0.915000, Test accuracy: 0.919300
Distillation: Epoch : 11, Loss : 0.292791, Accuracy: 0.918000, Test accuracy: 0.921900
Distillation: Epoch : 12, Loss : 0.313193, Accuracy: 0.913000, Test accuracy: 0.924500
Distillation: Epoch : 13, Loss : 0.274419, Accuracy: 0.914000, Test accuracy: 0.925800
Distillation: Epoch : 14, Loss : 0.270094, Accuracy: 0.926000, Test accuracy: 0.929200
Distillation: Epoch : 15, Loss : 0.251082, Accuracy: 0.930000, Test accuracy: 0.930300
Distillation: Epoch : 16, Loss : 0.233223, Accuracy: 0.940000, Test accuracy: 0.932600
Distillation: Epoch : 17, Loss : 0.239800, Accuracy: 0.928000, Test accuracy: 0.934300
Distillation: Epoch : 18, Loss : 0.208679, Accuracy: 0.941000, Test accuracy: 0.938000
Distillation: Epoch : 19, Loss : 0.180323, Accuracy: 0.950000, Test accuracy: 0.940300
Distillation: Epoch : 20, Loss : 0.220942, Accuracy: 0.931000, Test accuracy: 0.941900
Distillation: Epoch : 21, Loss : 0.205790, Accuracy: 0.931000, Test accuracy: 0.942600
Distillation: Epoch : 22, Loss : 0.229045, Accuracy: 0.923000, Test accuracy: 0.945300
Distillation: Epoch : 23, Loss : 0.161668, Accuracy: 0.947000, Test accuracy: 0.945500
Distillation: Epoch : 24, Loss : 0.212733, Accuracy: 0.944000, Test accuracy: 0.947100
Distillation: Epoch : 25, Loss : 0.209486, Accuracy: 0.944000, Test accuracy: 0.947200
Distillation: Epoch : 26, Loss : 0.172679, Accuracy: 0.953000, Test accuracy: 0.950400
Distillation: Epoch : 27, Loss : 0.162441, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 28, Loss : 0.150894, Accuracy: 0.953000, Test accuracy: 0.952400
Distillation: Epoch : 29, Loss : 0.166183, Accuracy: 0.946000, Test accuracy: 0.951400
Distillation: Epoch : 30, Loss : 0.171889, Accuracy: 0.950000, Test accuracy: 0.953500
Distillation: Epoch : 31, Loss : 0.120547, Accuracy: 0.967000, Test accuracy: 0.952300
Distillation: Epoch : 32, Loss : 0.185911, Accuracy: 0.947000, Test accuracy: 0.954400
Distillation: Epoch : 33, Loss : 0.148179, Accuracy: 0.952000, Test accuracy: 0.955700
Distillation: Epoch : 34, Loss : 0.122013, Accuracy: 0.957000, Test accuracy: 0.956000
Distillation: Epoch : 35, Loss : 0.117725, Accuracy: 0.965000, Test accuracy: 0.956700
Distillation: Epoch : 36, Loss : 0.133790, Accuracy: 0.964000, Test accuracy: 0.957700
Distillation: Epoch : 37, Loss : 0.120972, Accuracy: 0.961000, Test accuracy: 0.956800
Distillation: Epoch : 38, Loss : 0.145056, Accuracy: 0.954000, Test accuracy: 0.958200
Distillation: Epoch : 39, Loss : 0.136255, Accuracy: 0.963000, Test accuracy: 0.959400
Distillation: Epoch : 40, Loss : 0.119069, Accuracy: 0.963000, Test accuracy: 0.958600
Distillation: Epoch : 41, Loss : 0.189367, Accuracy: 0.955000, Test accuracy: 0.961200
Distillation: Epoch : 42, Loss : 0.144808, Accuracy: 0.963000, Test accuracy: 0.961200
Distillation: Epoch : 43, Loss : 0.130510, Accuracy: 0.956000, Test accuracy: 0.962800
Distillation: Epoch : 44, Loss : 0.104419, Accuracy: 0.967000, Test accuracy: 0.961700
Distillation: Epoch : 45, Loss : 0.123376, Accuracy: 0.962000, Test accuracy: 0.962500
Distillation: Epoch : 46, Loss : 0.118459, Accuracy: 0.965000, Test accuracy: 0.962600
Distillation: Epoch : 47, Loss : 0.139938, Accuracy: 0.964000, Test accuracy: 0.963900
Distillation: Epoch : 48, Loss : 0.139305, Accuracy: 0.956000, Test accuracy: 0.962600
Distillation: Epoch : 49, Loss : 0.127641, Accuracy: 0.959000, Test accuracy: 0.964100
Distillation: Epoch : 50, Loss : 0.108573, Accuracy: 0.969000, Test accuracy: 0.964700
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9647
Generating confusion matrix for student5
[[ 974.    0.    5.    1.    2.    2.   15.    2.    8.    9.]
 [   0. 1121.    4.    0.    1.    2.    3.    3.    1.    5.]
 [   2.    2.  986.    5.    4.    1.    5.   21.   12.    1.]
 [   0.    2.    5.  978.    0.   12.    0.    6.    6.   10.]
 [   0.    0.    4.    0.  955.    0.    2.    1.    5.   10.]
 [   1.    0.    0.    7.    0.  859.   10.    0.   10.    9.]
 [   1.    1.    2.    0.    0.    2.  918.    0.    0.    0.]
 [   1.    0.    7.    6.    3.    3.    0.  985.    4.   14.]
 [   1.    9.   18.   10.    3.    8.    5.    1.  925.    5.]
 [   0.    0.    1.    3.   14.    3.    0.    9.    3.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.274788, Accuracy: 0.750000, Test accuracy: 0.764300
Distillation: Epoch : 2, Loss : 0.527476, Accuracy: 0.854000, Test accuracy: 0.861100
Distillation: Epoch : 3, Loss : 0.460095, Accuracy: 0.870000, Test accuracy: 0.884300
Distillation: Epoch : 4, Loss : 0.395080, Accuracy: 0.885000, Test accuracy: 0.893100
Distillation: Epoch : 5, Loss : 0.338585, Accuracy: 0.908000, Test accuracy: 0.897800
Distillation: Epoch : 6, Loss : 0.391462, Accuracy: 0.890000, Test accuracy: 0.902300
Distillation: Epoch : 7, Loss : 0.364487, Accuracy: 0.892000, Test accuracy: 0.904200
Distillation: Epoch : 8, Loss : 0.333316, Accuracy: 0.914000, Test accuracy: 0.907000
Distillation: Epoch : 9, Loss : 0.324565, Accuracy: 0.916000, Test accuracy: 0.909700
Distillation: Epoch : 10, Loss : 0.331356, Accuracy: 0.913000, Test accuracy: 0.910600
Distillation: Epoch : 11, Loss : 0.337497, Accuracy: 0.901000, Test accuracy: 0.913800
Distillation: Epoch : 12, Loss : 0.385089, Accuracy: 0.904000, Test accuracy: 0.913500
Distillation: Epoch : 13, Loss : 0.324299, Accuracy: 0.915000, Test accuracy: 0.915800
Distillation: Epoch : 14, Loss : 0.357064, Accuracy: 0.909000, Test accuracy: 0.918000
Distillation: Epoch : 15, Loss : 0.306842, Accuracy: 0.911000, Test accuracy: 0.918700
Distillation: Epoch : 16, Loss : 0.310203, Accuracy: 0.921000, Test accuracy: 0.919300
Distillation: Epoch : 17, Loss : 0.254536, Accuracy: 0.937000, Test accuracy: 0.921100
Distillation: Epoch : 18, Loss : 0.294531, Accuracy: 0.910000, Test accuracy: 0.922700
Distillation: Epoch : 19, Loss : 0.259092, Accuracy: 0.921000, Test accuracy: 0.923500
Distillation: Epoch : 20, Loss : 0.269589, Accuracy: 0.929000, Test accuracy: 0.925400
Distillation: Epoch : 21, Loss : 0.293938, Accuracy: 0.918000, Test accuracy: 0.926500
Distillation: Epoch : 22, Loss : 0.265409, Accuracy: 0.921000, Test accuracy: 0.926700
Distillation: Epoch : 23, Loss : 0.250920, Accuracy: 0.939000, Test accuracy: 0.929100
Distillation: Epoch : 24, Loss : 0.257290, Accuracy: 0.934000, Test accuracy: 0.930200
Distillation: Epoch : 25, Loss : 0.239872, Accuracy: 0.934000, Test accuracy: 0.930600
Distillation: Epoch : 26, Loss : 0.221362, Accuracy: 0.944000, Test accuracy: 0.933100
Distillation: Epoch : 27, Loss : 0.234942, Accuracy: 0.935000, Test accuracy: 0.933400
Distillation: Epoch : 28, Loss : 0.261227, Accuracy: 0.940000, Test accuracy: 0.935400
Distillation: Epoch : 29, Loss : 0.252221, Accuracy: 0.935000, Test accuracy: 0.937200
Distillation: Epoch : 30, Loss : 0.245159, Accuracy: 0.925000, Test accuracy: 0.938400
Distillation: Epoch : 31, Loss : 0.244350, Accuracy: 0.943000, Test accuracy: 0.940600
Distillation: Epoch : 32, Loss : 0.225070, Accuracy: 0.948000, Test accuracy: 0.940800
Distillation: Epoch : 33, Loss : 0.210498, Accuracy: 0.942000, Test accuracy: 0.942500
Distillation: Epoch : 34, Loss : 0.243761, Accuracy: 0.942000, Test accuracy: 0.942700
Distillation: Epoch : 35, Loss : 0.228412, Accuracy: 0.946000, Test accuracy: 0.944900
Distillation: Epoch : 36, Loss : 0.239696, Accuracy: 0.937000, Test accuracy: 0.944500
Distillation: Epoch : 37, Loss : 0.247351, Accuracy: 0.933000, Test accuracy: 0.945800
Distillation: Epoch : 38, Loss : 0.223705, Accuracy: 0.943000, Test accuracy: 0.946700
Distillation: Epoch : 39, Loss : 0.213508, Accuracy: 0.945000, Test accuracy: 0.947500
Distillation: Epoch : 40, Loss : 0.179464, Accuracy: 0.951000, Test accuracy: 0.948500
Distillation: Epoch : 41, Loss : 0.197258, Accuracy: 0.951000, Test accuracy: 0.949500
Distillation: Epoch : 42, Loss : 0.163675, Accuracy: 0.960000, Test accuracy: 0.950300
Distillation: Epoch : 43, Loss : 0.154538, Accuracy: 0.961000, Test accuracy: 0.952500
Distillation: Epoch : 44, Loss : 0.168153, Accuracy: 0.962000, Test accuracy: 0.951500
Distillation: Epoch : 45, Loss : 0.200954, Accuracy: 0.952000, Test accuracy: 0.952400
Distillation: Epoch : 46, Loss : 0.174683, Accuracy: 0.959000, Test accuracy: 0.953000
Distillation: Epoch : 47, Loss : 0.222509, Accuracy: 0.936000, Test accuracy: 0.955300
Distillation: Epoch : 48, Loss : 0.191216, Accuracy: 0.955000, Test accuracy: 0.954300
Distillation: Epoch : 49, Loss : 0.192256, Accuracy: 0.947000, Test accuracy: 0.954900
Distillation: Epoch : 50, Loss : 0.179726, Accuracy: 0.958000, Test accuracy: 0.955500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9555
Generating confusion matrix for student5
[[ 968.    0.    5.    1.    1.    4.    7.    2.    6.    8.]
 [   0. 1114.    9.    0.    4.    2.    2.    7.    6.    7.]
 [   1.    2.  973.    8.    5.    0.    4.   22.    5.    0.]
 [   1.    2.   12.  974.    1.   12.    1.    6.   14.    9.]
 [   0.    0.    6.    0.  942.    1.    7.    2.    7.   21.]
 [   1.    1.    0.    8.    0.  852.    6.    1.    7.    8.]
 [   6.    4.    4.    0.    3.   10.  928.    0.   10.    1.]
 [   1.    0.    9.    8.    3.    3.    0.  960.    5.   13.]
 [   2.   12.   10.    8.    2.    3.    3.    2.  908.    6.]
 [   0.    0.    4.    3.   21.    5.    0.   26.    6.  936.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.019007, Accuracy: 0.550000, Test accuracy: 0.559700
Distillation: Epoch : 2, Loss : 0.948697, Accuracy: 0.816000, Test accuracy: 0.804500
Distillation: Epoch : 3, Loss : 0.812986, Accuracy: 0.846000, Test accuracy: 0.855200
Distillation: Epoch : 4, Loss : 0.753514, Accuracy: 0.865000, Test accuracy: 0.876700
Distillation: Epoch : 5, Loss : 0.671506, Accuracy: 0.906000, Test accuracy: 0.887600
Distillation: Epoch : 6, Loss : 0.694180, Accuracy: 0.892000, Test accuracy: 0.893200
Distillation: Epoch : 7, Loss : 0.716985, Accuracy: 0.889000, Test accuracy: 0.898700
Distillation: Epoch : 8, Loss : 0.699696, Accuracy: 0.873000, Test accuracy: 0.901700
Distillation: Epoch : 9, Loss : 0.676819, Accuracy: 0.887000, Test accuracy: 0.904300
Distillation: Epoch : 10, Loss : 0.665638, Accuracy: 0.898000, Test accuracy: 0.905700
Distillation: Epoch : 11, Loss : 0.682977, Accuracy: 0.901000, Test accuracy: 0.906300
Distillation: Epoch : 12, Loss : 0.688342, Accuracy: 0.889000, Test accuracy: 0.907600
Distillation: Epoch : 13, Loss : 0.664232, Accuracy: 0.903000, Test accuracy: 0.907500
Distillation: Epoch : 14, Loss : 0.646929, Accuracy: 0.907000, Test accuracy: 0.908700
Distillation: Epoch : 15, Loss : 0.644631, Accuracy: 0.912000, Test accuracy: 0.909100
Distillation: Epoch : 16, Loss : 0.684972, Accuracy: 0.896000, Test accuracy: 0.909700
Distillation: Epoch : 17, Loss : 0.657067, Accuracy: 0.907000, Test accuracy: 0.909800
Distillation: Epoch : 18, Loss : 0.688965, Accuracy: 0.898000, Test accuracy: 0.910300
Distillation: Epoch : 19, Loss : 0.612813, Accuracy: 0.913000, Test accuracy: 0.911800
Distillation: Epoch : 20, Loss : 0.642324, Accuracy: 0.900000, Test accuracy: 0.912200
Distillation: Epoch : 21, Loss : 0.635975, Accuracy: 0.900000, Test accuracy: 0.911500
Distillation: Epoch : 22, Loss : 0.666614, Accuracy: 0.905000, Test accuracy: 0.912600
Distillation: Epoch : 23, Loss : 0.652334, Accuracy: 0.908000, Test accuracy: 0.912900
Distillation: Epoch : 24, Loss : 0.639593, Accuracy: 0.920000, Test accuracy: 0.913100
Distillation: Epoch : 25, Loss : 0.652013, Accuracy: 0.908000, Test accuracy: 0.914000
Distillation: Epoch : 26, Loss : 0.642266, Accuracy: 0.901000, Test accuracy: 0.914700
Distillation: Epoch : 27, Loss : 0.610690, Accuracy: 0.914000, Test accuracy: 0.915400
Distillation: Epoch : 28, Loss : 0.627599, Accuracy: 0.908000, Test accuracy: 0.914800
Distillation: Epoch : 29, Loss : 0.637761, Accuracy: 0.913000, Test accuracy: 0.915900
Distillation: Epoch : 30, Loss : 0.661272, Accuracy: 0.896000, Test accuracy: 0.915900
Distillation: Epoch : 31, Loss : 0.634192, Accuracy: 0.912000, Test accuracy: 0.914500
Distillation: Epoch : 32, Loss : 0.607324, Accuracy: 0.924000, Test accuracy: 0.916100
Distillation: Epoch : 33, Loss : 0.620400, Accuracy: 0.911000, Test accuracy: 0.915700
Distillation: Epoch : 34, Loss : 0.622428, Accuracy: 0.902000, Test accuracy: 0.917900
Distillation: Epoch : 35, Loss : 0.629539, Accuracy: 0.920000, Test accuracy: 0.918000
Distillation: Epoch : 36, Loss : 0.646330, Accuracy: 0.913000, Test accuracy: 0.915200
Distillation: Epoch : 37, Loss : 0.621922, Accuracy: 0.905000, Test accuracy: 0.918000
Distillation: Epoch : 38, Loss : 0.634420, Accuracy: 0.906000, Test accuracy: 0.918200
Distillation: Epoch : 39, Loss : 0.586118, Accuracy: 0.931000, Test accuracy: 0.918100
Distillation: Epoch : 40, Loss : 0.599246, Accuracy: 0.916000, Test accuracy: 0.918100
Distillation: Epoch : 41, Loss : 0.639489, Accuracy: 0.910000, Test accuracy: 0.918000
Distillation: Epoch : 42, Loss : 0.660202, Accuracy: 0.900000, Test accuracy: 0.918100
Distillation: Epoch : 43, Loss : 0.618459, Accuracy: 0.925000, Test accuracy: 0.919400
Distillation: Epoch : 44, Loss : 0.627355, Accuracy: 0.918000, Test accuracy: 0.919400
Distillation: Epoch : 45, Loss : 0.617399, Accuracy: 0.926000, Test accuracy: 0.919000
Distillation: Epoch : 46, Loss : 0.637123, Accuracy: 0.905000, Test accuracy: 0.918700
Distillation: Epoch : 47, Loss : 0.649238, Accuracy: 0.908000, Test accuracy: 0.919500
Distillation: Epoch : 48, Loss : 0.606241, Accuracy: 0.933000, Test accuracy: 0.919700
Distillation: Epoch : 49, Loss : 0.623870, Accuracy: 0.914000, Test accuracy: 0.919200
Distillation: Epoch : 50, Loss : 0.645354, Accuracy: 0.922000, Test accuracy: 0.919200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9192
Generating confusion matrix for student5
[[ 955.    0.    8.    4.    0.    9.    8.    2.   11.   10.]
 [   0. 1113.   12.    2.    4.    3.    4.   16.   12.    8.]
 [   1.    4.  915.   19.    7.    3.    4.   19.    7.    1.]
 [   2.    1.   21.  923.    1.   38.    1.    7.   25.   11.]
 [   0.    0.   10.    2.  913.    9.    8.    9.   10.   31.]
 [   7.    2.    3.   21.    2.  772.   16.    1.   41.    9.]
 [   9.    4.   10.    4.   10.   18.  914.    0.   13.    1.]
 [   2.    1.   13.   13.    3.    8.    2.  942.    9.   25.]
 [   4.   10.   32.   18.    5.   25.    1.    1.  836.    4.]
 [   0.    0.    8.    4.   37.    7.    0.   31.   10.  909.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.544475, Accuracy: 0.753000, Test accuracy: 0.764300
Distillation: Epoch : 2, Loss : 0.950363, Accuracy: 0.852000, Test accuracy: 0.857500
Distillation: Epoch : 3, Loss : 0.895486, Accuracy: 0.867000, Test accuracy: 0.881100
Distillation: Epoch : 4, Loss : 0.913686, Accuracy: 0.879000, Test accuracy: 0.889700
Distillation: Epoch : 5, Loss : 0.888912, Accuracy: 0.881000, Test accuracy: 0.895700
Distillation: Epoch : 6, Loss : 0.838977, Accuracy: 0.897000, Test accuracy: 0.898900
Distillation: Epoch : 7, Loss : 0.876798, Accuracy: 0.886000, Test accuracy: 0.901600
Distillation: Epoch : 8, Loss : 0.866373, Accuracy: 0.887000, Test accuracy: 0.903900
Distillation: Epoch : 9, Loss : 0.846183, Accuracy: 0.891000, Test accuracy: 0.905200
Distillation: Epoch : 10, Loss : 0.854874, Accuracy: 0.888000, Test accuracy: 0.905800
Distillation: Epoch : 11, Loss : 0.850239, Accuracy: 0.875000, Test accuracy: 0.906300
Distillation: Epoch : 12, Loss : 0.828290, Accuracy: 0.903000, Test accuracy: 0.908100
Distillation: Epoch : 13, Loss : 0.830274, Accuracy: 0.911000, Test accuracy: 0.908800
Distillation: Epoch : 14, Loss : 0.857351, Accuracy: 0.891000, Test accuracy: 0.907500
Distillation: Epoch : 15, Loss : 0.839958, Accuracy: 0.905000, Test accuracy: 0.909300
Distillation: Epoch : 16, Loss : 0.817162, Accuracy: 0.902000, Test accuracy: 0.909000
Distillation: Epoch : 17, Loss : 0.832594, Accuracy: 0.897000, Test accuracy: 0.910300
Distillation: Epoch : 18, Loss : 0.822953, Accuracy: 0.903000, Test accuracy: 0.911000
Distillation: Epoch : 19, Loss : 0.853938, Accuracy: 0.892000, Test accuracy: 0.911600
Distillation: Epoch : 20, Loss : 0.840438, Accuracy: 0.894000, Test accuracy: 0.911800
Distillation: Epoch : 21, Loss : 0.828212, Accuracy: 0.905000, Test accuracy: 0.912400
Distillation: Epoch : 22, Loss : 0.822736, Accuracy: 0.918000, Test accuracy: 0.911400
Distillation: Epoch : 23, Loss : 0.802520, Accuracy: 0.915000, Test accuracy: 0.913000
Distillation: Epoch : 24, Loss : 0.816998, Accuracy: 0.913000, Test accuracy: 0.910800
Distillation: Epoch : 25, Loss : 0.805961, Accuracy: 0.914000, Test accuracy: 0.913600
Distillation: Epoch : 26, Loss : 0.788603, Accuracy: 0.911000, Test accuracy: 0.912400
Distillation: Epoch : 27, Loss : 0.817290, Accuracy: 0.912000, Test accuracy: 0.911700
Distillation: Epoch : 28, Loss : 0.797826, Accuracy: 0.911000, Test accuracy: 0.914000
Distillation: Epoch : 29, Loss : 0.829394, Accuracy: 0.902000, Test accuracy: 0.914100
Distillation: Epoch : 30, Loss : 0.807992, Accuracy: 0.915000, Test accuracy: 0.915000
Distillation: Epoch : 31, Loss : 0.808397, Accuracy: 0.910000, Test accuracy: 0.913600
Distillation: Epoch : 32, Loss : 0.781679, Accuracy: 0.920000, Test accuracy: 0.913700
Distillation: Epoch : 33, Loss : 0.840732, Accuracy: 0.895000, Test accuracy: 0.915300
Distillation: Epoch : 34, Loss : 0.774763, Accuracy: 0.907000, Test accuracy: 0.913700
Distillation: Epoch : 35, Loss : 0.758761, Accuracy: 0.921000, Test accuracy: 0.914500
Distillation: Epoch : 36, Loss : 0.870617, Accuracy: 0.896000, Test accuracy: 0.914400
Distillation: Epoch : 37, Loss : 0.822176, Accuracy: 0.908000, Test accuracy: 0.914100
Distillation: Epoch : 38, Loss : 0.790496, Accuracy: 0.915000, Test accuracy: 0.914500
Distillation: Epoch : 39, Loss : 0.799145, Accuracy: 0.906000, Test accuracy: 0.914800
Distillation: Epoch : 40, Loss : 0.761020, Accuracy: 0.931000, Test accuracy: 0.915400
Distillation: Epoch : 41, Loss : 0.823568, Accuracy: 0.909000, Test accuracy: 0.914400
Distillation: Epoch : 42, Loss : 0.838958, Accuracy: 0.914000, Test accuracy: 0.915400
Distillation: Epoch : 43, Loss : 0.818563, Accuracy: 0.911000, Test accuracy: 0.916700
Distillation: Epoch : 44, Loss : 0.804582, Accuracy: 0.909000, Test accuracy: 0.914800
Distillation: Epoch : 45, Loss : 0.800486, Accuracy: 0.920000, Test accuracy: 0.916500
Distillation: Epoch : 46, Loss : 0.783573, Accuracy: 0.911000, Test accuracy: 0.916100
Distillation: Epoch : 47, Loss : 0.795729, Accuracy: 0.913000, Test accuracy: 0.916800
Distillation: Epoch : 48, Loss : 0.803514, Accuracy: 0.911000, Test accuracy: 0.916100
Distillation: Epoch : 49, Loss : 0.869207, Accuracy: 0.903000, Test accuracy: 0.916800
Distillation: Epoch : 50, Loss : 0.769129, Accuracy: 0.922000, Test accuracy: 0.917300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9173
Generating confusion matrix for student5
[[ 959.    0.   10.    4.    0.    7.    8.    1.   11.    9.]
 [   0. 1110.   12.    2.    4.    3.    4.   24.   13.    7.]
 [   1.    2.  910.   20.    4.    3.    5.   15.    9.    0.]
 [   1.    4.   21.  924.    2.   41.    0.    5.   31.   13.]
 [   0.    0.   14.    2.  925.   10.    9.   10.   13.   41.]
 [   6.    4.    2.   22.    2.  771.   16.    1.   41.   12.]
 [   9.    4.   11.    3.    8.   18.  913.    0.   14.    1.]
 [   1.    0.   12.   12.    1.    7.    2.  939.    7.   22.]
 [   3.   11.   32.   16.    4.   25.    1.    0.  824.    6.]
 [   0.    0.    8.    5.   32.    7.    0.   33.   11.  898.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.962561, Accuracy: 0.731000, Test accuracy: 0.721200
Distillation: Epoch : 2, Loss : 1.172721, Accuracy: 0.836000, Test accuracy: 0.832000
Distillation: Epoch : 3, Loss : 1.104590, Accuracy: 0.860000, Test accuracy: 0.871500
Distillation: Epoch : 4, Loss : 1.069425, Accuracy: 0.870000, Test accuracy: 0.887100
Distillation: Epoch : 5, Loss : 0.989810, Accuracy: 0.901000, Test accuracy: 0.896600
Distillation: Epoch : 6, Loss : 1.028367, Accuracy: 0.888000, Test accuracy: 0.903700
Distillation: Epoch : 7, Loss : 0.955644, Accuracy: 0.926000, Test accuracy: 0.910300
Distillation: Epoch : 8, Loss : 0.989696, Accuracy: 0.900000, Test accuracy: 0.913500
Distillation: Epoch : 9, Loss : 0.985515, Accuracy: 0.904000, Test accuracy: 0.915400
Distillation: Epoch : 10, Loss : 0.978487, Accuracy: 0.912000, Test accuracy: 0.919100
Distillation: Epoch : 11, Loss : 0.941547, Accuracy: 0.927000, Test accuracy: 0.922300
Distillation: Epoch : 12, Loss : 0.941190, Accuracy: 0.926000, Test accuracy: 0.924400
Distillation: Epoch : 13, Loss : 0.982159, Accuracy: 0.918000, Test accuracy: 0.927800
Distillation: Epoch : 14, Loss : 0.941878, Accuracy: 0.919000, Test accuracy: 0.930200
Distillation: Epoch : 15, Loss : 0.946640, Accuracy: 0.925000, Test accuracy: 0.933100
Distillation: Epoch : 16, Loss : 0.957267, Accuracy: 0.925000, Test accuracy: 0.935600
Distillation: Epoch : 17, Loss : 0.939100, Accuracy: 0.921000, Test accuracy: 0.937600
Distillation: Epoch : 18, Loss : 0.922757, Accuracy: 0.931000, Test accuracy: 0.938400
Distillation: Epoch : 19, Loss : 0.925679, Accuracy: 0.926000, Test accuracy: 0.940700
Distillation: Epoch : 20, Loss : 0.930301, Accuracy: 0.935000, Test accuracy: 0.942700
Distillation: Epoch : 21, Loss : 0.912717, Accuracy: 0.945000, Test accuracy: 0.943200
Distillation: Epoch : 22, Loss : 0.919973, Accuracy: 0.928000, Test accuracy: 0.944400
Distillation: Epoch : 23, Loss : 0.879021, Accuracy: 0.940000, Test accuracy: 0.946300
Distillation: Epoch : 24, Loss : 0.917309, Accuracy: 0.934000, Test accuracy: 0.946700
Distillation: Epoch : 25, Loss : 0.882863, Accuracy: 0.948000, Test accuracy: 0.946900
Distillation: Epoch : 26, Loss : 0.872377, Accuracy: 0.942000, Test accuracy: 0.948200
Distillation: Epoch : 27, Loss : 0.900287, Accuracy: 0.943000, Test accuracy: 0.949100
Distillation: Epoch : 28, Loss : 0.913999, Accuracy: 0.955000, Test accuracy: 0.949100
Distillation: Epoch : 29, Loss : 0.904529, Accuracy: 0.951000, Test accuracy: 0.949900
Distillation: Epoch : 30, Loss : 0.865665, Accuracy: 0.944000, Test accuracy: 0.950800
Distillation: Epoch : 31, Loss : 0.921290, Accuracy: 0.938000, Test accuracy: 0.951700
Distillation: Epoch : 32, Loss : 0.896980, Accuracy: 0.944000, Test accuracy: 0.951100
Distillation: Epoch : 33, Loss : 0.882874, Accuracy: 0.943000, Test accuracy: 0.952600
Distillation: Epoch : 34, Loss : 0.908147, Accuracy: 0.948000, Test accuracy: 0.952800
Distillation: Epoch : 35, Loss : 0.901364, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 36, Loss : 0.875008, Accuracy: 0.960000, Test accuracy: 0.953400
Distillation: Epoch : 37, Loss : 0.887966, Accuracy: 0.947000, Test accuracy: 0.953500
Distillation: Epoch : 38, Loss : 0.902044, Accuracy: 0.937000, Test accuracy: 0.954600
Distillation: Epoch : 39, Loss : 0.848401, Accuracy: 0.962000, Test accuracy: 0.954600
Distillation: Epoch : 40, Loss : 0.883915, Accuracy: 0.947000, Test accuracy: 0.955400
Distillation: Epoch : 41, Loss : 0.886993, Accuracy: 0.950000, Test accuracy: 0.954600
Distillation: Epoch : 42, Loss : 0.845194, Accuracy: 0.967000, Test accuracy: 0.955600
Distillation: Epoch : 43, Loss : 0.886580, Accuracy: 0.946000, Test accuracy: 0.956600
Distillation: Epoch : 44, Loss : 0.898743, Accuracy: 0.955000, Test accuracy: 0.956300
Distillation: Epoch : 45, Loss : 0.861904, Accuracy: 0.959000, Test accuracy: 0.956700
Distillation: Epoch : 46, Loss : 0.860076, Accuracy: 0.949000, Test accuracy: 0.957700
Distillation: Epoch : 47, Loss : 0.859689, Accuracy: 0.947000, Test accuracy: 0.958400
Distillation: Epoch : 48, Loss : 0.873067, Accuracy: 0.956000, Test accuracy: 0.958300
Distillation: Epoch : 49, Loss : 0.864496, Accuracy: 0.956000, Test accuracy: 0.959000
Distillation: Epoch : 50, Loss : 0.849302, Accuracy: 0.954000, Test accuracy: 0.959700
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9597
Generating confusion matrix for student5
[[ 967.    0.    3.    1.    0.    2.    6.    0.    9.    5.]
 [   0. 1120.   15.    0.    3.    0.    3.   13.    7.    8.]
 [   0.    3.  969.    4.    6.    0.    1.   12.    7.    2.]
 [   0.    2.   10.  982.    0.   18.    0.    2.   11.    3.]
 [   2.    2.    5.    2.  937.    0.    3.    4.    8.   25.]
 [   1.    0.    1.    5.    0.  855.    6.    1.   11.    6.]
 [   4.    3.    3.    2.    4.    9.  936.    0.    7.    1.]
 [   3.    0.   13.   11.    3.    0.    0.  981.    4.    4.]
 [   2.    5.   11.    2.    2.    5.    3.    2.  900.    5.]
 [   1.    0.    2.    1.   27.    3.    0.   13.   10.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.052365, Accuracy: 0.645000, Test accuracy: 0.664400
Distillation: Epoch : 2, Loss : 1.386423, Accuracy: 0.799000, Test accuracy: 0.819400
Distillation: Epoch : 3, Loss : 1.261537, Accuracy: 0.845000, Test accuracy: 0.865400
Distillation: Epoch : 4, Loss : 1.218645, Accuracy: 0.864000, Test accuracy: 0.880000
Distillation: Epoch : 5, Loss : 1.192607, Accuracy: 0.885000, Test accuracy: 0.889600
Distillation: Epoch : 6, Loss : 1.185425, Accuracy: 0.897000, Test accuracy: 0.896900
Distillation: Epoch : 7, Loss : 1.144868, Accuracy: 0.899000, Test accuracy: 0.900200
Distillation: Epoch : 8, Loss : 1.189900, Accuracy: 0.884000, Test accuracy: 0.904500
Distillation: Epoch : 9, Loss : 1.155253, Accuracy: 0.898000, Test accuracy: 0.908400
Distillation: Epoch : 10, Loss : 1.149918, Accuracy: 0.910000, Test accuracy: 0.911300
Distillation: Epoch : 11, Loss : 1.162905, Accuracy: 0.901000, Test accuracy: 0.914700
Distillation: Epoch : 12, Loss : 1.160336, Accuracy: 0.903000, Test accuracy: 0.916400
Distillation: Epoch : 13, Loss : 1.120523, Accuracy: 0.931000, Test accuracy: 0.919000
Distillation: Epoch : 14, Loss : 1.144106, Accuracy: 0.911000, Test accuracy: 0.921000
Distillation: Epoch : 15, Loss : 1.180436, Accuracy: 0.891000, Test accuracy: 0.923100
Distillation: Epoch : 16, Loss : 1.146709, Accuracy: 0.903000, Test accuracy: 0.927300
Distillation: Epoch : 17, Loss : 1.107245, Accuracy: 0.936000, Test accuracy: 0.927500
Distillation: Epoch : 18, Loss : 1.119639, Accuracy: 0.910000, Test accuracy: 0.930700
Distillation: Epoch : 19, Loss : 1.112897, Accuracy: 0.935000, Test accuracy: 0.932300
Distillation: Epoch : 20, Loss : 1.097564, Accuracy: 0.918000, Test accuracy: 0.934100
Distillation: Epoch : 21, Loss : 1.108315, Accuracy: 0.915000, Test accuracy: 0.936000
Distillation: Epoch : 22, Loss : 1.087241, Accuracy: 0.928000, Test accuracy: 0.937100
Distillation: Epoch : 23, Loss : 1.084374, Accuracy: 0.926000, Test accuracy: 0.940100
Distillation: Epoch : 24, Loss : 1.092297, Accuracy: 0.929000, Test accuracy: 0.940500
Distillation: Epoch : 25, Loss : 1.088645, Accuracy: 0.936000, Test accuracy: 0.941900
Distillation: Epoch : 26, Loss : 1.072439, Accuracy: 0.944000, Test accuracy: 0.943400
Distillation: Epoch : 27, Loss : 1.085279, Accuracy: 0.939000, Test accuracy: 0.944600
Distillation: Epoch : 28, Loss : 1.067998, Accuracy: 0.941000, Test accuracy: 0.946100
Distillation: Epoch : 29, Loss : 1.075405, Accuracy: 0.948000, Test accuracy: 0.946300
Distillation: Epoch : 30, Loss : 1.042285, Accuracy: 0.956000, Test accuracy: 0.947500
Distillation: Epoch : 31, Loss : 1.060611, Accuracy: 0.955000, Test accuracy: 0.947600
Distillation: Epoch : 32, Loss : 1.056368, Accuracy: 0.945000, Test accuracy: 0.949300
Distillation: Epoch : 33, Loss : 1.049792, Accuracy: 0.944000, Test accuracy: 0.949300
Distillation: Epoch : 34, Loss : 1.054646, Accuracy: 0.960000, Test accuracy: 0.951300
Distillation: Epoch : 35, Loss : 1.061996, Accuracy: 0.946000, Test accuracy: 0.951800
Distillation: Epoch : 36, Loss : 1.075182, Accuracy: 0.947000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 1.049723, Accuracy: 0.960000, Test accuracy: 0.952900
Distillation: Epoch : 38, Loss : 1.062054, Accuracy: 0.941000, Test accuracy: 0.953800
Distillation: Epoch : 39, Loss : 1.029452, Accuracy: 0.963000, Test accuracy: 0.954500
Distillation: Epoch : 40, Loss : 1.041371, Accuracy: 0.957000, Test accuracy: 0.954700
Distillation: Epoch : 41, Loss : 1.039539, Accuracy: 0.940000, Test accuracy: 0.954200
Distillation: Epoch : 42, Loss : 1.016815, Accuracy: 0.957000, Test accuracy: 0.955300
Distillation: Epoch : 43, Loss : 1.080395, Accuracy: 0.933000, Test accuracy: 0.955900
Distillation: Epoch : 44, Loss : 1.062129, Accuracy: 0.948000, Test accuracy: 0.956500
Distillation: Epoch : 45, Loss : 1.023956, Accuracy: 0.951000, Test accuracy: 0.955800
Distillation: Epoch : 46, Loss : 1.038802, Accuracy: 0.962000, Test accuracy: 0.956300
Distillation: Epoch : 47, Loss : 1.060119, Accuracy: 0.960000, Test accuracy: 0.956200
Distillation: Epoch : 48, Loss : 1.042290, Accuracy: 0.964000, Test accuracy: 0.956600
Distillation: Epoch : 49, Loss : 1.030816, Accuracy: 0.956000, Test accuracy: 0.957000
Distillation: Epoch : 50, Loss : 1.041803, Accuracy: 0.967000, Test accuracy: 0.956900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9569
Generating confusion matrix for student5
[[ 965.    0.    3.    0.    0.    2.    6.    2.    6.    5.]
 [   1. 1102.    5.    0.    0.    0.    3.   11.    3.    5.]
 [   0.    2.  984.    7.    3.    1.    2.   13.   12.    0.]
 [   1.    2.   11.  989.    0.   16.    1.    5.   27.    9.]
 [   0.    0.    6.    0.  949.    0.    2.    3.    3.   10.]
 [   1.    1.    0.    2.    0.  849.    7.    1.   19.   11.]
 [   6.    5.    4.    0.    8.    8.  936.    0.   10.    0.]
 [   3.    1.    5.   10.    4.    5.    0.  963.    5.   14.]
 [   1.   22.   14.    2.    2.    7.    1.    1.  881.    4.]
 [   2.    0.    0.    0.   16.    4.    0.   29.    8.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.991372, Accuracy: 0.690000, Test accuracy: 0.700000
Distillation: Epoch : 2, Loss : 1.426373, Accuracy: 0.845000, Test accuracy: 0.849600
Distillation: Epoch : 3, Loss : 1.371907, Accuracy: 0.871000, Test accuracy: 0.878200
Distillation: Epoch : 4, Loss : 1.366106, Accuracy: 0.881000, Test accuracy: 0.894800
Distillation: Epoch : 5, Loss : 1.343481, Accuracy: 0.890000, Test accuracy: 0.906100
Distillation: Epoch : 6, Loss : 1.329496, Accuracy: 0.892000, Test accuracy: 0.914500
Distillation: Epoch : 7, Loss : 1.278640, Accuracy: 0.905000, Test accuracy: 0.918500
Distillation: Epoch : 8, Loss : 1.257497, Accuracy: 0.925000, Test accuracy: 0.925000
Distillation: Epoch : 9, Loss : 1.261884, Accuracy: 0.937000, Test accuracy: 0.928100
Distillation: Epoch : 10, Loss : 1.268484, Accuracy: 0.921000, Test accuracy: 0.930800
Distillation: Epoch : 11, Loss : 1.258940, Accuracy: 0.925000, Test accuracy: 0.933500
Distillation: Epoch : 12, Loss : 1.244714, Accuracy: 0.923000, Test accuracy: 0.935600
Distillation: Epoch : 13, Loss : 1.241427, Accuracy: 0.930000, Test accuracy: 0.938700
Distillation: Epoch : 14, Loss : 1.243006, Accuracy: 0.939000, Test accuracy: 0.941000
Distillation: Epoch : 15, Loss : 1.242324, Accuracy: 0.946000, Test accuracy: 0.943300
Distillation: Epoch : 16, Loss : 1.220414, Accuracy: 0.946000, Test accuracy: 0.943300
Distillation: Epoch : 17, Loss : 1.227453, Accuracy: 0.943000, Test accuracy: 0.944900
Distillation: Epoch : 18, Loss : 1.219534, Accuracy: 0.937000, Test accuracy: 0.945900
Distillation: Epoch : 19, Loss : 1.224217, Accuracy: 0.941000, Test accuracy: 0.946600
Distillation: Epoch : 20, Loss : 1.219718, Accuracy: 0.942000, Test accuracy: 0.947900
Distillation: Epoch : 21, Loss : 1.219742, Accuracy: 0.945000, Test accuracy: 0.948400
Distillation: Epoch : 22, Loss : 1.211729, Accuracy: 0.947000, Test accuracy: 0.948700
Distillation: Epoch : 23, Loss : 1.208078, Accuracy: 0.939000, Test accuracy: 0.949200
Distillation: Epoch : 24, Loss : 1.200164, Accuracy: 0.947000, Test accuracy: 0.951200
Distillation: Epoch : 25, Loss : 1.206581, Accuracy: 0.946000, Test accuracy: 0.950900
Distillation: Epoch : 26, Loss : 1.225210, Accuracy: 0.942000, Test accuracy: 0.951800
Distillation: Epoch : 27, Loss : 1.203055, Accuracy: 0.939000, Test accuracy: 0.951800
Distillation: Epoch : 28, Loss : 1.201813, Accuracy: 0.955000, Test accuracy: 0.953300
Distillation: Epoch : 29, Loss : 1.207094, Accuracy: 0.947000, Test accuracy: 0.953400
Distillation: Epoch : 30, Loss : 1.209189, Accuracy: 0.949000, Test accuracy: 0.954200
Distillation: Epoch : 31, Loss : 1.213173, Accuracy: 0.957000, Test accuracy: 0.954000
Distillation: Epoch : 32, Loss : 1.209410, Accuracy: 0.940000, Test accuracy: 0.954500
Distillation: Epoch : 33, Loss : 1.198121, Accuracy: 0.962000, Test accuracy: 0.955700
Distillation: Epoch : 34, Loss : 1.205244, Accuracy: 0.948000, Test accuracy: 0.955600
Distillation: Epoch : 35, Loss : 1.221236, Accuracy: 0.947000, Test accuracy: 0.956700
Distillation: Epoch : 36, Loss : 1.209473, Accuracy: 0.940000, Test accuracy: 0.955600
Distillation: Epoch : 37, Loss : 1.206190, Accuracy: 0.956000, Test accuracy: 0.956300
Distillation: Epoch : 38, Loss : 1.213573, Accuracy: 0.958000, Test accuracy: 0.956900
Distillation: Epoch : 39, Loss : 1.213229, Accuracy: 0.962000, Test accuracy: 0.956600
Distillation: Epoch : 40, Loss : 1.216447, Accuracy: 0.959000, Test accuracy: 0.956500
Distillation: Epoch : 41, Loss : 1.164461, Accuracy: 0.951000, Test accuracy: 0.958100
Distillation: Epoch : 42, Loss : 1.212049, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 43, Loss : 1.197533, Accuracy: 0.943000, Test accuracy: 0.958300
Distillation: Epoch : 44, Loss : 1.194640, Accuracy: 0.958000, Test accuracy: 0.957900
Distillation: Epoch : 45, Loss : 1.210646, Accuracy: 0.955000, Test accuracy: 0.957900
Distillation: Epoch : 46, Loss : 1.216837, Accuracy: 0.957000, Test accuracy: 0.958300
Distillation: Epoch : 47, Loss : 1.177479, Accuracy: 0.958000, Test accuracy: 0.958400
Distillation: Epoch : 48, Loss : 1.201036, Accuracy: 0.943000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 1.193095, Accuracy: 0.962000, Test accuracy: 0.959300
Distillation: Epoch : 50, Loss : 1.193950, Accuracy: 0.947000, Test accuracy: 0.959300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9593
Generating confusion matrix for student5
[[ 973.    0.    3.    0.    1.    1.    9.    4.    6.    6.]
 [   1. 1116.    8.    1.    3.    1.    3.   13.    6.    8.]
 [   1.    6.  973.    3.    1.    1.    1.   11.   10.    2.]
 [   0.    3.    9.  985.    0.   21.    1.    2.    9.   10.]
 [   1.    1.   10.    0.  949.    0.    3.    1.    6.   21.]
 [   0.    0.    1.    5.    0.  850.    3.    0.    6.    2.]
 [   3.    2.    1.    0.    3.    6.  935.    0.   12.    0.]
 [   1.    1.   15.    8.    2.    2.    0.  975.   12.   16.]
 [   0.    6.   11.    6.    2.    4.    3.    3.  896.    3.]
 [   0.    0.    1.    2.   21.    6.    0.   19.   11.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.257088, Accuracy: 0.268000, Test accuracy: 0.270700
Distillation: Epoch : 2, Loss : 1.977701, Accuracy: 0.759000, Test accuracy: 0.766300
Distillation: Epoch : 3, Loss : 1.587047, Accuracy: 0.836000, Test accuracy: 0.841500
Distillation: Epoch : 4, Loss : 1.489815, Accuracy: 0.870000, Test accuracy: 0.872200
Distillation: Epoch : 5, Loss : 1.524598, Accuracy: 0.869000, Test accuracy: 0.887200
Distillation: Epoch : 6, Loss : 1.454598, Accuracy: 0.909000, Test accuracy: 0.897900
Distillation: Epoch : 7, Loss : 1.422648, Accuracy: 0.885000, Test accuracy: 0.906600
Distillation: Epoch : 8, Loss : 1.426800, Accuracy: 0.900000, Test accuracy: 0.912600
Distillation: Epoch : 9, Loss : 1.427898, Accuracy: 0.905000, Test accuracy: 0.917300
Distillation: Epoch : 10, Loss : 1.408704, Accuracy: 0.916000, Test accuracy: 0.921300
Distillation: Epoch : 11, Loss : 1.404703, Accuracy: 0.930000, Test accuracy: 0.924400
Distillation: Epoch : 12, Loss : 1.416576, Accuracy: 0.926000, Test accuracy: 0.927700
Distillation: Epoch : 13, Loss : 1.379284, Accuracy: 0.925000, Test accuracy: 0.928500
Distillation: Epoch : 14, Loss : 1.419359, Accuracy: 0.927000, Test accuracy: 0.930500
Distillation: Epoch : 15, Loss : 1.391361, Accuracy: 0.925000, Test accuracy: 0.932900
Distillation: Epoch : 16, Loss : 1.400064, Accuracy: 0.937000, Test accuracy: 0.933600
Distillation: Epoch : 17, Loss : 1.414512, Accuracy: 0.917000, Test accuracy: 0.935800
Distillation: Epoch : 18, Loss : 1.411816, Accuracy: 0.927000, Test accuracy: 0.935400
Distillation: Epoch : 19, Loss : 1.412231, Accuracy: 0.916000, Test accuracy: 0.936900
Distillation: Epoch : 20, Loss : 1.354245, Accuracy: 0.949000, Test accuracy: 0.937500
Distillation: Epoch : 21, Loss : 1.362613, Accuracy: 0.934000, Test accuracy: 0.938600
Distillation: Epoch : 22, Loss : 1.380830, Accuracy: 0.940000, Test accuracy: 0.939200
Distillation: Epoch : 23, Loss : 1.395392, Accuracy: 0.933000, Test accuracy: 0.940800
Distillation: Epoch : 24, Loss : 1.377531, Accuracy: 0.921000, Test accuracy: 0.940600
Distillation: Epoch : 25, Loss : 1.388125, Accuracy: 0.936000, Test accuracy: 0.942700
Distillation: Epoch : 26, Loss : 1.374424, Accuracy: 0.936000, Test accuracy: 0.943800
Distillation: Epoch : 27, Loss : 1.380660, Accuracy: 0.943000, Test accuracy: 0.943700
Distillation: Epoch : 28, Loss : 1.346403, Accuracy: 0.955000, Test accuracy: 0.944600
Distillation: Epoch : 29, Loss : 1.392208, Accuracy: 0.940000, Test accuracy: 0.945700
Distillation: Epoch : 30, Loss : 1.361486, Accuracy: 0.954000, Test accuracy: 0.945800
Distillation: Epoch : 31, Loss : 1.369117, Accuracy: 0.949000, Test accuracy: 0.947100
Distillation: Epoch : 32, Loss : 1.369102, Accuracy: 0.951000, Test accuracy: 0.948500
Distillation: Epoch : 33, Loss : 1.358875, Accuracy: 0.945000, Test accuracy: 0.948500
Distillation: Epoch : 34, Loss : 1.352198, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 35, Loss : 1.351370, Accuracy: 0.950000, Test accuracy: 0.949600
Distillation: Epoch : 36, Loss : 1.373196, Accuracy: 0.940000, Test accuracy: 0.950300
Distillation: Epoch : 37, Loss : 1.365889, Accuracy: 0.951000, Test accuracy: 0.951600
Distillation: Epoch : 38, Loss : 1.365627, Accuracy: 0.944000, Test accuracy: 0.951500
Distillation: Epoch : 39, Loss : 1.344586, Accuracy: 0.940000, Test accuracy: 0.951500
Distillation: Epoch : 40, Loss : 1.355506, Accuracy: 0.943000, Test accuracy: 0.952500
Distillation: Epoch : 41, Loss : 1.363080, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 42, Loss : 1.375348, Accuracy: 0.933000, Test accuracy: 0.952900
Distillation: Epoch : 43, Loss : 1.351537, Accuracy: 0.951000, Test accuracy: 0.953800
Distillation: Epoch : 44, Loss : 1.362018, Accuracy: 0.949000, Test accuracy: 0.954000
Distillation: Epoch : 45, Loss : 1.351238, Accuracy: 0.959000, Test accuracy: 0.954200
Distillation: Epoch : 46, Loss : 1.366817, Accuracy: 0.947000, Test accuracy: 0.954200
Distillation: Epoch : 47, Loss : 1.354517, Accuracy: 0.960000, Test accuracy: 0.954400
Distillation: Epoch : 48, Loss : 1.330969, Accuracy: 0.951000, Test accuracy: 0.954800
Distillation: Epoch : 49, Loss : 1.357574, Accuracy: 0.957000, Test accuracy: 0.955800
Distillation: Epoch : 50, Loss : 1.335705, Accuracy: 0.964000, Test accuracy: 0.955200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9552
Generating confusion matrix for student5
[[ 964.    0.    5.    0.    0.    1.    9.    3.    8.    9.]
 [   0. 1121.    9.    1.    2.    0.    3.   15.    6.    7.]
 [   0.    3.  960.    7.    2.    0.    1.   16.   11.    1.]
 [   0.    1.   18.  977.    0.   16.    0.    7.    8.   15.]
 [   1.    1.   11.    3.  949.    2.    5.    4.    7.   24.]
 [   1.    0.    1.    4.    0.  856.    6.    0.    5.    8.]
 [   7.    5.    1.    0.    5.    7.  934.    0.   10.    0.]
 [   2.    0.   14.    8.    1.    2.    0.  955.    5.   10.]
 [   4.    4.   11.    7.    4.    3.    0.    4.  907.    6.]
 [   1.    0.    2.    3.   19.    5.    0.   24.    7.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.826518, Accuracy: 0.764000, Test accuracy: 0.786500
Distillation: Epoch : 2, Loss : 1.645611, Accuracy: 0.852000, Test accuracy: 0.860500
Distillation: Epoch : 3, Loss : 1.637931, Accuracy: 0.850000, Test accuracy: 0.875900
Distillation: Epoch : 4, Loss : 1.603670, Accuracy: 0.873000, Test accuracy: 0.884300
Distillation: Epoch : 5, Loss : 1.594476, Accuracy: 0.876000, Test accuracy: 0.885400
Distillation: Epoch : 6, Loss : 1.614027, Accuracy: 0.870000, Test accuracy: 0.889500
Distillation: Epoch : 7, Loss : 1.606183, Accuracy: 0.878000, Test accuracy: 0.891900
Distillation: Epoch : 8, Loss : 1.578727, Accuracy: 0.877000, Test accuracy: 0.894000
Distillation: Epoch : 9, Loss : 1.597346, Accuracy: 0.877000, Test accuracy: 0.895600
Distillation: Epoch : 10, Loss : 1.569958, Accuracy: 0.890000, Test accuracy: 0.897100
Distillation: Epoch : 11, Loss : 1.586958, Accuracy: 0.876000, Test accuracy: 0.897300
Distillation: Epoch : 12, Loss : 1.577508, Accuracy: 0.890000, Test accuracy: 0.899200
Distillation: Epoch : 13, Loss : 1.560591, Accuracy: 0.904000, Test accuracy: 0.898700
Distillation: Epoch : 14, Loss : 1.585499, Accuracy: 0.888000, Test accuracy: 0.900400
Distillation: Epoch : 15, Loss : 1.568512, Accuracy: 0.902000, Test accuracy: 0.900800
Distillation: Epoch : 16, Loss : 1.569624, Accuracy: 0.890000, Test accuracy: 0.902100
Distillation: Epoch : 17, Loss : 1.584621, Accuracy: 0.897000, Test accuracy: 0.901200
Distillation: Epoch : 18, Loss : 1.569654, Accuracy: 0.895000, Test accuracy: 0.902100
Distillation: Epoch : 19, Loss : 1.576955, Accuracy: 0.890000, Test accuracy: 0.901100
Distillation: Epoch : 20, Loss : 1.581462, Accuracy: 0.893000, Test accuracy: 0.903800
Distillation: Epoch : 21, Loss : 1.565430, Accuracy: 0.900000, Test accuracy: 0.902700
Distillation: Epoch : 22, Loss : 1.576724, Accuracy: 0.897000, Test accuracy: 0.903400
Distillation: Epoch : 23, Loss : 1.574339, Accuracy: 0.887000, Test accuracy: 0.902600
Distillation: Epoch : 24, Loss : 1.541484, Accuracy: 0.912000, Test accuracy: 0.902600
Distillation: Epoch : 25, Loss : 1.590874, Accuracy: 0.878000, Test accuracy: 0.904300
Distillation: Epoch : 26, Loss : 1.570498, Accuracy: 0.898000, Test accuracy: 0.900900
Distillation: Epoch : 27, Loss : 1.563731, Accuracy: 0.899000, Test accuracy: 0.902300
Distillation: Epoch : 28, Loss : 1.561106, Accuracy: 0.901000, Test accuracy: 0.900600
Distillation: Epoch : 29, Loss : 1.588527, Accuracy: 0.896000, Test accuracy: 0.903000
Distillation: Epoch : 30, Loss : 1.552653, Accuracy: 0.898000, Test accuracy: 0.903000
Distillation: Epoch : 31, Loss : 1.585675, Accuracy: 0.889000, Test accuracy: 0.903100
Distillation: Epoch : 32, Loss : 1.562252, Accuracy: 0.887000, Test accuracy: 0.903200
Distillation: Epoch : 33, Loss : 1.577145, Accuracy: 0.902000, Test accuracy: 0.904000
Distillation: Epoch : 34, Loss : 1.569819, Accuracy: 0.897000, Test accuracy: 0.902700
Distillation: Epoch : 35, Loss : 1.564365, Accuracy: 0.893000, Test accuracy: 0.904000
Distillation: Epoch : 36, Loss : 1.586823, Accuracy: 0.895000, Test accuracy: 0.903400
Distillation: Epoch : 37, Loss : 1.558145, Accuracy: 0.898000, Test accuracy: 0.904200
Distillation: Epoch : 38, Loss : 1.592079, Accuracy: 0.877000, Test accuracy: 0.903200
Distillation: Epoch : 39, Loss : 1.586507, Accuracy: 0.880000, Test accuracy: 0.903600
Distillation: Epoch : 40, Loss : 1.557035, Accuracy: 0.908000, Test accuracy: 0.904800
Distillation: Epoch : 41, Loss : 1.554174, Accuracy: 0.906000, Test accuracy: 0.905700
Distillation: Epoch : 42, Loss : 1.547495, Accuracy: 0.915000, Test accuracy: 0.903400
Distillation: Epoch : 43, Loss : 1.591979, Accuracy: 0.884000, Test accuracy: 0.904600
Distillation: Epoch : 44, Loss : 1.572787, Accuracy: 0.898000, Test accuracy: 0.905000
Distillation: Epoch : 45, Loss : 1.567833, Accuracy: 0.900000, Test accuracy: 0.906300
Distillation: Epoch : 46, Loss : 1.594030, Accuracy: 0.890000, Test accuracy: 0.905300
Distillation: Epoch : 47, Loss : 1.565758, Accuracy: 0.906000, Test accuracy: 0.903200
Distillation: Epoch : 48, Loss : 1.574370, Accuracy: 0.898000, Test accuracy: 0.904600
Distillation: Epoch : 49, Loss : 1.581812, Accuracy: 0.886000, Test accuracy: 0.906300
Distillation: Epoch : 50, Loss : 1.559999, Accuracy: 0.895000, Test accuracy: 0.904400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9044
Generating confusion matrix for student5
[[ 952.    0.   10.    4.    2.    8.    9.    2.   10.   14.]
 [   0. 1109.   22.    4.    6.    4.    4.   29.   14.    7.]
 [   1.    2.  889.   18.    5.    2.    7.   14.    7.    0.]
 [   2.    6.   29.  925.    1.   45.    1.    8.   50.   19.]
 [   2.    0.   20.    3.  916.    9.   10.   14.   19.   55.]
 [   9.    6.    3.   27.    4.  773.   21.    3.   48.   11.]
 [  10.    4.   16.    3.   10.   20.  905.    1.   18.    1.]
 [   2.    0.   13.   11.    1.    7.    1.  916.    8.   28.]
 [   2.    8.   26.   11.    6.   18.    0.    0.  789.    4.]
 [   0.    0.    4.    4.   31.    6.    0.   41.   11.  870.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.243780, Accuracy: 0.436000, Test accuracy: 0.451600
Distillation: Epoch : 2, Loss : 1.968108, Accuracy: 0.753000, Test accuracy: 0.763900
Distillation: Epoch : 3, Loss : 1.899835, Accuracy: 0.804000, Test accuracy: 0.816800
Distillation: Epoch : 4, Loss : 1.863391, Accuracy: 0.845000, Test accuracy: 0.840900
Distillation: Epoch : 5, Loss : 1.861316, Accuracy: 0.845000, Test accuracy: 0.855700
Distillation: Epoch : 6, Loss : 1.848001, Accuracy: 0.865000, Test accuracy: 0.867400
Distillation: Epoch : 7, Loss : 1.849007, Accuracy: 0.850000, Test accuracy: 0.875000
Distillation: Epoch : 8, Loss : 1.841388, Accuracy: 0.883000, Test accuracy: 0.880900
Distillation: Epoch : 9, Loss : 1.821961, Accuracy: 0.874000, Test accuracy: 0.885900
Distillation: Epoch : 10, Loss : 1.828954, Accuracy: 0.882000, Test accuracy: 0.889700
Distillation: Epoch : 11, Loss : 1.833878, Accuracy: 0.877000, Test accuracy: 0.892500
Distillation: Epoch : 12, Loss : 1.831143, Accuracy: 0.868000, Test accuracy: 0.894700
Distillation: Epoch : 13, Loss : 1.814543, Accuracy: 0.885000, Test accuracy: 0.898300
Distillation: Epoch : 14, Loss : 1.813027, Accuracy: 0.887000, Test accuracy: 0.899800
Distillation: Epoch : 15, Loss : 1.814004, Accuracy: 0.893000, Test accuracy: 0.903100
Distillation: Epoch : 16, Loss : 1.821097, Accuracy: 0.888000, Test accuracy: 0.903800
Distillation: Epoch : 17, Loss : 1.803565, Accuracy: 0.893000, Test accuracy: 0.905300
Distillation: Epoch : 18, Loss : 1.818666, Accuracy: 0.913000, Test accuracy: 0.909100
Distillation: Epoch : 19, Loss : 1.802275, Accuracy: 0.889000, Test accuracy: 0.909700
Distillation: Epoch : 20, Loss : 1.814609, Accuracy: 0.905000, Test accuracy: 0.909900
Distillation: Epoch : 21, Loss : 1.793349, Accuracy: 0.916000, Test accuracy: 0.911700
Distillation: Epoch : 22, Loss : 1.797767, Accuracy: 0.910000, Test accuracy: 0.913100
Distillation: Epoch : 23, Loss : 1.806578, Accuracy: 0.896000, Test accuracy: 0.914100
Distillation: Epoch : 24, Loss : 1.809514, Accuracy: 0.908000, Test accuracy: 0.914300
Distillation: Epoch : 25, Loss : 1.790623, Accuracy: 0.918000, Test accuracy: 0.916900
Distillation: Epoch : 26, Loss : 1.795540, Accuracy: 0.909000, Test accuracy: 0.918600
Distillation: Epoch : 27, Loss : 1.790867, Accuracy: 0.923000, Test accuracy: 0.918700
Distillation: Epoch : 28, Loss : 1.798354, Accuracy: 0.915000, Test accuracy: 0.922400
Distillation: Epoch : 29, Loss : 1.794733, Accuracy: 0.908000, Test accuracy: 0.922200
Distillation: Epoch : 30, Loss : 1.782013, Accuracy: 0.919000, Test accuracy: 0.922600
Distillation: Epoch : 31, Loss : 1.781287, Accuracy: 0.919000, Test accuracy: 0.924500
Distillation: Epoch : 32, Loss : 1.794166, Accuracy: 0.916000, Test accuracy: 0.928100
Distillation: Epoch : 33, Loss : 1.766321, Accuracy: 0.926000, Test accuracy: 0.928200
Distillation: Epoch : 34, Loss : 1.781040, Accuracy: 0.923000, Test accuracy: 0.930700
Distillation: Epoch : 35, Loss : 1.763011, Accuracy: 0.932000, Test accuracy: 0.930900
Distillation: Epoch : 36, Loss : 1.777721, Accuracy: 0.931000, Test accuracy: 0.932900
Distillation: Epoch : 37, Loss : 1.776672, Accuracy: 0.925000, Test accuracy: 0.935400
Distillation: Epoch : 38, Loss : 1.784400, Accuracy: 0.920000, Test accuracy: 0.937200
Distillation: Epoch : 39, Loss : 1.785377, Accuracy: 0.930000, Test accuracy: 0.938000
Distillation: Epoch : 40, Loss : 1.777527, Accuracy: 0.933000, Test accuracy: 0.939000
Distillation: Epoch : 41, Loss : 1.786584, Accuracy: 0.927000, Test accuracy: 0.939400
Distillation: Epoch : 42, Loss : 1.771940, Accuracy: 0.942000, Test accuracy: 0.940100
Distillation: Epoch : 43, Loss : 1.769979, Accuracy: 0.941000, Test accuracy: 0.941100
Distillation: Epoch : 44, Loss : 1.771626, Accuracy: 0.934000, Test accuracy: 0.942700
Distillation: Epoch : 45, Loss : 1.771540, Accuracy: 0.938000, Test accuracy: 0.944500
Distillation: Epoch : 46, Loss : 1.786845, Accuracy: 0.935000, Test accuracy: 0.944800
Distillation: Epoch : 47, Loss : 1.769481, Accuracy: 0.941000, Test accuracy: 0.945300
Distillation: Epoch : 48, Loss : 1.777245, Accuracy: 0.932000, Test accuracy: 0.945700
Distillation: Epoch : 49, Loss : 1.757127, Accuracy: 0.939000, Test accuracy: 0.947300
Distillation: Epoch : 50, Loss : 1.774698, Accuracy: 0.958000, Test accuracy: 0.946400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9464
Generating confusion matrix for student5
[[ 959.    0.    7.    1.    0.    6.   11.    1.    6.    6.]
 [   1. 1111.    5.    0.    0.    1.    3.    4.    0.    4.]
 [   2.    3.  951.    1.    3.    2.    3.   14.   12.    2.]
 [   0.    0.   21.  967.    3.   20.    0.   18.   17.   10.]
 [   0.    1.    7.    1.  921.    2.    6.    3.    4.   11.]
 [  11.    2.    1.   13.    0.  836.   12.    4.   18.   10.]
 [   4.    6.    4.    0.   17.   11.  922.    0.   10.    4.]
 [   1.    0.   12.    8.    2.    1.    0.  966.    7.   12.]
 [   2.   12.   21.   12.    3.    7.    1.    3.  887.    6.]
 [   0.    0.    3.    7.   33.    6.    0.   15.   13.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.144129, Accuracy: 0.768000, Test accuracy: 0.788900
Distillation: Epoch : 2, Loss : 2.082226, Accuracy: 0.828000, Test accuracy: 0.841300
Distillation: Epoch : 3, Loss : 2.080458, Accuracy: 0.837000, Test accuracy: 0.860000
Distillation: Epoch : 4, Loss : 2.075656, Accuracy: 0.848000, Test accuracy: 0.866400
Distillation: Epoch : 5, Loss : 2.064193, Accuracy: 0.865000, Test accuracy: 0.871800
Distillation: Epoch : 6, Loss : 2.057931, Accuracy: 0.843000, Test accuracy: 0.873500
Distillation: Epoch : 7, Loss : 2.056652, Accuracy: 0.873000, Test accuracy: 0.876400
Distillation: Epoch : 8, Loss : 2.070805, Accuracy: 0.858000, Test accuracy: 0.880100
Distillation: Epoch : 9, Loss : 2.064310, Accuracy: 0.882000, Test accuracy: 0.883200
Distillation: Epoch : 10, Loss : 2.062650, Accuracy: 0.877000, Test accuracy: 0.883700
Distillation: Epoch : 11, Loss : 2.061646, Accuracy: 0.870000, Test accuracy: 0.886200
Distillation: Epoch : 12, Loss : 2.061120, Accuracy: 0.862000, Test accuracy: 0.885500
Distillation: Epoch : 13, Loss : 2.059575, Accuracy: 0.878000, Test accuracy: 0.887900
Distillation: Epoch : 14, Loss : 2.050761, Accuracy: 0.877000, Test accuracy: 0.888900
Distillation: Epoch : 15, Loss : 2.060053, Accuracy: 0.888000, Test accuracy: 0.887900
Distillation: Epoch : 16, Loss : 2.056844, Accuracy: 0.882000, Test accuracy: 0.888100
Distillation: Epoch : 17, Loss : 2.059191, Accuracy: 0.882000, Test accuracy: 0.887200
Distillation: Epoch : 18, Loss : 2.054388, Accuracy: 0.875000, Test accuracy: 0.889200
Distillation: Epoch : 19, Loss : 2.050060, Accuracy: 0.886000, Test accuracy: 0.889000
Distillation: Epoch : 20, Loss : 2.051331, Accuracy: 0.870000, Test accuracy: 0.890900
Distillation: Epoch : 21, Loss : 2.059622, Accuracy: 0.872000, Test accuracy: 0.890300
Distillation: Epoch : 22, Loss : 2.057073, Accuracy: 0.878000, Test accuracy: 0.890300
Distillation: Epoch : 23, Loss : 2.058389, Accuracy: 0.853000, Test accuracy: 0.891300
Distillation: Epoch : 24, Loss : 2.054208, Accuracy: 0.877000, Test accuracy: 0.890700
Distillation: Epoch : 25, Loss : 2.052664, Accuracy: 0.882000, Test accuracy: 0.890900
Distillation: Epoch : 26, Loss : 2.046511, Accuracy: 0.900000, Test accuracy: 0.891200
Distillation: Epoch : 27, Loss : 2.042122, Accuracy: 0.899000, Test accuracy: 0.890000
Distillation: Epoch : 28, Loss : 2.051077, Accuracy: 0.887000, Test accuracy: 0.890500
Distillation: Epoch : 29, Loss : 2.048991, Accuracy: 0.878000, Test accuracy: 0.893500
Distillation: Epoch : 30, Loss : 2.041467, Accuracy: 0.891000, Test accuracy: 0.892900
Distillation: Epoch : 31, Loss : 2.059412, Accuracy: 0.877000, Test accuracy: 0.893300
Distillation: Epoch : 32, Loss : 2.052440, Accuracy: 0.879000, Test accuracy: 0.892100
Distillation: Epoch : 33, Loss : 2.052086, Accuracy: 0.877000, Test accuracy: 0.893700
Distillation: Epoch : 34, Loss : 2.054700, Accuracy: 0.877000, Test accuracy: 0.892500
Distillation: Epoch : 35, Loss : 2.052041, Accuracy: 0.884000, Test accuracy: 0.893000
Distillation: Epoch : 36, Loss : 2.046377, Accuracy: 0.878000, Test accuracy: 0.890300
Distillation: Epoch : 37, Loss : 2.051163, Accuracy: 0.893000, Test accuracy: 0.891200
Distillation: Epoch : 38, Loss : 2.057459, Accuracy: 0.871000, Test accuracy: 0.892100
Distillation: Epoch : 39, Loss : 2.048632, Accuracy: 0.889000, Test accuracy: 0.893300
Distillation: Epoch : 40, Loss : 2.038872, Accuracy: 0.891000, Test accuracy: 0.894900
Distillation: Epoch : 41, Loss : 2.042894, Accuracy: 0.892000, Test accuracy: 0.893500
Distillation: Epoch : 42, Loss : 2.050210, Accuracy: 0.882000, Test accuracy: 0.892800
Distillation: Epoch : 43, Loss : 2.056957, Accuracy: 0.874000, Test accuracy: 0.894800
Distillation: Epoch : 44, Loss : 2.049014, Accuracy: 0.880000, Test accuracy: 0.894300
Distillation: Epoch : 45, Loss : 2.047721, Accuracy: 0.879000, Test accuracy: 0.893900
Distillation: Epoch : 46, Loss : 2.037322, Accuracy: 0.906000, Test accuracy: 0.894700
Distillation: Epoch : 47, Loss : 2.057914, Accuracy: 0.885000, Test accuracy: 0.893500
Distillation: Epoch : 48, Loss : 2.048161, Accuracy: 0.893000, Test accuracy: 0.893700
Distillation: Epoch : 49, Loss : 2.037822, Accuracy: 0.892000, Test accuracy: 0.894500
Distillation: Epoch : 50, Loss : 2.048310, Accuracy: 0.886000, Test accuracy: 0.892500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.8925
Generating confusion matrix for student5
[[ 937.    0.    7.    6.    2.    7.   11.    2.    9.   14.]
 [   0. 1106.   37.    4.    4.    4.    4.   34.   18.    8.]
 [   1.    2.  860.   15.    6.    2.    5.   11.    8.    2.]
 [   4.    5.   28.  924.    0.   51.    0.    9.   63.   21.]
 [   4.    1.   31.    3.  921.   14.   13.   18.   17.   76.]
 [  17.    6.    2.   27.    8.  764.   24.    3.   57.   14.]
 [  11.    4.   21.    3.   10.   19.  900.    1.   16.    0.]
 [   2.    0.   16.   13.    1.    7.    1.  908.    8.   35.]
 [   4.   11.   27.   10.    5.   19.    0.    0.  772.    6.]
 [   0.    0.    3.    5.   25.    5.    0.   42.    6.  833.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.573704, Accuracy: 0.845000, Test accuracy: 0.850000
Distillation: Epoch : 2, Loss : 0.363710, Accuracy: 0.900000, Test accuracy: 0.892400
Distillation: Epoch : 3, Loss : 0.288765, Accuracy: 0.911000, Test accuracy: 0.907900
Distillation: Epoch : 4, Loss : 0.311211, Accuracy: 0.917000, Test accuracy: 0.920500
Distillation: Epoch : 5, Loss : 0.305533, Accuracy: 0.911000, Test accuracy: 0.928700
Distillation: Epoch : 6, Loss : 0.278083, Accuracy: 0.922000, Test accuracy: 0.936000
Distillation: Epoch : 7, Loss : 0.218948, Accuracy: 0.934000, Test accuracy: 0.942400
Distillation: Epoch : 8, Loss : 0.196723, Accuracy: 0.943000, Test accuracy: 0.946200
Distillation: Epoch : 9, Loss : 0.212502, Accuracy: 0.937000, Test accuracy: 0.951900
Distillation: Epoch : 10, Loss : 0.169126, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 11, Loss : 0.158405, Accuracy: 0.953000, Test accuracy: 0.957900
Distillation: Epoch : 12, Loss : 0.134597, Accuracy: 0.961000, Test accuracy: 0.961500
Distillation: Epoch : 13, Loss : 0.128164, Accuracy: 0.967000, Test accuracy: 0.963600
Distillation: Epoch : 14, Loss : 0.111571, Accuracy: 0.964000, Test accuracy: 0.962700
Distillation: Epoch : 15, Loss : 0.105079, Accuracy: 0.965000, Test accuracy: 0.965300
Distillation: Epoch : 16, Loss : 0.154840, Accuracy: 0.960000, Test accuracy: 0.966800
Distillation: Epoch : 17, Loss : 0.114399, Accuracy: 0.961000, Test accuracy: 0.966500
Distillation: Epoch : 18, Loss : 0.108657, Accuracy: 0.970000, Test accuracy: 0.968600
Distillation: Epoch : 19, Loss : 0.124383, Accuracy: 0.966000, Test accuracy: 0.969100
Distillation: Epoch : 20, Loss : 0.087792, Accuracy: 0.973000, Test accuracy: 0.969700
Distillation: Epoch : 21, Loss : 0.117309, Accuracy: 0.963000, Test accuracy: 0.970300
Distillation: Epoch : 22, Loss : 0.087784, Accuracy: 0.971000, Test accuracy: 0.971300
Distillation: Epoch : 23, Loss : 0.090511, Accuracy: 0.968000, Test accuracy: 0.972700
Distillation: Epoch : 24, Loss : 0.106310, Accuracy: 0.974000, Test accuracy: 0.972900
Distillation: Epoch : 25, Loss : 0.094449, Accuracy: 0.972000, Test accuracy: 0.973800
Distillation: Epoch : 26, Loss : 0.109613, Accuracy: 0.962000, Test accuracy: 0.973600
Distillation: Epoch : 27, Loss : 0.097943, Accuracy: 0.964000, Test accuracy: 0.974600
Distillation: Epoch : 28, Loss : 0.095374, Accuracy: 0.970000, Test accuracy: 0.973500
Distillation: Epoch : 29, Loss : 0.089951, Accuracy: 0.975000, Test accuracy: 0.975900
Distillation: Epoch : 30, Loss : 0.089240, Accuracy: 0.973000, Test accuracy: 0.975400
Distillation: Epoch : 31, Loss : 0.086258, Accuracy: 0.973000, Test accuracy: 0.975500
Distillation: Epoch : 32, Loss : 0.105255, Accuracy: 0.964000, Test accuracy: 0.975900
Distillation: Epoch : 33, Loss : 0.080273, Accuracy: 0.977000, Test accuracy: 0.975200
Distillation: Epoch : 34, Loss : 0.100817, Accuracy: 0.980000, Test accuracy: 0.975100
Distillation: Epoch : 35, Loss : 0.084660, Accuracy: 0.977000, Test accuracy: 0.976800
Distillation: Epoch : 36, Loss : 0.096533, Accuracy: 0.974000, Test accuracy: 0.976600
Distillation: Epoch : 37, Loss : 0.072631, Accuracy: 0.980000, Test accuracy: 0.977900
Distillation: Epoch : 38, Loss : 0.094386, Accuracy: 0.968000, Test accuracy: 0.976900
Distillation: Epoch : 39, Loss : 0.067665, Accuracy: 0.979000, Test accuracy: 0.977700
Distillation: Epoch : 40, Loss : 0.079099, Accuracy: 0.980000, Test accuracy: 0.977000
Distillation: Epoch : 41, Loss : 0.055703, Accuracy: 0.984000, Test accuracy: 0.977900
Distillation: Epoch : 42, Loss : 0.072282, Accuracy: 0.979000, Test accuracy: 0.978500
Distillation: Epoch : 43, Loss : 0.087424, Accuracy: 0.972000, Test accuracy: 0.978300
Distillation: Epoch : 44, Loss : 0.081680, Accuracy: 0.976000, Test accuracy: 0.978300
Distillation: Epoch : 45, Loss : 0.052160, Accuracy: 0.985000, Test accuracy: 0.977900
Distillation: Epoch : 46, Loss : 0.050115, Accuracy: 0.986000, Test accuracy: 0.979400
Distillation: Epoch : 47, Loss : 0.061240, Accuracy: 0.981000, Test accuracy: 0.978800
Distillation: Epoch : 48, Loss : 0.075429, Accuracy: 0.976000, Test accuracy: 0.979500
Distillation: Epoch : 49, Loss : 0.063102, Accuracy: 0.979000, Test accuracy: 0.978100
Distillation: Epoch : 50, Loss : 0.074448, Accuracy: 0.978000, Test accuracy: 0.979800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9798
Generating confusion matrix for student
[[ 974.    0.    2.    1.    1.    2.    5.    2.    5.    3.]
 [   0. 1127.    6.    0.    1.    1.    2.    4.    0.    5.]
 [   1.    2. 1017.    2.    2.    1.    2.   11.    6.    2.]
 [   0.    1.    2.  996.    0.   13.    2.    3.    9.    6.]
 [   0.    0.    1.    1.  961.    1.    2.    2.    3.    6.]
 [   0.    0.    0.    2.    0.  864.    3.    0.    1.    1.]
 [   2.    1.    0.    0.    4.    2.  941.    0.    1.    1.]
 [   1.    0.    1.    3.    2.    0.    0.  998.    2.    4.]
 [   2.    4.    3.    4.    1.    5.    1.    1.  942.    3.]
 [   0.    0.    0.    1.   10.    3.    0.    7.    5.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.880868, Accuracy: 0.755000, Test accuracy: 0.774500
Distillation: Epoch : 2, Loss : 0.485374, Accuracy: 0.863000, Test accuracy: 0.868500
Distillation: Epoch : 3, Loss : 0.386588, Accuracy: 0.905000, Test accuracy: 0.891800
Distillation: Epoch : 4, Loss : 0.337371, Accuracy: 0.904000, Test accuracy: 0.904400
Distillation: Epoch : 5, Loss : 0.284891, Accuracy: 0.915000, Test accuracy: 0.917600
Distillation: Epoch : 6, Loss : 0.255155, Accuracy: 0.926000, Test accuracy: 0.924700
Distillation: Epoch : 7, Loss : 0.262219, Accuracy: 0.935000, Test accuracy: 0.931900
Distillation: Epoch : 8, Loss : 0.278272, Accuracy: 0.918000, Test accuracy: 0.938100
Distillation: Epoch : 9, Loss : 0.214447, Accuracy: 0.945000, Test accuracy: 0.943600
Distillation: Epoch : 10, Loss : 0.231144, Accuracy: 0.943000, Test accuracy: 0.948500
Distillation: Epoch : 11, Loss : 0.236240, Accuracy: 0.936000, Test accuracy: 0.951000
Distillation: Epoch : 12, Loss : 0.192128, Accuracy: 0.952000, Test accuracy: 0.955600
Distillation: Epoch : 13, Loss : 0.185286, Accuracy: 0.951000, Test accuracy: 0.958800
Distillation: Epoch : 14, Loss : 0.168698, Accuracy: 0.952000, Test accuracy: 0.962400
Distillation: Epoch : 15, Loss : 0.168829, Accuracy: 0.957000, Test accuracy: 0.963900
Distillation: Epoch : 16, Loss : 0.141902, Accuracy: 0.969000, Test accuracy: 0.966400
Distillation: Epoch : 17, Loss : 0.168955, Accuracy: 0.957000, Test accuracy: 0.967800
Distillation: Epoch : 18, Loss : 0.135562, Accuracy: 0.963000, Test accuracy: 0.968700
Distillation: Epoch : 19, Loss : 0.143793, Accuracy: 0.958000, Test accuracy: 0.969900
Distillation: Epoch : 20, Loss : 0.136175, Accuracy: 0.970000, Test accuracy: 0.970800
Distillation: Epoch : 21, Loss : 0.121399, Accuracy: 0.968000, Test accuracy: 0.972100
Distillation: Epoch : 22, Loss : 0.130870, Accuracy: 0.968000, Test accuracy: 0.973200
Distillation: Epoch : 23, Loss : 0.138019, Accuracy: 0.967000, Test accuracy: 0.972900
Distillation: Epoch : 24, Loss : 0.139128, Accuracy: 0.969000, Test accuracy: 0.973700
Distillation: Epoch : 25, Loss : 0.119439, Accuracy: 0.970000, Test accuracy: 0.974700
Distillation: Epoch : 26, Loss : 0.132680, Accuracy: 0.965000, Test accuracy: 0.975500
Distillation: Epoch : 27, Loss : 0.112177, Accuracy: 0.977000, Test accuracy: 0.974900
Distillation: Epoch : 28, Loss : 0.134492, Accuracy: 0.969000, Test accuracy: 0.976300
Distillation: Epoch : 29, Loss : 0.115837, Accuracy: 0.970000, Test accuracy: 0.976600
Distillation: Epoch : 30, Loss : 0.104405, Accuracy: 0.976000, Test accuracy: 0.977200
Distillation: Epoch : 31, Loss : 0.111355, Accuracy: 0.979000, Test accuracy: 0.977000
Distillation: Epoch : 32, Loss : 0.095349, Accuracy: 0.974000, Test accuracy: 0.977700
Distillation: Epoch : 33, Loss : 0.104042, Accuracy: 0.978000, Test accuracy: 0.978200
Distillation: Epoch : 34, Loss : 0.106472, Accuracy: 0.974000, Test accuracy: 0.978100
Distillation: Epoch : 35, Loss : 0.109311, Accuracy: 0.974000, Test accuracy: 0.978200
Distillation: Epoch : 36, Loss : 0.072370, Accuracy: 0.989000, Test accuracy: 0.978900
Distillation: Epoch : 37, Loss : 0.112275, Accuracy: 0.972000, Test accuracy: 0.979500
Distillation: Epoch : 38, Loss : 0.096563, Accuracy: 0.981000, Test accuracy: 0.979400
Distillation: Epoch : 39, Loss : 0.101795, Accuracy: 0.981000, Test accuracy: 0.980200
Distillation: Epoch : 40, Loss : 0.098359, Accuracy: 0.983000, Test accuracy: 0.979900
Distillation: Epoch : 41, Loss : 0.098880, Accuracy: 0.980000, Test accuracy: 0.980500
Distillation: Epoch : 42, Loss : 0.096227, Accuracy: 0.979000, Test accuracy: 0.980500
Distillation: Epoch : 43, Loss : 0.108472, Accuracy: 0.977000, Test accuracy: 0.980600
Distillation: Epoch : 44, Loss : 0.106227, Accuracy: 0.974000, Test accuracy: 0.980500
Distillation: Epoch : 45, Loss : 0.123448, Accuracy: 0.970000, Test accuracy: 0.981800
Distillation: Epoch : 46, Loss : 0.096736, Accuracy: 0.981000, Test accuracy: 0.981000
Distillation: Epoch : 47, Loss : 0.085596, Accuracy: 0.984000, Test accuracy: 0.980100
Distillation: Epoch : 48, Loss : 0.079213, Accuracy: 0.981000, Test accuracy: 0.981800
Distillation: Epoch : 49, Loss : 0.100382, Accuracy: 0.977000, Test accuracy: 0.980000
Distillation: Epoch : 50, Loss : 0.093082, Accuracy: 0.979000, Test accuracy: 0.981000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.981
Generating confusion matrix for student
[[ 970.    0.    2.    1.    1.    2.    4.    0.    5.    4.]
 [   0. 1126.    6.    0.    0.    0.    3.    3.    1.    6.]
 [   2.    4. 1004.    1.    1.    1.    0.   10.    3.    0.]
 [   0.    0.    6. 1000.    0.    8.    0.    2.    4.    5.]
 [   1.    1.    1.    0.  970.    0.    8.    0.    3.    5.]
 [   0.    0.    0.    3.    0.  875.    3.    0.    2.    4.]
 [   3.    0.    0.    0.    1.    2.  937.    0.    3.    0.]
 [   1.    2.    7.    2.    1.    0.    0. 1009.    5.    9.]
 [   2.    2.    6.    3.    2.    2.    3.    2.  943.    0.]
 [   1.    0.    0.    0.    6.    2.    0.    2.    5.  976.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.281597, Accuracy: 0.746000, Test accuracy: 0.758800
Distillation: Epoch : 2, Loss : 0.789541, Accuracy: 0.853000, Test accuracy: 0.866200
Distillation: Epoch : 3, Loss : 0.704170, Accuracy: 0.886000, Test accuracy: 0.896800
Distillation: Epoch : 4, Loss : 0.651273, Accuracy: 0.902000, Test accuracy: 0.908800
Distillation: Epoch : 5, Loss : 0.618312, Accuracy: 0.911000, Test accuracy: 0.920000
Distillation: Epoch : 6, Loss : 0.613141, Accuracy: 0.922000, Test accuracy: 0.925700
Distillation: Epoch : 7, Loss : 0.588110, Accuracy: 0.931000, Test accuracy: 0.930900
Distillation: Epoch : 8, Loss : 0.586853, Accuracy: 0.929000, Test accuracy: 0.937900
Distillation: Epoch : 9, Loss : 0.546569, Accuracy: 0.937000, Test accuracy: 0.940800
Distillation: Epoch : 10, Loss : 0.566796, Accuracy: 0.936000, Test accuracy: 0.946500
Distillation: Epoch : 11, Loss : 0.562548, Accuracy: 0.945000, Test accuracy: 0.949700
Distillation: Epoch : 12, Loss : 0.515911, Accuracy: 0.950000, Test accuracy: 0.952500
Distillation: Epoch : 13, Loss : 0.494317, Accuracy: 0.956000, Test accuracy: 0.956000
Distillation: Epoch : 14, Loss : 0.489010, Accuracy: 0.963000, Test accuracy: 0.959600
Distillation: Epoch : 15, Loss : 0.498393, Accuracy: 0.963000, Test accuracy: 0.963500
Distillation: Epoch : 16, Loss : 0.473861, Accuracy: 0.969000, Test accuracy: 0.965100
Distillation: Epoch : 17, Loss : 0.477319, Accuracy: 0.961000, Test accuracy: 0.965500
Distillation: Epoch : 18, Loss : 0.497647, Accuracy: 0.961000, Test accuracy: 0.965700
Distillation: Epoch : 19, Loss : 0.489340, Accuracy: 0.967000, Test accuracy: 0.968800
Distillation: Epoch : 20, Loss : 0.490073, Accuracy: 0.959000, Test accuracy: 0.969500
Distillation: Epoch : 21, Loss : 0.488242, Accuracy: 0.969000, Test accuracy: 0.971000
Distillation: Epoch : 22, Loss : 0.462139, Accuracy: 0.975000, Test accuracy: 0.972400
Distillation: Epoch : 23, Loss : 0.465223, Accuracy: 0.969000, Test accuracy: 0.973500
Distillation: Epoch : 24, Loss : 0.467281, Accuracy: 0.969000, Test accuracy: 0.972700
Distillation: Epoch : 25, Loss : 0.468389, Accuracy: 0.964000, Test accuracy: 0.974400
Distillation: Epoch : 26, Loss : 0.453750, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 27, Loss : 0.472133, Accuracy: 0.963000, Test accuracy: 0.975500
Distillation: Epoch : 28, Loss : 0.450247, Accuracy: 0.971000, Test accuracy: 0.975900
Distillation: Epoch : 29, Loss : 0.443712, Accuracy: 0.972000, Test accuracy: 0.976100
Distillation: Epoch : 30, Loss : 0.453084, Accuracy: 0.969000, Test accuracy: 0.977100
Distillation: Epoch : 31, Loss : 0.457967, Accuracy: 0.971000, Test accuracy: 0.977200
Distillation: Epoch : 32, Loss : 0.436472, Accuracy: 0.982000, Test accuracy: 0.978200
Distillation: Epoch : 33, Loss : 0.460250, Accuracy: 0.972000, Test accuracy: 0.978000
Distillation: Epoch : 34, Loss : 0.464044, Accuracy: 0.976000, Test accuracy: 0.977700
Distillation: Epoch : 35, Loss : 0.436029, Accuracy: 0.984000, Test accuracy: 0.978200
Distillation: Epoch : 36, Loss : 0.479923, Accuracy: 0.972000, Test accuracy: 0.978300
Distillation: Epoch : 37, Loss : 0.425301, Accuracy: 0.982000, Test accuracy: 0.978400
Distillation: Epoch : 38, Loss : 0.442178, Accuracy: 0.974000, Test accuracy: 0.978700
Distillation: Epoch : 39, Loss : 0.449279, Accuracy: 0.973000, Test accuracy: 0.979200
Distillation: Epoch : 40, Loss : 0.433770, Accuracy: 0.984000, Test accuracy: 0.979100
Distillation: Epoch : 41, Loss : 0.440221, Accuracy: 0.980000, Test accuracy: 0.979700
Distillation: Epoch : 42, Loss : 0.448858, Accuracy: 0.983000, Test accuracy: 0.979400
Distillation: Epoch : 43, Loss : 0.428629, Accuracy: 0.977000, Test accuracy: 0.979300
Distillation: Epoch : 44, Loss : 0.440650, Accuracy: 0.982000, Test accuracy: 0.979900
Distillation: Epoch : 45, Loss : 0.438764, Accuracy: 0.982000, Test accuracy: 0.979900
Distillation: Epoch : 46, Loss : 0.448871, Accuracy: 0.979000, Test accuracy: 0.981100
Distillation: Epoch : 47, Loss : 0.438833, Accuracy: 0.984000, Test accuracy: 0.980100
Distillation: Epoch : 48, Loss : 0.442043, Accuracy: 0.969000, Test accuracy: 0.979900
Distillation: Epoch : 49, Loss : 0.444994, Accuracy: 0.984000, Test accuracy: 0.980400
Distillation: Epoch : 50, Loss : 0.455044, Accuracy: 0.978000, Test accuracy: 0.980300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9803
Generating confusion matrix for student
[[ 971.    0.    1.    0.    0.    1.    5.    1.    6.    4.]
 [   0. 1129.    6.    0.    0.    0.    3.    2.    0.    6.]
 [   1.    3. 1007.    0.    1.    1.    0.   13.    3.    0.]
 [   0.    0.    5. 1002.    0.   14.    0.    3.    6.    4.]
 [   0.    0.    0.    0.  962.    1.    5.    0.    2.    4.]
 [   2.    1.    0.    2.    0.  867.    3.    0.    1.    3.]
 [   3.    0.    0.    0.    3.    4.  942.    0.    3.    0.]
 [   1.    0.    5.    2.    1.    2.    0. 1002.    3.    8.]
 [   2.    2.    8.    3.    2.    2.    0.    1.  943.    2.]
 [   0.    0.    0.    1.   13.    0.    0.    6.    7.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.392481, Accuracy: 0.715000, Test accuracy: 0.739200
Distillation: Epoch : 2, Loss : 0.957558, Accuracy: 0.851000, Test accuracy: 0.851600
Distillation: Epoch : 3, Loss : 0.852362, Accuracy: 0.895000, Test accuracy: 0.889200
Distillation: Epoch : 4, Loss : 0.847517, Accuracy: 0.898000, Test accuracy: 0.903100
Distillation: Epoch : 5, Loss : 0.810286, Accuracy: 0.908000, Test accuracy: 0.915700
Distillation: Epoch : 6, Loss : 0.777683, Accuracy: 0.902000, Test accuracy: 0.921600
Distillation: Epoch : 7, Loss : 0.760425, Accuracy: 0.929000, Test accuracy: 0.930100
Distillation: Epoch : 8, Loss : 0.760686, Accuracy: 0.936000, Test accuracy: 0.936900
Distillation: Epoch : 9, Loss : 0.739476, Accuracy: 0.947000, Test accuracy: 0.942700
Distillation: Epoch : 10, Loss : 0.713939, Accuracy: 0.951000, Test accuracy: 0.949400
Distillation: Epoch : 11, Loss : 0.690281, Accuracy: 0.955000, Test accuracy: 0.954500
Distillation: Epoch : 12, Loss : 0.694465, Accuracy: 0.943000, Test accuracy: 0.957300
Distillation: Epoch : 13, Loss : 0.689214, Accuracy: 0.956000, Test accuracy: 0.961000
Distillation: Epoch : 14, Loss : 0.695604, Accuracy: 0.956000, Test accuracy: 0.962700
Distillation: Epoch : 15, Loss : 0.676751, Accuracy: 0.958000, Test accuracy: 0.964800
Distillation: Epoch : 16, Loss : 0.698386, Accuracy: 0.949000, Test accuracy: 0.967000
Distillation: Epoch : 17, Loss : 0.667442, Accuracy: 0.958000, Test accuracy: 0.967300
Distillation: Epoch : 18, Loss : 0.658057, Accuracy: 0.979000, Test accuracy: 0.968500
Distillation: Epoch : 19, Loss : 0.651725, Accuracy: 0.976000, Test accuracy: 0.969900
Distillation: Epoch : 20, Loss : 0.655906, Accuracy: 0.973000, Test accuracy: 0.970800
Distillation: Epoch : 21, Loss : 0.680784, Accuracy: 0.967000, Test accuracy: 0.971700
Distillation: Epoch : 22, Loss : 0.652211, Accuracy: 0.962000, Test accuracy: 0.972700
Distillation: Epoch : 23, Loss : 0.657564, Accuracy: 0.970000, Test accuracy: 0.973400
Distillation: Epoch : 24, Loss : 0.640695, Accuracy: 0.975000, Test accuracy: 0.973600
Distillation: Epoch : 25, Loss : 0.650687, Accuracy: 0.969000, Test accuracy: 0.974200
Distillation: Epoch : 26, Loss : 0.632162, Accuracy: 0.967000, Test accuracy: 0.974700
Distillation: Epoch : 27, Loss : 0.638303, Accuracy: 0.969000, Test accuracy: 0.975200
Distillation: Epoch : 28, Loss : 0.617935, Accuracy: 0.980000, Test accuracy: 0.975500
Distillation: Epoch : 29, Loss : 0.627894, Accuracy: 0.972000, Test accuracy: 0.975400
Distillation: Epoch : 30, Loss : 0.613141, Accuracy: 0.981000, Test accuracy: 0.976300
Distillation: Epoch : 31, Loss : 0.636129, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 32, Loss : 0.615682, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 33, Loss : 0.646047, Accuracy: 0.969000, Test accuracy: 0.976700
Distillation: Epoch : 34, Loss : 0.642089, Accuracy: 0.970000, Test accuracy: 0.977300
Distillation: Epoch : 35, Loss : 0.629248, Accuracy: 0.978000, Test accuracy: 0.977600
Distillation: Epoch : 36, Loss : 0.633348, Accuracy: 0.972000, Test accuracy: 0.978100
Distillation: Epoch : 37, Loss : 0.623428, Accuracy: 0.980000, Test accuracy: 0.978300
Distillation: Epoch : 38, Loss : 0.638091, Accuracy: 0.978000, Test accuracy: 0.979200
Distillation: Epoch : 39, Loss : 0.627608, Accuracy: 0.973000, Test accuracy: 0.979200
Distillation: Epoch : 40, Loss : 0.617145, Accuracy: 0.975000, Test accuracy: 0.979200
Distillation: Epoch : 41, Loss : 0.627272, Accuracy: 0.975000, Test accuracy: 0.979500
Distillation: Epoch : 42, Loss : 0.612553, Accuracy: 0.975000, Test accuracy: 0.980500
Distillation: Epoch : 43, Loss : 0.644415, Accuracy: 0.969000, Test accuracy: 0.980100
Distillation: Epoch : 44, Loss : 0.634781, Accuracy: 0.976000, Test accuracy: 0.980100
Distillation: Epoch : 45, Loss : 0.616293, Accuracy: 0.981000, Test accuracy: 0.980500
Distillation: Epoch : 46, Loss : 0.634753, Accuracy: 0.973000, Test accuracy: 0.979600
Distillation: Epoch : 47, Loss : 0.625726, Accuracy: 0.978000, Test accuracy: 0.980400
Distillation: Epoch : 48, Loss : 0.652056, Accuracy: 0.966000, Test accuracy: 0.980600
Distillation: Epoch : 49, Loss : 0.622341, Accuracy: 0.983000, Test accuracy: 0.981400
Distillation: Epoch : 50, Loss : 0.596636, Accuracy: 0.983000, Test accuracy: 0.981300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9813
Generating confusion matrix for student
[[ 973.    0.    5.    0.    0.    1.    2.    0.    6.    5.]
 [   0. 1128.    3.    0.    1.    0.    3.    3.    1.    7.]
 [   0.    3. 1011.    1.    2.    0.    0.    9.    3.    0.]
 [   0.    1.    2.  995.    0.    6.    0.    3.    7.    2.]
 [   0.    0.    1.    0.  961.    0.    2.    1.    3.    2.]
 [   3.    2.    0.    5.    0.  880.    3.    0.    6.    3.]
 [   2.    0.    0.    0.    1.    3.  947.    0.    2.    0.]
 [   1.    0.    5.    6.    0.    1.    0. 1000.    3.    6.]
 [   1.    1.    4.    3.    2.    1.    1.    1.  935.    1.]
 [   0.    0.    1.    0.   15.    0.    0.   11.    8.  983.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.641346, Accuracy: 0.770000, Test accuracy: 0.795300
Distillation: Epoch : 2, Loss : 1.072934, Accuracy: 0.871000, Test accuracy: 0.878500
Distillation: Epoch : 3, Loss : 1.003453, Accuracy: 0.906000, Test accuracy: 0.911400
Distillation: Epoch : 4, Loss : 0.988501, Accuracy: 0.889000, Test accuracy: 0.923000
Distillation: Epoch : 5, Loss : 0.921374, Accuracy: 0.937000, Test accuracy: 0.931500
Distillation: Epoch : 6, Loss : 0.912670, Accuracy: 0.948000, Test accuracy: 0.938000
Distillation: Epoch : 7, Loss : 0.912277, Accuracy: 0.945000, Test accuracy: 0.944400
Distillation: Epoch : 8, Loss : 0.899817, Accuracy: 0.947000, Test accuracy: 0.948800
Distillation: Epoch : 9, Loss : 0.883272, Accuracy: 0.952000, Test accuracy: 0.951800
Distillation: Epoch : 10, Loss : 0.866761, Accuracy: 0.957000, Test accuracy: 0.954800
Distillation: Epoch : 11, Loss : 0.866817, Accuracy: 0.966000, Test accuracy: 0.957000
Distillation: Epoch : 12, Loss : 0.875546, Accuracy: 0.961000, Test accuracy: 0.959000
Distillation: Epoch : 13, Loss : 0.828365, Accuracy: 0.966000, Test accuracy: 0.961900
Distillation: Epoch : 14, Loss : 0.845912, Accuracy: 0.966000, Test accuracy: 0.963600
Distillation: Epoch : 15, Loss : 0.857233, Accuracy: 0.958000, Test accuracy: 0.965600
Distillation: Epoch : 16, Loss : 0.844502, Accuracy: 0.959000, Test accuracy: 0.967400
Distillation: Epoch : 17, Loss : 0.840237, Accuracy: 0.975000, Test accuracy: 0.967500
Distillation: Epoch : 18, Loss : 0.823870, Accuracy: 0.971000, Test accuracy: 0.969700
Distillation: Epoch : 19, Loss : 0.847823, Accuracy: 0.963000, Test accuracy: 0.969600
Distillation: Epoch : 20, Loss : 0.843481, Accuracy: 0.971000, Test accuracy: 0.970400
Distillation: Epoch : 21, Loss : 0.820191, Accuracy: 0.969000, Test accuracy: 0.971600
Distillation: Epoch : 22, Loss : 0.827633, Accuracy: 0.979000, Test accuracy: 0.972000
Distillation: Epoch : 23, Loss : 0.830460, Accuracy: 0.967000, Test accuracy: 0.972600
Distillation: Epoch : 24, Loss : 0.846186, Accuracy: 0.970000, Test accuracy: 0.973000
Distillation: Epoch : 25, Loss : 0.808468, Accuracy: 0.974000, Test accuracy: 0.973800
Distillation: Epoch : 26, Loss : 0.850121, Accuracy: 0.969000, Test accuracy: 0.974700
Distillation: Epoch : 27, Loss : 0.809460, Accuracy: 0.972000, Test accuracy: 0.975200
Distillation: Epoch : 28, Loss : 0.833006, Accuracy: 0.974000, Test accuracy: 0.976300
Distillation: Epoch : 29, Loss : 0.813837, Accuracy: 0.975000, Test accuracy: 0.976000
Distillation: Epoch : 30, Loss : 0.813219, Accuracy: 0.975000, Test accuracy: 0.976400
Distillation: Epoch : 31, Loss : 0.806395, Accuracy: 0.981000, Test accuracy: 0.977100
Distillation: Epoch : 32, Loss : 0.827873, Accuracy: 0.972000, Test accuracy: 0.978000
Distillation: Epoch : 33, Loss : 0.819605, Accuracy: 0.970000, Test accuracy: 0.978200
Distillation: Epoch : 34, Loss : 0.825751, Accuracy: 0.979000, Test accuracy: 0.978400
Distillation: Epoch : 35, Loss : 0.802888, Accuracy: 0.975000, Test accuracy: 0.977800
Distillation: Epoch : 36, Loss : 0.825096, Accuracy: 0.968000, Test accuracy: 0.979000
Distillation: Epoch : 37, Loss : 0.837086, Accuracy: 0.978000, Test accuracy: 0.979400
Distillation: Epoch : 38, Loss : 0.848104, Accuracy: 0.974000, Test accuracy: 0.979300
Distillation: Epoch : 39, Loss : 0.850887, Accuracy: 0.966000, Test accuracy: 0.979300
Distillation: Epoch : 40, Loss : 0.787176, Accuracy: 0.983000, Test accuracy: 0.979600
Distillation: Epoch : 41, Loss : 0.825203, Accuracy: 0.981000, Test accuracy: 0.979900
Distillation: Epoch : 42, Loss : 0.816575, Accuracy: 0.972000, Test accuracy: 0.980800
Distillation: Epoch : 43, Loss : 0.802175, Accuracy: 0.984000, Test accuracy: 0.980700
Distillation: Epoch : 44, Loss : 0.809032, Accuracy: 0.977000, Test accuracy: 0.980900
Distillation: Epoch : 45, Loss : 0.794205, Accuracy: 0.978000, Test accuracy: 0.980900
Distillation: Epoch : 46, Loss : 0.807184, Accuracy: 0.980000, Test accuracy: 0.980900
Distillation: Epoch : 47, Loss : 0.819428, Accuracy: 0.976000, Test accuracy: 0.981800
Distillation: Epoch : 48, Loss : 0.829575, Accuracy: 0.977000, Test accuracy: 0.981700
Distillation: Epoch : 49, Loss : 0.828023, Accuracy: 0.979000, Test accuracy: 0.981700
Distillation: Epoch : 50, Loss : 0.818130, Accuracy: 0.983000, Test accuracy: 0.981800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9818
Generating confusion matrix for student
[[ 973.    0.    3.    0.    2.    2.    5.    0.    5.    3.]
 [   0. 1128.    1.    0.    1.    0.    2.    6.    1.    7.]
 [   0.    2. 1006.    0.    1.    0.    0.    7.    4.    0.]
 [   0.    0.    3.  997.    0.    6.    0.    3.    3.    3.]
 [   0.    0.    4.    0.  961.    0.    2.    0.    4.    3.]
 [   1.    1.    1.    7.    0.  876.    3.    0.    4.    3.]
 [   4.    3.    0.    0.    1.    6.  945.    0.    5.    1.]
 [   1.    0.    8.    2.    1.    0.    0. 1007.    3.    4.]
 [   1.    1.    6.    4.    1.    0.    1.    2.  941.    1.]
 [   0.    0.    0.    0.   14.    2.    0.    3.    4.  984.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.401711, Accuracy: 0.830000, Test accuracy: 0.842700
Distillation: Epoch : 2, Loss : 1.204403, Accuracy: 0.886000, Test accuracy: 0.897000
Distillation: Epoch : 3, Loss : 1.172435, Accuracy: 0.892000, Test accuracy: 0.917800
Distillation: Epoch : 4, Loss : 1.100330, Accuracy: 0.934000, Test accuracy: 0.929100
Distillation: Epoch : 5, Loss : 1.096006, Accuracy: 0.940000, Test accuracy: 0.935700
Distillation: Epoch : 6, Loss : 1.091164, Accuracy: 0.946000, Test accuracy: 0.942100
Distillation: Epoch : 7, Loss : 1.078459, Accuracy: 0.949000, Test accuracy: 0.948800
Distillation: Epoch : 8, Loss : 1.051052, Accuracy: 0.949000, Test accuracy: 0.952700
Distillation: Epoch : 9, Loss : 1.078680, Accuracy: 0.952000, Test accuracy: 0.954200
Distillation: Epoch : 10, Loss : 1.067191, Accuracy: 0.957000, Test accuracy: 0.957600
Distillation: Epoch : 11, Loss : 1.060926, Accuracy: 0.942000, Test accuracy: 0.958800
Distillation: Epoch : 12, Loss : 1.077386, Accuracy: 0.947000, Test accuracy: 0.960300
Distillation: Epoch : 13, Loss : 1.030030, Accuracy: 0.951000, Test accuracy: 0.961300
Distillation: Epoch : 14, Loss : 1.013324, Accuracy: 0.963000, Test accuracy: 0.964900
Distillation: Epoch : 15, Loss : 1.044389, Accuracy: 0.960000, Test accuracy: 0.965500
Distillation: Epoch : 16, Loss : 1.017855, Accuracy: 0.968000, Test accuracy: 0.966700
Distillation: Epoch : 17, Loss : 1.043544, Accuracy: 0.957000, Test accuracy: 0.967600
Distillation: Epoch : 18, Loss : 1.028024, Accuracy: 0.966000, Test accuracy: 0.969300
Distillation: Epoch : 19, Loss : 1.021326, Accuracy: 0.966000, Test accuracy: 0.969600
Distillation: Epoch : 20, Loss : 1.005881, Accuracy: 0.973000, Test accuracy: 0.970400
Distillation: Epoch : 21, Loss : 1.026282, Accuracy: 0.965000, Test accuracy: 0.970600
Distillation: Epoch : 22, Loss : 1.022683, Accuracy: 0.974000, Test accuracy: 0.972000
Distillation: Epoch : 23, Loss : 1.010964, Accuracy: 0.964000, Test accuracy: 0.972400
Distillation: Epoch : 24, Loss : 1.000139, Accuracy: 0.966000, Test accuracy: 0.973300
Distillation: Epoch : 25, Loss : 1.009652, Accuracy: 0.967000, Test accuracy: 0.973900
Distillation: Epoch : 26, Loss : 1.000586, Accuracy: 0.969000, Test accuracy: 0.974500
Distillation: Epoch : 27, Loss : 1.000197, Accuracy: 0.975000, Test accuracy: 0.974000
Distillation: Epoch : 28, Loss : 1.004238, Accuracy: 0.964000, Test accuracy: 0.974800
Distillation: Epoch : 29, Loss : 0.998466, Accuracy: 0.973000, Test accuracy: 0.975500
Distillation: Epoch : 30, Loss : 0.996261, Accuracy: 0.973000, Test accuracy: 0.975500
Distillation: Epoch : 31, Loss : 1.007728, Accuracy: 0.970000, Test accuracy: 0.976000
Distillation: Epoch : 32, Loss : 0.976360, Accuracy: 0.968000, Test accuracy: 0.976200
Distillation: Epoch : 33, Loss : 0.967282, Accuracy: 0.979000, Test accuracy: 0.976800
Distillation: Epoch : 34, Loss : 1.020232, Accuracy: 0.967000, Test accuracy: 0.977000
Distillation: Epoch : 35, Loss : 0.996702, Accuracy: 0.985000, Test accuracy: 0.978000
Distillation: Epoch : 36, Loss : 0.998340, Accuracy: 0.982000, Test accuracy: 0.977600
Distillation: Epoch : 37, Loss : 0.985887, Accuracy: 0.978000, Test accuracy: 0.977800
Distillation: Epoch : 38, Loss : 0.999931, Accuracy: 0.972000, Test accuracy: 0.978000
Distillation: Epoch : 39, Loss : 0.999349, Accuracy: 0.973000, Test accuracy: 0.978600
Distillation: Epoch : 40, Loss : 0.988866, Accuracy: 0.980000, Test accuracy: 0.978600
Distillation: Epoch : 41, Loss : 0.987441, Accuracy: 0.980000, Test accuracy: 0.980300
Distillation: Epoch : 42, Loss : 1.016282, Accuracy: 0.974000, Test accuracy: 0.979000
Distillation: Epoch : 43, Loss : 0.990882, Accuracy: 0.984000, Test accuracy: 0.979400
Distillation: Epoch : 44, Loss : 0.996889, Accuracy: 0.974000, Test accuracy: 0.979600
Distillation: Epoch : 45, Loss : 0.993872, Accuracy: 0.973000, Test accuracy: 0.980000
Distillation: Epoch : 46, Loss : 1.002208, Accuracy: 0.977000, Test accuracy: 0.979800
Distillation: Epoch : 47, Loss : 1.007384, Accuracy: 0.983000, Test accuracy: 0.980700
Distillation: Epoch : 48, Loss : 1.014663, Accuracy: 0.975000, Test accuracy: 0.980700
Distillation: Epoch : 49, Loss : 0.989921, Accuracy: 0.987000, Test accuracy: 0.980800
Distillation: Epoch : 50, Loss : 1.005687, Accuracy: 0.982000, Test accuracy: 0.980800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9808
Generating confusion matrix for student
[[ 977.    0.    2.    1.    1.    1.    5.    0.    4.    3.]
 [   0. 1129.    6.    0.    3.    0.    3.    7.    1.    6.]
 [   1.    3. 1004.    0.    1.    0.    0.    9.    5.    2.]
 [   0.    0.    7.  993.    0.   10.    0.    2.    5.    4.]
 [   0.    0.    2.    0.  961.    0.    3.    2.    3.    2.]
 [   1.    1.    1.    3.    0.  875.    5.    0.    4.    3.]
 [   0.    1.    0.    0.    1.    3.  941.    0.    4.    0.]
 [   1.    1.    3.    5.    1.    2.    0. 1005.    5.    3.]
 [   0.    0.    7.    7.    2.    1.    1.    1.  937.    0.]
 [   0.    0.    0.    1.   12.    0.    0.    2.    6.  986.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.700303, Accuracy: 0.785000, Test accuracy: 0.774700
Distillation: Epoch : 2, Loss : 1.394921, Accuracy: 0.859000, Test accuracy: 0.870700
Distillation: Epoch : 3, Loss : 1.350824, Accuracy: 0.894000, Test accuracy: 0.902800
Distillation: Epoch : 4, Loss : 1.277057, Accuracy: 0.909000, Test accuracy: 0.916100
Distillation: Epoch : 5, Loss : 1.284241, Accuracy: 0.918000, Test accuracy: 0.925800
Distillation: Epoch : 6, Loss : 1.282433, Accuracy: 0.916000, Test accuracy: 0.932100
Distillation: Epoch : 7, Loss : 1.248228, Accuracy: 0.941000, Test accuracy: 0.936800
Distillation: Epoch : 8, Loss : 1.216709, Accuracy: 0.943000, Test accuracy: 0.942000
Distillation: Epoch : 9, Loss : 1.234888, Accuracy: 0.942000, Test accuracy: 0.947000
Distillation: Epoch : 10, Loss : 1.230126, Accuracy: 0.943000, Test accuracy: 0.950600
Distillation: Epoch : 11, Loss : 1.204557, Accuracy: 0.951000, Test accuracy: 0.954900
Distillation: Epoch : 12, Loss : 1.209444, Accuracy: 0.947000, Test accuracy: 0.955700
Distillation: Epoch : 13, Loss : 1.199310, Accuracy: 0.959000, Test accuracy: 0.959700
Distillation: Epoch : 14, Loss : 1.203934, Accuracy: 0.938000, Test accuracy: 0.961500
Distillation: Epoch : 15, Loss : 1.204665, Accuracy: 0.965000, Test accuracy: 0.963500
Distillation: Epoch : 16, Loss : 1.179842, Accuracy: 0.967000, Test accuracy: 0.965000
Distillation: Epoch : 17, Loss : 1.185196, Accuracy: 0.969000, Test accuracy: 0.965500
Distillation: Epoch : 18, Loss : 1.174469, Accuracy: 0.969000, Test accuracy: 0.967500
Distillation: Epoch : 19, Loss : 1.173144, Accuracy: 0.970000, Test accuracy: 0.968600
Distillation: Epoch : 20, Loss : 1.147269, Accuracy: 0.971000, Test accuracy: 0.969500
Distillation: Epoch : 21, Loss : 1.175477, Accuracy: 0.967000, Test accuracy: 0.970400
Distillation: Epoch : 22, Loss : 1.172939, Accuracy: 0.977000, Test accuracy: 0.970600
Distillation: Epoch : 23, Loss : 1.189433, Accuracy: 0.966000, Test accuracy: 0.970400
Distillation: Epoch : 24, Loss : 1.173235, Accuracy: 0.973000, Test accuracy: 0.971700
Distillation: Epoch : 25, Loss : 1.159409, Accuracy: 0.974000, Test accuracy: 0.972300
Distillation: Epoch : 26, Loss : 1.161480, Accuracy: 0.968000, Test accuracy: 0.972800
Distillation: Epoch : 27, Loss : 1.155455, Accuracy: 0.979000, Test accuracy: 0.972700
Distillation: Epoch : 28, Loss : 1.168884, Accuracy: 0.959000, Test accuracy: 0.974000
Distillation: Epoch : 29, Loss : 1.151486, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 30, Loss : 1.171161, Accuracy: 0.973000, Test accuracy: 0.975300
Distillation: Epoch : 31, Loss : 1.150823, Accuracy: 0.975000, Test accuracy: 0.974400
Distillation: Epoch : 32, Loss : 1.160062, Accuracy: 0.980000, Test accuracy: 0.975700
Distillation: Epoch : 33, Loss : 1.176833, Accuracy: 0.974000, Test accuracy: 0.976300
Distillation: Epoch : 34, Loss : 1.170928, Accuracy: 0.966000, Test accuracy: 0.976900
Distillation: Epoch : 35, Loss : 1.158144, Accuracy: 0.971000, Test accuracy: 0.976800
Distillation: Epoch : 36, Loss : 1.150874, Accuracy: 0.976000, Test accuracy: 0.977600
Distillation: Epoch : 37, Loss : 1.160528, Accuracy: 0.980000, Test accuracy: 0.977800
Distillation: Epoch : 38, Loss : 1.173780, Accuracy: 0.979000, Test accuracy: 0.978500
Distillation: Epoch : 39, Loss : 1.165239, Accuracy: 0.982000, Test accuracy: 0.978300
Distillation: Epoch : 40, Loss : 1.136368, Accuracy: 0.976000, Test accuracy: 0.978500
Distillation: Epoch : 41, Loss : 1.183934, Accuracy: 0.980000, Test accuracy: 0.979400
Distillation: Epoch : 42, Loss : 1.160270, Accuracy: 0.978000, Test accuracy: 0.979200
Distillation: Epoch : 43, Loss : 1.146191, Accuracy: 0.977000, Test accuracy: 0.979900
Distillation: Epoch : 44, Loss : 1.152071, Accuracy: 0.981000, Test accuracy: 0.980200
Distillation: Epoch : 45, Loss : 1.192335, Accuracy: 0.967000, Test accuracy: 0.980300
Distillation: Epoch : 46, Loss : 1.162645, Accuracy: 0.980000, Test accuracy: 0.979600
Distillation: Epoch : 47, Loss : 1.176160, Accuracy: 0.979000, Test accuracy: 0.981100
Distillation: Epoch : 48, Loss : 1.140252, Accuracy: 0.982000, Test accuracy: 0.980800
Distillation: Epoch : 49, Loss : 1.160976, Accuracy: 0.976000, Test accuracy: 0.981100
Distillation: Epoch : 50, Loss : 1.150938, Accuracy: 0.987000, Test accuracy: 0.980600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9806
Generating confusion matrix for student
[[ 973.    0.    2.    0.    1.    1.    6.    1.    5.    6.]
 [   0. 1128.    3.    0.    1.    0.    2.    7.    0.    6.]
 [   1.    4. 1012.    1.    0.    0.    0.   10.    6.    1.]
 [   0.    0.    2.  999.    0.    7.    1.    2.    5.    3.]
 [   0.    0.    1.    0.  963.    0.    4.    1.    3.    7.]
 [   0.    1.    1.    4.    0.  879.    4.    2.    4.    5.]
 [   4.    1.    0.    0.    0.    3.  940.    0.    3.    0.]
 [   1.    0.    6.    4.    0.    1.    0.  999.    3.    5.]
 [   1.    1.    4.    1.    2.    0.    1.    2.  938.    1.]
 [   0.    0.    1.    1.   15.    1.    0.    4.    7.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.710192, Accuracy: 0.792000, Test accuracy: 0.796700
Distillation: Epoch : 2, Loss : 1.534365, Accuracy: 0.853000, Test accuracy: 0.867500
Distillation: Epoch : 3, Loss : 1.464025, Accuracy: 0.888000, Test accuracy: 0.895200
Distillation: Epoch : 4, Loss : 1.451825, Accuracy: 0.889000, Test accuracy: 0.910500
Distillation: Epoch : 5, Loss : 1.417841, Accuracy: 0.920000, Test accuracy: 0.920300
Distillation: Epoch : 6, Loss : 1.394665, Accuracy: 0.924000, Test accuracy: 0.930100
Distillation: Epoch : 7, Loss : 1.389154, Accuracy: 0.920000, Test accuracy: 0.936700
Distillation: Epoch : 8, Loss : 1.400636, Accuracy: 0.936000, Test accuracy: 0.942800
Distillation: Epoch : 9, Loss : 1.366978, Accuracy: 0.947000, Test accuracy: 0.949000
Distillation: Epoch : 10, Loss : 1.378183, Accuracy: 0.937000, Test accuracy: 0.954500
Distillation: Epoch : 11, Loss : 1.368412, Accuracy: 0.936000, Test accuracy: 0.957600
Distillation: Epoch : 12, Loss : 1.328661, Accuracy: 0.956000, Test accuracy: 0.961200
Distillation: Epoch : 13, Loss : 1.333073, Accuracy: 0.958000, Test accuracy: 0.963500
Distillation: Epoch : 14, Loss : 1.346715, Accuracy: 0.963000, Test accuracy: 0.965300
Distillation: Epoch : 15, Loss : 1.345300, Accuracy: 0.957000, Test accuracy: 0.967400
Distillation: Epoch : 16, Loss : 1.307162, Accuracy: 0.967000, Test accuracy: 0.969200
Distillation: Epoch : 17, Loss : 1.325170, Accuracy: 0.956000, Test accuracy: 0.968800
Distillation: Epoch : 18, Loss : 1.345324, Accuracy: 0.969000, Test accuracy: 0.970800
Distillation: Epoch : 19, Loss : 1.302650, Accuracy: 0.975000, Test accuracy: 0.970100
Distillation: Epoch : 20, Loss : 1.331081, Accuracy: 0.964000, Test accuracy: 0.972200
Distillation: Epoch : 21, Loss : 1.330635, Accuracy: 0.974000, Test accuracy: 0.972800
Distillation: Epoch : 22, Loss : 1.333717, Accuracy: 0.970000, Test accuracy: 0.973700
Distillation: Epoch : 23, Loss : 1.339733, Accuracy: 0.973000, Test accuracy: 0.975300
Distillation: Epoch : 24, Loss : 1.342453, Accuracy: 0.967000, Test accuracy: 0.975900
Distillation: Epoch : 25, Loss : 1.338830, Accuracy: 0.976000, Test accuracy: 0.975800
Distillation: Epoch : 26, Loss : 1.348449, Accuracy: 0.968000, Test accuracy: 0.976700
Distillation: Epoch : 27, Loss : 1.324034, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 28, Loss : 1.319991, Accuracy: 0.968000, Test accuracy: 0.976500
Distillation: Epoch : 29, Loss : 1.318387, Accuracy: 0.968000, Test accuracy: 0.976900
Distillation: Epoch : 30, Loss : 1.307931, Accuracy: 0.973000, Test accuracy: 0.976900
Distillation: Epoch : 31, Loss : 1.310171, Accuracy: 0.975000, Test accuracy: 0.976800
Distillation: Epoch : 32, Loss : 1.339656, Accuracy: 0.985000, Test accuracy: 0.977800
Distillation: Epoch : 33, Loss : 1.318285, Accuracy: 0.979000, Test accuracy: 0.978000
Distillation: Epoch : 34, Loss : 1.313779, Accuracy: 0.980000, Test accuracy: 0.977800
Distillation: Epoch : 35, Loss : 1.298303, Accuracy: 0.973000, Test accuracy: 0.978200
Distillation: Epoch : 36, Loss : 1.308541, Accuracy: 0.976000, Test accuracy: 0.978700
Distillation: Epoch : 37, Loss : 1.328892, Accuracy: 0.978000, Test accuracy: 0.978700
Distillation: Epoch : 38, Loss : 1.288128, Accuracy: 0.979000, Test accuracy: 0.979000
Distillation: Epoch : 39, Loss : 1.334641, Accuracy: 0.970000, Test accuracy: 0.979200
Distillation: Epoch : 40, Loss : 1.320414, Accuracy: 0.979000, Test accuracy: 0.979900
Distillation: Epoch : 41, Loss : 1.325337, Accuracy: 0.975000, Test accuracy: 0.979500
Distillation: Epoch : 42, Loss : 1.309434, Accuracy: 0.977000, Test accuracy: 0.979700
Distillation: Epoch : 43, Loss : 1.317420, Accuracy: 0.974000, Test accuracy: 0.979500
Distillation: Epoch : 44, Loss : 1.303712, Accuracy: 0.979000, Test accuracy: 0.979500
Distillation: Epoch : 45, Loss : 1.305168, Accuracy: 0.974000, Test accuracy: 0.980500
Distillation: Epoch : 46, Loss : 1.288113, Accuracy: 0.975000, Test accuracy: 0.980100
Distillation: Epoch : 47, Loss : 1.326281, Accuracy: 0.978000, Test accuracy: 0.980000
Distillation: Epoch : 48, Loss : 1.280481, Accuracy: 0.976000, Test accuracy: 0.980300
Distillation: Epoch : 49, Loss : 1.314628, Accuracy: 0.975000, Test accuracy: 0.980700
Distillation: Epoch : 50, Loss : 1.333032, Accuracy: 0.980000, Test accuracy: 0.980000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.98
Generating confusion matrix for student
[[ 973.    0.    2.    0.    0.    1.    5.    1.    3.    6.]
 [   1. 1127.    2.    0.    0.    0.    3.    6.    1.    4.]
 [   0.    1. 1001.    1.    2.    1.    0.    9.    7.    0.]
 [   0.    4.   10.  997.    0.    8.    0.    2.    7.    7.]
 [   0.    0.    2.    0.  965.    0.    2.    1.    3.    4.]
 [   2.    0.    1.    4.    0.  878.    6.    0.    4.    1.]
 [   2.    1.    0.    0.    2.    3.  940.    0.    2.    0.]
 [   1.    0.    4.    3.    0.    0.    0. 1000.    3.    2.]
 [   1.    2.   10.    3.    2.    0.    2.    1.  936.    2.]
 [   0.    0.    0.    2.   11.    1.    0.    8.    8.  983.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.907340, Accuracy: 0.713000, Test accuracy: 0.737500
Distillation: Epoch : 2, Loss : 1.660338, Accuracy: 0.822000, Test accuracy: 0.842600
Distillation: Epoch : 3, Loss : 1.624556, Accuracy: 0.862000, Test accuracy: 0.881100
Distillation: Epoch : 4, Loss : 1.598420, Accuracy: 0.878000, Test accuracy: 0.898100
Distillation: Epoch : 5, Loss : 1.547642, Accuracy: 0.911000, Test accuracy: 0.916200
Distillation: Epoch : 6, Loss : 1.532488, Accuracy: 0.928000, Test accuracy: 0.929300
Distillation: Epoch : 7, Loss : 1.535456, Accuracy: 0.923000, Test accuracy: 0.938000
Distillation: Epoch : 8, Loss : 1.513033, Accuracy: 0.939000, Test accuracy: 0.946200
Distillation: Epoch : 9, Loss : 1.491164, Accuracy: 0.945000, Test accuracy: 0.953800
Distillation: Epoch : 10, Loss : 1.505407, Accuracy: 0.941000, Test accuracy: 0.957200
Distillation: Epoch : 11, Loss : 1.467461, Accuracy: 0.961000, Test accuracy: 0.960200
Distillation: Epoch : 12, Loss : 1.489776, Accuracy: 0.958000, Test accuracy: 0.963500
Distillation: Epoch : 13, Loss : 1.486654, Accuracy: 0.958000, Test accuracy: 0.964200
Distillation: Epoch : 14, Loss : 1.471052, Accuracy: 0.970000, Test accuracy: 0.966400
Distillation: Epoch : 15, Loss : 1.450409, Accuracy: 0.963000, Test accuracy: 0.967700
Distillation: Epoch : 16, Loss : 1.450845, Accuracy: 0.957000, Test accuracy: 0.968900
Distillation: Epoch : 17, Loss : 1.458241, Accuracy: 0.943000, Test accuracy: 0.969900
Distillation: Epoch : 18, Loss : 1.464441, Accuracy: 0.956000, Test accuracy: 0.970100
Distillation: Epoch : 19, Loss : 1.436133, Accuracy: 0.971000, Test accuracy: 0.970900
Distillation: Epoch : 20, Loss : 1.461781, Accuracy: 0.965000, Test accuracy: 0.971700
Distillation: Epoch : 21, Loss : 1.475742, Accuracy: 0.979000, Test accuracy: 0.971300
Distillation: Epoch : 22, Loss : 1.455576, Accuracy: 0.963000, Test accuracy: 0.972600
Distillation: Epoch : 23, Loss : 1.436233, Accuracy: 0.980000, Test accuracy: 0.972700
Distillation: Epoch : 24, Loss : 1.436890, Accuracy: 0.969000, Test accuracy: 0.972900
Distillation: Epoch : 25, Loss : 1.438901, Accuracy: 0.981000, Test accuracy: 0.973800
Distillation: Epoch : 26, Loss : 1.458784, Accuracy: 0.968000, Test accuracy: 0.974600
Distillation: Epoch : 27, Loss : 1.422072, Accuracy: 0.973000, Test accuracy: 0.974700
Distillation: Epoch : 28, Loss : 1.444307, Accuracy: 0.978000, Test accuracy: 0.974200
Distillation: Epoch : 29, Loss : 1.468445, Accuracy: 0.966000, Test accuracy: 0.975200
Distillation: Epoch : 30, Loss : 1.445376, Accuracy: 0.965000, Test accuracy: 0.975200
Distillation: Epoch : 31, Loss : 1.447147, Accuracy: 0.977000, Test accuracy: 0.974700
Distillation: Epoch : 32, Loss : 1.430613, Accuracy: 0.977000, Test accuracy: 0.974800
Distillation: Epoch : 33, Loss : 1.457682, Accuracy: 0.958000, Test accuracy: 0.976200
Distillation: Epoch : 34, Loss : 1.456083, Accuracy: 0.974000, Test accuracy: 0.975700
Distillation: Epoch : 35, Loss : 1.449931, Accuracy: 0.968000, Test accuracy: 0.975800
Distillation: Epoch : 36, Loss : 1.444644, Accuracy: 0.973000, Test accuracy: 0.977000
Distillation: Epoch : 37, Loss : 1.434700, Accuracy: 0.979000, Test accuracy: 0.976500
Distillation: Epoch : 38, Loss : 1.453539, Accuracy: 0.979000, Test accuracy: 0.976500
Distillation: Epoch : 39, Loss : 1.468747, Accuracy: 0.970000, Test accuracy: 0.976800
Distillation: Epoch : 40, Loss : 1.440247, Accuracy: 0.978000, Test accuracy: 0.976300
Distillation: Epoch : 41, Loss : 1.439995, Accuracy: 0.973000, Test accuracy: 0.977200
Distillation: Epoch : 42, Loss : 1.439103, Accuracy: 0.969000, Test accuracy: 0.977700
Distillation: Epoch : 43, Loss : 1.439337, Accuracy: 0.967000, Test accuracy: 0.976800
Distillation: Epoch : 44, Loss : 1.426506, Accuracy: 0.983000, Test accuracy: 0.977200
Distillation: Epoch : 45, Loss : 1.465002, Accuracy: 0.971000, Test accuracy: 0.976600
Distillation: Epoch : 46, Loss : 1.413998, Accuracy: 0.973000, Test accuracy: 0.977400
Distillation: Epoch : 47, Loss : 1.430700, Accuracy: 0.977000, Test accuracy: 0.977000
Distillation: Epoch : 48, Loss : 1.437786, Accuracy: 0.974000, Test accuracy: 0.977700
Distillation: Epoch : 49, Loss : 1.435038, Accuracy: 0.973000, Test accuracy: 0.978200
Distillation: Epoch : 50, Loss : 1.448129, Accuracy: 0.977000, Test accuracy: 0.977700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9777
Generating confusion matrix for student
[[ 972.    0.    2.    1.    1.    1.    6.    1.    5.    6.]
 [   1. 1110.    1.    0.    1.    1.    3.    6.    0.    7.]
 [   1.    6. 1008.    0.    1.    1.    0.    7.    6.    0.]
 [   0.    0.    5.  995.    0.    6.    0.    3.    6.    2.]
 [   0.    0.    2.    1.  961.    0.    2.    1.    5.    5.]
 [   2.    1.    1.    5.    0.  877.    2.    1.    4.    2.]
 [   1.    4.    1.    0.    0.    4.  943.    0.    6.    0.]
 [   1.    0.    5.    6.    2.    1.    0. 1002.    3.    5.]
 [   2.   14.    6.    1.    2.    0.    2.    1.  931.    4.]
 [   0.    0.    1.    1.   14.    1.    0.    6.    8.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.973887, Accuracy: 0.797000, Test accuracy: 0.776100
Distillation: Epoch : 2, Loss : 1.869210, Accuracy: 0.857000, Test accuracy: 0.870700
Distillation: Epoch : 3, Loss : 1.828745, Accuracy: 0.889000, Test accuracy: 0.903600
Distillation: Epoch : 4, Loss : 1.806884, Accuracy: 0.935000, Test accuracy: 0.921300
Distillation: Epoch : 5, Loss : 1.790386, Accuracy: 0.924000, Test accuracy: 0.934300
Distillation: Epoch : 6, Loss : 1.795280, Accuracy: 0.926000, Test accuracy: 0.941800
Distillation: Epoch : 7, Loss : 1.766512, Accuracy: 0.945000, Test accuracy: 0.948300
Distillation: Epoch : 8, Loss : 1.760833, Accuracy: 0.956000, Test accuracy: 0.950400
Distillation: Epoch : 9, Loss : 1.769300, Accuracy: 0.943000, Test accuracy: 0.952200
Distillation: Epoch : 10, Loss : 1.762684, Accuracy: 0.945000, Test accuracy: 0.955100
Distillation: Epoch : 11, Loss : 1.757845, Accuracy: 0.949000, Test accuracy: 0.957300
Distillation: Epoch : 12, Loss : 1.762082, Accuracy: 0.943000, Test accuracy: 0.958000
Distillation: Epoch : 13, Loss : 1.759451, Accuracy: 0.957000, Test accuracy: 0.959100
Distillation: Epoch : 14, Loss : 1.760773, Accuracy: 0.952000, Test accuracy: 0.959500
Distillation: Epoch : 15, Loss : 1.750494, Accuracy: 0.963000, Test accuracy: 0.962500
Distillation: Epoch : 16, Loss : 1.770512, Accuracy: 0.962000, Test accuracy: 0.962000
Distillation: Epoch : 17, Loss : 1.742976, Accuracy: 0.967000, Test accuracy: 0.963700
Distillation: Epoch : 18, Loss : 1.745589, Accuracy: 0.958000, Test accuracy: 0.963400
Distillation: Epoch : 19, Loss : 1.740234, Accuracy: 0.960000, Test accuracy: 0.964000
Distillation: Epoch : 20, Loss : 1.741651, Accuracy: 0.971000, Test accuracy: 0.964300
Distillation: Epoch : 21, Loss : 1.750385, Accuracy: 0.967000, Test accuracy: 0.966000
Distillation: Epoch : 22, Loss : 1.742798, Accuracy: 0.964000, Test accuracy: 0.966600
Distillation: Epoch : 23, Loss : 1.745538, Accuracy: 0.955000, Test accuracy: 0.967700
Distillation: Epoch : 24, Loss : 1.742908, Accuracy: 0.965000, Test accuracy: 0.967700
Distillation: Epoch : 25, Loss : 1.743189, Accuracy: 0.969000, Test accuracy: 0.969600
Distillation: Epoch : 26, Loss : 1.751301, Accuracy: 0.952000, Test accuracy: 0.970000
Distillation: Epoch : 27, Loss : 1.743893, Accuracy: 0.962000, Test accuracy: 0.969800
Distillation: Epoch : 28, Loss : 1.717111, Accuracy: 0.969000, Test accuracy: 0.970600
Distillation: Epoch : 29, Loss : 1.742727, Accuracy: 0.960000, Test accuracy: 0.970600
Distillation: Epoch : 30, Loss : 1.754973, Accuracy: 0.971000, Test accuracy: 0.972100
Distillation: Epoch : 31, Loss : 1.754726, Accuracy: 0.974000, Test accuracy: 0.972000
Distillation: Epoch : 32, Loss : 1.738200, Accuracy: 0.971000, Test accuracy: 0.972400
Distillation: Epoch : 33, Loss : 1.729273, Accuracy: 0.970000, Test accuracy: 0.973000
Distillation: Epoch : 34, Loss : 1.740834, Accuracy: 0.963000, Test accuracy: 0.973000
Distillation: Epoch : 35, Loss : 1.727751, Accuracy: 0.974000, Test accuracy: 0.974000
Distillation: Epoch : 36, Loss : 1.749252, Accuracy: 0.975000, Test accuracy: 0.973500
Distillation: Epoch : 37, Loss : 1.739963, Accuracy: 0.973000, Test accuracy: 0.973800
Distillation: Epoch : 38, Loss : 1.726258, Accuracy: 0.975000, Test accuracy: 0.974100
Distillation: Epoch : 39, Loss : 1.728927, Accuracy: 0.968000, Test accuracy: 0.975100
Distillation: Epoch : 40, Loss : 1.739116, Accuracy: 0.971000, Test accuracy: 0.975400
Distillation: Epoch : 41, Loss : 1.734625, Accuracy: 0.977000, Test accuracy: 0.976600
Distillation: Epoch : 42, Loss : 1.739951, Accuracy: 0.972000, Test accuracy: 0.976700
Distillation: Epoch : 43, Loss : 1.740983, Accuracy: 0.968000, Test accuracy: 0.976700
Distillation: Epoch : 44, Loss : 1.745215, Accuracy: 0.968000, Test accuracy: 0.976500
Distillation: Epoch : 45, Loss : 1.722694, Accuracy: 0.976000, Test accuracy: 0.977600
Distillation: Epoch : 46, Loss : 1.740524, Accuracy: 0.978000, Test accuracy: 0.977500
Distillation: Epoch : 47, Loss : 1.748315, Accuracy: 0.966000, Test accuracy: 0.978400
Distillation: Epoch : 48, Loss : 1.726470, Accuracy: 0.973000, Test accuracy: 0.977600
Distillation: Epoch : 49, Loss : 1.731577, Accuracy: 0.968000, Test accuracy: 0.978200
Distillation: Epoch : 50, Loss : 1.742683, Accuracy: 0.970000, Test accuracy: 0.978100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9781
Generating confusion matrix for student
[[ 976.    0.    3.    1.    1.    2.    5.    0.    6.    3.]
 [   0. 1127.    4.    0.    1.    0.    2.    9.    2.    7.]
 [   0.    3. 1003.    0.    1.    0.    0.    5.    4.    0.]
 [   0.    2.    7.  990.    0.    6.    0.    2.    6.    6.]
 [   0.    0.    2.    0.  965.    1.    3.    1.    6.    7.]
 [   2.    0.    1.    8.    0.  878.    6.    0.    9.    0.]
 [   0.    2.    0.    0.    2.    4.  940.    0.    6.    0.]
 [   1.    0.    6.    9.    0.    0.    0.  999.    5.    4.]
 [   1.    1.    6.    2.    1.    0.    2.    1.  922.    1.]
 [   0.    0.    0.    0.   11.    1.    0.   11.    8.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.132644, Accuracy: 0.753000, Test accuracy: 0.770300
Distillation: Epoch : 2, Loss : 2.074897, Accuracy: 0.841000, Test accuracy: 0.849100
Distillation: Epoch : 3, Loss : 2.056125, Accuracy: 0.870000, Test accuracy: 0.869900
Distillation: Epoch : 4, Loss : 2.051160, Accuracy: 0.887000, Test accuracy: 0.891100
Distillation: Epoch : 5, Loss : 2.037146, Accuracy: 0.890000, Test accuracy: 0.905200
Distillation: Epoch : 6, Loss : 2.041938, Accuracy: 0.903000, Test accuracy: 0.916600
Distillation: Epoch : 7, Loss : 2.027360, Accuracy: 0.929000, Test accuracy: 0.925200
Distillation: Epoch : 8, Loss : 2.025958, Accuracy: 0.936000, Test accuracy: 0.934900
Distillation: Epoch : 9, Loss : 2.029574, Accuracy: 0.932000, Test accuracy: 0.941600
Distillation: Epoch : 10, Loss : 2.024974, Accuracy: 0.942000, Test accuracy: 0.948100
Distillation: Epoch : 11, Loss : 2.011956, Accuracy: 0.956000, Test accuracy: 0.951500
Distillation: Epoch : 12, Loss : 2.007085, Accuracy: 0.959000, Test accuracy: 0.953500
Distillation: Epoch : 13, Loss : 2.006468, Accuracy: 0.949000, Test accuracy: 0.955300
Distillation: Epoch : 14, Loss : 2.007706, Accuracy: 0.960000, Test accuracy: 0.958400
Distillation: Epoch : 15, Loss : 2.008818, Accuracy: 0.957000, Test accuracy: 0.959900
Distillation: Epoch : 16, Loss : 1.992049, Accuracy: 0.958000, Test accuracy: 0.963900
Distillation: Epoch : 17, Loss : 1.999840, Accuracy: 0.957000, Test accuracy: 0.964100
Distillation: Epoch : 18, Loss : 2.009767, Accuracy: 0.946000, Test accuracy: 0.966000
Distillation: Epoch : 19, Loss : 2.007188, Accuracy: 0.964000, Test accuracy: 0.967000
Distillation: Epoch : 20, Loss : 2.005517, Accuracy: 0.960000, Test accuracy: 0.968100
Distillation: Epoch : 21, Loss : 2.001879, Accuracy: 0.965000, Test accuracy: 0.969100
Distillation: Epoch : 22, Loss : 1.998907, Accuracy: 0.968000, Test accuracy: 0.969500
Distillation: Epoch : 23, Loss : 2.006155, Accuracy: 0.968000, Test accuracy: 0.969100
Distillation: Epoch : 24, Loss : 1.997041, Accuracy: 0.969000, Test accuracy: 0.969500
Distillation: Epoch : 25, Loss : 2.006909, Accuracy: 0.960000, Test accuracy: 0.970100
Distillation: Epoch : 26, Loss : 2.001029, Accuracy: 0.970000, Test accuracy: 0.971500
Distillation: Epoch : 27, Loss : 2.001081, Accuracy: 0.970000, Test accuracy: 0.970700
Distillation: Epoch : 28, Loss : 1.990756, Accuracy: 0.970000, Test accuracy: 0.971700
Distillation: Epoch : 29, Loss : 1.990922, Accuracy: 0.970000, Test accuracy: 0.972500
Distillation: Epoch : 30, Loss : 1.997965, Accuracy: 0.976000, Test accuracy: 0.971600
Distillation: Epoch : 31, Loss : 2.000012, Accuracy: 0.966000, Test accuracy: 0.972800
Distillation: Epoch : 32, Loss : 1.996285, Accuracy: 0.957000, Test accuracy: 0.972400
Distillation: Epoch : 33, Loss : 1.983111, Accuracy: 0.966000, Test accuracy: 0.973400
Distillation: Epoch : 34, Loss : 2.002329, Accuracy: 0.976000, Test accuracy: 0.974200
Distillation: Epoch : 35, Loss : 1.999208, Accuracy: 0.971000, Test accuracy: 0.974400
Distillation: Epoch : 36, Loss : 2.005875, Accuracy: 0.973000, Test accuracy: 0.974200
Distillation: Epoch : 37, Loss : 1.998670, Accuracy: 0.968000, Test accuracy: 0.974600
Distillation: Epoch : 38, Loss : 1.995688, Accuracy: 0.970000, Test accuracy: 0.974900
Distillation: Epoch : 39, Loss : 1.997089, Accuracy: 0.971000, Test accuracy: 0.974700
Distillation: Epoch : 40, Loss : 2.001650, Accuracy: 0.970000, Test accuracy: 0.975300
Distillation: Epoch : 41, Loss : 1.998105, Accuracy: 0.969000, Test accuracy: 0.976200
Distillation: Epoch : 42, Loss : 1.992539, Accuracy: 0.980000, Test accuracy: 0.975400
Distillation: Epoch : 43, Loss : 1.991968, Accuracy: 0.969000, Test accuracy: 0.976100
Distillation: Epoch : 44, Loss : 2.006489, Accuracy: 0.979000, Test accuracy: 0.975600
Distillation: Epoch : 45, Loss : 1.985753, Accuracy: 0.978000, Test accuracy: 0.976800
Distillation: Epoch : 46, Loss : 1.991740, Accuracy: 0.970000, Test accuracy: 0.976600
Distillation: Epoch : 47, Loss : 1.986942, Accuracy: 0.979000, Test accuracy: 0.976600
Distillation: Epoch : 48, Loss : 1.983626, Accuracy: 0.971000, Test accuracy: 0.977200
Distillation: Epoch : 49, Loss : 1.990048, Accuracy: 0.971000, Test accuracy: 0.977000
Distillation: Epoch : 50, Loss : 1.985844, Accuracy: 0.970000, Test accuracy: 0.977100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9771
Generating confusion matrix for student
[[ 971.    0.    3.    0.    1.    3.    7.    1.    2.    5.]
 [   0. 1121.    2.    0.    1.    0.    3.    7.    0.    6.]
 [   0.    3. 1007.    2.    2.    1.    0.   11.    5.    0.]
 [   0.    1.    9.  999.    0.    7.    0.    3.   11.    9.]
 [   0.    0.    0.    0.  960.    0.    2.    1.    5.    7.]
 [   1.    1.    0.    4.    0.  876.    4.    1.    7.    1.]
 [   6.    3.    0.    0.    1.    4.  941.    0.    2.    0.]
 [   1.    0.    5.    1.    1.    0.    0.  992.    4.    6.]
 [   1.    6.    6.    3.    1.    1.    1.    3.  930.    1.]
 [   0.    0.    0.    1.   15.    0.    0.    9.    8.  974.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.750008, Accuracy: 0.822000, Test accuracy: 0.834900
Distillation: Epoch : 2, Loss : 0.418025, Accuracy: 0.888000, Test accuracy: 0.897900
Distillation: Epoch : 3, Loss : 0.316182, Accuracy: 0.911000, Test accuracy: 0.916200
Distillation: Epoch : 4, Loss : 0.283752, Accuracy: 0.929000, Test accuracy: 0.925000
Distillation: Epoch : 5, Loss : 0.274280, Accuracy: 0.922000, Test accuracy: 0.931600
Distillation: Epoch : 6, Loss : 0.250489, Accuracy: 0.930000, Test accuracy: 0.936000
Distillation: Epoch : 7, Loss : 0.203126, Accuracy: 0.942000, Test accuracy: 0.939400
Distillation: Epoch : 8, Loss : 0.209474, Accuracy: 0.927000, Test accuracy: 0.943500
Distillation: Epoch : 9, Loss : 0.195795, Accuracy: 0.940000, Test accuracy: 0.944100
Distillation: Epoch : 10, Loss : 0.172219, Accuracy: 0.955000, Test accuracy: 0.948300
Distillation: Epoch : 11, Loss : 0.201176, Accuracy: 0.945000, Test accuracy: 0.949500
Distillation: Epoch : 12, Loss : 0.185086, Accuracy: 0.953000, Test accuracy: 0.952400
Distillation: Epoch : 13, Loss : 0.201208, Accuracy: 0.948000, Test accuracy: 0.952800
Distillation: Epoch : 14, Loss : 0.168470, Accuracy: 0.958000, Test accuracy: 0.954200
Distillation: Epoch : 15, Loss : 0.181591, Accuracy: 0.948000, Test accuracy: 0.956200
Distillation: Epoch : 16, Loss : 0.181382, Accuracy: 0.947000, Test accuracy: 0.957300
Distillation: Epoch : 17, Loss : 0.142686, Accuracy: 0.962000, Test accuracy: 0.958300
Distillation: Epoch : 18, Loss : 0.138120, Accuracy: 0.960000, Test accuracy: 0.958900
Distillation: Epoch : 19, Loss : 0.126524, Accuracy: 0.963000, Test accuracy: 0.961500
Distillation: Epoch : 20, Loss : 0.165473, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 21, Loss : 0.110905, Accuracy: 0.972000, Test accuracy: 0.961000
Distillation: Epoch : 22, Loss : 0.121225, Accuracy: 0.961000, Test accuracy: 0.962700
Distillation: Epoch : 23, Loss : 0.132835, Accuracy: 0.964000, Test accuracy: 0.963600
Distillation: Epoch : 24, Loss : 0.125981, Accuracy: 0.957000, Test accuracy: 0.964200
Distillation: Epoch : 25, Loss : 0.146090, Accuracy: 0.966000, Test accuracy: 0.964000
Distillation: Epoch : 26, Loss : 0.097372, Accuracy: 0.974000, Test accuracy: 0.965400
Distillation: Epoch : 27, Loss : 0.104175, Accuracy: 0.967000, Test accuracy: 0.965800
Distillation: Epoch : 28, Loss : 0.134612, Accuracy: 0.963000, Test accuracy: 0.966800
Distillation: Epoch : 29, Loss : 0.123078, Accuracy: 0.967000, Test accuracy: 0.966600
Distillation: Epoch : 30, Loss : 0.110449, Accuracy: 0.968000, Test accuracy: 0.967300
Distillation: Epoch : 31, Loss : 0.101495, Accuracy: 0.979000, Test accuracy: 0.968200
Distillation: Epoch : 32, Loss : 0.100649, Accuracy: 0.959000, Test accuracy: 0.968100
Distillation: Epoch : 33, Loss : 0.146113, Accuracy: 0.956000, Test accuracy: 0.968000
Distillation: Epoch : 34, Loss : 0.111858, Accuracy: 0.976000, Test accuracy: 0.968600
Distillation: Epoch : 35, Loss : 0.099043, Accuracy: 0.971000, Test accuracy: 0.968100
Distillation: Epoch : 36, Loss : 0.113443, Accuracy: 0.968000, Test accuracy: 0.969000
Distillation: Epoch : 37, Loss : 0.109332, Accuracy: 0.964000, Test accuracy: 0.969700
Distillation: Epoch : 38, Loss : 0.129059, Accuracy: 0.960000, Test accuracy: 0.969700
Distillation: Epoch : 39, Loss : 0.110965, Accuracy: 0.970000, Test accuracy: 0.969500
Distillation: Epoch : 40, Loss : 0.112098, Accuracy: 0.962000, Test accuracy: 0.970600
Distillation: Epoch : 41, Loss : 0.106444, Accuracy: 0.963000, Test accuracy: 0.969600
Distillation: Epoch : 42, Loss : 0.081922, Accuracy: 0.979000, Test accuracy: 0.969700
Distillation: Epoch : 43, Loss : 0.122219, Accuracy: 0.961000, Test accuracy: 0.970800
Distillation: Epoch : 44, Loss : 0.125863, Accuracy: 0.970000, Test accuracy: 0.971100
Distillation: Epoch : 45, Loss : 0.081377, Accuracy: 0.978000, Test accuracy: 0.971900
Distillation: Epoch : 46, Loss : 0.080879, Accuracy: 0.980000, Test accuracy: 0.971200
Distillation: Epoch : 47, Loss : 0.140557, Accuracy: 0.961000, Test accuracy: 0.970500
Distillation: Epoch : 48, Loss : 0.093664, Accuracy: 0.978000, Test accuracy: 0.972400
Distillation: Epoch : 49, Loss : 0.084377, Accuracy: 0.980000, Test accuracy: 0.971600
Distillation: Epoch : 50, Loss : 0.115258, Accuracy: 0.967000, Test accuracy: 0.971900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9719
Generating confusion matrix for student2
[[ 970.    0.    3.    0.    1.    2.   12.    2.    7.   10.]
 [   0. 1124.    8.    0.    1.    1.    3.    3.    1.    6.]
 [   1.    5.  985.    4.    2.    0.    0.   13.    7.    1.]
 [   0.    1.    7.  988.    0.    7.    1.    4.    7.    7.]
 [   0.    0.    3.    1.  969.    0.    4.    1.    1.    9.]
 [   0.    1.    0.    5.    0.  867.    3.    0.    5.    2.]
 [   2.    2.    3.    0.    0.    4.  932.    0.    2.    0.]
 [   4.    0.    7.    5.    1.    1.    0.  988.    7.   10.]
 [   3.    2.   14.    6.    2.   10.    3.    4.  934.    2.]
 [   0.    0.    2.    1.    6.    0.    0.   13.    3.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.953914, Accuracy: 0.793000, Test accuracy: 0.801900
Distillation: Epoch : 2, Loss : 0.590297, Accuracy: 0.838000, Test accuracy: 0.859600
Distillation: Epoch : 3, Loss : 0.506260, Accuracy: 0.872000, Test accuracy: 0.882400
Distillation: Epoch : 4, Loss : 0.420326, Accuracy: 0.886000, Test accuracy: 0.891100
Distillation: Epoch : 5, Loss : 0.346413, Accuracy: 0.920000, Test accuracy: 0.898000
Distillation: Epoch : 6, Loss : 0.375135, Accuracy: 0.908000, Test accuracy: 0.902500
Distillation: Epoch : 7, Loss : 0.379352, Accuracy: 0.894000, Test accuracy: 0.905600
Distillation: Epoch : 8, Loss : 0.343383, Accuracy: 0.906000, Test accuracy: 0.907100
Distillation: Epoch : 9, Loss : 0.319832, Accuracy: 0.904000, Test accuracy: 0.910100
Distillation: Epoch : 10, Loss : 0.354384, Accuracy: 0.908000, Test accuracy: 0.911300
Distillation: Epoch : 11, Loss : 0.292953, Accuracy: 0.918000, Test accuracy: 0.912400
Distillation: Epoch : 12, Loss : 0.333421, Accuracy: 0.900000, Test accuracy: 0.912600
Distillation: Epoch : 13, Loss : 0.347103, Accuracy: 0.908000, Test accuracy: 0.914000
Distillation: Epoch : 14, Loss : 0.315533, Accuracy: 0.915000, Test accuracy: 0.914500
Distillation: Epoch : 15, Loss : 0.314589, Accuracy: 0.903000, Test accuracy: 0.914800
Distillation: Epoch : 16, Loss : 0.365917, Accuracy: 0.899000, Test accuracy: 0.916400
Distillation: Epoch : 17, Loss : 0.309209, Accuracy: 0.910000, Test accuracy: 0.916900
Distillation: Epoch : 18, Loss : 0.363560, Accuracy: 0.898000, Test accuracy: 0.917400
Distillation: Epoch : 19, Loss : 0.247066, Accuracy: 0.933000, Test accuracy: 0.918600
Distillation: Epoch : 20, Loss : 0.280774, Accuracy: 0.924000, Test accuracy: 0.917900
Distillation: Epoch : 21, Loss : 0.333226, Accuracy: 0.907000, Test accuracy: 0.917000
Distillation: Epoch : 22, Loss : 0.336029, Accuracy: 0.914000, Test accuracy: 0.919200
Distillation: Epoch : 23, Loss : 0.288876, Accuracy: 0.929000, Test accuracy: 0.920300
Distillation: Epoch : 24, Loss : 0.296550, Accuracy: 0.917000, Test accuracy: 0.920100
Distillation: Epoch : 25, Loss : 0.285935, Accuracy: 0.924000, Test accuracy: 0.921100
Distillation: Epoch : 26, Loss : 0.279336, Accuracy: 0.930000, Test accuracy: 0.921300
Distillation: Epoch : 27, Loss : 0.282633, Accuracy: 0.917000, Test accuracy: 0.923100
Distillation: Epoch : 28, Loss : 0.272912, Accuracy: 0.927000, Test accuracy: 0.921300
Distillation: Epoch : 29, Loss : 0.258144, Accuracy: 0.930000, Test accuracy: 0.923800
Distillation: Epoch : 30, Loss : 0.291229, Accuracy: 0.920000, Test accuracy: 0.925000
Distillation: Epoch : 31, Loss : 0.294112, Accuracy: 0.922000, Test accuracy: 0.924500
Distillation: Epoch : 32, Loss : 0.253488, Accuracy: 0.936000, Test accuracy: 0.925700
Distillation: Epoch : 33, Loss : 0.319648, Accuracy: 0.913000, Test accuracy: 0.926200
Distillation: Epoch : 34, Loss : 0.302873, Accuracy: 0.920000, Test accuracy: 0.926700
Distillation: Epoch : 35, Loss : 0.257514, Accuracy: 0.928000, Test accuracy: 0.928500
Distillation: Epoch : 36, Loss : 0.265396, Accuracy: 0.924000, Test accuracy: 0.927600
Distillation: Epoch : 37, Loss : 0.314027, Accuracy: 0.911000, Test accuracy: 0.929500
Distillation: Epoch : 38, Loss : 0.227349, Accuracy: 0.940000, Test accuracy: 0.930100
Distillation: Epoch : 39, Loss : 0.264326, Accuracy: 0.934000, Test accuracy: 0.930400
Distillation: Epoch : 40, Loss : 0.269659, Accuracy: 0.940000, Test accuracy: 0.931600
Distillation: Epoch : 41, Loss : 0.281853, Accuracy: 0.926000, Test accuracy: 0.932500
Distillation: Epoch : 42, Loss : 0.257501, Accuracy: 0.935000, Test accuracy: 0.933300
Distillation: Epoch : 43, Loss : 0.249571, Accuracy: 0.936000, Test accuracy: 0.932800
Distillation: Epoch : 44, Loss : 0.266206, Accuracy: 0.921000, Test accuracy: 0.933100
Distillation: Epoch : 45, Loss : 0.284240, Accuracy: 0.928000, Test accuracy: 0.935500
Distillation: Epoch : 46, Loss : 0.260776, Accuracy: 0.921000, Test accuracy: 0.936300
Distillation: Epoch : 47, Loss : 0.252909, Accuracy: 0.941000, Test accuracy: 0.937800
Distillation: Epoch : 48, Loss : 0.255251, Accuracy: 0.938000, Test accuracy: 0.937500
Distillation: Epoch : 49, Loss : 0.210966, Accuracy: 0.950000, Test accuracy: 0.937500
Distillation: Epoch : 50, Loss : 0.250133, Accuracy: 0.937000, Test accuracy: 0.939500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9395
Generating confusion matrix for student2
[[ 963.    0.    5.    3.    1.    5.    9.    1.    9.    8.]
 [   0. 1116.    9.    0.    1.    2.    3.    8.    5.    7.]
 [   2.    3.  941.   14.    7.    3.    4.   21.    9.    2.]
 [   1.    2.   15.  943.    2.   29.    2.    9.   16.   11.]
 [   0.    0.    9.    2.  932.    5.    6.    6.    9.   21.]
 [   3.    2.    1.   18.    0.  808.   11.    1.   13.   11.]
 [   7.    3.    8.    1.    6.   13.  919.    0.    9.    0.]
 [   2.    1.   11.   10.    3.    3.    2.  952.    6.   14.]
 [   2.    8.   27.   12.    9.   21.    2.    2.  889.    3.]
 [   0.    0.    6.    7.   21.    3.    0.   28.    9.  932.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.448729, Accuracy: 0.733000, Test accuracy: 0.765200
Distillation: Epoch : 2, Loss : 0.937184, Accuracy: 0.817000, Test accuracy: 0.833900
Distillation: Epoch : 3, Loss : 0.808366, Accuracy: 0.848000, Test accuracy: 0.870900
Distillation: Epoch : 4, Loss : 0.712919, Accuracy: 0.879000, Test accuracy: 0.886100
Distillation: Epoch : 5, Loss : 0.705401, Accuracy: 0.880000, Test accuracy: 0.891800
Distillation: Epoch : 6, Loss : 0.695929, Accuracy: 0.882000, Test accuracy: 0.899700
Distillation: Epoch : 7, Loss : 0.705639, Accuracy: 0.893000, Test accuracy: 0.903300
Distillation: Epoch : 8, Loss : 0.639454, Accuracy: 0.909000, Test accuracy: 0.905700
Distillation: Epoch : 9, Loss : 0.708818, Accuracy: 0.887000, Test accuracy: 0.907000
Distillation: Epoch : 10, Loss : 0.670477, Accuracy: 0.901000, Test accuracy: 0.907800
Distillation: Epoch : 11, Loss : 0.651274, Accuracy: 0.901000, Test accuracy: 0.908100
Distillation: Epoch : 12, Loss : 0.649380, Accuracy: 0.905000, Test accuracy: 0.909600
Distillation: Epoch : 13, Loss : 0.679537, Accuracy: 0.900000, Test accuracy: 0.912400
Distillation: Epoch : 14, Loss : 0.619858, Accuracy: 0.920000, Test accuracy: 0.912800
Distillation: Epoch : 15, Loss : 0.677886, Accuracy: 0.899000, Test accuracy: 0.913200
Distillation: Epoch : 16, Loss : 0.650192, Accuracy: 0.898000, Test accuracy: 0.914100
Distillation: Epoch : 17, Loss : 0.659012, Accuracy: 0.908000, Test accuracy: 0.915400
Distillation: Epoch : 18, Loss : 0.623049, Accuracy: 0.915000, Test accuracy: 0.916200
Distillation: Epoch : 19, Loss : 0.665439, Accuracy: 0.900000, Test accuracy: 0.917900
Distillation: Epoch : 20, Loss : 0.642185, Accuracy: 0.909000, Test accuracy: 0.917800
Distillation: Epoch : 21, Loss : 0.600583, Accuracy: 0.934000, Test accuracy: 0.919100
Distillation: Epoch : 22, Loss : 0.633264, Accuracy: 0.902000, Test accuracy: 0.920800
Distillation: Epoch : 23, Loss : 0.602395, Accuracy: 0.920000, Test accuracy: 0.920600
Distillation: Epoch : 24, Loss : 0.625171, Accuracy: 0.907000, Test accuracy: 0.921600
Distillation: Epoch : 25, Loss : 0.622832, Accuracy: 0.919000, Test accuracy: 0.921900
Distillation: Epoch : 26, Loss : 0.628843, Accuracy: 0.915000, Test accuracy: 0.923900
Distillation: Epoch : 27, Loss : 0.607917, Accuracy: 0.924000, Test accuracy: 0.926200
Distillation: Epoch : 28, Loss : 0.579525, Accuracy: 0.927000, Test accuracy: 0.926500
Distillation: Epoch : 29, Loss : 0.598183, Accuracy: 0.924000, Test accuracy: 0.927400
Distillation: Epoch : 30, Loss : 0.602042, Accuracy: 0.925000, Test accuracy: 0.929100
Distillation: Epoch : 31, Loss : 0.603669, Accuracy: 0.925000, Test accuracy: 0.929400
Distillation: Epoch : 32, Loss : 0.601280, Accuracy: 0.920000, Test accuracy: 0.930400
Distillation: Epoch : 33, Loss : 0.561471, Accuracy: 0.932000, Test accuracy: 0.932800
Distillation: Epoch : 34, Loss : 0.596102, Accuracy: 0.921000, Test accuracy: 0.935000
Distillation: Epoch : 35, Loss : 0.559458, Accuracy: 0.945000, Test accuracy: 0.935200
Distillation: Epoch : 36, Loss : 0.584017, Accuracy: 0.935000, Test accuracy: 0.935600
Distillation: Epoch : 37, Loss : 0.586116, Accuracy: 0.943000, Test accuracy: 0.936600
Distillation: Epoch : 38, Loss : 0.533360, Accuracy: 0.948000, Test accuracy: 0.938000
Distillation: Epoch : 39, Loss : 0.588717, Accuracy: 0.920000, Test accuracy: 0.939200
Distillation: Epoch : 40, Loss : 0.571208, Accuracy: 0.930000, Test accuracy: 0.939700
Distillation: Epoch : 41, Loss : 0.550763, Accuracy: 0.940000, Test accuracy: 0.941500
Distillation: Epoch : 42, Loss : 0.565372, Accuracy: 0.930000, Test accuracy: 0.941900
Distillation: Epoch : 43, Loss : 0.592674, Accuracy: 0.935000, Test accuracy: 0.943700
Distillation: Epoch : 44, Loss : 0.522779, Accuracy: 0.941000, Test accuracy: 0.943000
Distillation: Epoch : 45, Loss : 0.521545, Accuracy: 0.947000, Test accuracy: 0.944300
Distillation: Epoch : 46, Loss : 0.551804, Accuracy: 0.942000, Test accuracy: 0.945300
Distillation: Epoch : 47, Loss : 0.534176, Accuracy: 0.958000, Test accuracy: 0.947000
Distillation: Epoch : 48, Loss : 0.541991, Accuracy: 0.938000, Test accuracy: 0.946900
Distillation: Epoch : 49, Loss : 0.546638, Accuracy: 0.944000, Test accuracy: 0.948500
Distillation: Epoch : 50, Loss : 0.557122, Accuracy: 0.935000, Test accuracy: 0.949500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9495
Generating confusion matrix for student2
[[ 964.    0.    9.    0.    1.    5.    8.    2.    6.    9.]
 [   0. 1123.    7.    1.    3.    1.    4.    8.    2.    5.]
 [   1.    2.  951.    8.    2.    2.    1.   22.   11.    1.]
 [   1.    3.   10.  965.    0.   17.    0.    5.   20.   11.]
 [   1.    0.   10.    0.  940.    0.    7.    4.    8.   13.]
 [   3.    2.    0.    9.    0.  830.   13.    0.   12.    4.]
 [   5.    4.    4.    0.    7.    9.  924.    0.    3.    0.]
 [   2.    0.   11.    8.    2.    4.    0.  954.    6.   12.]
 [   2.    1.   28.   17.    2.   16.    1.    2.  894.    4.]
 [   1.    0.    2.    2.   25.    8.    0.   31.   12.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.432433, Accuracy: 0.762000, Test accuracy: 0.765900
Distillation: Epoch : 2, Loss : 1.059514, Accuracy: 0.799000, Test accuracy: 0.839800
Distillation: Epoch : 3, Loss : 0.925117, Accuracy: 0.860000, Test accuracy: 0.867800
Distillation: Epoch : 4, Loss : 0.926210, Accuracy: 0.857000, Test accuracy: 0.880800
Distillation: Epoch : 5, Loss : 0.859961, Accuracy: 0.884000, Test accuracy: 0.889600
Distillation: Epoch : 6, Loss : 0.847197, Accuracy: 0.884000, Test accuracy: 0.894100
Distillation: Epoch : 7, Loss : 0.886017, Accuracy: 0.882000, Test accuracy: 0.898500
Distillation: Epoch : 8, Loss : 0.900458, Accuracy: 0.878000, Test accuracy: 0.901500
Distillation: Epoch : 9, Loss : 0.807273, Accuracy: 0.921000, Test accuracy: 0.903100
Distillation: Epoch : 10, Loss : 0.859210, Accuracy: 0.892000, Test accuracy: 0.903900
Distillation: Epoch : 11, Loss : 0.844168, Accuracy: 0.903000, Test accuracy: 0.905700
Distillation: Epoch : 12, Loss : 0.823085, Accuracy: 0.908000, Test accuracy: 0.908000
Distillation: Epoch : 13, Loss : 0.861047, Accuracy: 0.892000, Test accuracy: 0.907800
Distillation: Epoch : 14, Loss : 0.835331, Accuracy: 0.903000, Test accuracy: 0.909900
Distillation: Epoch : 15, Loss : 0.805501, Accuracy: 0.894000, Test accuracy: 0.910800
Distillation: Epoch : 16, Loss : 0.820512, Accuracy: 0.893000, Test accuracy: 0.910500
Distillation: Epoch : 17, Loss : 0.802702, Accuracy: 0.920000, Test accuracy: 0.911300
Distillation: Epoch : 18, Loss : 0.765798, Accuracy: 0.921000, Test accuracy: 0.912700
Distillation: Epoch : 19, Loss : 0.832629, Accuracy: 0.914000, Test accuracy: 0.913000
Distillation: Epoch : 20, Loss : 0.819425, Accuracy: 0.908000, Test accuracy: 0.914600
Distillation: Epoch : 21, Loss : 0.817711, Accuracy: 0.897000, Test accuracy: 0.913800
Distillation: Epoch : 22, Loss : 0.804784, Accuracy: 0.902000, Test accuracy: 0.914400
Distillation: Epoch : 23, Loss : 0.820364, Accuracy: 0.908000, Test accuracy: 0.914400
Distillation: Epoch : 24, Loss : 0.767753, Accuracy: 0.927000, Test accuracy: 0.913600
Distillation: Epoch : 25, Loss : 0.800206, Accuracy: 0.909000, Test accuracy: 0.915600
Distillation: Epoch : 26, Loss : 0.814801, Accuracy: 0.904000, Test accuracy: 0.915200
Distillation: Epoch : 27, Loss : 0.810811, Accuracy: 0.904000, Test accuracy: 0.916200
Distillation: Epoch : 28, Loss : 0.803303, Accuracy: 0.907000, Test accuracy: 0.916800
Distillation: Epoch : 29, Loss : 0.771555, Accuracy: 0.921000, Test accuracy: 0.916500
Distillation: Epoch : 30, Loss : 0.798763, Accuracy: 0.911000, Test accuracy: 0.916800
Distillation: Epoch : 31, Loss : 0.794281, Accuracy: 0.921000, Test accuracy: 0.918000
Distillation: Epoch : 32, Loss : 0.776584, Accuracy: 0.909000, Test accuracy: 0.917900
Distillation: Epoch : 33, Loss : 0.794884, Accuracy: 0.923000, Test accuracy: 0.919000
Distillation: Epoch : 34, Loss : 0.799242, Accuracy: 0.904000, Test accuracy: 0.919800
Distillation: Epoch : 35, Loss : 0.801778, Accuracy: 0.915000, Test accuracy: 0.918900
Distillation: Epoch : 36, Loss : 0.778829, Accuracy: 0.918000, Test accuracy: 0.920700
Distillation: Epoch : 37, Loss : 0.800892, Accuracy: 0.901000, Test accuracy: 0.921600
Distillation: Epoch : 38, Loss : 0.757823, Accuracy: 0.922000, Test accuracy: 0.922100
Distillation: Epoch : 39, Loss : 0.783805, Accuracy: 0.915000, Test accuracy: 0.921900
Distillation: Epoch : 40, Loss : 0.797655, Accuracy: 0.907000, Test accuracy: 0.922500
Distillation: Epoch : 41, Loss : 0.796134, Accuracy: 0.922000, Test accuracy: 0.924300
Distillation: Epoch : 42, Loss : 0.787499, Accuracy: 0.925000, Test accuracy: 0.924500
Distillation: Epoch : 43, Loss : 0.763686, Accuracy: 0.920000, Test accuracy: 0.924000
Distillation: Epoch : 44, Loss : 0.733893, Accuracy: 0.939000, Test accuracy: 0.926100
Distillation: Epoch : 45, Loss : 0.750384, Accuracy: 0.919000, Test accuracy: 0.926600
Distillation: Epoch : 46, Loss : 0.750569, Accuracy: 0.928000, Test accuracy: 0.927200
Distillation: Epoch : 47, Loss : 0.752113, Accuracy: 0.929000, Test accuracy: 0.928800
Distillation: Epoch : 48, Loss : 0.764268, Accuracy: 0.924000, Test accuracy: 0.930200
Distillation: Epoch : 49, Loss : 0.725686, Accuracy: 0.941000, Test accuracy: 0.932600
Distillation: Epoch : 50, Loss : 0.752122, Accuracy: 0.932000, Test accuracy: 0.932500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9325
Generating confusion matrix for student2
[[ 966.    0.   11.    3.    1.    7.   12.    3.   11.   11.]
 [   0. 1116.   11.    1.    4.    2.    4.   13.    7.    5.]
 [   0.    3.  924.   12.    3.    2.    5.   16.    9.    2.]
 [   1.    1.   19.  945.    1.   33.    1.    7.   26.   16.]
 [   0.    1.   11.    2.  934.    2.    6.    8.    9.   30.]
 [   4.    2.    0.   14.    0.  813.   15.    2.   28.   10.]
 [   6.    4.    9.    3.    5.    9.  913.    0.    9.    0.]
 [   1.    1.   13.    7.    1.    3.    1.  943.    7.   19.]
 [   2.    7.   29.   15.    5.   16.    1.    0.  857.    2.]
 [   0.    0.    5.    8.   28.    5.    0.   36.   11.  914.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.654940, Accuracy: 0.756000, Test accuracy: 0.755600
Distillation: Epoch : 2, Loss : 1.205022, Accuracy: 0.832000, Test accuracy: 0.840300
Distillation: Epoch : 3, Loss : 1.093454, Accuracy: 0.866000, Test accuracy: 0.878900
Distillation: Epoch : 4, Loss : 1.036041, Accuracy: 0.895000, Test accuracy: 0.896800
Distillation: Epoch : 5, Loss : 0.992397, Accuracy: 0.886000, Test accuracy: 0.906800
Distillation: Epoch : 6, Loss : 0.989920, Accuracy: 0.905000, Test accuracy: 0.914500
Distillation: Epoch : 7, Loss : 1.002355, Accuracy: 0.911000, Test accuracy: 0.920900
Distillation: Epoch : 8, Loss : 0.973088, Accuracy: 0.907000, Test accuracy: 0.925000
Distillation: Epoch : 9, Loss : 0.944746, Accuracy: 0.932000, Test accuracy: 0.927900
Distillation: Epoch : 10, Loss : 0.932867, Accuracy: 0.924000, Test accuracy: 0.931100
Distillation: Epoch : 11, Loss : 0.941560, Accuracy: 0.922000, Test accuracy: 0.932800
Distillation: Epoch : 12, Loss : 0.900458, Accuracy: 0.936000, Test accuracy: 0.935300
Distillation: Epoch : 13, Loss : 0.920719, Accuracy: 0.935000, Test accuracy: 0.937200
Distillation: Epoch : 14, Loss : 0.924204, Accuracy: 0.945000, Test accuracy: 0.939400
Distillation: Epoch : 15, Loss : 0.921867, Accuracy: 0.938000, Test accuracy: 0.941900
Distillation: Epoch : 16, Loss : 0.915289, Accuracy: 0.925000, Test accuracy: 0.944600
Distillation: Epoch : 17, Loss : 0.877846, Accuracy: 0.941000, Test accuracy: 0.946300
Distillation: Epoch : 18, Loss : 0.919652, Accuracy: 0.936000, Test accuracy: 0.947900
Distillation: Epoch : 19, Loss : 0.894703, Accuracy: 0.933000, Test accuracy: 0.948500
Distillation: Epoch : 20, Loss : 0.890779, Accuracy: 0.940000, Test accuracy: 0.950300
Distillation: Epoch : 21, Loss : 0.897660, Accuracy: 0.937000, Test accuracy: 0.950600
Distillation: Epoch : 22, Loss : 0.879572, Accuracy: 0.946000, Test accuracy: 0.950800
Distillation: Epoch : 23, Loss : 0.866641, Accuracy: 0.953000, Test accuracy: 0.951200
Distillation: Epoch : 24, Loss : 0.909152, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 25, Loss : 0.888631, Accuracy: 0.955000, Test accuracy: 0.952900
Distillation: Epoch : 26, Loss : 0.904682, Accuracy: 0.948000, Test accuracy: 0.953800
Distillation: Epoch : 27, Loss : 0.901775, Accuracy: 0.943000, Test accuracy: 0.953900
Distillation: Epoch : 28, Loss : 0.879883, Accuracy: 0.947000, Test accuracy: 0.954000
Distillation: Epoch : 29, Loss : 0.851984, Accuracy: 0.956000, Test accuracy: 0.955400
Distillation: Epoch : 30, Loss : 0.852111, Accuracy: 0.965000, Test accuracy: 0.956700
Distillation: Epoch : 31, Loss : 0.866199, Accuracy: 0.947000, Test accuracy: 0.956200
Distillation: Epoch : 32, Loss : 0.857856, Accuracy: 0.954000, Test accuracy: 0.956400
Distillation: Epoch : 33, Loss : 0.867911, Accuracy: 0.952000, Test accuracy: 0.957700
Distillation: Epoch : 34, Loss : 0.868874, Accuracy: 0.969000, Test accuracy: 0.957900
Distillation: Epoch : 35, Loss : 0.862279, Accuracy: 0.948000, Test accuracy: 0.959100
Distillation: Epoch : 36, Loss : 0.885404, Accuracy: 0.939000, Test accuracy: 0.959200
Distillation: Epoch : 37, Loss : 0.879211, Accuracy: 0.948000, Test accuracy: 0.957600
Distillation: Epoch : 38, Loss : 0.880574, Accuracy: 0.942000, Test accuracy: 0.959400
Distillation: Epoch : 39, Loss : 0.849488, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 40, Loss : 0.906583, Accuracy: 0.943000, Test accuracy: 0.959900
Distillation: Epoch : 41, Loss : 0.874339, Accuracy: 0.952000, Test accuracy: 0.960000
Distillation: Epoch : 42, Loss : 0.854215, Accuracy: 0.966000, Test accuracy: 0.960700
Distillation: Epoch : 43, Loss : 0.892661, Accuracy: 0.945000, Test accuracy: 0.959600
Distillation: Epoch : 44, Loss : 0.845309, Accuracy: 0.946000, Test accuracy: 0.960900
Distillation: Epoch : 45, Loss : 0.847968, Accuracy: 0.953000, Test accuracy: 0.960800
Distillation: Epoch : 46, Loss : 0.865016, Accuracy: 0.955000, Test accuracy: 0.960700
Distillation: Epoch : 47, Loss : 0.839528, Accuracy: 0.961000, Test accuracy: 0.961600
Distillation: Epoch : 48, Loss : 0.857833, Accuracy: 0.956000, Test accuracy: 0.961600
Distillation: Epoch : 49, Loss : 0.845253, Accuracy: 0.961000, Test accuracy: 0.961700
Distillation: Epoch : 50, Loss : 0.857328, Accuracy: 0.955000, Test accuracy: 0.961800
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9618
Generating confusion matrix for student2
[[ 967.    0.    4.    0.    1.    1.    8.    3.    7.    6.]
 [   1. 1122.   11.    0.    3.    1.    3.    8.    4.    5.]
 [   0.    3.  975.    3.    1.    1.    0.   16.    9.    0.]
 [   0.    1.    9.  983.    0.   11.    0.    3.   11.    8.]
 [   2.    0.    8.    1.  951.    0.    5.    2.    6.   20.]
 [   2.    0.    0.    8.    1.  867.    5.    0.   10.    5.]
 [   3.    4.    1.    0.    3.    4.  935.    0.   10.    0.]
 [   4.    1.   12.    9.    4.    1.    0.  975.    9.   18.]
 [   1.    4.   11.    3.    2.    3.    2.    2.  898.    2.]
 [   0.    0.    1.    3.   16.    3.    0.   19.   10.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.764124, Accuracy: 0.748000, Test accuracy: 0.776500
Distillation: Epoch : 2, Loss : 1.321498, Accuracy: 0.817000, Test accuracy: 0.834500
Distillation: Epoch : 3, Loss : 1.245979, Accuracy: 0.866000, Test accuracy: 0.866900
Distillation: Epoch : 4, Loss : 1.212511, Accuracy: 0.862000, Test accuracy: 0.881200
Distillation: Epoch : 5, Loss : 1.232591, Accuracy: 0.874000, Test accuracy: 0.891300
Distillation: Epoch : 6, Loss : 1.175690, Accuracy: 0.893000, Test accuracy: 0.895400
Distillation: Epoch : 7, Loss : 1.166682, Accuracy: 0.899000, Test accuracy: 0.898800
Distillation: Epoch : 8, Loss : 1.200981, Accuracy: 0.878000, Test accuracy: 0.902000
Distillation: Epoch : 9, Loss : 1.206020, Accuracy: 0.887000, Test accuracy: 0.904400
Distillation: Epoch : 10, Loss : 1.147367, Accuracy: 0.907000, Test accuracy: 0.908000
Distillation: Epoch : 11, Loss : 1.140500, Accuracy: 0.889000, Test accuracy: 0.909900
Distillation: Epoch : 12, Loss : 1.168377, Accuracy: 0.897000, Test accuracy: 0.910700
Distillation: Epoch : 13, Loss : 1.160366, Accuracy: 0.903000, Test accuracy: 0.912800
Distillation: Epoch : 14, Loss : 1.153270, Accuracy: 0.910000, Test accuracy: 0.912700
Distillation: Epoch : 15, Loss : 1.135665, Accuracy: 0.904000, Test accuracy: 0.914900
Distillation: Epoch : 16, Loss : 1.155266, Accuracy: 0.911000, Test accuracy: 0.916100
Distillation: Epoch : 17, Loss : 1.152595, Accuracy: 0.892000, Test accuracy: 0.917900
Distillation: Epoch : 18, Loss : 1.116542, Accuracy: 0.912000, Test accuracy: 0.921000
Distillation: Epoch : 19, Loss : 1.130744, Accuracy: 0.900000, Test accuracy: 0.922100
Distillation: Epoch : 20, Loss : 1.110439, Accuracy: 0.914000, Test accuracy: 0.924500
Distillation: Epoch : 21, Loss : 1.090493, Accuracy: 0.932000, Test accuracy: 0.925600
Distillation: Epoch : 22, Loss : 1.125999, Accuracy: 0.928000, Test accuracy: 0.926700
Distillation: Epoch : 23, Loss : 1.114697, Accuracy: 0.927000, Test accuracy: 0.927900
Distillation: Epoch : 24, Loss : 1.096957, Accuracy: 0.935000, Test accuracy: 0.930400
Distillation: Epoch : 25, Loss : 1.112550, Accuracy: 0.924000, Test accuracy: 0.932000
Distillation: Epoch : 26, Loss : 1.099036, Accuracy: 0.922000, Test accuracy: 0.933400
Distillation: Epoch : 27, Loss : 1.074834, Accuracy: 0.924000, Test accuracy: 0.936600
Distillation: Epoch : 28, Loss : 1.109938, Accuracy: 0.916000, Test accuracy: 0.937700
Distillation: Epoch : 29, Loss : 1.090158, Accuracy: 0.938000, Test accuracy: 0.940300
Distillation: Epoch : 30, Loss : 1.048841, Accuracy: 0.945000, Test accuracy: 0.941200
Distillation: Epoch : 31, Loss : 1.084986, Accuracy: 0.915000, Test accuracy: 0.942800
Distillation: Epoch : 32, Loss : 1.091124, Accuracy: 0.936000, Test accuracy: 0.944200
Distillation: Epoch : 33, Loss : 1.075192, Accuracy: 0.941000, Test accuracy: 0.946400
Distillation: Epoch : 34, Loss : 1.051505, Accuracy: 0.939000, Test accuracy: 0.947400
Distillation: Epoch : 35, Loss : 1.047814, Accuracy: 0.948000, Test accuracy: 0.949600
Distillation: Epoch : 36, Loss : 1.061788, Accuracy: 0.939000, Test accuracy: 0.950300
Distillation: Epoch : 37, Loss : 1.042405, Accuracy: 0.952000, Test accuracy: 0.952400
Distillation: Epoch : 38, Loss : 1.055049, Accuracy: 0.947000, Test accuracy: 0.954700
Distillation: Epoch : 39, Loss : 1.054241, Accuracy: 0.940000, Test accuracy: 0.955400
Distillation: Epoch : 40, Loss : 1.027558, Accuracy: 0.957000, Test accuracy: 0.956700
Distillation: Epoch : 41, Loss : 1.032944, Accuracy: 0.961000, Test accuracy: 0.957900
Distillation: Epoch : 42, Loss : 1.043950, Accuracy: 0.949000, Test accuracy: 0.959200
Distillation: Epoch : 43, Loss : 1.037442, Accuracy: 0.962000, Test accuracy: 0.960800
Distillation: Epoch : 44, Loss : 1.024233, Accuracy: 0.945000, Test accuracy: 0.961100
Distillation: Epoch : 45, Loss : 1.022523, Accuracy: 0.960000, Test accuracy: 0.962100
Distillation: Epoch : 46, Loss : 1.012369, Accuracy: 0.969000, Test accuracy: 0.962900
Distillation: Epoch : 47, Loss : 1.014444, Accuracy: 0.960000, Test accuracy: 0.964200
Distillation: Epoch : 48, Loss : 1.031942, Accuracy: 0.963000, Test accuracy: 0.963300
Distillation: Epoch : 49, Loss : 1.036970, Accuracy: 0.957000, Test accuracy: 0.964400
Distillation: Epoch : 50, Loss : 1.039938, Accuracy: 0.965000, Test accuracy: 0.966600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9666
Generating confusion matrix for student2
[[ 970.    0.    2.    0.    0.    3.    9.    0.    5.    8.]
 [   1. 1124.    4.    0.    2.    0.    2.    5.    4.    5.]
 [   2.    3.  987.    2.    4.    0.    0.   17.    6.    2.]
 [   0.    2.    6.  987.    0.    8.    0.    2.   12.   13.]
 [   0.    0.    8.    0.  950.    0.    2.    2.    6.   11.]
 [   1.    0.    0.    7.    0.  868.    9.    1.   10.    6.]
 [   3.    4.    2.    1.    4.    5.  934.    0.    7.    2.]
 [   1.    0.   10.    6.    1.    0.    0.  986.    6.    7.]
 [   1.    2.   12.    6.    3.    6.    2.    2.  906.    1.]
 [   1.    0.    1.    1.   18.    2.    0.   13.   12.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.837782, Accuracy: 0.762000, Test accuracy: 0.763100
Distillation: Epoch : 2, Loss : 1.450735, Accuracy: 0.850000, Test accuracy: 0.835000
Distillation: Epoch : 3, Loss : 1.381992, Accuracy: 0.863000, Test accuracy: 0.863600
Distillation: Epoch : 4, Loss : 1.359874, Accuracy: 0.860000, Test accuracy: 0.878300
Distillation: Epoch : 5, Loss : 1.374240, Accuracy: 0.876000, Test accuracy: 0.888300
Distillation: Epoch : 6, Loss : 1.341981, Accuracy: 0.895000, Test accuracy: 0.892200
Distillation: Epoch : 7, Loss : 1.330899, Accuracy: 0.887000, Test accuracy: 0.895900
Distillation: Epoch : 8, Loss : 1.330122, Accuracy: 0.893000, Test accuracy: 0.900100
Distillation: Epoch : 9, Loss : 1.324160, Accuracy: 0.885000, Test accuracy: 0.902000
Distillation: Epoch : 10, Loss : 1.318754, Accuracy: 0.906000, Test accuracy: 0.905500
Distillation: Epoch : 11, Loss : 1.319148, Accuracy: 0.902000, Test accuracy: 0.906500
Distillation: Epoch : 12, Loss : 1.308554, Accuracy: 0.901000, Test accuracy: 0.909700
Distillation: Epoch : 13, Loss : 1.298950, Accuracy: 0.907000, Test accuracy: 0.909800
Distillation: Epoch : 14, Loss : 1.312446, Accuracy: 0.889000, Test accuracy: 0.911900
Distillation: Epoch : 15, Loss : 1.294834, Accuracy: 0.900000, Test accuracy: 0.913000
Distillation: Epoch : 16, Loss : 1.307903, Accuracy: 0.894000, Test accuracy: 0.914300
Distillation: Epoch : 17, Loss : 1.282928, Accuracy: 0.891000, Test accuracy: 0.916000
Distillation: Epoch : 18, Loss : 1.268192, Accuracy: 0.913000, Test accuracy: 0.917000
Distillation: Epoch : 19, Loss : 1.267910, Accuracy: 0.918000, Test accuracy: 0.920300
Distillation: Epoch : 20, Loss : 1.291463, Accuracy: 0.914000, Test accuracy: 0.921900
Distillation: Epoch : 21, Loss : 1.270289, Accuracy: 0.912000, Test accuracy: 0.922400
Distillation: Epoch : 22, Loss : 1.229189, Accuracy: 0.926000, Test accuracy: 0.925600
Distillation: Epoch : 23, Loss : 1.230053, Accuracy: 0.928000, Test accuracy: 0.927600
Distillation: Epoch : 24, Loss : 1.231792, Accuracy: 0.941000, Test accuracy: 0.930900
Distillation: Epoch : 25, Loss : 1.254435, Accuracy: 0.933000, Test accuracy: 0.933800
Distillation: Epoch : 26, Loss : 1.247304, Accuracy: 0.918000, Test accuracy: 0.935200
Distillation: Epoch : 27, Loss : 1.233850, Accuracy: 0.930000, Test accuracy: 0.938300
Distillation: Epoch : 28, Loss : 1.236734, Accuracy: 0.945000, Test accuracy: 0.939300
Distillation: Epoch : 29, Loss : 1.250668, Accuracy: 0.931000, Test accuracy: 0.941300
Distillation: Epoch : 30, Loss : 1.237205, Accuracy: 0.945000, Test accuracy: 0.943000
Distillation: Epoch : 31, Loss : 1.209829, Accuracy: 0.931000, Test accuracy: 0.943200
Distillation: Epoch : 32, Loss : 1.214372, Accuracy: 0.938000, Test accuracy: 0.946100
Distillation: Epoch : 33, Loss : 1.235749, Accuracy: 0.940000, Test accuracy: 0.948600
Distillation: Epoch : 34, Loss : 1.208899, Accuracy: 0.931000, Test accuracy: 0.951000
Distillation: Epoch : 35, Loss : 1.219883, Accuracy: 0.948000, Test accuracy: 0.951100
Distillation: Epoch : 36, Loss : 1.226165, Accuracy: 0.952000, Test accuracy: 0.951700
Distillation: Epoch : 37, Loss : 1.199105, Accuracy: 0.940000, Test accuracy: 0.952400
Distillation: Epoch : 38, Loss : 1.213098, Accuracy: 0.955000, Test accuracy: 0.953200
Distillation: Epoch : 39, Loss : 1.176525, Accuracy: 0.967000, Test accuracy: 0.954300
Distillation: Epoch : 40, Loss : 1.222046, Accuracy: 0.939000, Test accuracy: 0.954600
Distillation: Epoch : 41, Loss : 1.219210, Accuracy: 0.945000, Test accuracy: 0.956000
Distillation: Epoch : 42, Loss : 1.191476, Accuracy: 0.953000, Test accuracy: 0.955100
Distillation: Epoch : 43, Loss : 1.191487, Accuracy: 0.964000, Test accuracy: 0.956300
Distillation: Epoch : 44, Loss : 1.200952, Accuracy: 0.956000, Test accuracy: 0.958100
Distillation: Epoch : 45, Loss : 1.195897, Accuracy: 0.959000, Test accuracy: 0.956900
Distillation: Epoch : 46, Loss : 1.190808, Accuracy: 0.954000, Test accuracy: 0.957700
Distillation: Epoch : 47, Loss : 1.197538, Accuracy: 0.970000, Test accuracy: 0.958000
Distillation: Epoch : 48, Loss : 1.199840, Accuracy: 0.958000, Test accuracy: 0.959200
Distillation: Epoch : 49, Loss : 1.165827, Accuracy: 0.962000, Test accuracy: 0.958700
Distillation: Epoch : 50, Loss : 1.206798, Accuracy: 0.955000, Test accuracy: 0.959600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9596
Generating confusion matrix for student2
[[ 966.    0.    5.    1.    0.    1.    9.    2.    8.    6.]
 [   3. 1119.   10.    1.    3.    1.    4.   10.    3.    6.]
 [   1.    2.  977.    3.    3.    0.    0.   20.    8.    1.]
 [   0.    1.    7.  982.    0.   16.    0.    2.   16.   15.]
 [   2.    0.    5.    1.  948.    0.    3.    2.    6.   12.]
 [   2.    1.    1.    6.    0.  860.   11.    2.   11.    6.]
 [   3.    5.    2.    0.    7.    6.  929.    0.    5.    1.]
 [   1.    0.   11.    3.    1.    2.    0.  965.    6.    8.]
 [   2.    7.   13.   10.    2.    5.    2.    2.  897.    1.]
 [   0.    0.    1.    3.   18.    1.    0.   23.   14.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.016037, Accuracy: 0.733000, Test accuracy: 0.750800
Distillation: Epoch : 2, Loss : 1.641853, Accuracy: 0.819000, Test accuracy: 0.833600
Distillation: Epoch : 3, Loss : 1.511569, Accuracy: 0.882000, Test accuracy: 0.871400
Distillation: Epoch : 4, Loss : 1.485901, Accuracy: 0.881000, Test accuracy: 0.891300
Distillation: Epoch : 5, Loss : 1.450367, Accuracy: 0.895000, Test accuracy: 0.906300
Distillation: Epoch : 6, Loss : 1.430720, Accuracy: 0.903000, Test accuracy: 0.913900
Distillation: Epoch : 7, Loss : 1.422587, Accuracy: 0.910000, Test accuracy: 0.922400
Distillation: Epoch : 8, Loss : 1.385188, Accuracy: 0.930000, Test accuracy: 0.926800
Distillation: Epoch : 9, Loss : 1.415953, Accuracy: 0.923000, Test accuracy: 0.930500
Distillation: Epoch : 10, Loss : 1.397922, Accuracy: 0.937000, Test accuracy: 0.935500
Distillation: Epoch : 11, Loss : 1.380903, Accuracy: 0.932000, Test accuracy: 0.938100
Distillation: Epoch : 12, Loss : 1.378472, Accuracy: 0.928000, Test accuracy: 0.940600
Distillation: Epoch : 13, Loss : 1.373847, Accuracy: 0.939000, Test accuracy: 0.942700
Distillation: Epoch : 14, Loss : 1.390519, Accuracy: 0.952000, Test accuracy: 0.945900
Distillation: Epoch : 15, Loss : 1.365092, Accuracy: 0.934000, Test accuracy: 0.947800
Distillation: Epoch : 16, Loss : 1.363624, Accuracy: 0.948000, Test accuracy: 0.949700
Distillation: Epoch : 17, Loss : 1.365946, Accuracy: 0.943000, Test accuracy: 0.951900
Distillation: Epoch : 18, Loss : 1.353873, Accuracy: 0.953000, Test accuracy: 0.953300
Distillation: Epoch : 19, Loss : 1.346132, Accuracy: 0.960000, Test accuracy: 0.954000
Distillation: Epoch : 20, Loss : 1.358457, Accuracy: 0.942000, Test accuracy: 0.955400
Distillation: Epoch : 21, Loss : 1.346304, Accuracy: 0.961000, Test accuracy: 0.957200
Distillation: Epoch : 22, Loss : 1.351099, Accuracy: 0.938000, Test accuracy: 0.958200
Distillation: Epoch : 23, Loss : 1.348116, Accuracy: 0.940000, Test accuracy: 0.958900
Distillation: Epoch : 24, Loss : 1.340318, Accuracy: 0.946000, Test accuracy: 0.959400
Distillation: Epoch : 25, Loss : 1.324773, Accuracy: 0.964000, Test accuracy: 0.959800
Distillation: Epoch : 26, Loss : 1.320351, Accuracy: 0.953000, Test accuracy: 0.960300
Distillation: Epoch : 27, Loss : 1.344271, Accuracy: 0.964000, Test accuracy: 0.961100
Distillation: Epoch : 28, Loss : 1.351312, Accuracy: 0.965000, Test accuracy: 0.961800
Distillation: Epoch : 29, Loss : 1.337860, Accuracy: 0.951000, Test accuracy: 0.962400
Distillation: Epoch : 30, Loss : 1.331799, Accuracy: 0.957000, Test accuracy: 0.962700
Distillation: Epoch : 31, Loss : 1.331831, Accuracy: 0.972000, Test accuracy: 0.962900
Distillation: Epoch : 32, Loss : 1.331896, Accuracy: 0.956000, Test accuracy: 0.963800
Distillation: Epoch : 33, Loss : 1.351979, Accuracy: 0.956000, Test accuracy: 0.963700
Distillation: Epoch : 34, Loss : 1.321075, Accuracy: 0.968000, Test accuracy: 0.963700
Distillation: Epoch : 35, Loss : 1.337890, Accuracy: 0.965000, Test accuracy: 0.964000
Distillation: Epoch : 36, Loss : 1.335843, Accuracy: 0.956000, Test accuracy: 0.964000
Distillation: Epoch : 37, Loss : 1.332011, Accuracy: 0.966000, Test accuracy: 0.965100
Distillation: Epoch : 38, Loss : 1.316009, Accuracy: 0.969000, Test accuracy: 0.965000
Distillation: Epoch : 39, Loss : 1.331260, Accuracy: 0.958000, Test accuracy: 0.964900
Distillation: Epoch : 40, Loss : 1.322844, Accuracy: 0.967000, Test accuracy: 0.965200
Distillation: Epoch : 41, Loss : 1.342253, Accuracy: 0.955000, Test accuracy: 0.965700
Distillation: Epoch : 42, Loss : 1.331975, Accuracy: 0.966000, Test accuracy: 0.965600
Distillation: Epoch : 43, Loss : 1.339496, Accuracy: 0.964000, Test accuracy: 0.966400
Distillation: Epoch : 44, Loss : 1.328912, Accuracy: 0.964000, Test accuracy: 0.966100
Distillation: Epoch : 45, Loss : 1.310092, Accuracy: 0.958000, Test accuracy: 0.966700
Distillation: Epoch : 46, Loss : 1.309510, Accuracy: 0.966000, Test accuracy: 0.967300
Distillation: Epoch : 47, Loss : 1.324745, Accuracy: 0.961000, Test accuracy: 0.967000
Distillation: Epoch : 48, Loss : 1.350446, Accuracy: 0.958000, Test accuracy: 0.967600
Distillation: Epoch : 49, Loss : 1.341076, Accuracy: 0.969000, Test accuracy: 0.967300
Distillation: Epoch : 50, Loss : 1.322528, Accuracy: 0.967000, Test accuracy: 0.967200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9672
Generating confusion matrix for student2
[[ 971.    0.    5.    0.    1.    1.    7.    2.    9.    4.]
 [   1. 1125.    6.    1.    2.    0.    3.   12.    1.    6.]
 [   0.    2.  987.    3.    1.    1.    0.   14.    5.    0.]
 [   1.    3.    8.  985.    0.   18.    0.    5.   11.    9.]
 [   0.    0.    5.    2.  953.    0.    5.    4.    5.   14.]
 [   1.    0.    1.    3.    1.  863.    6.    0.    5.    5.]
 [   2.    4.    1.    0.    1.    2.  935.    0.    7.    1.]
 [   1.    0.   11.    7.    3.    2.    0.  977.    6.    8.]
 [   3.    1.    6.    5.    2.    3.    2.    1.  915.    1.]
 [   0.    0.    2.    4.   18.    2.    0.   13.   10.  961.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.948914, Accuracy: 0.745000, Test accuracy: 0.756700
Distillation: Epoch : 2, Loss : 1.685724, Accuracy: 0.809000, Test accuracy: 0.824000
Distillation: Epoch : 3, Loss : 1.623728, Accuracy: 0.867000, Test accuracy: 0.863300
Distillation: Epoch : 4, Loss : 1.611253, Accuracy: 0.867000, Test accuracy: 0.879800
Distillation: Epoch : 5, Loss : 1.575225, Accuracy: 0.898000, Test accuracy: 0.885900
Distillation: Epoch : 6, Loss : 1.584845, Accuracy: 0.873000, Test accuracy: 0.893400
Distillation: Epoch : 7, Loss : 1.590387, Accuracy: 0.876000, Test accuracy: 0.900300
Distillation: Epoch : 8, Loss : 1.576160, Accuracy: 0.890000, Test accuracy: 0.903800
Distillation: Epoch : 9, Loss : 1.561575, Accuracy: 0.900000, Test accuracy: 0.906300
Distillation: Epoch : 10, Loss : 1.561767, Accuracy: 0.897000, Test accuracy: 0.912000
Distillation: Epoch : 11, Loss : 1.554210, Accuracy: 0.909000, Test accuracy: 0.914800
Distillation: Epoch : 12, Loss : 1.534974, Accuracy: 0.920000, Test accuracy: 0.917500
Distillation: Epoch : 13, Loss : 1.516983, Accuracy: 0.919000, Test accuracy: 0.920200
Distillation: Epoch : 14, Loss : 1.545767, Accuracy: 0.923000, Test accuracy: 0.923200
Distillation: Epoch : 15, Loss : 1.535893, Accuracy: 0.926000, Test accuracy: 0.926100
Distillation: Epoch : 16, Loss : 1.523336, Accuracy: 0.928000, Test accuracy: 0.926800
Distillation: Epoch : 17, Loss : 1.544847, Accuracy: 0.937000, Test accuracy: 0.928600
Distillation: Epoch : 18, Loss : 1.527601, Accuracy: 0.928000, Test accuracy: 0.930800
Distillation: Epoch : 19, Loss : 1.508395, Accuracy: 0.947000, Test accuracy: 0.933000
Distillation: Epoch : 20, Loss : 1.482359, Accuracy: 0.934000, Test accuracy: 0.934800
Distillation: Epoch : 21, Loss : 1.507495, Accuracy: 0.933000, Test accuracy: 0.938200
Distillation: Epoch : 22, Loss : 1.499182, Accuracy: 0.931000, Test accuracy: 0.939100
Distillation: Epoch : 23, Loss : 1.521850, Accuracy: 0.932000, Test accuracy: 0.941200
Distillation: Epoch : 24, Loss : 1.488406, Accuracy: 0.934000, Test accuracy: 0.942500
Distillation: Epoch : 25, Loss : 1.517251, Accuracy: 0.934000, Test accuracy: 0.943700
Distillation: Epoch : 26, Loss : 1.473698, Accuracy: 0.949000, Test accuracy: 0.944700
Distillation: Epoch : 27, Loss : 1.498883, Accuracy: 0.938000, Test accuracy: 0.945600
Distillation: Epoch : 28, Loss : 1.477716, Accuracy: 0.951000, Test accuracy: 0.946400
Distillation: Epoch : 29, Loss : 1.498885, Accuracy: 0.937000, Test accuracy: 0.947500
Distillation: Epoch : 30, Loss : 1.482090, Accuracy: 0.952000, Test accuracy: 0.947900
Distillation: Epoch : 31, Loss : 1.491853, Accuracy: 0.955000, Test accuracy: 0.948900
Distillation: Epoch : 32, Loss : 1.478678, Accuracy: 0.949000, Test accuracy: 0.949600
Distillation: Epoch : 33, Loss : 1.492631, Accuracy: 0.943000, Test accuracy: 0.950500
Distillation: Epoch : 34, Loss : 1.483794, Accuracy: 0.947000, Test accuracy: 0.951100
Distillation: Epoch : 35, Loss : 1.509877, Accuracy: 0.943000, Test accuracy: 0.951800
Distillation: Epoch : 36, Loss : 1.485609, Accuracy: 0.948000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 1.509299, Accuracy: 0.940000, Test accuracy: 0.952200
Distillation: Epoch : 38, Loss : 1.485044, Accuracy: 0.956000, Test accuracy: 0.953700
Distillation: Epoch : 39, Loss : 1.493575, Accuracy: 0.948000, Test accuracy: 0.953000
Distillation: Epoch : 40, Loss : 1.485270, Accuracy: 0.951000, Test accuracy: 0.954700
Distillation: Epoch : 41, Loss : 1.472574, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 42, Loss : 1.468432, Accuracy: 0.954000, Test accuracy: 0.955200
Distillation: Epoch : 43, Loss : 1.472006, Accuracy: 0.955000, Test accuracy: 0.955900
Distillation: Epoch : 44, Loss : 1.479612, Accuracy: 0.944000, Test accuracy: 0.957000
Distillation: Epoch : 45, Loss : 1.463181, Accuracy: 0.952000, Test accuracy: 0.958100
Distillation: Epoch : 46, Loss : 1.467587, Accuracy: 0.955000, Test accuracy: 0.958700
Distillation: Epoch : 47, Loss : 1.464020, Accuracy: 0.956000, Test accuracy: 0.958900
Distillation: Epoch : 48, Loss : 1.466007, Accuracy: 0.958000, Test accuracy: 0.959500
Distillation: Epoch : 49, Loss : 1.445816, Accuracy: 0.962000, Test accuracy: 0.958800
Distillation: Epoch : 50, Loss : 1.467938, Accuracy: 0.957000, Test accuracy: 0.960100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9601
Generating confusion matrix for student2
[[ 971.    0.    7.    1.    0.    1.    4.    1.    7.    6.]
 [   0. 1113.    8.    0.    0.    0.    4.    8.    4.    5.]
 [   2.    2.  973.    4.    4.    0.    1.   15.   10.    1.]
 [   0.    1.   11.  979.    0.   16.    0.    5.   13.   13.]
 [   0.    1.    5.    0.  950.    1.    2.    1.    6.    8.]
 [   1.    2.    0.    7.    0.  857.   11.    2.   15.    7.]
 [   3.    4.    2.    0.    4.   11.  933.    0.    5.    0.]
 [   1.    0.    8.    9.    2.    1.    0.  977.    5.   13.]
 [   2.   12.   16.   10.    2.    4.    3.    1.  897.    5.]
 [   0.    0.    2.    0.   20.    1.    0.   18.   12.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.132005, Accuracy: 0.733000, Test accuracy: 0.733500
Distillation: Epoch : 2, Loss : 1.909512, Accuracy: 0.809000, Test accuracy: 0.817900
Distillation: Epoch : 3, Loss : 1.881492, Accuracy: 0.837000, Test accuracy: 0.853700
Distillation: Epoch : 4, Loss : 1.842904, Accuracy: 0.889000, Test accuracy: 0.872700
Distillation: Epoch : 5, Loss : 1.852656, Accuracy: 0.854000, Test accuracy: 0.885100
Distillation: Epoch : 6, Loss : 1.835087, Accuracy: 0.873000, Test accuracy: 0.891300
Distillation: Epoch : 7, Loss : 1.839623, Accuracy: 0.877000, Test accuracy: 0.898500
Distillation: Epoch : 8, Loss : 1.819113, Accuracy: 0.886000, Test accuracy: 0.902400
Distillation: Epoch : 9, Loss : 1.822605, Accuracy: 0.887000, Test accuracy: 0.907400
Distillation: Epoch : 10, Loss : 1.806679, Accuracy: 0.905000, Test accuracy: 0.910400
Distillation: Epoch : 11, Loss : 1.815763, Accuracy: 0.913000, Test accuracy: 0.915000
Distillation: Epoch : 12, Loss : 1.794078, Accuracy: 0.917000, Test accuracy: 0.918700
Distillation: Epoch : 13, Loss : 1.805143, Accuracy: 0.919000, Test accuracy: 0.923800
Distillation: Epoch : 14, Loss : 1.797795, Accuracy: 0.916000, Test accuracy: 0.926500
Distillation: Epoch : 15, Loss : 1.787489, Accuracy: 0.924000, Test accuracy: 0.929200
Distillation: Epoch : 16, Loss : 1.786062, Accuracy: 0.926000, Test accuracy: 0.932400
Distillation: Epoch : 17, Loss : 1.771236, Accuracy: 0.926000, Test accuracy: 0.934200
Distillation: Epoch : 18, Loss : 1.772598, Accuracy: 0.934000, Test accuracy: 0.937300
Distillation: Epoch : 19, Loss : 1.771875, Accuracy: 0.933000, Test accuracy: 0.939000
Distillation: Epoch : 20, Loss : 1.787436, Accuracy: 0.930000, Test accuracy: 0.941200
Distillation: Epoch : 21, Loss : 1.765416, Accuracy: 0.935000, Test accuracy: 0.941900
Distillation: Epoch : 22, Loss : 1.769224, Accuracy: 0.944000, Test accuracy: 0.942700
Distillation: Epoch : 23, Loss : 1.776844, Accuracy: 0.936000, Test accuracy: 0.944300
Distillation: Epoch : 24, Loss : 1.766901, Accuracy: 0.953000, Test accuracy: 0.945600
Distillation: Epoch : 25, Loss : 1.771911, Accuracy: 0.936000, Test accuracy: 0.946400
Distillation: Epoch : 26, Loss : 1.758320, Accuracy: 0.946000, Test accuracy: 0.947300
Distillation: Epoch : 27, Loss : 1.766132, Accuracy: 0.956000, Test accuracy: 0.948200
Distillation: Epoch : 28, Loss : 1.775695, Accuracy: 0.949000, Test accuracy: 0.948300
Distillation: Epoch : 29, Loss : 1.778719, Accuracy: 0.947000, Test accuracy: 0.949200
Distillation: Epoch : 30, Loss : 1.756649, Accuracy: 0.949000, Test accuracy: 0.950500
Distillation: Epoch : 31, Loss : 1.761530, Accuracy: 0.949000, Test accuracy: 0.951000
Distillation: Epoch : 32, Loss : 1.746138, Accuracy: 0.944000, Test accuracy: 0.950600
Distillation: Epoch : 33, Loss : 1.785337, Accuracy: 0.955000, Test accuracy: 0.953100
Distillation: Epoch : 34, Loss : 1.754598, Accuracy: 0.954000, Test accuracy: 0.952900
Distillation: Epoch : 35, Loss : 1.746444, Accuracy: 0.968000, Test accuracy: 0.953900
Distillation: Epoch : 36, Loss : 1.750299, Accuracy: 0.950000, Test accuracy: 0.954400
Distillation: Epoch : 37, Loss : 1.756087, Accuracy: 0.935000, Test accuracy: 0.955600
Distillation: Epoch : 38, Loss : 1.756544, Accuracy: 0.952000, Test accuracy: 0.956000
Distillation: Epoch : 39, Loss : 1.761370, Accuracy: 0.944000, Test accuracy: 0.956400
Distillation: Epoch : 40, Loss : 1.755064, Accuracy: 0.951000, Test accuracy: 0.957400
Distillation: Epoch : 41, Loss : 1.768697, Accuracy: 0.946000, Test accuracy: 0.957500
Distillation: Epoch : 42, Loss : 1.752108, Accuracy: 0.942000, Test accuracy: 0.958400
Distillation: Epoch : 43, Loss : 1.760709, Accuracy: 0.960000, Test accuracy: 0.959300
Distillation: Epoch : 44, Loss : 1.764979, Accuracy: 0.962000, Test accuracy: 0.959300
Distillation: Epoch : 45, Loss : 1.746679, Accuracy: 0.958000, Test accuracy: 0.959900
Distillation: Epoch : 46, Loss : 1.747633, Accuracy: 0.956000, Test accuracy: 0.961600
Distillation: Epoch : 47, Loss : 1.739884, Accuracy: 0.960000, Test accuracy: 0.960900
Distillation: Epoch : 48, Loss : 1.747024, Accuracy: 0.966000, Test accuracy: 0.960900
Distillation: Epoch : 49, Loss : 1.730916, Accuracy: 0.963000, Test accuracy: 0.962200
Distillation: Epoch : 50, Loss : 1.763416, Accuracy: 0.957000, Test accuracy: 0.962300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9623
Generating confusion matrix for student2
[[ 969.    0.    4.    0.    1.    1.   10.    2.   10.    8.]
 [   1. 1121.    7.    0.    3.    1.    3.   14.    4.    5.]
 [   1.    2.  979.    1.    0.    0.    0.   17.    9.    0.]
 [   0.    1.    9.  990.    0.   12.    0.    4.   13.   10.]
 [   0.    0.    8.    1.  951.    0.    2.    8.    6.   16.]
 [   0.    0.    0.    5.    1.  869.    8.    0.    8.    4.]
 [   4.    4.    2.    0.    4.    3.  932.    0.   10.    1.]
 [   1.    0.   13.    8.    4.    1.    0.  965.    5.   13.]
 [   4.    7.   10.    4.    2.    3.    3.    3.  898.    3.]
 [   0.    0.    0.    1.   16.    2.    0.   15.   11.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.174456, Accuracy: 0.746000, Test accuracy: 0.753100
Distillation: Epoch : 2, Loss : 2.094738, Accuracy: 0.810000, Test accuracy: 0.822800
Distillation: Epoch : 3, Loss : 2.074455, Accuracy: 0.867000, Test accuracy: 0.852100
Distillation: Epoch : 4, Loss : 2.064026, Accuracy: 0.849000, Test accuracy: 0.864800
Distillation: Epoch : 5, Loss : 2.064972, Accuracy: 0.846000, Test accuracy: 0.871900
Distillation: Epoch : 6, Loss : 2.058853, Accuracy: 0.865000, Test accuracy: 0.876000
Distillation: Epoch : 7, Loss : 2.054712, Accuracy: 0.873000, Test accuracy: 0.881400
Distillation: Epoch : 8, Loss : 2.054669, Accuracy: 0.866000, Test accuracy: 0.882300
Distillation: Epoch : 9, Loss : 2.049887, Accuracy: 0.882000, Test accuracy: 0.888300
Distillation: Epoch : 10, Loss : 2.054308, Accuracy: 0.882000, Test accuracy: 0.890300
Distillation: Epoch : 11, Loss : 2.057703, Accuracy: 0.874000, Test accuracy: 0.891700
Distillation: Epoch : 12, Loss : 2.043175, Accuracy: 0.893000, Test accuracy: 0.893600
Distillation: Epoch : 13, Loss : 2.042888, Accuracy: 0.901000, Test accuracy: 0.895700
Distillation: Epoch : 14, Loss : 2.047348, Accuracy: 0.898000, Test accuracy: 0.895200
Distillation: Epoch : 15, Loss : 2.049854, Accuracy: 0.883000, Test accuracy: 0.897700
Distillation: Epoch : 16, Loss : 2.051173, Accuracy: 0.890000, Test accuracy: 0.901200
Distillation: Epoch : 17, Loss : 2.044090, Accuracy: 0.894000, Test accuracy: 0.901200
Distillation: Epoch : 18, Loss : 2.047483, Accuracy: 0.904000, Test accuracy: 0.904000
Distillation: Epoch : 19, Loss : 2.043739, Accuracy: 0.901000, Test accuracy: 0.906800
Distillation: Epoch : 20, Loss : 2.036753, Accuracy: 0.903000, Test accuracy: 0.909500
Distillation: Epoch : 21, Loss : 2.037564, Accuracy: 0.899000, Test accuracy: 0.913300
Distillation: Epoch : 22, Loss : 2.035980, Accuracy: 0.907000, Test accuracy: 0.915900
Distillation: Epoch : 23, Loss : 2.037099, Accuracy: 0.891000, Test accuracy: 0.919500
Distillation: Epoch : 24, Loss : 2.030758, Accuracy: 0.913000, Test accuracy: 0.921300
Distillation: Epoch : 25, Loss : 2.031866, Accuracy: 0.917000, Test accuracy: 0.925200
Distillation: Epoch : 26, Loss : 2.027857, Accuracy: 0.928000, Test accuracy: 0.928400
Distillation: Epoch : 27, Loss : 2.024197, Accuracy: 0.931000, Test accuracy: 0.930700
Distillation: Epoch : 28, Loss : 2.022269, Accuracy: 0.943000, Test accuracy: 0.932800
Distillation: Epoch : 29, Loss : 2.023841, Accuracy: 0.926000, Test accuracy: 0.935100
Distillation: Epoch : 30, Loss : 2.026852, Accuracy: 0.901000, Test accuracy: 0.937200
Distillation: Epoch : 31, Loss : 2.031543, Accuracy: 0.919000, Test accuracy: 0.940100
Distillation: Epoch : 32, Loss : 2.016859, Accuracy: 0.915000, Test accuracy: 0.943300
Distillation: Epoch : 33, Loss : 2.018793, Accuracy: 0.935000, Test accuracy: 0.943200
Distillation: Epoch : 34, Loss : 2.027031, Accuracy: 0.931000, Test accuracy: 0.944700
Distillation: Epoch : 35, Loss : 2.026759, Accuracy: 0.936000, Test accuracy: 0.946500
Distillation: Epoch : 36, Loss : 2.025047, Accuracy: 0.940000, Test accuracy: 0.947200
Distillation: Epoch : 37, Loss : 2.001975, Accuracy: 0.958000, Test accuracy: 0.946800
Distillation: Epoch : 38, Loss : 2.015734, Accuracy: 0.952000, Test accuracy: 0.949400
Distillation: Epoch : 39, Loss : 2.008751, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 40, Loss : 2.012244, Accuracy: 0.949000, Test accuracy: 0.951000
Distillation: Epoch : 41, Loss : 2.018850, Accuracy: 0.935000, Test accuracy: 0.951000
Distillation: Epoch : 42, Loss : 2.000862, Accuracy: 0.958000, Test accuracy: 0.953100
Distillation: Epoch : 43, Loss : 2.010418, Accuracy: 0.951000, Test accuracy: 0.954200
Distillation: Epoch : 44, Loss : 2.012270, Accuracy: 0.959000, Test accuracy: 0.955000
Distillation: Epoch : 45, Loss : 2.008486, Accuracy: 0.952000, Test accuracy: 0.956000
Distillation: Epoch : 46, Loss : 2.013929, Accuracy: 0.955000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 2.009719, Accuracy: 0.947000, Test accuracy: 0.957900
Distillation: Epoch : 48, Loss : 2.014243, Accuracy: 0.956000, Test accuracy: 0.958600
Distillation: Epoch : 49, Loss : 2.005920, Accuracy: 0.966000, Test accuracy: 0.958200
Distillation: Epoch : 50, Loss : 2.013000, Accuracy: 0.952000, Test accuracy: 0.959000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.959
Generating confusion matrix for student2
[[ 971.    0.    3.    1.    0.    0.    7.    4.    9.    8.]
 [   0. 1123.   15.    0.    1.    1.    4.   17.    4.    5.]
 [   1.    3.  966.    1.    5.    1.    0.   13.    8.    1.]
 [   0.    1.   19.  989.    0.   16.    0.    7.   15.    8.]
 [   1.    1.    4.    1.  953.    0.    2.    8.    7.   15.]
 [   1.    0.    1.    7.    0.  860.    9.    0.   14.    9.]
 [   3.    4.    2.    1.    3.    5.  935.    0.    9.    1.]
 [   1.    0.   13.    6.    1.    3.    0.  959.    9.   12.]
 [   2.    3.    8.    2.    3.    4.    1.    0.  887.    3.]
 [   0.    0.    1.    2.   16.    2.    0.   20.   12.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.845773, Accuracy: 0.806000, Test accuracy: 0.802300
Distillation: Epoch : 2, Loss : 0.521877, Accuracy: 0.850000, Test accuracy: 0.873800
Distillation: Epoch : 3, Loss : 0.388707, Accuracy: 0.901000, Test accuracy: 0.895300
Distillation: Epoch : 4, Loss : 0.340852, Accuracy: 0.900000, Test accuracy: 0.907000
Distillation: Epoch : 5, Loss : 0.309092, Accuracy: 0.903000, Test accuracy: 0.916100
Distillation: Epoch : 6, Loss : 0.280881, Accuracy: 0.922000, Test accuracy: 0.924000
Distillation: Epoch : 7, Loss : 0.261591, Accuracy: 0.925000, Test accuracy: 0.930200
Distillation: Epoch : 8, Loss : 0.232554, Accuracy: 0.927000, Test accuracy: 0.934700
Distillation: Epoch : 9, Loss : 0.233461, Accuracy: 0.936000, Test accuracy: 0.938500
Distillation: Epoch : 10, Loss : 0.199252, Accuracy: 0.938000, Test accuracy: 0.943300
Distillation: Epoch : 11, Loss : 0.211074, Accuracy: 0.940000, Test accuracy: 0.945300
Distillation: Epoch : 12, Loss : 0.223809, Accuracy: 0.928000, Test accuracy: 0.949000
Distillation: Epoch : 13, Loss : 0.173377, Accuracy: 0.951000, Test accuracy: 0.949900
Distillation: Epoch : 14, Loss : 0.223827, Accuracy: 0.929000, Test accuracy: 0.951600
Distillation: Epoch : 15, Loss : 0.138979, Accuracy: 0.966000, Test accuracy: 0.952000
Distillation: Epoch : 16, Loss : 0.191599, Accuracy: 0.946000, Test accuracy: 0.953500
Distillation: Epoch : 17, Loss : 0.192882, Accuracy: 0.935000, Test accuracy: 0.955100
Distillation: Epoch : 18, Loss : 0.159865, Accuracy: 0.953000, Test accuracy: 0.955800
Distillation: Epoch : 19, Loss : 0.198343, Accuracy: 0.942000, Test accuracy: 0.955600
Distillation: Epoch : 20, Loss : 0.152706, Accuracy: 0.958000, Test accuracy: 0.957100
Distillation: Epoch : 21, Loss : 0.156436, Accuracy: 0.954000, Test accuracy: 0.957300
Distillation: Epoch : 22, Loss : 0.165731, Accuracy: 0.953000, Test accuracy: 0.957700
Distillation: Epoch : 23, Loss : 0.172794, Accuracy: 0.947000, Test accuracy: 0.958500
Distillation: Epoch : 24, Loss : 0.153069, Accuracy: 0.957000, Test accuracy: 0.959000
Distillation: Epoch : 25, Loss : 0.132518, Accuracy: 0.958000, Test accuracy: 0.959100
Distillation: Epoch : 26, Loss : 0.137394, Accuracy: 0.956000, Test accuracy: 0.959200
Distillation: Epoch : 27, Loss : 0.159964, Accuracy: 0.948000, Test accuracy: 0.959000
Distillation: Epoch : 28, Loss : 0.153909, Accuracy: 0.953000, Test accuracy: 0.960400
Distillation: Epoch : 29, Loss : 0.136575, Accuracy: 0.961000, Test accuracy: 0.960500
Distillation: Epoch : 30, Loss : 0.114350, Accuracy: 0.965000, Test accuracy: 0.960700
Distillation: Epoch : 31, Loss : 0.129062, Accuracy: 0.966000, Test accuracy: 0.960400
Distillation: Epoch : 32, Loss : 0.141733, Accuracy: 0.960000, Test accuracy: 0.960000
Distillation: Epoch : 33, Loss : 0.122262, Accuracy: 0.963000, Test accuracy: 0.961600
Distillation: Epoch : 34, Loss : 0.139547, Accuracy: 0.956000, Test accuracy: 0.961300
Distillation: Epoch : 35, Loss : 0.135224, Accuracy: 0.957000, Test accuracy: 0.961200
Distillation: Epoch : 36, Loss : 0.153252, Accuracy: 0.960000, Test accuracy: 0.961300
Distillation: Epoch : 37, Loss : 0.128250, Accuracy: 0.960000, Test accuracy: 0.961200
Distillation: Epoch : 38, Loss : 0.145934, Accuracy: 0.960000, Test accuracy: 0.961800
Distillation: Epoch : 39, Loss : 0.132129, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 40, Loss : 0.088275, Accuracy: 0.974000, Test accuracy: 0.962700
Distillation: Epoch : 41, Loss : 0.128685, Accuracy: 0.959000, Test accuracy: 0.962600
Distillation: Epoch : 42, Loss : 0.146625, Accuracy: 0.950000, Test accuracy: 0.962700
Distillation: Epoch : 43, Loss : 0.108048, Accuracy: 0.969000, Test accuracy: 0.962800
Distillation: Epoch : 44, Loss : 0.107924, Accuracy: 0.976000, Test accuracy: 0.962800
Distillation: Epoch : 45, Loss : 0.136628, Accuracy: 0.951000, Test accuracy: 0.962500
Distillation: Epoch : 46, Loss : 0.127114, Accuracy: 0.959000, Test accuracy: 0.963800
Distillation: Epoch : 47, Loss : 0.109127, Accuracy: 0.971000, Test accuracy: 0.962600
Distillation: Epoch : 48, Loss : 0.086283, Accuracy: 0.969000, Test accuracy: 0.962400
Distillation: Epoch : 49, Loss : 0.112083, Accuracy: 0.966000, Test accuracy: 0.963400
Distillation: Epoch : 50, Loss : 0.145039, Accuracy: 0.957000, Test accuracy: 0.963400
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9634
Generating confusion matrix for student3
[[ 964.    0.    3.    2.    1.    5.   11.    1.    7.    6.]
 [   0. 1120.    4.    0.    1.    1.    3.    6.    1.    6.]
 [   2.    2.  998.    8.    4.    0.    3.   17.    7.    1.]
 [   1.    2.    2.  977.    2.   18.    0.    9.   13.   10.]
 [   1.    0.    5.    0.  952.    2.    5.    1.    7.   12.]
 [   2.    0.    0.    4.    0.  844.   10.    0.    4.    6.]
 [   7.    4.    5.    0.    4.    6.  925.    0.    0.    1.]
 [   2.    1.    7.    8.    2.    2.    0.  981.    6.   10.]
 [   1.    6.    8.   10.    2.   14.    1.    2.  921.    5.]
 [   0.    0.    0.    1.   14.    0.    0.   11.    8.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.347402, Accuracy: 0.791000, Test accuracy: 0.796300
Distillation: Epoch : 2, Loss : 0.635193, Accuracy: 0.878000, Test accuracy: 0.860900
Distillation: Epoch : 3, Loss : 0.487399, Accuracy: 0.877000, Test accuracy: 0.885300
Distillation: Epoch : 4, Loss : 0.395170, Accuracy: 0.913000, Test accuracy: 0.901000
Distillation: Epoch : 5, Loss : 0.382584, Accuracy: 0.900000, Test accuracy: 0.908400
Distillation: Epoch : 6, Loss : 0.330285, Accuracy: 0.916000, Test accuracy: 0.913500
Distillation: Epoch : 7, Loss : 0.332243, Accuracy: 0.902000, Test accuracy: 0.915900
Distillation: Epoch : 8, Loss : 0.313339, Accuracy: 0.920000, Test accuracy: 0.922500
Distillation: Epoch : 9, Loss : 0.321758, Accuracy: 0.915000, Test accuracy: 0.924500
Distillation: Epoch : 10, Loss : 0.263835, Accuracy: 0.928000, Test accuracy: 0.928000
Distillation: Epoch : 11, Loss : 0.266401, Accuracy: 0.927000, Test accuracy: 0.929900
Distillation: Epoch : 12, Loss : 0.232506, Accuracy: 0.948000, Test accuracy: 0.932000
Distillation: Epoch : 13, Loss : 0.320406, Accuracy: 0.913000, Test accuracy: 0.933500
Distillation: Epoch : 14, Loss : 0.260284, Accuracy: 0.931000, Test accuracy: 0.933300
Distillation: Epoch : 15, Loss : 0.260423, Accuracy: 0.928000, Test accuracy: 0.936400
Distillation: Epoch : 16, Loss : 0.278120, Accuracy: 0.928000, Test accuracy: 0.937200
Distillation: Epoch : 17, Loss : 0.232457, Accuracy: 0.949000, Test accuracy: 0.939300
Distillation: Epoch : 18, Loss : 0.209498, Accuracy: 0.930000, Test accuracy: 0.940300
Distillation: Epoch : 19, Loss : 0.230154, Accuracy: 0.946000, Test accuracy: 0.941800
Distillation: Epoch : 20, Loss : 0.271201, Accuracy: 0.932000, Test accuracy: 0.942800
Distillation: Epoch : 21, Loss : 0.244296, Accuracy: 0.944000, Test accuracy: 0.943900
Distillation: Epoch : 22, Loss : 0.218363, Accuracy: 0.942000, Test accuracy: 0.945800
Distillation: Epoch : 23, Loss : 0.208317, Accuracy: 0.943000, Test accuracy: 0.945800
Distillation: Epoch : 24, Loss : 0.208202, Accuracy: 0.941000, Test accuracy: 0.947400
Distillation: Epoch : 25, Loss : 0.212451, Accuracy: 0.942000, Test accuracy: 0.948100
Distillation: Epoch : 26, Loss : 0.178703, Accuracy: 0.959000, Test accuracy: 0.950300
Distillation: Epoch : 27, Loss : 0.221649, Accuracy: 0.943000, Test accuracy: 0.950100
Distillation: Epoch : 28, Loss : 0.191003, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 29, Loss : 0.217077, Accuracy: 0.941000, Test accuracy: 0.952000
Distillation: Epoch : 30, Loss : 0.219580, Accuracy: 0.942000, Test accuracy: 0.953000
Distillation: Epoch : 31, Loss : 0.184685, Accuracy: 0.947000, Test accuracy: 0.953400
Distillation: Epoch : 32, Loss : 0.183920, Accuracy: 0.955000, Test accuracy: 0.955200
Distillation: Epoch : 33, Loss : 0.209393, Accuracy: 0.948000, Test accuracy: 0.955200
Distillation: Epoch : 34, Loss : 0.185252, Accuracy: 0.954000, Test accuracy: 0.955300
Distillation: Epoch : 35, Loss : 0.195333, Accuracy: 0.940000, Test accuracy: 0.955800
Distillation: Epoch : 36, Loss : 0.191836, Accuracy: 0.957000, Test accuracy: 0.955700
Distillation: Epoch : 37, Loss : 0.218043, Accuracy: 0.944000, Test accuracy: 0.956200
Distillation: Epoch : 38, Loss : 0.190398, Accuracy: 0.956000, Test accuracy: 0.957800
Distillation: Epoch : 39, Loss : 0.209583, Accuracy: 0.947000, Test accuracy: 0.958200
Distillation: Epoch : 40, Loss : 0.172733, Accuracy: 0.959000, Test accuracy: 0.958800
Distillation: Epoch : 41, Loss : 0.165690, Accuracy: 0.958000, Test accuracy: 0.957900
Distillation: Epoch : 42, Loss : 0.203563, Accuracy: 0.955000, Test accuracy: 0.959000
Distillation: Epoch : 43, Loss : 0.186848, Accuracy: 0.955000, Test accuracy: 0.959200
Distillation: Epoch : 44, Loss : 0.140322, Accuracy: 0.973000, Test accuracy: 0.960100
Distillation: Epoch : 45, Loss : 0.174619, Accuracy: 0.957000, Test accuracy: 0.960400
Distillation: Epoch : 46, Loss : 0.165795, Accuracy: 0.959000, Test accuracy: 0.960800
Distillation: Epoch : 47, Loss : 0.214528, Accuracy: 0.950000, Test accuracy: 0.961300
Distillation: Epoch : 48, Loss : 0.156035, Accuracy: 0.963000, Test accuracy: 0.960600
Distillation: Epoch : 49, Loss : 0.163874, Accuracy: 0.960000, Test accuracy: 0.961400
Distillation: Epoch : 50, Loss : 0.155742, Accuracy: 0.957000, Test accuracy: 0.960800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9608
Generating confusion matrix for student3
[[ 971.    0.    5.    0.    1.    4.    5.    0.    8.    5.]
 [   0. 1122.    7.    0.    2.    1.    3.    8.    5.    5.]
 [   1.    4.  980.    6.    3.    0.    1.   18.    9.    0.]
 [   0.    1.    9.  978.    0.   11.    1.    6.   17.    7.]
 [   0.    0.    6.    0.  956.    0.    5.    3.    8.   17.]
 [   3.    1.    0.    7.    0.  856.    6.    1.   12.    6.]
 [   2.    3.    4.    0.    4.    6.  934.    0.    7.    0.]
 [   1.    0.    8.    6.    2.    2.    0.  972.   10.   15.]
 [   2.    4.    9.    8.    3.    7.    3.    3.  887.    2.]
 [   0.    0.    4.    5.   11.    5.    0.   17.   11.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.659341, Accuracy: 0.719000, Test accuracy: 0.735000
Distillation: Epoch : 2, Loss : 1.042699, Accuracy: 0.778000, Test accuracy: 0.818300
Distillation: Epoch : 3, Loss : 0.852772, Accuracy: 0.842000, Test accuracy: 0.858000
Distillation: Epoch : 4, Loss : 0.778939, Accuracy: 0.864000, Test accuracy: 0.876800
Distillation: Epoch : 5, Loss : 0.714013, Accuracy: 0.876000, Test accuracy: 0.886800
Distillation: Epoch : 6, Loss : 0.652152, Accuracy: 0.911000, Test accuracy: 0.893200
Distillation: Epoch : 7, Loss : 0.678793, Accuracy: 0.885000, Test accuracy: 0.898600
Distillation: Epoch : 8, Loss : 0.705160, Accuracy: 0.880000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 0.724708, Accuracy: 0.887000, Test accuracy: 0.905100
Distillation: Epoch : 10, Loss : 0.648193, Accuracy: 0.906000, Test accuracy: 0.907700
Distillation: Epoch : 11, Loss : 0.670237, Accuracy: 0.897000, Test accuracy: 0.909900
Distillation: Epoch : 12, Loss : 0.662192, Accuracy: 0.905000, Test accuracy: 0.910300
Distillation: Epoch : 13, Loss : 0.660582, Accuracy: 0.913000, Test accuracy: 0.911700
Distillation: Epoch : 14, Loss : 0.654632, Accuracy: 0.906000, Test accuracy: 0.912800
Distillation: Epoch : 15, Loss : 0.681566, Accuracy: 0.897000, Test accuracy: 0.914700
Distillation: Epoch : 16, Loss : 0.653598, Accuracy: 0.904000, Test accuracy: 0.913400
Distillation: Epoch : 17, Loss : 0.617070, Accuracy: 0.921000, Test accuracy: 0.916000
Distillation: Epoch : 18, Loss : 0.660960, Accuracy: 0.905000, Test accuracy: 0.915700
Distillation: Epoch : 19, Loss : 0.631839, Accuracy: 0.910000, Test accuracy: 0.917600
Distillation: Epoch : 20, Loss : 0.661123, Accuracy: 0.897000, Test accuracy: 0.917500
Distillation: Epoch : 21, Loss : 0.643393, Accuracy: 0.903000, Test accuracy: 0.917400
Distillation: Epoch : 22, Loss : 0.627629, Accuracy: 0.919000, Test accuracy: 0.917900
Distillation: Epoch : 23, Loss : 0.618591, Accuracy: 0.917000, Test accuracy: 0.919200
Distillation: Epoch : 24, Loss : 0.615078, Accuracy: 0.926000, Test accuracy: 0.920600
Distillation: Epoch : 25, Loss : 0.654533, Accuracy: 0.905000, Test accuracy: 0.922800
Distillation: Epoch : 26, Loss : 0.595749, Accuracy: 0.929000, Test accuracy: 0.921800
Distillation: Epoch : 27, Loss : 0.603396, Accuracy: 0.928000, Test accuracy: 0.923300
Distillation: Epoch : 28, Loss : 0.599818, Accuracy: 0.928000, Test accuracy: 0.924300
Distillation: Epoch : 29, Loss : 0.634056, Accuracy: 0.907000, Test accuracy: 0.924000
Distillation: Epoch : 30, Loss : 0.602997, Accuracy: 0.920000, Test accuracy: 0.925800
Distillation: Epoch : 31, Loss : 0.622040, Accuracy: 0.920000, Test accuracy: 0.925400
Distillation: Epoch : 32, Loss : 0.651745, Accuracy: 0.904000, Test accuracy: 0.925700
Distillation: Epoch : 33, Loss : 0.580687, Accuracy: 0.922000, Test accuracy: 0.926400
Distillation: Epoch : 34, Loss : 0.555428, Accuracy: 0.933000, Test accuracy: 0.927900
Distillation: Epoch : 35, Loss : 0.622644, Accuracy: 0.917000, Test accuracy: 0.927900
Distillation: Epoch : 36, Loss : 0.574383, Accuracy: 0.931000, Test accuracy: 0.928700
Distillation: Epoch : 37, Loss : 0.573522, Accuracy: 0.938000, Test accuracy: 0.929500
Distillation: Epoch : 38, Loss : 0.587674, Accuracy: 0.922000, Test accuracy: 0.929700
Distillation: Epoch : 39, Loss : 0.557933, Accuracy: 0.934000, Test accuracy: 0.929400
Distillation: Epoch : 40, Loss : 0.609100, Accuracy: 0.924000, Test accuracy: 0.930200
Distillation: Epoch : 41, Loss : 0.556720, Accuracy: 0.930000, Test accuracy: 0.930900
Distillation: Epoch : 42, Loss : 0.558126, Accuracy: 0.933000, Test accuracy: 0.932300
Distillation: Epoch : 43, Loss : 0.612741, Accuracy: 0.919000, Test accuracy: 0.933300
Distillation: Epoch : 44, Loss : 0.569177, Accuracy: 0.933000, Test accuracy: 0.933000
Distillation: Epoch : 45, Loss : 0.592844, Accuracy: 0.925000, Test accuracy: 0.933900
Distillation: Epoch : 46, Loss : 0.603892, Accuracy: 0.921000, Test accuracy: 0.933100
Distillation: Epoch : 47, Loss : 0.617487, Accuracy: 0.920000, Test accuracy: 0.934400
Distillation: Epoch : 48, Loss : 0.608409, Accuracy: 0.933000, Test accuracy: 0.935700
Distillation: Epoch : 49, Loss : 0.612059, Accuracy: 0.934000, Test accuracy: 0.935800
Distillation: Epoch : 50, Loss : 0.561539, Accuracy: 0.935000, Test accuracy: 0.935700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9357
Generating confusion matrix for student3
[[ 959.    0.    8.    3.    1.    9.   10.    1.   10.    8.]
 [   0. 1119.    9.    1.    2.    2.    3.   14.    3.    5.]
 [   1.    2.  934.   14.    7.    3.    5.   13.    8.    2.]
 [   3.    3.   21.  945.    0.   38.    0.    6.   14.   14.]
 [   0.    0.    9.    2.  913.    4.    7.    7.   10.   25.]
 [   5.    3.    1.   16.    1.  799.   10.    1.   17.    6.]
 [   9.    4.    9.    2.    8.   14.  918.    0.   12.    1.]
 [   1.    1.   13.    8.    2.    4.    2.  955.    4.   14.]
 [   1.    3.   22.   15.    5.   15.    3.    1.  884.    3.]
 [   1.    0.    6.    4.   43.    4.    0.   30.   12.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.651271, Accuracy: 0.786000, Test accuracy: 0.765100
Distillation: Epoch : 2, Loss : 1.140488, Accuracy: 0.815000, Test accuracy: 0.823700
Distillation: Epoch : 3, Loss : 1.015932, Accuracy: 0.832000, Test accuracy: 0.856400
Distillation: Epoch : 4, Loss : 0.904621, Accuracy: 0.858000, Test accuracy: 0.872900
Distillation: Epoch : 5, Loss : 0.908755, Accuracy: 0.865000, Test accuracy: 0.883000
Distillation: Epoch : 6, Loss : 0.854181, Accuracy: 0.888000, Test accuracy: 0.889900
Distillation: Epoch : 7, Loss : 0.856165, Accuracy: 0.893000, Test accuracy: 0.895400
Distillation: Epoch : 8, Loss : 0.860213, Accuracy: 0.895000, Test accuracy: 0.898300
Distillation: Epoch : 9, Loss : 0.871797, Accuracy: 0.887000, Test accuracy: 0.900600
Distillation: Epoch : 10, Loss : 0.880230, Accuracy: 0.892000, Test accuracy: 0.902300
Distillation: Epoch : 11, Loss : 0.826899, Accuracy: 0.901000, Test accuracy: 0.904300
Distillation: Epoch : 12, Loss : 0.856377, Accuracy: 0.892000, Test accuracy: 0.906900
Distillation: Epoch : 13, Loss : 0.844077, Accuracy: 0.897000, Test accuracy: 0.907500
Distillation: Epoch : 14, Loss : 0.800481, Accuracy: 0.917000, Test accuracy: 0.908000
Distillation: Epoch : 15, Loss : 0.817263, Accuracy: 0.898000, Test accuracy: 0.909600
Distillation: Epoch : 16, Loss : 0.854663, Accuracy: 0.905000, Test accuracy: 0.909800
Distillation: Epoch : 17, Loss : 0.841282, Accuracy: 0.898000, Test accuracy: 0.911300
Distillation: Epoch : 18, Loss : 0.795093, Accuracy: 0.907000, Test accuracy: 0.912300
Distillation: Epoch : 19, Loss : 0.873547, Accuracy: 0.892000, Test accuracy: 0.912400
Distillation: Epoch : 20, Loss : 0.839565, Accuracy: 0.897000, Test accuracy: 0.912400
Distillation: Epoch : 21, Loss : 0.818567, Accuracy: 0.902000, Test accuracy: 0.912700
Distillation: Epoch : 22, Loss : 0.798214, Accuracy: 0.906000, Test accuracy: 0.913400
Distillation: Epoch : 23, Loss : 0.836929, Accuracy: 0.901000, Test accuracy: 0.913500
Distillation: Epoch : 24, Loss : 0.814386, Accuracy: 0.906000, Test accuracy: 0.913400
Distillation: Epoch : 25, Loss : 0.846815, Accuracy: 0.877000, Test accuracy: 0.914700
Distillation: Epoch : 26, Loss : 0.832260, Accuracy: 0.908000, Test accuracy: 0.914000
Distillation: Epoch : 27, Loss : 0.831366, Accuracy: 0.900000, Test accuracy: 0.914600
Distillation: Epoch : 28, Loss : 0.808823, Accuracy: 0.909000, Test accuracy: 0.915300
Distillation: Epoch : 29, Loss : 0.822797, Accuracy: 0.892000, Test accuracy: 0.915300
Distillation: Epoch : 30, Loss : 0.810789, Accuracy: 0.918000, Test accuracy: 0.915800
Distillation: Epoch : 31, Loss : 0.787776, Accuracy: 0.917000, Test accuracy: 0.916100
Distillation: Epoch : 32, Loss : 0.815901, Accuracy: 0.892000, Test accuracy: 0.917200
Distillation: Epoch : 33, Loss : 0.801415, Accuracy: 0.915000, Test accuracy: 0.916400
Distillation: Epoch : 34, Loss : 0.792517, Accuracy: 0.909000, Test accuracy: 0.917100
Distillation: Epoch : 35, Loss : 0.819081, Accuracy: 0.904000, Test accuracy: 0.916900
Distillation: Epoch : 36, Loss : 0.838409, Accuracy: 0.902000, Test accuracy: 0.917400
Distillation: Epoch : 37, Loss : 0.792289, Accuracy: 0.920000, Test accuracy: 0.917500
Distillation: Epoch : 38, Loss : 0.749466, Accuracy: 0.936000, Test accuracy: 0.917700
Distillation: Epoch : 39, Loss : 0.806124, Accuracy: 0.900000, Test accuracy: 0.918200
Distillation: Epoch : 40, Loss : 0.751867, Accuracy: 0.924000, Test accuracy: 0.919100
Distillation: Epoch : 41, Loss : 0.785942, Accuracy: 0.917000, Test accuracy: 0.919600
Distillation: Epoch : 42, Loss : 0.756593, Accuracy: 0.932000, Test accuracy: 0.919800
Distillation: Epoch : 43, Loss : 0.768453, Accuracy: 0.915000, Test accuracy: 0.920700
Distillation: Epoch : 44, Loss : 0.791301, Accuracy: 0.914000, Test accuracy: 0.921500
Distillation: Epoch : 45, Loss : 0.760084, Accuracy: 0.929000, Test accuracy: 0.921800
Distillation: Epoch : 46, Loss : 0.788960, Accuracy: 0.914000, Test accuracy: 0.922300
Distillation: Epoch : 47, Loss : 0.769148, Accuracy: 0.920000, Test accuracy: 0.922400
Distillation: Epoch : 48, Loss : 0.775088, Accuracy: 0.922000, Test accuracy: 0.922900
Distillation: Epoch : 49, Loss : 0.799499, Accuracy: 0.905000, Test accuracy: 0.923800
Distillation: Epoch : 50, Loss : 0.753379, Accuracy: 0.929000, Test accuracy: 0.924100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9241
Generating confusion matrix for student3
[[ 958.    0.   11.    3.    0.    7.    9.    3.    8.   11.]
 [   0. 1119.    5.    2.    5.    3.    4.   17.    9.    6.]
 [   1.    2.  912.   11.    6.    1.    4.   18.    8.    0.]
 [   3.    2.   24.  944.    0.   36.    0.    7.   25.   17.]
 [   0.    1.   16.    2.  924.    4.    9.    9.   10.   36.]
 [   6.    3.    0.   13.    2.  790.   18.    1.   36.    9.]
 [   7.    4.   13.    4.    7.   17.  911.    0.   13.    1.]
 [   3.    0.   13.    9.    1.    5.    2.  936.    8.   21.]
 [   1.    4.   33.   18.    5.   25.    1.    0.  842.    3.]
 [   1.    0.    5.    4.   32.    4.    0.   37.   15.  905.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.771284, Accuracy: 0.741000, Test accuracy: 0.746200
Distillation: Epoch : 2, Loss : 1.263512, Accuracy: 0.803000, Test accuracy: 0.816100
Distillation: Epoch : 3, Loss : 1.133664, Accuracy: 0.853000, Test accuracy: 0.853200
Distillation: Epoch : 4, Loss : 1.074225, Accuracy: 0.867000, Test accuracy: 0.872700
Distillation: Epoch : 5, Loss : 1.097380, Accuracy: 0.852000, Test accuracy: 0.881900
Distillation: Epoch : 6, Loss : 1.023212, Accuracy: 0.888000, Test accuracy: 0.889400
Distillation: Epoch : 7, Loss : 1.081917, Accuracy: 0.858000, Test accuracy: 0.893600
Distillation: Epoch : 8, Loss : 1.051535, Accuracy: 0.882000, Test accuracy: 0.895900
Distillation: Epoch : 9, Loss : 1.030517, Accuracy: 0.873000, Test accuracy: 0.898600
Distillation: Epoch : 10, Loss : 1.019392, Accuracy: 0.891000, Test accuracy: 0.901800
Distillation: Epoch : 11, Loss : 1.056296, Accuracy: 0.883000, Test accuracy: 0.902600
Distillation: Epoch : 12, Loss : 0.989910, Accuracy: 0.911000, Test accuracy: 0.905600
Distillation: Epoch : 13, Loss : 1.027930, Accuracy: 0.886000, Test accuracy: 0.906500
Distillation: Epoch : 14, Loss : 0.986022, Accuracy: 0.900000, Test accuracy: 0.906600
Distillation: Epoch : 15, Loss : 1.003260, Accuracy: 0.895000, Test accuracy: 0.907700
Distillation: Epoch : 16, Loss : 1.036139, Accuracy: 0.884000, Test accuracy: 0.909400
Distillation: Epoch : 17, Loss : 0.996949, Accuracy: 0.898000, Test accuracy: 0.910300
Distillation: Epoch : 18, Loss : 0.998227, Accuracy: 0.910000, Test accuracy: 0.909200
Distillation: Epoch : 19, Loss : 0.989185, Accuracy: 0.909000, Test accuracy: 0.911400
Distillation: Epoch : 20, Loss : 1.026078, Accuracy: 0.903000, Test accuracy: 0.912000
Distillation: Epoch : 21, Loss : 1.010477, Accuracy: 0.874000, Test accuracy: 0.913300
Distillation: Epoch : 22, Loss : 0.985900, Accuracy: 0.905000, Test accuracy: 0.914800
Distillation: Epoch : 23, Loss : 0.991954, Accuracy: 0.911000, Test accuracy: 0.914200
Distillation: Epoch : 24, Loss : 0.959578, Accuracy: 0.919000, Test accuracy: 0.914500
Distillation: Epoch : 25, Loss : 0.964569, Accuracy: 0.917000, Test accuracy: 0.916600
Distillation: Epoch : 26, Loss : 1.006794, Accuracy: 0.910000, Test accuracy: 0.917100
Distillation: Epoch : 27, Loss : 0.971828, Accuracy: 0.905000, Test accuracy: 0.918400
Distillation: Epoch : 28, Loss : 0.962085, Accuracy: 0.922000, Test accuracy: 0.918800
Distillation: Epoch : 29, Loss : 0.965933, Accuracy: 0.900000, Test accuracy: 0.918900
Distillation: Epoch : 30, Loss : 0.971401, Accuracy: 0.910000, Test accuracy: 0.919900
Distillation: Epoch : 31, Loss : 0.955542, Accuracy: 0.919000, Test accuracy: 0.921300
Distillation: Epoch : 32, Loss : 0.972452, Accuracy: 0.906000, Test accuracy: 0.922600
Distillation: Epoch : 33, Loss : 0.957694, Accuracy: 0.912000, Test accuracy: 0.923400
Distillation: Epoch : 34, Loss : 0.940733, Accuracy: 0.922000, Test accuracy: 0.924800
Distillation: Epoch : 35, Loss : 0.941142, Accuracy: 0.924000, Test accuracy: 0.926100
Distillation: Epoch : 36, Loss : 0.916008, Accuracy: 0.924000, Test accuracy: 0.927300
Distillation: Epoch : 37, Loss : 0.966720, Accuracy: 0.928000, Test accuracy: 0.928700
Distillation: Epoch : 38, Loss : 0.924212, Accuracy: 0.930000, Test accuracy: 0.930300
Distillation: Epoch : 39, Loss : 0.903851, Accuracy: 0.944000, Test accuracy: 0.931500
Distillation: Epoch : 40, Loss : 0.931783, Accuracy: 0.930000, Test accuracy: 0.932600
Distillation: Epoch : 41, Loss : 0.931288, Accuracy: 0.919000, Test accuracy: 0.934100
Distillation: Epoch : 42, Loss : 0.969569, Accuracy: 0.921000, Test accuracy: 0.935300
Distillation: Epoch : 43, Loss : 0.932609, Accuracy: 0.933000, Test accuracy: 0.935500
Distillation: Epoch : 44, Loss : 0.928902, Accuracy: 0.933000, Test accuracy: 0.938200
Distillation: Epoch : 45, Loss : 0.953546, Accuracy: 0.921000, Test accuracy: 0.938400
Distillation: Epoch : 46, Loss : 0.924913, Accuracy: 0.930000, Test accuracy: 0.940500
Distillation: Epoch : 47, Loss : 0.925145, Accuracy: 0.944000, Test accuracy: 0.941800
Distillation: Epoch : 48, Loss : 0.864796, Accuracy: 0.936000, Test accuracy: 0.943200
Distillation: Epoch : 49, Loss : 0.910076, Accuracy: 0.939000, Test accuracy: 0.944600
Distillation: Epoch : 50, Loss : 0.900349, Accuracy: 0.939000, Test accuracy: 0.946100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9461
Generating confusion matrix for student3
[[ 962.    0.   10.    1.    1.    5.   11.    1.    9.    8.]
 [   0. 1114.    7.    0.    2.    1.    3.   13.    5.    6.]
 [   1.    2.  939.    3.    5.    2.    1.   14.    9.    0.]
 [   2.    3.   14.  972.    0.   24.    1.    3.   19.   16.]
 [   1.    0.   11.    1.  933.    1.    7.    8.   10.   22.]
 [   4.    2.    0.   10.    1.  834.    9.    2.   17.    7.]
 [   8.    5.   10.    1.    6.    9.  925.    0.   12.    0.]
 [   1.    1.   16.    7.    1.    3.    0.  966.    5.   11.]
 [   1.    8.   21.   10.    4.   10.    1.    2.  878.    1.]
 [   0.    0.    4.    5.   29.    3.    0.   19.   10.  938.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.867394, Accuracy: 0.731000, Test accuracy: 0.729800
Distillation: Epoch : 2, Loss : 1.411801, Accuracy: 0.802000, Test accuracy: 0.812900
Distillation: Epoch : 3, Loss : 1.267030, Accuracy: 0.869000, Test accuracy: 0.849400
Distillation: Epoch : 4, Loss : 1.246320, Accuracy: 0.864000, Test accuracy: 0.867300
Distillation: Epoch : 5, Loss : 1.262253, Accuracy: 0.862000, Test accuracy: 0.878000
Distillation: Epoch : 6, Loss : 1.230471, Accuracy: 0.878000, Test accuracy: 0.884200
Distillation: Epoch : 7, Loss : 1.197637, Accuracy: 0.876000, Test accuracy: 0.888800
Distillation: Epoch : 8, Loss : 1.208762, Accuracy: 0.876000, Test accuracy: 0.893000
Distillation: Epoch : 9, Loss : 1.177866, Accuracy: 0.898000, Test accuracy: 0.895400
Distillation: Epoch : 10, Loss : 1.192537, Accuracy: 0.880000, Test accuracy: 0.899000
Distillation: Epoch : 11, Loss : 1.211611, Accuracy: 0.892000, Test accuracy: 0.900000
Distillation: Epoch : 12, Loss : 1.194961, Accuracy: 0.896000, Test accuracy: 0.902200
Distillation: Epoch : 13, Loss : 1.180695, Accuracy: 0.887000, Test accuracy: 0.902100
Distillation: Epoch : 14, Loss : 1.161643, Accuracy: 0.897000, Test accuracy: 0.904400
Distillation: Epoch : 15, Loss : 1.174181, Accuracy: 0.897000, Test accuracy: 0.905100
Distillation: Epoch : 16, Loss : 1.180340, Accuracy: 0.883000, Test accuracy: 0.906000
Distillation: Epoch : 17, Loss : 1.157230, Accuracy: 0.890000, Test accuracy: 0.907300
Distillation: Epoch : 18, Loss : 1.161658, Accuracy: 0.897000, Test accuracy: 0.908000
Distillation: Epoch : 19, Loss : 1.148147, Accuracy: 0.898000, Test accuracy: 0.909200
Distillation: Epoch : 20, Loss : 1.152041, Accuracy: 0.920000, Test accuracy: 0.910000
Distillation: Epoch : 21, Loss : 1.152251, Accuracy: 0.910000, Test accuracy: 0.910300
Distillation: Epoch : 22, Loss : 1.146167, Accuracy: 0.909000, Test accuracy: 0.910800
Distillation: Epoch : 23, Loss : 1.160202, Accuracy: 0.902000, Test accuracy: 0.911700
Distillation: Epoch : 24, Loss : 1.172635, Accuracy: 0.886000, Test accuracy: 0.912800
Distillation: Epoch : 25, Loss : 1.149751, Accuracy: 0.903000, Test accuracy: 0.914400
Distillation: Epoch : 26, Loss : 1.164266, Accuracy: 0.894000, Test accuracy: 0.914900
Distillation: Epoch : 27, Loss : 1.138559, Accuracy: 0.897000, Test accuracy: 0.917200
Distillation: Epoch : 28, Loss : 1.144598, Accuracy: 0.885000, Test accuracy: 0.916800
Distillation: Epoch : 29, Loss : 1.120274, Accuracy: 0.906000, Test accuracy: 0.917800
Distillation: Epoch : 30, Loss : 1.144628, Accuracy: 0.902000, Test accuracy: 0.918800
Distillation: Epoch : 31, Loss : 1.167352, Accuracy: 0.889000, Test accuracy: 0.919800
Distillation: Epoch : 32, Loss : 1.097054, Accuracy: 0.927000, Test accuracy: 0.920600
Distillation: Epoch : 33, Loss : 1.125662, Accuracy: 0.910000, Test accuracy: 0.921500
Distillation: Epoch : 34, Loss : 1.121533, Accuracy: 0.900000, Test accuracy: 0.922900
Distillation: Epoch : 35, Loss : 1.136738, Accuracy: 0.913000, Test accuracy: 0.925700
Distillation: Epoch : 36, Loss : 1.127754, Accuracy: 0.904000, Test accuracy: 0.926000
Distillation: Epoch : 37, Loss : 1.116790, Accuracy: 0.912000, Test accuracy: 0.925800
Distillation: Epoch : 38, Loss : 1.112985, Accuracy: 0.928000, Test accuracy: 0.927300
Distillation: Epoch : 39, Loss : 1.118404, Accuracy: 0.919000, Test accuracy: 0.929600
Distillation: Epoch : 40, Loss : 1.069420, Accuracy: 0.928000, Test accuracy: 0.930800
Distillation: Epoch : 41, Loss : 1.112150, Accuracy: 0.937000, Test accuracy: 0.930900
Distillation: Epoch : 42, Loss : 1.096716, Accuracy: 0.932000, Test accuracy: 0.932200
Distillation: Epoch : 43, Loss : 1.130433, Accuracy: 0.924000, Test accuracy: 0.933000
Distillation: Epoch : 44, Loss : 1.077485, Accuracy: 0.935000, Test accuracy: 0.934000
Distillation: Epoch : 45, Loss : 1.087889, Accuracy: 0.933000, Test accuracy: 0.935400
Distillation: Epoch : 46, Loss : 1.079432, Accuracy: 0.937000, Test accuracy: 0.936100
Distillation: Epoch : 47, Loss : 1.101768, Accuracy: 0.927000, Test accuracy: 0.936600
Distillation: Epoch : 48, Loss : 1.087907, Accuracy: 0.928000, Test accuracy: 0.938600
Distillation: Epoch : 49, Loss : 1.065757, Accuracy: 0.959000, Test accuracy: 0.938500
Distillation: Epoch : 50, Loss : 1.099189, Accuracy: 0.931000, Test accuracy: 0.939500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9395
Generating confusion matrix for student3
[[ 965.    0.    9.    4.    0.    8.    6.    2.    8.    8.]
 [   0. 1120.   11.    4.    2.    2.    3.   17.    7.    6.]
 [   1.    2.  939.   11.    4.    0.    1.   16.   10.    1.]
 [   2.    2.   15.  958.    0.   27.    0.    7.   18.   13.]
 [   2.    1.   13.    2.  930.    7.    7.    8.   15.   23.]
 [   2.    3.    0.   10.    0.  816.   11.    1.   21.    6.]
 [   4.    4.    6.    3.    6.   13.  928.    0.    9.    1.]
 [   2.    0.   17.   12.    2.    4.    1.  946.    9.   19.]
 [   1.    3.   19.    6.    4.   10.    1.    0.  863.    2.]
 [   1.    0.    3.    0.   34.    5.    0.   31.   14.  930.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.964223, Accuracy: 0.758000, Test accuracy: 0.755600
Distillation: Epoch : 2, Loss : 1.547857, Accuracy: 0.807000, Test accuracy: 0.834400
Distillation: Epoch : 3, Loss : 1.412312, Accuracy: 0.850000, Test accuracy: 0.864900
Distillation: Epoch : 4, Loss : 1.354285, Accuracy: 0.879000, Test accuracy: 0.885900
Distillation: Epoch : 5, Loss : 1.318074, Accuracy: 0.903000, Test accuracy: 0.896100
Distillation: Epoch : 6, Loss : 1.324266, Accuracy: 0.891000, Test accuracy: 0.906300
Distillation: Epoch : 7, Loss : 1.310552, Accuracy: 0.904000, Test accuracy: 0.911500
Distillation: Epoch : 8, Loss : 1.314603, Accuracy: 0.911000, Test accuracy: 0.916800
Distillation: Epoch : 9, Loss : 1.271306, Accuracy: 0.931000, Test accuracy: 0.921100
Distillation: Epoch : 10, Loss : 1.282135, Accuracy: 0.903000, Test accuracy: 0.924100
Distillation: Epoch : 11, Loss : 1.255870, Accuracy: 0.928000, Test accuracy: 0.926200
Distillation: Epoch : 12, Loss : 1.267952, Accuracy: 0.917000, Test accuracy: 0.927600
Distillation: Epoch : 13, Loss : 1.260747, Accuracy: 0.920000, Test accuracy: 0.931500
Distillation: Epoch : 14, Loss : 1.259400, Accuracy: 0.916000, Test accuracy: 0.933400
Distillation: Epoch : 15, Loss : 1.234507, Accuracy: 0.932000, Test accuracy: 0.934000
Distillation: Epoch : 16, Loss : 1.262312, Accuracy: 0.928000, Test accuracy: 0.936800
Distillation: Epoch : 17, Loss : 1.250719, Accuracy: 0.932000, Test accuracy: 0.938200
Distillation: Epoch : 18, Loss : 1.244505, Accuracy: 0.934000, Test accuracy: 0.939900
Distillation: Epoch : 19, Loss : 1.243543, Accuracy: 0.930000, Test accuracy: 0.940900
Distillation: Epoch : 20, Loss : 1.236810, Accuracy: 0.941000, Test accuracy: 0.942100
Distillation: Epoch : 21, Loss : 1.231430, Accuracy: 0.934000, Test accuracy: 0.943000
Distillation: Epoch : 22, Loss : 1.217207, Accuracy: 0.941000, Test accuracy: 0.943900
Distillation: Epoch : 23, Loss : 1.237638, Accuracy: 0.943000, Test accuracy: 0.945100
Distillation: Epoch : 24, Loss : 1.225566, Accuracy: 0.950000, Test accuracy: 0.946900
Distillation: Epoch : 25, Loss : 1.213074, Accuracy: 0.950000, Test accuracy: 0.947900
Distillation: Epoch : 26, Loss : 1.209231, Accuracy: 0.944000, Test accuracy: 0.948600
Distillation: Epoch : 27, Loss : 1.224327, Accuracy: 0.936000, Test accuracy: 0.948700
Distillation: Epoch : 28, Loss : 1.214502, Accuracy: 0.949000, Test accuracy: 0.949600
Distillation: Epoch : 29, Loss : 1.228170, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 30, Loss : 1.267186, Accuracy: 0.929000, Test accuracy: 0.950600
Distillation: Epoch : 31, Loss : 1.233548, Accuracy: 0.945000, Test accuracy: 0.951800
Distillation: Epoch : 32, Loss : 1.227341, Accuracy: 0.954000, Test accuracy: 0.952500
Distillation: Epoch : 33, Loss : 1.205276, Accuracy: 0.948000, Test accuracy: 0.952500
Distillation: Epoch : 34, Loss : 1.226262, Accuracy: 0.947000, Test accuracy: 0.952400
Distillation: Epoch : 35, Loss : 1.203105, Accuracy: 0.948000, Test accuracy: 0.953400
Distillation: Epoch : 36, Loss : 1.183334, Accuracy: 0.961000, Test accuracy: 0.953600
Distillation: Epoch : 37, Loss : 1.224054, Accuracy: 0.943000, Test accuracy: 0.954000
Distillation: Epoch : 38, Loss : 1.188859, Accuracy: 0.964000, Test accuracy: 0.954700
Distillation: Epoch : 39, Loss : 1.197872, Accuracy: 0.957000, Test accuracy: 0.954400
Distillation: Epoch : 40, Loss : 1.213316, Accuracy: 0.958000, Test accuracy: 0.954400
Distillation: Epoch : 41, Loss : 1.194469, Accuracy: 0.951000, Test accuracy: 0.955100
Distillation: Epoch : 42, Loss : 1.220339, Accuracy: 0.958000, Test accuracy: 0.955300
Distillation: Epoch : 43, Loss : 1.221790, Accuracy: 0.934000, Test accuracy: 0.956200
Distillation: Epoch : 44, Loss : 1.198758, Accuracy: 0.959000, Test accuracy: 0.956000
Distillation: Epoch : 45, Loss : 1.200851, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 46, Loss : 1.196186, Accuracy: 0.955000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 1.194907, Accuracy: 0.955000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 1.190495, Accuracy: 0.955000, Test accuracy: 0.957100
Distillation: Epoch : 49, Loss : 1.189829, Accuracy: 0.953000, Test accuracy: 0.957700
Distillation: Epoch : 50, Loss : 1.189204, Accuracy: 0.969000, Test accuracy: 0.958000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.958
Generating confusion matrix for student3
[[ 968.    0.    5.    0.    1.    1.    8.    3.    7.    7.]
 [   2. 1119.   11.    1.    4.    1.    3.   13.    6.    7.]
 [   1.    4.  971.    5.    1.    1.    0.   15.    6.    1.]
 [   0.    1.   11.  982.    0.   13.    0.    6.   16.   12.]
 [   1.    0.   10.    2.  951.    0.    5.    3.   10.   19.]
 [   1.    0.    0.    7.    0.  861.    6.    0.   10.    3.]
 [   4.    3.    1.    0.    3.    7.  934.    0.   10.    0.]
 [   1.    1.   11.    5.    3.    1.    0.  958.    7.   12.]
 [   2.    7.   11.    6.    2.    4.    2.    1.  890.    2.]
 [   0.    0.    1.    2.   17.    3.    0.   29.   12.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.047572, Accuracy: 0.656000, Test accuracy: 0.674700
Distillation: Epoch : 2, Loss : 1.675230, Accuracy: 0.797000, Test accuracy: 0.806900
Distillation: Epoch : 3, Loss : 1.552882, Accuracy: 0.837000, Test accuracy: 0.841400
Distillation: Epoch : 4, Loss : 1.523927, Accuracy: 0.848000, Test accuracy: 0.863900
Distillation: Epoch : 5, Loss : 1.517095, Accuracy: 0.855000, Test accuracy: 0.879500
Distillation: Epoch : 6, Loss : 1.500724, Accuracy: 0.865000, Test accuracy: 0.890000
Distillation: Epoch : 7, Loss : 1.474761, Accuracy: 0.892000, Test accuracy: 0.895300
Distillation: Epoch : 8, Loss : 1.438254, Accuracy: 0.891000, Test accuracy: 0.900300
Distillation: Epoch : 9, Loss : 1.451024, Accuracy: 0.894000, Test accuracy: 0.906200
Distillation: Epoch : 10, Loss : 1.408554, Accuracy: 0.922000, Test accuracy: 0.910500
Distillation: Epoch : 11, Loss : 1.428709, Accuracy: 0.909000, Test accuracy: 0.915300
Distillation: Epoch : 12, Loss : 1.418433, Accuracy: 0.926000, Test accuracy: 0.918400
Distillation: Epoch : 13, Loss : 1.401324, Accuracy: 0.910000, Test accuracy: 0.921500
Distillation: Epoch : 14, Loss : 1.400746, Accuracy: 0.921000, Test accuracy: 0.924900
Distillation: Epoch : 15, Loss : 1.414118, Accuracy: 0.926000, Test accuracy: 0.928000
Distillation: Epoch : 16, Loss : 1.428242, Accuracy: 0.924000, Test accuracy: 0.931000
Distillation: Epoch : 17, Loss : 1.392211, Accuracy: 0.923000, Test accuracy: 0.934000
Distillation: Epoch : 18, Loss : 1.394182, Accuracy: 0.920000, Test accuracy: 0.936200
Distillation: Epoch : 19, Loss : 1.404271, Accuracy: 0.938000, Test accuracy: 0.937900
Distillation: Epoch : 20, Loss : 1.371991, Accuracy: 0.938000, Test accuracy: 0.940700
Distillation: Epoch : 21, Loss : 1.385298, Accuracy: 0.929000, Test accuracy: 0.942100
Distillation: Epoch : 22, Loss : 1.383011, Accuracy: 0.945000, Test accuracy: 0.943500
Distillation: Epoch : 23, Loss : 1.353172, Accuracy: 0.939000, Test accuracy: 0.945500
Distillation: Epoch : 24, Loss : 1.371104, Accuracy: 0.951000, Test accuracy: 0.946800
Distillation: Epoch : 25, Loss : 1.345750, Accuracy: 0.941000, Test accuracy: 0.947800
Distillation: Epoch : 26, Loss : 1.352736, Accuracy: 0.952000, Test accuracy: 0.948800
Distillation: Epoch : 27, Loss : 1.341047, Accuracy: 0.957000, Test accuracy: 0.950500
Distillation: Epoch : 28, Loss : 1.357958, Accuracy: 0.937000, Test accuracy: 0.952100
Distillation: Epoch : 29, Loss : 1.344707, Accuracy: 0.948000, Test accuracy: 0.952200
Distillation: Epoch : 30, Loss : 1.340111, Accuracy: 0.951000, Test accuracy: 0.952900
Distillation: Epoch : 31, Loss : 1.369686, Accuracy: 0.951000, Test accuracy: 0.952800
Distillation: Epoch : 32, Loss : 1.325089, Accuracy: 0.955000, Test accuracy: 0.953200
Distillation: Epoch : 33, Loss : 1.345347, Accuracy: 0.955000, Test accuracy: 0.953800
Distillation: Epoch : 34, Loss : 1.352542, Accuracy: 0.959000, Test accuracy: 0.954900
Distillation: Epoch : 35, Loss : 1.344700, Accuracy: 0.961000, Test accuracy: 0.955300
Distillation: Epoch : 36, Loss : 1.340487, Accuracy: 0.952000, Test accuracy: 0.955400
Distillation: Epoch : 37, Loss : 1.371513, Accuracy: 0.947000, Test accuracy: 0.956400
Distillation: Epoch : 38, Loss : 1.350541, Accuracy: 0.955000, Test accuracy: 0.956100
Distillation: Epoch : 39, Loss : 1.359822, Accuracy: 0.949000, Test accuracy: 0.956000
Distillation: Epoch : 40, Loss : 1.375676, Accuracy: 0.952000, Test accuracy: 0.956300
Distillation: Epoch : 41, Loss : 1.337116, Accuracy: 0.952000, Test accuracy: 0.956900
Distillation: Epoch : 42, Loss : 1.350849, Accuracy: 0.953000, Test accuracy: 0.957700
Distillation: Epoch : 43, Loss : 1.347639, Accuracy: 0.948000, Test accuracy: 0.957400
Distillation: Epoch : 44, Loss : 1.349229, Accuracy: 0.947000, Test accuracy: 0.957700
Distillation: Epoch : 45, Loss : 1.330205, Accuracy: 0.962000, Test accuracy: 0.958100
Distillation: Epoch : 46, Loss : 1.343211, Accuracy: 0.958000, Test accuracy: 0.958100
Distillation: Epoch : 47, Loss : 1.336694, Accuracy: 0.965000, Test accuracy: 0.958500
Distillation: Epoch : 48, Loss : 1.348359, Accuracy: 0.959000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 1.339640, Accuracy: 0.959000, Test accuracy: 0.958900
Distillation: Epoch : 50, Loss : 1.337984, Accuracy: 0.953000, Test accuracy: 0.958700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9587
Generating confusion matrix for student3
[[ 972.    0.    5.    1.    1.    2.   12.    4.   11.    6.]
 [   1. 1119.    8.    2.    2.    1.    4.   10.    4.    5.]
 [   1.    4.  976.    1.    1.    1.    0.   12.    9.    1.]
 [   0.    1.   10.  979.    0.    9.    1.    3.   12.   10.]
 [   0.    0.    4.    1.  950.    0.    6.    3.    9.   12.]
 [   1.    0.    1.    8.    0.  867.    9.    1.    8.    8.]
 [   4.    5.    3.    1.    6.    3.  923.    0.    9.    0.]
 [   1.    0.   11.    8.    3.    2.    0.  964.   14.   19.]
 [   0.    6.   13.    7.    3.    6.    3.    3.  892.    3.]
 [   0.    0.    1.    2.   16.    1.    0.   28.    6.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.069451, Accuracy: 0.691000, Test accuracy: 0.702500
Distillation: Epoch : 2, Loss : 1.713180, Accuracy: 0.812000, Test accuracy: 0.820500
Distillation: Epoch : 3, Loss : 1.663515, Accuracy: 0.843000, Test accuracy: 0.850000
Distillation: Epoch : 4, Loss : 1.627547, Accuracy: 0.867000, Test accuracy: 0.870500
Distillation: Epoch : 5, Loss : 1.622604, Accuracy: 0.855000, Test accuracy: 0.882600
Distillation: Epoch : 6, Loss : 1.626067, Accuracy: 0.865000, Test accuracy: 0.889200
Distillation: Epoch : 7, Loss : 1.581797, Accuracy: 0.898000, Test accuracy: 0.893400
Distillation: Epoch : 8, Loss : 1.577152, Accuracy: 0.892000, Test accuracy: 0.896100
Distillation: Epoch : 9, Loss : 1.555719, Accuracy: 0.891000, Test accuracy: 0.898100
Distillation: Epoch : 10, Loss : 1.568729, Accuracy: 0.902000, Test accuracy: 0.901300
Distillation: Epoch : 11, Loss : 1.571651, Accuracy: 0.905000, Test accuracy: 0.903100
Distillation: Epoch : 12, Loss : 1.559524, Accuracy: 0.900000, Test accuracy: 0.904400
Distillation: Epoch : 13, Loss : 1.538545, Accuracy: 0.894000, Test accuracy: 0.906000
Distillation: Epoch : 14, Loss : 1.554581, Accuracy: 0.900000, Test accuracy: 0.908500
Distillation: Epoch : 15, Loss : 1.526685, Accuracy: 0.904000, Test accuracy: 0.910500
Distillation: Epoch : 16, Loss : 1.555824, Accuracy: 0.892000, Test accuracy: 0.914200
Distillation: Epoch : 17, Loss : 1.544927, Accuracy: 0.910000, Test accuracy: 0.916100
Distillation: Epoch : 18, Loss : 1.536837, Accuracy: 0.909000, Test accuracy: 0.918500
Distillation: Epoch : 19, Loss : 1.522734, Accuracy: 0.910000, Test accuracy: 0.921700
Distillation: Epoch : 20, Loss : 1.554321, Accuracy: 0.892000, Test accuracy: 0.923200
Distillation: Epoch : 21, Loss : 1.520701, Accuracy: 0.926000, Test accuracy: 0.926300
Distillation: Epoch : 22, Loss : 1.513145, Accuracy: 0.926000, Test accuracy: 0.927700
Distillation: Epoch : 23, Loss : 1.505909, Accuracy: 0.937000, Test accuracy: 0.928900
Distillation: Epoch : 24, Loss : 1.520259, Accuracy: 0.923000, Test accuracy: 0.931900
Distillation: Epoch : 25, Loss : 1.496879, Accuracy: 0.927000, Test accuracy: 0.933000
Distillation: Epoch : 26, Loss : 1.514001, Accuracy: 0.932000, Test accuracy: 0.934600
Distillation: Epoch : 27, Loss : 1.506830, Accuracy: 0.915000, Test accuracy: 0.936200
Distillation: Epoch : 28, Loss : 1.503934, Accuracy: 0.931000, Test accuracy: 0.938100
Distillation: Epoch : 29, Loss : 1.488859, Accuracy: 0.924000, Test accuracy: 0.938700
Distillation: Epoch : 30, Loss : 1.480210, Accuracy: 0.939000, Test accuracy: 0.941200
Distillation: Epoch : 31, Loss : 1.488156, Accuracy: 0.934000, Test accuracy: 0.942400
Distillation: Epoch : 32, Loss : 1.461895, Accuracy: 0.948000, Test accuracy: 0.943000
Distillation: Epoch : 33, Loss : 1.478945, Accuracy: 0.943000, Test accuracy: 0.943900
Distillation: Epoch : 34, Loss : 1.491197, Accuracy: 0.932000, Test accuracy: 0.945600
Distillation: Epoch : 35, Loss : 1.512291, Accuracy: 0.939000, Test accuracy: 0.946700
Distillation: Epoch : 36, Loss : 1.502732, Accuracy: 0.938000, Test accuracy: 0.947500
Distillation: Epoch : 37, Loss : 1.491994, Accuracy: 0.938000, Test accuracy: 0.948100
Distillation: Epoch : 38, Loss : 1.483263, Accuracy: 0.941000, Test accuracy: 0.949100
Distillation: Epoch : 39, Loss : 1.495252, Accuracy: 0.937000, Test accuracy: 0.949500
Distillation: Epoch : 40, Loss : 1.479893, Accuracy: 0.951000, Test accuracy: 0.950300
Distillation: Epoch : 41, Loss : 1.477575, Accuracy: 0.945000, Test accuracy: 0.950300
Distillation: Epoch : 42, Loss : 1.511880, Accuracy: 0.938000, Test accuracy: 0.951700
Distillation: Epoch : 43, Loss : 1.479000, Accuracy: 0.947000, Test accuracy: 0.951200
Distillation: Epoch : 44, Loss : 1.499999, Accuracy: 0.947000, Test accuracy: 0.952100
Distillation: Epoch : 45, Loss : 1.484403, Accuracy: 0.947000, Test accuracy: 0.952100
Distillation: Epoch : 46, Loss : 1.515885, Accuracy: 0.935000, Test accuracy: 0.952000
Distillation: Epoch : 47, Loss : 1.490149, Accuracy: 0.959000, Test accuracy: 0.952900
Distillation: Epoch : 48, Loss : 1.466734, Accuracy: 0.946000, Test accuracy: 0.954000
Distillation: Epoch : 49, Loss : 1.483821, Accuracy: 0.949000, Test accuracy: 0.953000
Distillation: Epoch : 50, Loss : 1.481708, Accuracy: 0.947000, Test accuracy: 0.953400
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9534
Generating confusion matrix for student3
[[ 965.    0.    4.    1.    1.    3.    5.    4.    9.    6.]
 [   1. 1121.    5.    1.    3.    1.    3.   13.    5.    6.]
 [   1.    4.  972.    6.    2.    1.    1.   12.    6.    2.]
 [   0.    0.   12.  973.    0.   12.    1.    5.   17.    9.]
 [   1.    1.    7.    2.  949.    0.    7.    6.    9.   19.]
 [   2.    0.    1.   12.    0.  856.    9.    1.   17.    9.]
 [   5.    4.    2.    1.    6.    6.  930.    0.    9.    0.]
 [   2.    0.   12.    6.    2.    4.    0.  955.   10.   19.]
 [   3.    5.   15.    6.    5.    5.    2.    2.  876.    2.]
 [   0.    0.    2.    2.   14.    4.    0.   30.   16.  937.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.188050, Accuracy: 0.618000, Test accuracy: 0.621000
Distillation: Epoch : 2, Loss : 1.981460, Accuracy: 0.799000, Test accuracy: 0.807400
Distillation: Epoch : 3, Loss : 1.890892, Accuracy: 0.843000, Test accuracy: 0.846800
Distillation: Epoch : 4, Loss : 1.871804, Accuracy: 0.879000, Test accuracy: 0.868600
Distillation: Epoch : 5, Loss : 1.839609, Accuracy: 0.872000, Test accuracy: 0.884600
Distillation: Epoch : 6, Loss : 1.829614, Accuracy: 0.881000, Test accuracy: 0.900400
Distillation: Epoch : 7, Loss : 1.803605, Accuracy: 0.909000, Test accuracy: 0.910400
Distillation: Epoch : 8, Loss : 1.828669, Accuracy: 0.890000, Test accuracy: 0.917400
Distillation: Epoch : 9, Loss : 1.807914, Accuracy: 0.907000, Test accuracy: 0.921800
Distillation: Epoch : 10, Loss : 1.805966, Accuracy: 0.905000, Test accuracy: 0.925100
Distillation: Epoch : 11, Loss : 1.801179, Accuracy: 0.904000, Test accuracy: 0.928900
Distillation: Epoch : 12, Loss : 1.781311, Accuracy: 0.924000, Test accuracy: 0.930400
Distillation: Epoch : 13, Loss : 1.783811, Accuracy: 0.919000, Test accuracy: 0.933900
Distillation: Epoch : 14, Loss : 1.784372, Accuracy: 0.942000, Test accuracy: 0.937600
Distillation: Epoch : 15, Loss : 1.763423, Accuracy: 0.942000, Test accuracy: 0.940900
Distillation: Epoch : 16, Loss : 1.763601, Accuracy: 0.950000, Test accuracy: 0.944700
Distillation: Epoch : 17, Loss : 1.767783, Accuracy: 0.935000, Test accuracy: 0.946000
Distillation: Epoch : 18, Loss : 1.778077, Accuracy: 0.942000, Test accuracy: 0.948800
Distillation: Epoch : 19, Loss : 1.766850, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 20, Loss : 1.776649, Accuracy: 0.934000, Test accuracy: 0.951600
Distillation: Epoch : 21, Loss : 1.773133, Accuracy: 0.940000, Test accuracy: 0.952500
Distillation: Epoch : 22, Loss : 1.759206, Accuracy: 0.950000, Test accuracy: 0.953600
Distillation: Epoch : 23, Loss : 1.764153, Accuracy: 0.933000, Test accuracy: 0.954400
Distillation: Epoch : 24, Loss : 1.766059, Accuracy: 0.946000, Test accuracy: 0.954300
Distillation: Epoch : 25, Loss : 1.762882, Accuracy: 0.945000, Test accuracy: 0.954700
Distillation: Epoch : 26, Loss : 1.785848, Accuracy: 0.944000, Test accuracy: 0.954900
Distillation: Epoch : 27, Loss : 1.764267, Accuracy: 0.943000, Test accuracy: 0.955800
Distillation: Epoch : 28, Loss : 1.767548, Accuracy: 0.949000, Test accuracy: 0.955700
Distillation: Epoch : 29, Loss : 1.765189, Accuracy: 0.958000, Test accuracy: 0.956200
Distillation: Epoch : 30, Loss : 1.756039, Accuracy: 0.949000, Test accuracy: 0.956500
Distillation: Epoch : 31, Loss : 1.765154, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 32, Loss : 1.763707, Accuracy: 0.956000, Test accuracy: 0.956700
Distillation: Epoch : 33, Loss : 1.773482, Accuracy: 0.944000, Test accuracy: 0.957100
Distillation: Epoch : 34, Loss : 1.748638, Accuracy: 0.951000, Test accuracy: 0.958100
Distillation: Epoch : 35, Loss : 1.762578, Accuracy: 0.953000, Test accuracy: 0.957900
Distillation: Epoch : 36, Loss : 1.755256, Accuracy: 0.946000, Test accuracy: 0.958200
Distillation: Epoch : 37, Loss : 1.769487, Accuracy: 0.944000, Test accuracy: 0.959200
Distillation: Epoch : 38, Loss : 1.742499, Accuracy: 0.947000, Test accuracy: 0.957900
Distillation: Epoch : 39, Loss : 1.764239, Accuracy: 0.949000, Test accuracy: 0.958400
Distillation: Epoch : 40, Loss : 1.750378, Accuracy: 0.950000, Test accuracy: 0.958400
Distillation: Epoch : 41, Loss : 1.745784, Accuracy: 0.955000, Test accuracy: 0.958600
Distillation: Epoch : 42, Loss : 1.769137, Accuracy: 0.949000, Test accuracy: 0.958100
Distillation: Epoch : 43, Loss : 1.742929, Accuracy: 0.954000, Test accuracy: 0.958300
Distillation: Epoch : 44, Loss : 1.748598, Accuracy: 0.961000, Test accuracy: 0.958500
Distillation: Epoch : 45, Loss : 1.760648, Accuracy: 0.952000, Test accuracy: 0.958000
Distillation: Epoch : 46, Loss : 1.756176, Accuracy: 0.953000, Test accuracy: 0.959000
Distillation: Epoch : 47, Loss : 1.759973, Accuracy: 0.949000, Test accuracy: 0.959400
Distillation: Epoch : 48, Loss : 1.727820, Accuracy: 0.959000, Test accuracy: 0.958000
Distillation: Epoch : 49, Loss : 1.738216, Accuracy: 0.963000, Test accuracy: 0.959000
Distillation: Epoch : 50, Loss : 1.752044, Accuracy: 0.958000, Test accuracy: 0.958300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9583
Generating confusion matrix for student3
[[ 972.    0.    5.    1.    1.    1.   12.    3.   10.    6.]
 [   2. 1121.    8.    0.    2.    1.    5.   11.    4.    6.]
 [   0.    3.  967.    3.    1.    1.    0.    9.    9.    1.]
 [   0.    1.   15.  986.    0.    9.    0.    5.   10.   13.]
 [   1.    0.    4.    0.  948.    0.    5.    3.   11.   20.]
 [   0.    0.    1.    8.    0.  869.   10.    2.   10.    7.]
 [   4.    4.    3.    0.    6.    6.  922.    0.   10.    0.]
 [   1.    0.   11.    6.    1.    2.    0.  974.   10.   20.]
 [   0.    6.   17.    5.    4.    1.    4.    2.  889.    1.]
 [   0.    0.    1.    1.   19.    2.    0.   19.   11.  935.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.249289, Accuracy: 0.507000, Test accuracy: 0.533900
Distillation: Epoch : 2, Loss : 2.130279, Accuracy: 0.820000, Test accuracy: 0.816600
Distillation: Epoch : 3, Loss : 2.085019, Accuracy: 0.848000, Test accuracy: 0.859200
Distillation: Epoch : 4, Loss : 2.070007, Accuracy: 0.862000, Test accuracy: 0.881800
Distillation: Epoch : 5, Loss : 2.047669, Accuracy: 0.887000, Test accuracy: 0.895500
Distillation: Epoch : 6, Loss : 2.038144, Accuracy: 0.907000, Test accuracy: 0.910000
Distillation: Epoch : 7, Loss : 2.040474, Accuracy: 0.921000, Test accuracy: 0.915900
Distillation: Epoch : 8, Loss : 2.040667, Accuracy: 0.906000, Test accuracy: 0.921800
Distillation: Epoch : 9, Loss : 2.025932, Accuracy: 0.920000, Test accuracy: 0.926300
Distillation: Epoch : 10, Loss : 2.025009, Accuracy: 0.914000, Test accuracy: 0.929300
Distillation: Epoch : 11, Loss : 2.016457, Accuracy: 0.915000, Test accuracy: 0.932100
Distillation: Epoch : 12, Loss : 2.019428, Accuracy: 0.929000, Test accuracy: 0.933000
Distillation: Epoch : 13, Loss : 2.020093, Accuracy: 0.944000, Test accuracy: 0.936400
Distillation: Epoch : 14, Loss : 2.031352, Accuracy: 0.924000, Test accuracy: 0.938100
Distillation: Epoch : 15, Loss : 2.012460, Accuracy: 0.939000, Test accuracy: 0.940400
Distillation: Epoch : 16, Loss : 2.019859, Accuracy: 0.924000, Test accuracy: 0.941600
Distillation: Epoch : 17, Loss : 2.013821, Accuracy: 0.964000, Test accuracy: 0.942400
Distillation: Epoch : 18, Loss : 2.023439, Accuracy: 0.935000, Test accuracy: 0.942900
Distillation: Epoch : 19, Loss : 2.007772, Accuracy: 0.937000, Test accuracy: 0.943400
Distillation: Epoch : 20, Loss : 2.017831, Accuracy: 0.930000, Test accuracy: 0.945300
Distillation: Epoch : 21, Loss : 2.010000, Accuracy: 0.946000, Test accuracy: 0.946100
Distillation: Epoch : 22, Loss : 2.010576, Accuracy: 0.930000, Test accuracy: 0.946100
Distillation: Epoch : 23, Loss : 2.018614, Accuracy: 0.934000, Test accuracy: 0.947100
Distillation: Epoch : 24, Loss : 2.010998, Accuracy: 0.923000, Test accuracy: 0.947000
Distillation: Epoch : 25, Loss : 2.022949, Accuracy: 0.938000, Test accuracy: 0.947900
Distillation: Epoch : 26, Loss : 2.008553, Accuracy: 0.958000, Test accuracy: 0.947200
Distillation: Epoch : 27, Loss : 2.018607, Accuracy: 0.946000, Test accuracy: 0.947200
Distillation: Epoch : 28, Loss : 2.012422, Accuracy: 0.953000, Test accuracy: 0.948500
Distillation: Epoch : 29, Loss : 2.010292, Accuracy: 0.952000, Test accuracy: 0.946800
Distillation: Epoch : 30, Loss : 2.017344, Accuracy: 0.964000, Test accuracy: 0.949400
Distillation: Epoch : 31, Loss : 2.009246, Accuracy: 0.934000, Test accuracy: 0.948300
Distillation: Epoch : 32, Loss : 2.003944, Accuracy: 0.938000, Test accuracy: 0.948900
Distillation: Epoch : 33, Loss : 2.019799, Accuracy: 0.941000, Test accuracy: 0.948800
Distillation: Epoch : 34, Loss : 2.011140, Accuracy: 0.946000, Test accuracy: 0.949200
Distillation: Epoch : 35, Loss : 2.029649, Accuracy: 0.945000, Test accuracy: 0.950300
Distillation: Epoch : 36, Loss : 2.007224, Accuracy: 0.946000, Test accuracy: 0.949600
Distillation: Epoch : 37, Loss : 2.011892, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 38, Loss : 2.015736, Accuracy: 0.941000, Test accuracy: 0.949800
Distillation: Epoch : 39, Loss : 2.021374, Accuracy: 0.944000, Test accuracy: 0.949600
Distillation: Epoch : 40, Loss : 2.007781, Accuracy: 0.948000, Test accuracy: 0.950000
Distillation: Epoch : 41, Loss : 2.012136, Accuracy: 0.939000, Test accuracy: 0.950900
Distillation: Epoch : 42, Loss : 2.001218, Accuracy: 0.953000, Test accuracy: 0.950100
Distillation: Epoch : 43, Loss : 2.016788, Accuracy: 0.938000, Test accuracy: 0.950600
Distillation: Epoch : 44, Loss : 2.009169, Accuracy: 0.942000, Test accuracy: 0.950900
Distillation: Epoch : 45, Loss : 2.023540, Accuracy: 0.948000, Test accuracy: 0.951300
Distillation: Epoch : 46, Loss : 2.008989, Accuracy: 0.948000, Test accuracy: 0.950700
Distillation: Epoch : 47, Loss : 2.002670, Accuracy: 0.950000, Test accuracy: 0.950600
Distillation: Epoch : 48, Loss : 1.994018, Accuracy: 0.950000, Test accuracy: 0.950500
Distillation: Epoch : 49, Loss : 2.007236, Accuracy: 0.952000, Test accuracy: 0.950600
Distillation: Epoch : 50, Loss : 2.013000, Accuracy: 0.947000, Test accuracy: 0.951000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.951
Generating confusion matrix for student3
[[ 962.    0.    3.    0.    1.    0.    9.    2.    9.    7.]
 [   2. 1116.   11.    0.    4.    1.    4.   13.    3.    8.]
 [   0.    4.  955.    3.    3.    1.    1.   13.   14.    1.]
 [   1.    3.   13.  987.    0.   20.    0.    6.   24.   10.]
 [   3.    1.    9.    2.  942.    1.    6.    7.    9.   19.]
 [   1.    0.    1.    3.    0.  851.   11.    2.   12.    7.]
 [   7.    3.    2.    0.    7.    7.  926.    0.    8.    0.]
 [   2.    1.   13.    7.    2.    2.    0.  953.    7.   20.]
 [   2.    7.   22.    6.    3.    7.    1.    3.  881.    0.]
 [   0.    0.    3.    2.   20.    2.    0.   29.    7.  937.]]
</confusion_matrix>
