Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.109712, Accuracy: 0.968000, Test accuracy: 0.961700
Starting training epoch 1
Epoch : 2, Loss : 0.110434, Accuracy: 0.952000, Test accuracy: 0.978000
Starting training epoch 2
Epoch : 3, Loss : 0.062005, Accuracy: 0.984000, Test accuracy: 0.984100
Starting training epoch 3
Epoch : 4, Loss : 0.026238, Accuracy: 0.996000, Test accuracy: 0.984600
Starting training epoch 4
Epoch : 5, Loss : 0.032322, Accuracy: 0.984000, Test accuracy: 0.987600
Starting training epoch 5
Epoch : 6, Loss : 0.012201, Accuracy: 0.992000, Test accuracy: 0.989100
Starting training epoch 6
Epoch : 7, Loss : 0.009718, Accuracy: 0.996000, Test accuracy: 0.988600
Starting training epoch 7
Epoch : 8, Loss : 0.009784, Accuracy: 1.000000, Test accuracy: 0.988700
Starting training epoch 8
Epoch : 9, Loss : 0.015243, Accuracy: 0.996000, Test accuracy: 0.990700
Starting training epoch 9
Epoch : 10, Loss : 0.015601, Accuracy: 0.996000, Test accuracy: 0.991400
Starting training epoch 10
Epoch : 11, Loss : 0.003359, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 11
Epoch : 12, Loss : 0.005053, Accuracy: 1.000000, Test accuracy: 0.991500
Starting training epoch 12
Epoch : 13, Loss : 0.013178, Accuracy: 0.992000, Test accuracy: 0.991800
Starting training epoch 13
Epoch : 14, Loss : 0.002129, Accuracy: 1.000000, Test accuracy: 0.991600
Starting training epoch 14
Epoch : 15, Loss : 0.015494, Accuracy: 0.988000, Test accuracy: 0.991900
Starting training epoch 15
Epoch : 16, Loss : 0.002368, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 16
Epoch : 17, Loss : 0.001420, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 17
Epoch : 18, Loss : 0.001086, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 18
Epoch : 19, Loss : 0.000935, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 19
Epoch : 20, Loss : 0.001214, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 20
Epoch : 21, Loss : 0.001382, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 21
Epoch : 22, Loss : 0.001000, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 22
Epoch : 23, Loss : 0.000108, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 23
Epoch : 24, Loss : 0.000381, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 24
Epoch : 25, Loss : 0.000442, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 25
Epoch : 26, Loss : 0.000691, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 26
Epoch : 27, Loss : 0.000517, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 27
Epoch : 28, Loss : 0.000328, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 28
Epoch : 29, Loss : 0.001789, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 29
Epoch : 30, Loss : 0.001145, Accuracy: 1.000000, Test accuracy: 0.991800
Starting training epoch 30
Epoch : 31, Loss : 0.000532, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 31
Epoch : 32, Loss : 0.000102, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 32
Epoch : 33, Loss : 0.000196, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 33
Epoch : 34, Loss : 0.000105, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 34
Epoch : 35, Loss : 0.000149, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 35
Epoch : 36, Loss : 0.000167, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 36
Epoch : 37, Loss : 0.000022, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 37
Epoch : 38, Loss : 0.000438, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 38
Epoch : 39, Loss : 0.000060, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 39
Epoch : 40, Loss : 0.000673, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 40
Epoch : 41, Loss : 0.000509, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 41
Epoch : 42, Loss : 0.000015, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 42
Epoch : 43, Loss : 0.000104, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 43
Epoch : 44, Loss : 0.000028, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 44
Epoch : 45, Loss : 0.000031, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 45
Epoch : 46, Loss : 0.000104, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 46
Epoch : 47, Loss : 0.000041, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 47
Epoch : 48, Loss : 0.000151, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 48
Epoch : 49, Loss : 0.000085, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 49
Epoch : 50, Loss : 0.000021, Accuracy: 1.000000, Test accuracy: 0.993000
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 0.670835, Accuracy: 0.812000, Test accuracy: 0.819700
Starting training epoch 1
Epoch : 2, Loss : 0.470879, Accuracy: 0.860000, Test accuracy: 0.885000
Starting training epoch 2
Epoch : 3, Loss : 0.392441, Accuracy: 0.904000, Test accuracy: 0.899800
Starting training epoch 3
Epoch : 4, Loss : 0.365378, Accuracy: 0.896000, Test accuracy: 0.903100
Starting training epoch 4
Epoch : 5, Loss : 0.452620, Accuracy: 0.908000, Test accuracy: 0.909800
Starting training epoch 5
Epoch : 6, Loss : 0.336296, Accuracy: 0.932000, Test accuracy: 0.911000
Starting training epoch 6
Epoch : 7, Loss : 0.330463, Accuracy: 0.904000, Test accuracy: 0.913600
Starting training epoch 7
Epoch : 8, Loss : 0.245173, Accuracy: 0.924000, Test accuracy: 0.915500
Starting training epoch 8
Epoch : 9, Loss : 0.260677, Accuracy: 0.928000, Test accuracy: 0.917200
Starting training epoch 9
Epoch : 10, Loss : 0.326431, Accuracy: 0.924000, Test accuracy: 0.917000
Starting training epoch 10
Epoch : 11, Loss : 0.239288, Accuracy: 0.932000, Test accuracy: 0.919700
Starting training epoch 11
Epoch : 12, Loss : 0.334667, Accuracy: 0.920000, Test accuracy: 0.917600
Starting training epoch 12
Epoch : 13, Loss : 0.211861, Accuracy: 0.936000, Test accuracy: 0.922000
Starting training epoch 13
Epoch : 14, Loss : 0.353700, Accuracy: 0.912000, Test accuracy: 0.922000
Starting training epoch 14
Epoch : 15, Loss : 0.350758, Accuracy: 0.908000, Test accuracy: 0.920600
Starting training epoch 15
Epoch : 16, Loss : 0.222754, Accuracy: 0.932000, Test accuracy: 0.922400
Starting training epoch 16
Epoch : 17, Loss : 0.181966, Accuracy: 0.960000, Test accuracy: 0.922600
Starting training epoch 17
Epoch : 18, Loss : 0.240082, Accuracy: 0.924000, Test accuracy: 0.924600
Starting training epoch 18
Epoch : 19, Loss : 0.232062, Accuracy: 0.948000, Test accuracy: 0.924000
Starting training epoch 19
Epoch : 20, Loss : 0.334402, Accuracy: 0.892000, Test accuracy: 0.921500
Starting training epoch 20
Epoch : 21, Loss : 0.244878, Accuracy: 0.924000, Test accuracy: 0.921900
Starting training epoch 21
Epoch : 22, Loss : 0.275527, Accuracy: 0.904000, Test accuracy: 0.923900
Starting training epoch 22
Epoch : 23, Loss : 0.242521, Accuracy: 0.920000, Test accuracy: 0.925300
Starting training epoch 23
Epoch : 24, Loss : 0.251802, Accuracy: 0.916000, Test accuracy: 0.924900
Starting training epoch 24
Epoch : 25, Loss : 0.293598, Accuracy: 0.904000, Test accuracy: 0.925800
Starting training epoch 25
Epoch : 26, Loss : 0.351229, Accuracy: 0.896000, Test accuracy: 0.926300
Starting training epoch 26
Epoch : 27, Loss : 0.204667, Accuracy: 0.940000, Test accuracy: 0.927300
Starting training epoch 27
Epoch : 28, Loss : 0.183320, Accuracy: 0.944000, Test accuracy: 0.926800
Starting training epoch 28
Epoch : 29, Loss : 0.265690, Accuracy: 0.908000, Test accuracy: 0.929000
Starting training epoch 29
Epoch : 30, Loss : 0.313554, Accuracy: 0.908000, Test accuracy: 0.928300
Starting training epoch 30
Epoch : 31, Loss : 0.208562, Accuracy: 0.952000, Test accuracy: 0.928600
Starting training epoch 31
Epoch : 32, Loss : 0.239254, Accuracy: 0.916000, Test accuracy: 0.929800
Starting training epoch 32
Epoch : 33, Loss : 0.204125, Accuracy: 0.944000, Test accuracy: 0.929300
Starting training epoch 33
Epoch : 34, Loss : 0.260857, Accuracy: 0.920000, Test accuracy: 0.929500
Starting training epoch 34
Epoch : 35, Loss : 0.385645, Accuracy: 0.912000, Test accuracy: 0.929900
Starting training epoch 35
Epoch : 36, Loss : 0.273505, Accuracy: 0.924000, Test accuracy: 0.930400
Starting training epoch 36
Epoch : 37, Loss : 0.234088, Accuracy: 0.940000, Test accuracy: 0.930800
Starting training epoch 37
Epoch : 38, Loss : 0.291427, Accuracy: 0.920000, Test accuracy: 0.931200
Starting training epoch 38
Epoch : 39, Loss : 0.194897, Accuracy: 0.944000, Test accuracy: 0.931100
Starting training epoch 39
Epoch : 40, Loss : 0.357884, Accuracy: 0.912000, Test accuracy: 0.932200
Starting training epoch 40
Epoch : 41, Loss : 0.168277, Accuracy: 0.952000, Test accuracy: 0.933100
Starting training epoch 41
Epoch : 42, Loss : 0.159542, Accuracy: 0.956000, Test accuracy: 0.933500
Starting training epoch 42
Epoch : 43, Loss : 0.291585, Accuracy: 0.912000, Test accuracy: 0.933400
Starting training epoch 43
Epoch : 44, Loss : 0.404597, Accuracy: 0.920000, Test accuracy: 0.932500
Starting training epoch 44
Epoch : 45, Loss : 0.250608, Accuracy: 0.924000, Test accuracy: 0.933700
Starting training epoch 45
Epoch : 46, Loss : 0.262691, Accuracy: 0.940000, Test accuracy: 0.933500
Starting training epoch 46
Epoch : 47, Loss : 0.279458, Accuracy: 0.892000, Test accuracy: 0.934300
Starting training epoch 47
Epoch : 48, Loss : 0.176832, Accuracy: 0.944000, Test accuracy: 0.933900
Starting training epoch 48
Epoch : 49, Loss : 0.174403, Accuracy: 0.944000, Test accuracy: 0.934500
Starting training epoch 49
Epoch : 50, Loss : 0.223289, Accuracy: 0.936000, Test accuracy: 0.934900
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 1.485554, Accuracy: 0.676000, Test accuracy: 0.681000
Starting training opoch 1
Epoch : 2, Loss : 0.640560, Accuracy: 0.844000, Test accuracy: 0.840100
Starting training opoch 2
Epoch : 3, Loss : 0.523621, Accuracy: 0.840000, Test accuracy: 0.880000
Starting training opoch 3
Epoch : 4, Loss : 0.440466, Accuracy: 0.864000, Test accuracy: 0.899000
Starting training opoch 4
Epoch : 5, Loss : 0.380780, Accuracy: 0.876000, Test accuracy: 0.907500
Starting training opoch 5
Epoch : 6, Loss : 0.455101, Accuracy: 0.868000, Test accuracy: 0.912100
Starting training opoch 6
Epoch : 7, Loss : 0.221900, Accuracy: 0.924000, Test accuracy: 0.918400
Starting training opoch 7
Epoch : 8, Loss : 0.301036, Accuracy: 0.904000, Test accuracy: 0.923000
Starting training opoch 8
Epoch : 9, Loss : 0.300744, Accuracy: 0.912000, Test accuracy: 0.923200
Starting training opoch 9
Epoch : 10, Loss : 0.380329, Accuracy: 0.892000, Test accuracy: 0.927900
Starting training opoch 10
Epoch : 11, Loss : 0.208856, Accuracy: 0.932000, Test accuracy: 0.928800
Starting training opoch 11
Epoch : 12, Loss : 0.282701, Accuracy: 0.908000, Test accuracy: 0.930300
Starting training opoch 12
Epoch : 13, Loss : 0.267348, Accuracy: 0.928000, Test accuracy: 0.931600
Starting training opoch 13
Epoch : 14, Loss : 0.215179, Accuracy: 0.928000, Test accuracy: 0.932000
Starting training opoch 14
Epoch : 15, Loss : 0.197220, Accuracy: 0.940000, Test accuracy: 0.934000
Starting training opoch 15
Epoch : 16, Loss : 0.175656, Accuracy: 0.952000, Test accuracy: 0.934500
Starting training opoch 16
Epoch : 17, Loss : 0.245786, Accuracy: 0.920000, Test accuracy: 0.936200
Starting training opoch 17
Epoch : 18, Loss : 0.229912, Accuracy: 0.948000, Test accuracy: 0.937100
Starting training opoch 18
Epoch : 19, Loss : 0.218840, Accuracy: 0.924000, Test accuracy: 0.937300
Starting training opoch 19
Epoch : 20, Loss : 0.253407, Accuracy: 0.932000, Test accuracy: 0.938500
Starting training opoch 20
Epoch : 21, Loss : 0.106117, Accuracy: 0.968000, Test accuracy: 0.940200
Starting training opoch 21
Epoch : 22, Loss : 0.190339, Accuracy: 0.912000, Test accuracy: 0.940500
Starting training opoch 22
Epoch : 23, Loss : 0.216284, Accuracy: 0.928000, Test accuracy: 0.940800
Starting training opoch 23
Epoch : 24, Loss : 0.181570, Accuracy: 0.948000, Test accuracy: 0.941400
Starting training opoch 24
Epoch : 25, Loss : 0.213854, Accuracy: 0.920000, Test accuracy: 0.943200
Starting training opoch 25
Epoch : 26, Loss : 0.187287, Accuracy: 0.956000, Test accuracy: 0.943000
Starting training opoch 26
Epoch : 27, Loss : 0.218338, Accuracy: 0.952000, Test accuracy: 0.943000
Starting training opoch 27
Epoch : 28, Loss : 0.182618, Accuracy: 0.940000, Test accuracy: 0.945200
Starting training opoch 28
Epoch : 29, Loss : 0.198706, Accuracy: 0.920000, Test accuracy: 0.945300
Starting training opoch 29
Epoch : 30, Loss : 0.108056, Accuracy: 0.960000, Test accuracy: 0.946700
Starting training opoch 30
Epoch : 31, Loss : 0.230361, Accuracy: 0.944000, Test accuracy: 0.946300
Starting training opoch 31
Epoch : 32, Loss : 0.141432, Accuracy: 0.964000, Test accuracy: 0.948800
Starting training opoch 32
Epoch : 33, Loss : 0.133726, Accuracy: 0.956000, Test accuracy: 0.949800
Starting training opoch 33
Epoch : 34, Loss : 0.078098, Accuracy: 0.980000, Test accuracy: 0.949500
Starting training opoch 34
Epoch : 35, Loss : 0.233476, Accuracy: 0.948000, Test accuracy: 0.950700
Starting training opoch 35
Epoch : 36, Loss : 0.112279, Accuracy: 0.960000, Test accuracy: 0.952000
Starting training opoch 36
Epoch : 37, Loss : 0.178771, Accuracy: 0.932000, Test accuracy: 0.951500
Starting training opoch 37
Epoch : 38, Loss : 0.132334, Accuracy: 0.940000, Test accuracy: 0.953000
Starting training opoch 38
Epoch : 39, Loss : 0.142911, Accuracy: 0.948000, Test accuracy: 0.953500
Starting training opoch 39
Epoch : 40, Loss : 0.116556, Accuracy: 0.968000, Test accuracy: 0.954200
Starting training opoch 40
Epoch : 41, Loss : 0.153643, Accuracy: 0.944000, Test accuracy: 0.953200
Starting training opoch 41
Epoch : 42, Loss : 0.170746, Accuracy: 0.960000, Test accuracy: 0.954300
Starting training opoch 42
Epoch : 43, Loss : 0.157344, Accuracy: 0.968000, Test accuracy: 0.953100
Starting training opoch 43
Epoch : 44, Loss : 0.166547, Accuracy: 0.948000, Test accuracy: 0.954300
Starting training opoch 44
Epoch : 45, Loss : 0.120296, Accuracy: 0.964000, Test accuracy: 0.957600
Starting training opoch 45
Epoch : 46, Loss : 0.151003, Accuracy: 0.960000, Test accuracy: 0.957600
Starting training opoch 46
Epoch : 47, Loss : 0.130706, Accuracy: 0.960000, Test accuracy: 0.957700
Starting training opoch 47
Epoch : 48, Loss : 0.221662, Accuracy: 0.964000, Test accuracy: 0.957000
Starting training opoch 48
Epoch : 49, Loss : 0.155553, Accuracy: 0.948000, Test accuracy: 0.958200
Starting training opoch 49
Epoch : 50, Loss : 0.215637, Accuracy: 0.948000, Test accuracy: 0.959400
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.603658, Accuracy: 0.828000, Test accuracy: 0.841400
Starting training epoch 1
Epoch : 2, Loss : 0.448513, Accuracy: 0.888000, Test accuracy: 0.886300
Starting training epoch 2
Epoch : 3, Loss : 0.286304, Accuracy: 0.900000, Test accuracy: 0.903600
Starting training epoch 3
Epoch : 4, Loss : 0.327816, Accuracy: 0.896000, Test accuracy: 0.915200
Starting training epoch 4
Epoch : 5, Loss : 0.255241, Accuracy: 0.912000, Test accuracy: 0.921600
Starting training epoch 5
Epoch : 6, Loss : 0.274353, Accuracy: 0.908000, Test accuracy: 0.928900
Starting training epoch 6
Epoch : 7, Loss : 0.264535, Accuracy: 0.936000, Test accuracy: 0.933500
Starting training epoch 7
Epoch : 8, Loss : 0.426149, Accuracy: 0.904000, Test accuracy: 0.936300
Starting training epoch 8
Epoch : 9, Loss : 0.307445, Accuracy: 0.908000, Test accuracy: 0.942800
Starting training epoch 9
Epoch : 10, Loss : 0.253308, Accuracy: 0.920000, Test accuracy: 0.945300
Starting training epoch 10
Epoch : 11, Loss : 0.123490, Accuracy: 0.964000, Test accuracy: 0.949500
Starting training epoch 11
Epoch : 12, Loss : 0.151420, Accuracy: 0.968000, Test accuracy: 0.951800
Starting training epoch 12
Epoch : 13, Loss : 0.173804, Accuracy: 0.952000, Test accuracy: 0.953800
Starting training epoch 13
Epoch : 14, Loss : 0.154421, Accuracy: 0.948000, Test accuracy: 0.956900
Starting training epoch 14
Epoch : 15, Loss : 0.165221, Accuracy: 0.944000, Test accuracy: 0.958100
Starting training epoch 15
Epoch : 16, Loss : 0.126984, Accuracy: 0.960000, Test accuracy: 0.959500
Starting training epoch 16
Epoch : 17, Loss : 0.196945, Accuracy: 0.952000, Test accuracy: 0.961200
Starting training epoch 17
Epoch : 18, Loss : 0.076598, Accuracy: 0.976000, Test accuracy: 0.962400
Starting training epoch 18
Epoch : 19, Loss : 0.157980, Accuracy: 0.948000, Test accuracy: 0.963800
Starting training epoch 19
Epoch : 20, Loss : 0.121716, Accuracy: 0.964000, Test accuracy: 0.964000
Starting training epoch 20
Epoch : 21, Loss : 0.151105, Accuracy: 0.952000, Test accuracy: 0.966400
Starting training epoch 21
Epoch : 22, Loss : 0.119758, Accuracy: 0.964000, Test accuracy: 0.967600
Starting training epoch 22
Epoch : 23, Loss : 0.117836, Accuracy: 0.956000, Test accuracy: 0.966300
Starting training epoch 23
Epoch : 24, Loss : 0.067630, Accuracy: 0.972000, Test accuracy: 0.969200
Starting training epoch 24
Epoch : 25, Loss : 0.112249, Accuracy: 0.976000, Test accuracy: 0.968900
Starting training epoch 25
Epoch : 26, Loss : 0.046841, Accuracy: 0.992000, Test accuracy: 0.969400
Starting training epoch 26
Epoch : 27, Loss : 0.070660, Accuracy: 0.976000, Test accuracy: 0.969800
Starting training epoch 27
Epoch : 28, Loss : 0.034083, Accuracy: 0.992000, Test accuracy: 0.969600
Starting training epoch 28
Epoch : 29, Loss : 0.106556, Accuracy: 0.956000, Test accuracy: 0.970000
Starting training epoch 29
Epoch : 30, Loss : 0.101931, Accuracy: 0.960000, Test accuracy: 0.970200
Starting training epoch 30
Epoch : 31, Loss : 0.104854, Accuracy: 0.964000, Test accuracy: 0.971300
Starting training epoch 31
Epoch : 32, Loss : 0.088671, Accuracy: 0.976000, Test accuracy: 0.971800
Starting training epoch 32
Epoch : 33, Loss : 0.070134, Accuracy: 0.968000, Test accuracy: 0.972800
Starting training epoch 33
Epoch : 34, Loss : 0.073040, Accuracy: 0.980000, Test accuracy: 0.972200
Starting training epoch 34
Epoch : 35, Loss : 0.066924, Accuracy: 0.976000, Test accuracy: 0.974300
Starting training epoch 35
Epoch : 36, Loss : 0.126797, Accuracy: 0.972000, Test accuracy: 0.974000
Starting training epoch 36
Epoch : 37, Loss : 0.071060, Accuracy: 0.984000, Test accuracy: 0.972700
Starting training epoch 37
Epoch : 38, Loss : 0.081604, Accuracy: 0.968000, Test accuracy: 0.974500
Starting training epoch 38
Epoch : 39, Loss : 0.102090, Accuracy: 0.980000, Test accuracy: 0.974100
Starting training epoch 39
Epoch : 40, Loss : 0.070766, Accuracy: 0.988000, Test accuracy: 0.973900
Starting training epoch 40
Epoch : 41, Loss : 0.108527, Accuracy: 0.988000, Test accuracy: 0.975200
Starting training epoch 41
Epoch : 42, Loss : 0.042523, Accuracy: 0.984000, Test accuracy: 0.975300
Starting training epoch 42
Epoch : 43, Loss : 0.089815, Accuracy: 0.976000, Test accuracy: 0.975400
Starting training epoch 43
Epoch : 44, Loss : 0.047890, Accuracy: 0.992000, Test accuracy: 0.974900
Starting training epoch 44
Epoch : 45, Loss : 0.046795, Accuracy: 0.980000, Test accuracy: 0.974900
Starting training epoch 45
Epoch : 46, Loss : 0.045360, Accuracy: 0.984000, Test accuracy: 0.975900
Starting training epoch 46
Epoch : 47, Loss : 0.058136, Accuracy: 0.980000, Test accuracy: 0.976700
Starting training epoch 47
Epoch : 48, Loss : 0.034561, Accuracy: 0.996000, Test accuracy: 0.976500
Starting training epoch 48
Epoch : 49, Loss : 0.044112, Accuracy: 0.984000, Test accuracy: 0.975800
Starting training epoch 49
Epoch : 50, Loss : 0.121962, Accuracy: 0.964000, Test accuracy: 0.976200
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.680870, Accuracy: 0.824000, Test accuracy: 0.834000
Starting training opoch 1
Epoch : 2, Loss : 0.428531, Accuracy: 0.896000, Test accuracy: 0.884300
Starting training opoch 2
Epoch : 3, Loss : 0.394553, Accuracy: 0.888000, Test accuracy: 0.899800
Starting training opoch 3
Epoch : 4, Loss : 0.337253, Accuracy: 0.896000, Test accuracy: 0.906900
Starting training opoch 4
Epoch : 5, Loss : 0.330188, Accuracy: 0.916000, Test accuracy: 0.910900
Starting training opoch 5
Epoch : 6, Loss : 0.270615, Accuracy: 0.916000, Test accuracy: 0.913700
Starting training opoch 6
Epoch : 7, Loss : 0.289919, Accuracy: 0.932000, Test accuracy: 0.916400
Starting training opoch 7
Epoch : 8, Loss : 0.331681, Accuracy: 0.904000, Test accuracy: 0.919200
Starting training opoch 8
Epoch : 9, Loss : 0.253967, Accuracy: 0.928000, Test accuracy: 0.920000
Starting training opoch 9
Epoch : 10, Loss : 0.296832, Accuracy: 0.900000, Test accuracy: 0.921500
Starting training opoch 10
Epoch : 11, Loss : 0.283979, Accuracy: 0.916000, Test accuracy: 0.922000
Starting training opoch 11
Epoch : 12, Loss : 0.271008, Accuracy: 0.932000, Test accuracy: 0.924700
Starting training opoch 12
Epoch : 13, Loss : 0.343196, Accuracy: 0.896000, Test accuracy: 0.924500
Starting training opoch 13
Epoch : 14, Loss : 0.282110, Accuracy: 0.920000, Test accuracy: 0.926900
Starting training opoch 14
Epoch : 15, Loss : 0.238272, Accuracy: 0.916000, Test accuracy: 0.927000
Starting training opoch 15
Epoch : 16, Loss : 0.241759, Accuracy: 0.944000, Test accuracy: 0.929900
Starting training opoch 16
Epoch : 17, Loss : 0.224603, Accuracy: 0.940000, Test accuracy: 0.930600
Starting training opoch 17
Epoch : 18, Loss : 0.216553, Accuracy: 0.932000, Test accuracy: 0.931400
Starting training opoch 18
Epoch : 19, Loss : 0.243604, Accuracy: 0.928000, Test accuracy: 0.934700
Starting training opoch 19
Epoch : 20, Loss : 0.240244, Accuracy: 0.928000, Test accuracy: 0.933900
Starting training opoch 20
Epoch : 21, Loss : 0.185636, Accuracy: 0.956000, Test accuracy: 0.936200
Starting training opoch 21
Epoch : 22, Loss : 0.231462, Accuracy: 0.932000, Test accuracy: 0.938400
Starting training opoch 22
Epoch : 23, Loss : 0.202861, Accuracy: 0.936000, Test accuracy: 0.940300
Starting training opoch 23
Epoch : 24, Loss : 0.195452, Accuracy: 0.948000, Test accuracy: 0.940300
Starting training opoch 24
Epoch : 25, Loss : 0.243109, Accuracy: 0.940000, Test accuracy: 0.943700
Starting training opoch 25
Epoch : 26, Loss : 0.165462, Accuracy: 0.960000, Test accuracy: 0.943900
Starting training opoch 26
Epoch : 27, Loss : 0.247511, Accuracy: 0.908000, Test accuracy: 0.945600
Starting training opoch 27
Epoch : 28, Loss : 0.209211, Accuracy: 0.944000, Test accuracy: 0.947000
Starting training opoch 28
Epoch : 29, Loss : 0.168081, Accuracy: 0.960000, Test accuracy: 0.949400
Starting training opoch 29
Epoch : 30, Loss : 0.138420, Accuracy: 0.964000, Test accuracy: 0.952300
Starting training opoch 30
Epoch : 31, Loss : 0.191807, Accuracy: 0.940000, Test accuracy: 0.953500
Starting training opoch 31
Epoch : 32, Loss : 0.124881, Accuracy: 0.972000, Test accuracy: 0.954600
Starting training opoch 32
Epoch : 33, Loss : 0.127992, Accuracy: 0.972000, Test accuracy: 0.956500
Starting training opoch 33
Epoch : 34, Loss : 0.198692, Accuracy: 0.940000, Test accuracy: 0.956600
Starting training opoch 34
Epoch : 35, Loss : 0.138524, Accuracy: 0.968000, Test accuracy: 0.958300
Starting training opoch 35
Epoch : 36, Loss : 0.128880, Accuracy: 0.964000, Test accuracy: 0.959300
Starting training opoch 36
Epoch : 37, Loss : 0.123149, Accuracy: 0.968000, Test accuracy: 0.961100
Starting training opoch 37
Epoch : 38, Loss : 0.130326, Accuracy: 0.944000, Test accuracy: 0.962500
Starting training opoch 38
Epoch : 39, Loss : 0.093461, Accuracy: 0.968000, Test accuracy: 0.962900
Starting training opoch 39
Epoch : 40, Loss : 0.137078, Accuracy: 0.960000, Test accuracy: 0.964500
Starting training opoch 40
Epoch : 41, Loss : 0.164365, Accuracy: 0.960000, Test accuracy: 0.965500
Starting training opoch 41
Epoch : 42, Loss : 0.118933, Accuracy: 0.960000, Test accuracy: 0.965100
Starting training opoch 42
Epoch : 43, Loss : 0.123858, Accuracy: 0.968000, Test accuracy: 0.966500
Starting training opoch 43
Epoch : 44, Loss : 0.086960, Accuracy: 0.968000, Test accuracy: 0.965800
Starting training opoch 44
Epoch : 45, Loss : 0.119337, Accuracy: 0.952000, Test accuracy: 0.966700
Starting training opoch 45
Epoch : 46, Loss : 0.109591, Accuracy: 0.968000, Test accuracy: 0.966500
Starting training opoch 46
Epoch : 47, Loss : 0.101796, Accuracy: 0.984000, Test accuracy: 0.967800
Starting training opoch 47
Epoch : 48, Loss : 0.152302, Accuracy: 0.960000, Test accuracy: 0.967400
Starting training opoch 48
Epoch : 49, Loss : 0.076415, Accuracy: 0.976000, Test accuracy: 0.968200
Starting training opoch 49
Epoch : 50, Loss : 0.140476, Accuracy: 0.968000, Test accuracy: 0.969000
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.897628, Accuracy: 0.780000, Test accuracy: 0.798600
Starting training opoch 1
Epoch : 2, Loss : 0.544840, Accuracy: 0.840000, Test accuracy: 0.869200
Starting training opoch 2
Epoch : 3, Loss : 0.433760, Accuracy: 0.880000, Test accuracy: 0.887900
Starting training opoch 3
Epoch : 4, Loss : 0.315791, Accuracy: 0.896000, Test accuracy: 0.898900
Starting training opoch 4
Epoch : 5, Loss : 0.389648, Accuracy: 0.900000, Test accuracy: 0.904600
Starting training opoch 5
Epoch : 6, Loss : 0.248906, Accuracy: 0.932000, Test accuracy: 0.908000
Starting training opoch 6
Epoch : 7, Loss : 0.296499, Accuracy: 0.896000, Test accuracy: 0.911700
Starting training opoch 7
Epoch : 8, Loss : 0.321750, Accuracy: 0.888000, Test accuracy: 0.911700
Starting training opoch 8
Epoch : 9, Loss : 0.316544, Accuracy: 0.916000, Test accuracy: 0.915500
Starting training opoch 9
Epoch : 10, Loss : 0.331980, Accuracy: 0.916000, Test accuracy: 0.915300
Starting training opoch 10
Epoch : 11, Loss : 0.304533, Accuracy: 0.904000, Test accuracy: 0.917300
Starting training opoch 11
Epoch : 12, Loss : 0.239026, Accuracy: 0.940000, Test accuracy: 0.919600
Starting training opoch 12
Epoch : 13, Loss : 0.317033, Accuracy: 0.920000, Test accuracy: 0.919400
Starting training opoch 13
Epoch : 14, Loss : 0.228270, Accuracy: 0.936000, Test accuracy: 0.921300
Starting training opoch 14
Epoch : 15, Loss : 0.296460, Accuracy: 0.904000, Test accuracy: 0.923300
Starting training opoch 15
Epoch : 16, Loss : 0.210443, Accuracy: 0.936000, Test accuracy: 0.924500
Starting training opoch 16
Epoch : 17, Loss : 0.186263, Accuracy: 0.952000, Test accuracy: 0.925000
Starting training opoch 17
Epoch : 18, Loss : 0.211519, Accuracy: 0.936000, Test accuracy: 0.925900
Starting training opoch 18
Epoch : 19, Loss : 0.356111, Accuracy: 0.892000, Test accuracy: 0.928100
Starting training opoch 19
Epoch : 20, Loss : 0.189294, Accuracy: 0.924000, Test accuracy: 0.928800
Starting training opoch 20
Epoch : 21, Loss : 0.264504, Accuracy: 0.928000, Test accuracy: 0.930600
Starting training opoch 21
Epoch : 22, Loss : 0.188187, Accuracy: 0.944000, Test accuracy: 0.931400
Starting training opoch 22
Epoch : 23, Loss : 0.269752, Accuracy: 0.924000, Test accuracy: 0.932200
Starting training opoch 23
Epoch : 24, Loss : 0.233873, Accuracy: 0.916000, Test accuracy: 0.934400
Starting training opoch 24
Epoch : 25, Loss : 0.249164, Accuracy: 0.936000, Test accuracy: 0.934400
Starting training opoch 25
Epoch : 26, Loss : 0.265561, Accuracy: 0.916000, Test accuracy: 0.936000
Starting training opoch 26
Epoch : 27, Loss : 0.172028, Accuracy: 0.960000, Test accuracy: 0.937200
Starting training opoch 27
Epoch : 28, Loss : 0.303999, Accuracy: 0.924000, Test accuracy: 0.937900
Starting training opoch 28
Epoch : 29, Loss : 0.330777, Accuracy: 0.912000, Test accuracy: 0.938000
Starting training opoch 29
Epoch : 30, Loss : 0.258154, Accuracy: 0.920000, Test accuracy: 0.939100
Starting training opoch 30
Epoch : 31, Loss : 0.182061, Accuracy: 0.944000, Test accuracy: 0.939600
Starting training opoch 31
Epoch : 32, Loss : 0.262519, Accuracy: 0.936000, Test accuracy: 0.939300
Starting training opoch 32
Epoch : 33, Loss : 0.199995, Accuracy: 0.940000, Test accuracy: 0.941400
Starting training opoch 33
Epoch : 34, Loss : 0.278665, Accuracy: 0.940000, Test accuracy: 0.942700
Starting training opoch 34
Epoch : 35, Loss : 0.171834, Accuracy: 0.952000, Test accuracy: 0.942800
Starting training opoch 35
Epoch : 36, Loss : 0.133410, Accuracy: 0.956000, Test accuracy: 0.943600
Starting training opoch 36
Epoch : 37, Loss : 0.260683, Accuracy: 0.936000, Test accuracy: 0.943200
Starting training opoch 37
Epoch : 38, Loss : 0.167338, Accuracy: 0.952000, Test accuracy: 0.944500
Starting training opoch 38
Epoch : 39, Loss : 0.151539, Accuracy: 0.960000, Test accuracy: 0.945800
Starting training opoch 39
Epoch : 40, Loss : 0.131620, Accuracy: 0.952000, Test accuracy: 0.945400
Starting training opoch 40
Epoch : 41, Loss : 0.150995, Accuracy: 0.960000, Test accuracy: 0.946300
Starting training opoch 41
Epoch : 42, Loss : 0.163845, Accuracy: 0.932000, Test accuracy: 0.947200
Starting training opoch 42
Epoch : 43, Loss : 0.087853, Accuracy: 0.976000, Test accuracy: 0.947800
Starting training opoch 43
Epoch : 44, Loss : 0.197593, Accuracy: 0.944000, Test accuracy: 0.948200
Starting training opoch 44
Epoch : 45, Loss : 0.230321, Accuracy: 0.944000, Test accuracy: 0.949100
Starting training opoch 45
Epoch : 46, Loss : 0.221469, Accuracy: 0.948000, Test accuracy: 0.949600
Starting training opoch 46
Epoch : 47, Loss : 0.170490, Accuracy: 0.956000, Test accuracy: 0.949900
Starting training opoch 47
Epoch : 48, Loss : 0.184536, Accuracy: 0.952000, Test accuracy: 0.950500
Starting training opoch 48
Epoch : 49, Loss : 0.239460, Accuracy: 0.932000, Test accuracy: 0.950200
Starting training opoch 49
Epoch : 50, Loss : 0.191056, Accuracy: 0.960000, Test accuracy: 0.951100
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.993
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.632064, Accuracy: 0.830000, Test accuracy: 0.843800
Distillation: Epoch : 2, Loss : 0.373129, Accuracy: 0.898000, Test accuracy: 0.899400
Distillation: Epoch : 3, Loss : 0.299069, Accuracy: 0.909000, Test accuracy: 0.911200
Distillation: Epoch : 4, Loss : 0.334710, Accuracy: 0.898000, Test accuracy: 0.919300
Distillation: Epoch : 5, Loss : 0.248888, Accuracy: 0.919000, Test accuracy: 0.925900
Distillation: Epoch : 6, Loss : 0.201912, Accuracy: 0.943000, Test accuracy: 0.930900
Distillation: Epoch : 7, Loss : 0.230757, Accuracy: 0.933000, Test accuracy: 0.932900
Distillation: Epoch : 8, Loss : 0.221631, Accuracy: 0.933000, Test accuracy: 0.937100
Distillation: Epoch : 9, Loss : 0.219385, Accuracy: 0.937000, Test accuracy: 0.939700
Distillation: Epoch : 10, Loss : 0.185697, Accuracy: 0.942000, Test accuracy: 0.941300
Distillation: Epoch : 11, Loss : 0.202795, Accuracy: 0.936000, Test accuracy: 0.943600
Distillation: Epoch : 12, Loss : 0.184394, Accuracy: 0.942000, Test accuracy: 0.946100
Distillation: Epoch : 13, Loss : 0.222807, Accuracy: 0.932000, Test accuracy: 0.948600
Distillation: Epoch : 14, Loss : 0.206344, Accuracy: 0.945000, Test accuracy: 0.949600
Distillation: Epoch : 15, Loss : 0.194680, Accuracy: 0.944000, Test accuracy: 0.951400
Distillation: Epoch : 16, Loss : 0.164288, Accuracy: 0.951000, Test accuracy: 0.952400
Distillation: Epoch : 17, Loss : 0.186854, Accuracy: 0.950000, Test accuracy: 0.953400
Distillation: Epoch : 18, Loss : 0.169260, Accuracy: 0.952000, Test accuracy: 0.954700
Distillation: Epoch : 19, Loss : 0.138750, Accuracy: 0.953000, Test accuracy: 0.955900
Distillation: Epoch : 20, Loss : 0.144600, Accuracy: 0.958000, Test accuracy: 0.956900
Distillation: Epoch : 21, Loss : 0.144288, Accuracy: 0.962000, Test accuracy: 0.957400
Distillation: Epoch : 22, Loss : 0.166798, Accuracy: 0.955000, Test accuracy: 0.958400
Distillation: Epoch : 23, Loss : 0.107170, Accuracy: 0.974000, Test accuracy: 0.958900
Distillation: Epoch : 24, Loss : 0.117452, Accuracy: 0.962000, Test accuracy: 0.959500
Distillation: Epoch : 25, Loss : 0.145314, Accuracy: 0.957000, Test accuracy: 0.960100
Distillation: Epoch : 26, Loss : 0.168191, Accuracy: 0.955000, Test accuracy: 0.960800
Distillation: Epoch : 27, Loss : 0.110813, Accuracy: 0.958000, Test accuracy: 0.961300
Distillation: Epoch : 28, Loss : 0.110039, Accuracy: 0.967000, Test accuracy: 0.961500
Distillation: Epoch : 29, Loss : 0.101417, Accuracy: 0.966000, Test accuracy: 0.961900
Distillation: Epoch : 30, Loss : 0.173939, Accuracy: 0.959000, Test accuracy: 0.962300
Distillation: Epoch : 31, Loss : 0.136522, Accuracy: 0.962000, Test accuracy: 0.962500
Distillation: Epoch : 32, Loss : 0.137395, Accuracy: 0.960000, Test accuracy: 0.963700
Distillation: Epoch : 33, Loss : 0.126136, Accuracy: 0.969000, Test accuracy: 0.963700
Distillation: Epoch : 34, Loss : 0.119554, Accuracy: 0.969000, Test accuracy: 0.964000
Distillation: Epoch : 35, Loss : 0.122782, Accuracy: 0.963000, Test accuracy: 0.964300
Distillation: Epoch : 36, Loss : 0.144493, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 37, Loss : 0.127949, Accuracy: 0.967000, Test accuracy: 0.964300
Distillation: Epoch : 38, Loss : 0.136863, Accuracy: 0.960000, Test accuracy: 0.964900
Distillation: Epoch : 39, Loss : 0.139975, Accuracy: 0.952000, Test accuracy: 0.964900
Distillation: Epoch : 40, Loss : 0.104140, Accuracy: 0.967000, Test accuracy: 0.965500
Distillation: Epoch : 41, Loss : 0.135090, Accuracy: 0.960000, Test accuracy: 0.965500
Distillation: Epoch : 42, Loss : 0.130111, Accuracy: 0.959000, Test accuracy: 0.966400
Distillation: Epoch : 43, Loss : 0.115458, Accuracy: 0.969000, Test accuracy: 0.966800
Distillation: Epoch : 44, Loss : 0.120250, Accuracy: 0.972000, Test accuracy: 0.966800
Distillation: Epoch : 45, Loss : 0.090434, Accuracy: 0.974000, Test accuracy: 0.966800
Distillation: Epoch : 46, Loss : 0.098615, Accuracy: 0.973000, Test accuracy: 0.966400
Distillation: Epoch : 47, Loss : 0.094972, Accuracy: 0.972000, Test accuracy: 0.966500
Distillation: Epoch : 48, Loss : 0.112719, Accuracy: 0.968000, Test accuracy: 0.968000
Distillation: Epoch : 49, Loss : 0.118653, Accuracy: 0.965000, Test accuracy: 0.966600
Distillation: Epoch : 50, Loss : 0.112712, Accuracy: 0.968000, Test accuracy: 0.969100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9691
Generating confusion matrix for student4
[[ 968.    0.    2.    0.    2.    1.    7.    1.    6.    4.]
 [   0. 1120.    7.    0.    3.    0.    2.    7.    2.    6.]
 [   2.    5.  995.    6.    3.    0.    2.   18.    6.    1.]
 [   0.    1.    6.  976.    0.    8.    0.    4.    8.    5.]
 [   0.    0.    4.    0.  955.    0.    4.    2.    3.   10.]
 [   2.    0.    0.   10.    0.  871.    6.    0.    4.    5.]
 [   1.    1.    1.    0.    1.    5.  933.    0.    2.    0.]
 [   2.    1.    8.    7.    2.    2.    0.  980.    7.   11.]
 [   4.    7.    7.    9.    2.    1.    4.    2.  931.    5.]
 [   1.    0.    2.    2.   14.    4.    0.   14.    5.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.850183, Accuracy: 0.798000, Test accuracy: 0.810300
Distillation: Epoch : 2, Loss : 0.466745, Accuracy: 0.867000, Test accuracy: 0.878700
Distillation: Epoch : 3, Loss : 0.387546, Accuracy: 0.889000, Test accuracy: 0.894200
Distillation: Epoch : 4, Loss : 0.371024, Accuracy: 0.900000, Test accuracy: 0.899900
Distillation: Epoch : 5, Loss : 0.377673, Accuracy: 0.899000, Test accuracy: 0.907000
Distillation: Epoch : 6, Loss : 0.316670, Accuracy: 0.907000, Test accuracy: 0.909800
Distillation: Epoch : 7, Loss : 0.332529, Accuracy: 0.906000, Test accuracy: 0.912800
Distillation: Epoch : 8, Loss : 0.318029, Accuracy: 0.917000, Test accuracy: 0.914500
Distillation: Epoch : 9, Loss : 0.355722, Accuracy: 0.908000, Test accuracy: 0.914800
Distillation: Epoch : 10, Loss : 0.298679, Accuracy: 0.909000, Test accuracy: 0.917800
Distillation: Epoch : 11, Loss : 0.321723, Accuracy: 0.905000, Test accuracy: 0.920400
Distillation: Epoch : 12, Loss : 0.271423, Accuracy: 0.920000, Test accuracy: 0.921700
Distillation: Epoch : 13, Loss : 0.262277, Accuracy: 0.920000, Test accuracy: 0.924200
Distillation: Epoch : 14, Loss : 0.278558, Accuracy: 0.918000, Test accuracy: 0.927600
Distillation: Epoch : 15, Loss : 0.288548, Accuracy: 0.931000, Test accuracy: 0.929900
Distillation: Epoch : 16, Loss : 0.282374, Accuracy: 0.917000, Test accuracy: 0.932200
Distillation: Epoch : 17, Loss : 0.235839, Accuracy: 0.945000, Test accuracy: 0.934200
Distillation: Epoch : 18, Loss : 0.261331, Accuracy: 0.937000, Test accuracy: 0.935600
Distillation: Epoch : 19, Loss : 0.206305, Accuracy: 0.949000, Test accuracy: 0.938200
Distillation: Epoch : 20, Loss : 0.218466, Accuracy: 0.938000, Test accuracy: 0.940400
Distillation: Epoch : 21, Loss : 0.180468, Accuracy: 0.948000, Test accuracy: 0.941600
Distillation: Epoch : 22, Loss : 0.205487, Accuracy: 0.940000, Test accuracy: 0.943300
Distillation: Epoch : 23, Loss : 0.249354, Accuracy: 0.936000, Test accuracy: 0.944700
Distillation: Epoch : 24, Loss : 0.186748, Accuracy: 0.961000, Test accuracy: 0.947200
Distillation: Epoch : 25, Loss : 0.197140, Accuracy: 0.940000, Test accuracy: 0.948700
Distillation: Epoch : 26, Loss : 0.167368, Accuracy: 0.960000, Test accuracy: 0.950300
Distillation: Epoch : 27, Loss : 0.157606, Accuracy: 0.955000, Test accuracy: 0.951700
Distillation: Epoch : 28, Loss : 0.173530, Accuracy: 0.948000, Test accuracy: 0.954200
Distillation: Epoch : 29, Loss : 0.202242, Accuracy: 0.950000, Test accuracy: 0.955500
Distillation: Epoch : 30, Loss : 0.196096, Accuracy: 0.943000, Test accuracy: 0.957300
Distillation: Epoch : 31, Loss : 0.197079, Accuracy: 0.943000, Test accuracy: 0.958100
Distillation: Epoch : 32, Loss : 0.161766, Accuracy: 0.963000, Test accuracy: 0.958900
Distillation: Epoch : 33, Loss : 0.153120, Accuracy: 0.967000, Test accuracy: 0.960300
Distillation: Epoch : 34, Loss : 0.167418, Accuracy: 0.952000, Test accuracy: 0.960300
Distillation: Epoch : 35, Loss : 0.206726, Accuracy: 0.935000, Test accuracy: 0.961300
Distillation: Epoch : 36, Loss : 0.177814, Accuracy: 0.961000, Test accuracy: 0.962000
Distillation: Epoch : 37, Loss : 0.178463, Accuracy: 0.949000, Test accuracy: 0.963800
Distillation: Epoch : 38, Loss : 0.178736, Accuracy: 0.960000, Test accuracy: 0.964500
Distillation: Epoch : 39, Loss : 0.160264, Accuracy: 0.962000, Test accuracy: 0.964100
Distillation: Epoch : 40, Loss : 0.179598, Accuracy: 0.953000, Test accuracy: 0.965500
Distillation: Epoch : 41, Loss : 0.151383, Accuracy: 0.958000, Test accuracy: 0.966400
Distillation: Epoch : 42, Loss : 0.136789, Accuracy: 0.967000, Test accuracy: 0.966900
Distillation: Epoch : 43, Loss : 0.176624, Accuracy: 0.952000, Test accuracy: 0.966600
Distillation: Epoch : 44, Loss : 0.119379, Accuracy: 0.972000, Test accuracy: 0.966000
Distillation: Epoch : 45, Loss : 0.136607, Accuracy: 0.967000, Test accuracy: 0.966100
Distillation: Epoch : 46, Loss : 0.125328, Accuracy: 0.973000, Test accuracy: 0.967100
Distillation: Epoch : 47, Loss : 0.136105, Accuracy: 0.965000, Test accuracy: 0.967900
Distillation: Epoch : 48, Loss : 0.145377, Accuracy: 0.968000, Test accuracy: 0.967200
Distillation: Epoch : 49, Loss : 0.122217, Accuracy: 0.968000, Test accuracy: 0.968500
Distillation: Epoch : 50, Loss : 0.115393, Accuracy: 0.970000, Test accuracy: 0.967400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9674
Generating confusion matrix for student4
[[ 971.    0.    2.    0.    2.    3.    5.    1.    8.    8.]
 [   0. 1117.    4.    0.    0.    2.    3.    7.    3.    7.]
 [   1.    2.  994.    9.    1.    1.    1.   20.    6.    0.]
 [   0.    4.    5.  974.    0.    9.    0.    4.    4.    5.]
 [   0.    0.    6.    0.  960.    0.    4.    1.    6.   14.]
 [   0.    0.    1.    7.    0.  855.    2.    0.    4.    2.]
 [   1.    2.    1.    0.    4.    7.  938.    0.    8.    1.]
 [   3.    1.    8.    8.    2.    3.    0.  987.   11.   12.]
 [   4.    9.   10.    4.    2.    7.    5.    0.  919.    1.]
 [   0.    0.    1.    8.   11.    5.    0.    8.    5.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.500034, Accuracy: 0.807000, Test accuracy: 0.799600
Distillation: Epoch : 2, Loss : 0.756584, Accuracy: 0.855000, Test accuracy: 0.874900
Distillation: Epoch : 3, Loss : 0.622047, Accuracy: 0.888000, Test accuracy: 0.894500
Distillation: Epoch : 4, Loss : 0.644777, Accuracy: 0.892000, Test accuracy: 0.906300
Distillation: Epoch : 5, Loss : 0.565069, Accuracy: 0.908000, Test accuracy: 0.913400
Distillation: Epoch : 6, Loss : 0.557996, Accuracy: 0.923000, Test accuracy: 0.919600
Distillation: Epoch : 7, Loss : 0.572598, Accuracy: 0.922000, Test accuracy: 0.923900
Distillation: Epoch : 8, Loss : 0.561038, Accuracy: 0.934000, Test accuracy: 0.927500
Distillation: Epoch : 9, Loss : 0.548650, Accuracy: 0.927000, Test accuracy: 0.932100
Distillation: Epoch : 10, Loss : 0.547055, Accuracy: 0.922000, Test accuracy: 0.936800
Distillation: Epoch : 11, Loss : 0.533429, Accuracy: 0.923000, Test accuracy: 0.939100
Distillation: Epoch : 12, Loss : 0.525801, Accuracy: 0.937000, Test accuracy: 0.941100
Distillation: Epoch : 13, Loss : 0.508194, Accuracy: 0.945000, Test accuracy: 0.942900
Distillation: Epoch : 14, Loss : 0.493150, Accuracy: 0.943000, Test accuracy: 0.945200
Distillation: Epoch : 15, Loss : 0.514317, Accuracy: 0.944000, Test accuracy: 0.947000
Distillation: Epoch : 16, Loss : 0.501084, Accuracy: 0.940000, Test accuracy: 0.948600
Distillation: Epoch : 17, Loss : 0.466747, Accuracy: 0.964000, Test accuracy: 0.949800
Distillation: Epoch : 18, Loss : 0.487200, Accuracy: 0.959000, Test accuracy: 0.951300
Distillation: Epoch : 19, Loss : 0.477737, Accuracy: 0.952000, Test accuracy: 0.952000
Distillation: Epoch : 20, Loss : 0.478597, Accuracy: 0.950000, Test accuracy: 0.954100
Distillation: Epoch : 21, Loss : 0.464610, Accuracy: 0.953000, Test accuracy: 0.954000
Distillation: Epoch : 22, Loss : 0.462904, Accuracy: 0.960000, Test accuracy: 0.955800
Distillation: Epoch : 23, Loss : 0.480936, Accuracy: 0.947000, Test accuracy: 0.956100
Distillation: Epoch : 24, Loss : 0.493165, Accuracy: 0.952000, Test accuracy: 0.957500
Distillation: Epoch : 25, Loss : 0.499324, Accuracy: 0.941000, Test accuracy: 0.957500
Distillation: Epoch : 26, Loss : 0.441530, Accuracy: 0.963000, Test accuracy: 0.958600
Distillation: Epoch : 27, Loss : 0.455580, Accuracy: 0.952000, Test accuracy: 0.959800
Distillation: Epoch : 28, Loss : 0.465093, Accuracy: 0.955000, Test accuracy: 0.960600
Distillation: Epoch : 29, Loss : 0.468783, Accuracy: 0.951000, Test accuracy: 0.960700
Distillation: Epoch : 30, Loss : 0.438541, Accuracy: 0.963000, Test accuracy: 0.961800
Distillation: Epoch : 31, Loss : 0.467932, Accuracy: 0.959000, Test accuracy: 0.961600
Distillation: Epoch : 32, Loss : 0.448627, Accuracy: 0.961000, Test accuracy: 0.962000
Distillation: Epoch : 33, Loss : 0.458741, Accuracy: 0.959000, Test accuracy: 0.962400
Distillation: Epoch : 34, Loss : 0.443380, Accuracy: 0.962000, Test accuracy: 0.962400
Distillation: Epoch : 35, Loss : 0.436947, Accuracy: 0.969000, Test accuracy: 0.962900
Distillation: Epoch : 36, Loss : 0.437850, Accuracy: 0.968000, Test accuracy: 0.962800
Distillation: Epoch : 37, Loss : 0.422032, Accuracy: 0.971000, Test accuracy: 0.961600
Distillation: Epoch : 38, Loss : 0.453692, Accuracy: 0.952000, Test accuracy: 0.963200
Distillation: Epoch : 39, Loss : 0.444731, Accuracy: 0.965000, Test accuracy: 0.963300
Distillation: Epoch : 40, Loss : 0.443476, Accuracy: 0.965000, Test accuracy: 0.963000
Distillation: Epoch : 41, Loss : 0.445945, Accuracy: 0.971000, Test accuracy: 0.964100
Distillation: Epoch : 42, Loss : 0.445201, Accuracy: 0.969000, Test accuracy: 0.964000
Distillation: Epoch : 43, Loss : 0.465906, Accuracy: 0.957000, Test accuracy: 0.964000
Distillation: Epoch : 44, Loss : 0.432185, Accuracy: 0.966000, Test accuracy: 0.964300
Distillation: Epoch : 45, Loss : 0.431818, Accuracy: 0.963000, Test accuracy: 0.965100
Distillation: Epoch : 46, Loss : 0.446192, Accuracy: 0.966000, Test accuracy: 0.964700
Distillation: Epoch : 47, Loss : 0.457676, Accuracy: 0.950000, Test accuracy: 0.965000
Distillation: Epoch : 48, Loss : 0.417926, Accuracy: 0.976000, Test accuracy: 0.965300
Distillation: Epoch : 49, Loss : 0.435911, Accuracy: 0.965000, Test accuracy: 0.965200
Distillation: Epoch : 50, Loss : 0.454464, Accuracy: 0.955000, Test accuracy: 0.965600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9656
Generating confusion matrix for student4
[[ 970.    0.    5.    1.    1.    1.   10.    3.    7.    4.]
 [   1. 1117.    6.    0.    2.    0.    3.    8.    3.    6.]
 [   1.    4.  994.   10.    2.    0.    2.   18.    6.    1.]
 [   0.    4.    3.  975.    0.    8.    0.    6.    9.    6.]
 [   0.    0.    7.    2.  954.    1.    4.    4.    8.   13.]
 [   1.    0.    0.    6.    0.  872.    4.    0.    7.    4.]
 [   3.    1.    0.    0.    3.    3.  933.    0.    6.    1.]
 [   2.    1.    6.    6.    1.    1.    0.  964.    6.    8.]
 [   2.    8.   10.    7.    3.    4.    2.    2.  912.    1.]
 [   0.    0.    1.    3.   16.    2.    0.   23.   10.  965.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.438503, Accuracy: 0.751000, Test accuracy: 0.766600
Distillation: Epoch : 2, Loss : 0.877904, Accuracy: 0.864000, Test accuracy: 0.874300
Distillation: Epoch : 3, Loss : 0.811804, Accuracy: 0.879000, Test accuracy: 0.895800
Distillation: Epoch : 4, Loss : 0.827183, Accuracy: 0.880000, Test accuracy: 0.905400
Distillation: Epoch : 5, Loss : 0.784350, Accuracy: 0.892000, Test accuracy: 0.908100
Distillation: Epoch : 6, Loss : 0.736887, Accuracy: 0.916000, Test accuracy: 0.910200
Distillation: Epoch : 7, Loss : 0.771842, Accuracy: 0.902000, Test accuracy: 0.913900
Distillation: Epoch : 8, Loss : 0.742513, Accuracy: 0.911000, Test accuracy: 0.917900
Distillation: Epoch : 9, Loss : 0.732819, Accuracy: 0.915000, Test accuracy: 0.918900
Distillation: Epoch : 10, Loss : 0.744013, Accuracy: 0.926000, Test accuracy: 0.922700
Distillation: Epoch : 11, Loss : 0.740018, Accuracy: 0.920000, Test accuracy: 0.925100
Distillation: Epoch : 12, Loss : 0.704290, Accuracy: 0.928000, Test accuracy: 0.928400
Distillation: Epoch : 13, Loss : 0.683301, Accuracy: 0.929000, Test accuracy: 0.931400
Distillation: Epoch : 14, Loss : 0.713416, Accuracy: 0.927000, Test accuracy: 0.933600
Distillation: Epoch : 15, Loss : 0.715006, Accuracy: 0.934000, Test accuracy: 0.937100
Distillation: Epoch : 16, Loss : 0.670594, Accuracy: 0.949000, Test accuracy: 0.939300
Distillation: Epoch : 17, Loss : 0.658427, Accuracy: 0.950000, Test accuracy: 0.941700
Distillation: Epoch : 18, Loss : 0.658316, Accuracy: 0.937000, Test accuracy: 0.944800
Distillation: Epoch : 19, Loss : 0.680484, Accuracy: 0.941000, Test accuracy: 0.946400
Distillation: Epoch : 20, Loss : 0.653035, Accuracy: 0.942000, Test accuracy: 0.948000
Distillation: Epoch : 21, Loss : 0.686498, Accuracy: 0.951000, Test accuracy: 0.949000
Distillation: Epoch : 22, Loss : 0.637467, Accuracy: 0.954000, Test accuracy: 0.950800
Distillation: Epoch : 23, Loss : 0.657698, Accuracy: 0.949000, Test accuracy: 0.952600
Distillation: Epoch : 24, Loss : 0.656879, Accuracy: 0.932000, Test accuracy: 0.953400
Distillation: Epoch : 25, Loss : 0.660190, Accuracy: 0.949000, Test accuracy: 0.954500
Distillation: Epoch : 26, Loss : 0.643917, Accuracy: 0.948000, Test accuracy: 0.953500
Distillation: Epoch : 27, Loss : 0.628382, Accuracy: 0.948000, Test accuracy: 0.955900
Distillation: Epoch : 28, Loss : 0.630517, Accuracy: 0.959000, Test accuracy: 0.956000
Distillation: Epoch : 29, Loss : 0.653870, Accuracy: 0.941000, Test accuracy: 0.955500
Distillation: Epoch : 30, Loss : 0.628520, Accuracy: 0.957000, Test accuracy: 0.957700
Distillation: Epoch : 31, Loss : 0.640085, Accuracy: 0.957000, Test accuracy: 0.957300
Distillation: Epoch : 32, Loss : 0.630677, Accuracy: 0.957000, Test accuracy: 0.959400
Distillation: Epoch : 33, Loss : 0.635202, Accuracy: 0.952000, Test accuracy: 0.958500
Distillation: Epoch : 34, Loss : 0.641553, Accuracy: 0.960000, Test accuracy: 0.960700
Distillation: Epoch : 35, Loss : 0.641641, Accuracy: 0.948000, Test accuracy: 0.959600
Distillation: Epoch : 36, Loss : 0.622774, Accuracy: 0.960000, Test accuracy: 0.960500
Distillation: Epoch : 37, Loss : 0.623247, Accuracy: 0.960000, Test accuracy: 0.960700
Distillation: Epoch : 38, Loss : 0.601295, Accuracy: 0.962000, Test accuracy: 0.960500
Distillation: Epoch : 39, Loss : 0.634303, Accuracy: 0.956000, Test accuracy: 0.961300
Distillation: Epoch : 40, Loss : 0.598622, Accuracy: 0.962000, Test accuracy: 0.962000
Distillation: Epoch : 41, Loss : 0.635946, Accuracy: 0.952000, Test accuracy: 0.961900
Distillation: Epoch : 42, Loss : 0.625020, Accuracy: 0.958000, Test accuracy: 0.962300
Distillation: Epoch : 43, Loss : 0.632060, Accuracy: 0.958000, Test accuracy: 0.962800
Distillation: Epoch : 44, Loss : 0.617920, Accuracy: 0.961000, Test accuracy: 0.963400
Distillation: Epoch : 45, Loss : 0.631797, Accuracy: 0.963000, Test accuracy: 0.963400
Distillation: Epoch : 46, Loss : 0.618691, Accuracy: 0.956000, Test accuracy: 0.964200
Distillation: Epoch : 47, Loss : 0.604152, Accuracy: 0.955000, Test accuracy: 0.964000
Distillation: Epoch : 48, Loss : 0.615144, Accuracy: 0.967000, Test accuracy: 0.964200
Distillation: Epoch : 49, Loss : 0.608724, Accuracy: 0.971000, Test accuracy: 0.964100
Distillation: Epoch : 50, Loss : 0.613552, Accuracy: 0.962000, Test accuracy: 0.964400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9644
Generating confusion matrix for student4
[[ 972.    0.    3.    1.    2.    1.    8.    3.    8.    4.]
 [   0. 1113.    8.    0.    1.    0.    3.   11.    5.    6.]
 [   2.    5.  998.   14.    3.    2.    3.   14.    5.    0.]
 [   0.    4.    3.  967.    0.    6.    1.    5.    6.    5.]
 [   0.    0.    8.    0.  957.    0.    3.    8.    8.   17.]
 [   0.    0.    0.   11.    0.  866.    8.    0.    4.    7.]
 [   4.    1.    3.    0.    4.    7.  929.    0.    7.    0.]
 [   2.    2.    7.    5.    1.    3.    0.  969.    5.    8.]
 [   0.   10.    2.   10.    3.    2.    3.    2.  916.    5.]
 [   0.    0.    0.    2.   11.    5.    0.   16.   10.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.301353, Accuracy: 0.803000, Test accuracy: 0.809100
Distillation: Epoch : 2, Loss : 1.045943, Accuracy: 0.852000, Test accuracy: 0.870200
Distillation: Epoch : 3, Loss : 0.996522, Accuracy: 0.872000, Test accuracy: 0.888000
Distillation: Epoch : 4, Loss : 1.000188, Accuracy: 0.874000, Test accuracy: 0.895200
Distillation: Epoch : 5, Loss : 0.939829, Accuracy: 0.900000, Test accuracy: 0.900800
Distillation: Epoch : 6, Loss : 0.949355, Accuracy: 0.907000, Test accuracy: 0.902900
Distillation: Epoch : 7, Loss : 0.960753, Accuracy: 0.893000, Test accuracy: 0.906100
Distillation: Epoch : 8, Loss : 0.978570, Accuracy: 0.890000, Test accuracy: 0.907000
Distillation: Epoch : 9, Loss : 0.924453, Accuracy: 0.910000, Test accuracy: 0.907100
Distillation: Epoch : 10, Loss : 0.940062, Accuracy: 0.892000, Test accuracy: 0.906800
Distillation: Epoch : 11, Loss : 0.904968, Accuracy: 0.918000, Test accuracy: 0.909200
Distillation: Epoch : 12, Loss : 0.946685, Accuracy: 0.889000, Test accuracy: 0.908800
Distillation: Epoch : 13, Loss : 0.945015, Accuracy: 0.891000, Test accuracy: 0.910000
Distillation: Epoch : 14, Loss : 0.915949, Accuracy: 0.900000, Test accuracy: 0.910900
Distillation: Epoch : 15, Loss : 0.938896, Accuracy: 0.911000, Test accuracy: 0.911400
Distillation: Epoch : 16, Loss : 0.958585, Accuracy: 0.893000, Test accuracy: 0.910900
Distillation: Epoch : 17, Loss : 0.916763, Accuracy: 0.912000, Test accuracy: 0.910600
Distillation: Epoch : 18, Loss : 0.923113, Accuracy: 0.899000, Test accuracy: 0.912500
Distillation: Epoch : 19, Loss : 0.918945, Accuracy: 0.899000, Test accuracy: 0.914200
Distillation: Epoch : 20, Loss : 0.906210, Accuracy: 0.903000, Test accuracy: 0.914100
Distillation: Epoch : 21, Loss : 0.920375, Accuracy: 0.912000, Test accuracy: 0.914100
Distillation: Epoch : 22, Loss : 0.908656, Accuracy: 0.902000, Test accuracy: 0.915400
Distillation: Epoch : 23, Loss : 0.928930, Accuracy: 0.895000, Test accuracy: 0.915000
Distillation: Epoch : 24, Loss : 0.895277, Accuracy: 0.925000, Test accuracy: 0.915400
Distillation: Epoch : 25, Loss : 0.878461, Accuracy: 0.913000, Test accuracy: 0.917400
Distillation: Epoch : 26, Loss : 0.898144, Accuracy: 0.915000, Test accuracy: 0.915600
Distillation: Epoch : 27, Loss : 0.922662, Accuracy: 0.911000, Test accuracy: 0.916800
Distillation: Epoch : 28, Loss : 0.913504, Accuracy: 0.922000, Test accuracy: 0.918500
Distillation: Epoch : 29, Loss : 0.901076, Accuracy: 0.909000, Test accuracy: 0.918900
Distillation: Epoch : 30, Loss : 0.904541, Accuracy: 0.912000, Test accuracy: 0.919700
Distillation: Epoch : 31, Loss : 0.898650, Accuracy: 0.915000, Test accuracy: 0.919700
Distillation: Epoch : 32, Loss : 0.877286, Accuracy: 0.937000, Test accuracy: 0.919800
Distillation: Epoch : 33, Loss : 0.913839, Accuracy: 0.899000, Test accuracy: 0.920400
Distillation: Epoch : 34, Loss : 0.883231, Accuracy: 0.921000, Test accuracy: 0.921100
Distillation: Epoch : 35, Loss : 0.867876, Accuracy: 0.928000, Test accuracy: 0.922100
Distillation: Epoch : 36, Loss : 0.884562, Accuracy: 0.925000, Test accuracy: 0.923600
Distillation: Epoch : 37, Loss : 0.929245, Accuracy: 0.918000, Test accuracy: 0.925100
Distillation: Epoch : 38, Loss : 0.887712, Accuracy: 0.912000, Test accuracy: 0.924900
Distillation: Epoch : 39, Loss : 0.898352, Accuracy: 0.909000, Test accuracy: 0.926400
Distillation: Epoch : 40, Loss : 0.922896, Accuracy: 0.901000, Test accuracy: 0.927100
Distillation: Epoch : 41, Loss : 0.911844, Accuracy: 0.917000, Test accuracy: 0.927900
Distillation: Epoch : 42, Loss : 0.844881, Accuracy: 0.925000, Test accuracy: 0.929800
Distillation: Epoch : 43, Loss : 0.868978, Accuracy: 0.926000, Test accuracy: 0.932400
Distillation: Epoch : 44, Loss : 0.900166, Accuracy: 0.931000, Test accuracy: 0.933800
Distillation: Epoch : 45, Loss : 0.867187, Accuracy: 0.918000, Test accuracy: 0.934000
Distillation: Epoch : 46, Loss : 0.877949, Accuracy: 0.929000, Test accuracy: 0.935900
Distillation: Epoch : 47, Loss : 0.859582, Accuracy: 0.940000, Test accuracy: 0.936700
Distillation: Epoch : 48, Loss : 0.858010, Accuracy: 0.935000, Test accuracy: 0.940300
Distillation: Epoch : 49, Loss : 0.858792, Accuracy: 0.936000, Test accuracy: 0.940300
Distillation: Epoch : 50, Loss : 0.842478, Accuracy: 0.935000, Test accuracy: 0.942600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9426
Generating confusion matrix for student4
[[ 967.    0.    6.    1.    2.    3.    8.    3.   11.    5.]
 [   0. 1110.    8.    2.    2.    2.    3.   20.   10.    8.]
 [   1.    3.  964.   21.    4.    2.    2.   20.    8.    0.]
 [   1.    2.    8.  947.    1.   13.    0.    4.    7.   10.]
 [   0.    1.   13.    1.  929.    1.    5.   12.   14.   36.]
 [   1.    1.    1.   14.    1.  846.   14.    1.   12.    7.]
 [   7.    4.    8.    0.    9.   10.  923.    0.   11.    1.]
 [   1.    0.   12.   10.    2.    3.    1.  929.    9.   10.]
 [   2.   14.    9.   11.    4.    5.    2.    2.  882.    3.]
 [   0.    0.    3.    3.   28.    7.    0.   37.   10.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.836815, Accuracy: 0.743000, Test accuracy: 0.762100
Distillation: Epoch : 2, Loss : 1.209190, Accuracy: 0.851000, Test accuracy: 0.861100
Distillation: Epoch : 3, Loss : 1.161144, Accuracy: 0.859000, Test accuracy: 0.888600
Distillation: Epoch : 4, Loss : 1.078086, Accuracy: 0.906000, Test accuracy: 0.901700
Distillation: Epoch : 5, Loss : 1.100751, Accuracy: 0.901000, Test accuracy: 0.909000
Distillation: Epoch : 6, Loss : 1.087896, Accuracy: 0.905000, Test accuracy: 0.917000
Distillation: Epoch : 7, Loss : 1.062206, Accuracy: 0.911000, Test accuracy: 0.921600
Distillation: Epoch : 8, Loss : 1.068563, Accuracy: 0.906000, Test accuracy: 0.925400
Distillation: Epoch : 9, Loss : 1.080144, Accuracy: 0.924000, Test accuracy: 0.929200
Distillation: Epoch : 10, Loss : 1.044749, Accuracy: 0.919000, Test accuracy: 0.930700
Distillation: Epoch : 11, Loss : 1.010190, Accuracy: 0.936000, Test accuracy: 0.933900
Distillation: Epoch : 12, Loss : 1.031852, Accuracy: 0.922000, Test accuracy: 0.935700
Distillation: Epoch : 13, Loss : 1.057418, Accuracy: 0.926000, Test accuracy: 0.939000
Distillation: Epoch : 14, Loss : 1.040655, Accuracy: 0.923000, Test accuracy: 0.941000
Distillation: Epoch : 15, Loss : 0.988990, Accuracy: 0.947000, Test accuracy: 0.943600
Distillation: Epoch : 16, Loss : 1.004959, Accuracy: 0.943000, Test accuracy: 0.945200
Distillation: Epoch : 17, Loss : 0.993722, Accuracy: 0.933000, Test accuracy: 0.945600
Distillation: Epoch : 18, Loss : 0.998854, Accuracy: 0.952000, Test accuracy: 0.948500
Distillation: Epoch : 19, Loss : 0.977680, Accuracy: 0.941000, Test accuracy: 0.948800
Distillation: Epoch : 20, Loss : 0.990026, Accuracy: 0.953000, Test accuracy: 0.950400
Distillation: Epoch : 21, Loss : 0.995399, Accuracy: 0.949000, Test accuracy: 0.951800
Distillation: Epoch : 22, Loss : 0.972859, Accuracy: 0.952000, Test accuracy: 0.953100
Distillation: Epoch : 23, Loss : 0.978180, Accuracy: 0.958000, Test accuracy: 0.953300
Distillation: Epoch : 24, Loss : 0.995020, Accuracy: 0.954000, Test accuracy: 0.953800
Distillation: Epoch : 25, Loss : 0.989929, Accuracy: 0.942000, Test accuracy: 0.955000
Distillation: Epoch : 26, Loss : 0.968960, Accuracy: 0.957000, Test accuracy: 0.957000
Distillation: Epoch : 27, Loss : 0.968539, Accuracy: 0.946000, Test accuracy: 0.956800
Distillation: Epoch : 28, Loss : 0.973977, Accuracy: 0.954000, Test accuracy: 0.957400
Distillation: Epoch : 29, Loss : 0.980919, Accuracy: 0.961000, Test accuracy: 0.958300
Distillation: Epoch : 30, Loss : 0.964874, Accuracy: 0.964000, Test accuracy: 0.959000
Distillation: Epoch : 31, Loss : 0.987218, Accuracy: 0.966000, Test accuracy: 0.959200
Distillation: Epoch : 32, Loss : 0.964493, Accuracy: 0.958000, Test accuracy: 0.960000
Distillation: Epoch : 33, Loss : 1.007923, Accuracy: 0.943000, Test accuracy: 0.959800
Distillation: Epoch : 34, Loss : 0.979576, Accuracy: 0.951000, Test accuracy: 0.961100
Distillation: Epoch : 35, Loss : 0.978127, Accuracy: 0.950000, Test accuracy: 0.960700
Distillation: Epoch : 36, Loss : 0.935601, Accuracy: 0.958000, Test accuracy: 0.960900
Distillation: Epoch : 37, Loss : 0.954101, Accuracy: 0.961000, Test accuracy: 0.962600
Distillation: Epoch : 38, Loss : 0.965809, Accuracy: 0.953000, Test accuracy: 0.962200
Distillation: Epoch : 39, Loss : 0.964304, Accuracy: 0.953000, Test accuracy: 0.963300
Distillation: Epoch : 40, Loss : 0.951425, Accuracy: 0.964000, Test accuracy: 0.963000
Distillation: Epoch : 41, Loss : 0.984990, Accuracy: 0.966000, Test accuracy: 0.963900
Distillation: Epoch : 42, Loss : 0.964206, Accuracy: 0.970000, Test accuracy: 0.964300
Distillation: Epoch : 43, Loss : 0.955844, Accuracy: 0.963000, Test accuracy: 0.964500
Distillation: Epoch : 44, Loss : 0.964801, Accuracy: 0.961000, Test accuracy: 0.965000
Distillation: Epoch : 45, Loss : 0.984681, Accuracy: 0.956000, Test accuracy: 0.965100
Distillation: Epoch : 46, Loss : 0.947595, Accuracy: 0.950000, Test accuracy: 0.965100
Distillation: Epoch : 47, Loss : 0.953123, Accuracy: 0.965000, Test accuracy: 0.966200
Distillation: Epoch : 48, Loss : 0.943087, Accuracy: 0.969000, Test accuracy: 0.965700
Distillation: Epoch : 49, Loss : 0.947425, Accuracy: 0.962000, Test accuracy: 0.966100
Distillation: Epoch : 50, Loss : 0.977849, Accuracy: 0.942000, Test accuracy: 0.965900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9659
Generating confusion matrix for student4
[[ 970.    0.    5.    0.    1.    1.    5.    4.    6.    6.]
 [   1. 1123.    5.    0.    0.    0.    3.   10.    3.    7.]
 [   2.    5. 1005.   19.    3.    0.    1.   18.    6.    1.]
 [   0.    2.    2.  962.    0.   13.    0.    3.    5.    7.]
 [   0.    0.    5.    2.  961.    0.    6.    4.    7.   19.]
 [   0.    0.    1.    7.    0.  862.    3.    0.    4.    5.]
 [   5.    2.    1.    0.    3.    8.  937.    0.    4.    0.]
 [   1.    0.    2.    4.    0.    2.    0.  963.    6.    6.]
 [   1.    3.    5.   12.    2.    2.    3.    2.  920.    2.]
 [   0.    0.    1.    4.   12.    4.    0.   24.   13.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.673720, Accuracy: 0.797000, Test accuracy: 0.808600
Distillation: Epoch : 2, Loss : 1.329008, Accuracy: 0.858000, Test accuracy: 0.867500
Distillation: Epoch : 3, Loss : 1.281044, Accuracy: 0.868000, Test accuracy: 0.886400
Distillation: Epoch : 4, Loss : 1.294888, Accuracy: 0.881000, Test accuracy: 0.893600
Distillation: Epoch : 5, Loss : 1.258194, Accuracy: 0.904000, Test accuracy: 0.900700
Distillation: Epoch : 6, Loss : 1.253923, Accuracy: 0.899000, Test accuracy: 0.904900
Distillation: Epoch : 7, Loss : 1.214502, Accuracy: 0.898000, Test accuracy: 0.909400
Distillation: Epoch : 8, Loss : 1.230140, Accuracy: 0.904000, Test accuracy: 0.912700
Distillation: Epoch : 9, Loss : 1.227961, Accuracy: 0.920000, Test accuracy: 0.917900
Distillation: Epoch : 10, Loss : 1.211128, Accuracy: 0.923000, Test accuracy: 0.922000
Distillation: Epoch : 11, Loss : 1.230763, Accuracy: 0.913000, Test accuracy: 0.924900
Distillation: Epoch : 12, Loss : 1.214280, Accuracy: 0.913000, Test accuracy: 0.928800
Distillation: Epoch : 13, Loss : 1.214186, Accuracy: 0.929000, Test accuracy: 0.931500
Distillation: Epoch : 14, Loss : 1.164650, Accuracy: 0.929000, Test accuracy: 0.935600
Distillation: Epoch : 15, Loss : 1.178468, Accuracy: 0.924000, Test accuracy: 0.938700
Distillation: Epoch : 16, Loss : 1.145429, Accuracy: 0.946000, Test accuracy: 0.941000
Distillation: Epoch : 17, Loss : 1.174708, Accuracy: 0.934000, Test accuracy: 0.944500
Distillation: Epoch : 18, Loss : 1.155377, Accuracy: 0.955000, Test accuracy: 0.948500
Distillation: Epoch : 19, Loss : 1.139216, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 20, Loss : 1.162109, Accuracy: 0.939000, Test accuracy: 0.955000
Distillation: Epoch : 21, Loss : 1.137222, Accuracy: 0.950000, Test accuracy: 0.956900
Distillation: Epoch : 22, Loss : 1.141118, Accuracy: 0.952000, Test accuracy: 0.958800
Distillation: Epoch : 23, Loss : 1.136401, Accuracy: 0.949000, Test accuracy: 0.961400
Distillation: Epoch : 24, Loss : 1.129824, Accuracy: 0.964000, Test accuracy: 0.961500
Distillation: Epoch : 25, Loss : 1.121632, Accuracy: 0.957000, Test accuracy: 0.962600
Distillation: Epoch : 26, Loss : 1.128925, Accuracy: 0.959000, Test accuracy: 0.963900
Distillation: Epoch : 27, Loss : 1.099025, Accuracy: 0.967000, Test accuracy: 0.965300
Distillation: Epoch : 28, Loss : 1.090181, Accuracy: 0.970000, Test accuracy: 0.965500
Distillation: Epoch : 29, Loss : 1.132187, Accuracy: 0.960000, Test accuracy: 0.967500
Distillation: Epoch : 30, Loss : 1.109841, Accuracy: 0.970000, Test accuracy: 0.967200
Distillation: Epoch : 31, Loss : 1.067651, Accuracy: 0.972000, Test accuracy: 0.968400
Distillation: Epoch : 32, Loss : 1.096767, Accuracy: 0.971000, Test accuracy: 0.968400
Distillation: Epoch : 33, Loss : 1.115318, Accuracy: 0.963000, Test accuracy: 0.969100
Distillation: Epoch : 34, Loss : 1.115700, Accuracy: 0.970000, Test accuracy: 0.970700
Distillation: Epoch : 35, Loss : 1.107706, Accuracy: 0.962000, Test accuracy: 0.971000
Distillation: Epoch : 36, Loss : 1.108612, Accuracy: 0.970000, Test accuracy: 0.970300
Distillation: Epoch : 37, Loss : 1.096003, Accuracy: 0.972000, Test accuracy: 0.970600
Distillation: Epoch : 38, Loss : 1.127491, Accuracy: 0.962000, Test accuracy: 0.971300
Distillation: Epoch : 39, Loss : 1.114658, Accuracy: 0.960000, Test accuracy: 0.971300
Distillation: Epoch : 40, Loss : 1.108241, Accuracy: 0.969000, Test accuracy: 0.972400
Distillation: Epoch : 41, Loss : 1.086840, Accuracy: 0.962000, Test accuracy: 0.971800
Distillation: Epoch : 42, Loss : 1.105405, Accuracy: 0.966000, Test accuracy: 0.972500
Distillation: Epoch : 43, Loss : 1.079084, Accuracy: 0.977000, Test accuracy: 0.973000
Distillation: Epoch : 44, Loss : 1.081156, Accuracy: 0.973000, Test accuracy: 0.972800
Distillation: Epoch : 45, Loss : 1.074536, Accuracy: 0.978000, Test accuracy: 0.972600
Distillation: Epoch : 46, Loss : 1.111960, Accuracy: 0.967000, Test accuracy: 0.973000
Distillation: Epoch : 47, Loss : 1.126861, Accuracy: 0.962000, Test accuracy: 0.972500
Distillation: Epoch : 48, Loss : 1.103455, Accuracy: 0.978000, Test accuracy: 0.973100
Distillation: Epoch : 49, Loss : 1.121693, Accuracy: 0.974000, Test accuracy: 0.972700
Distillation: Epoch : 50, Loss : 1.130308, Accuracy: 0.973000, Test accuracy: 0.973300
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9733
Generating confusion matrix for student4
[[ 969.    0.    5.    2.    1.    1.    5.    1.    6.    4.]
 [   1. 1122.    3.    0.    1.    1.    3.    5.    0.    7.]
 [   0.    4. 1007.    9.    4.    1.    0.   13.    6.    0.]
 [   0.    1.    3.  965.    0.    8.    0.    5.    3.    2.]
 [   1.    0.    2.    1.  959.    1.    3.    4.    4.    9.]
 [   1.    0.    1.   12.    0.  870.    5.    0.    3.    7.]
 [   4.    2.    0.    0.    2.    4.  940.    0.    1.    2.]
 [   0.    0.    3.   10.    0.    1.    0.  991.    3.    5.]
 [   2.    6.    7.    8.    2.    3.    2.    2.  939.    2.]
 [   2.    0.    1.    3.   13.    2.    0.    7.    9.  971.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.632976, Accuracy: 0.814000, Test accuracy: 0.800500
Distillation: Epoch : 2, Loss : 1.440160, Accuracy: 0.869000, Test accuracy: 0.868700
Distillation: Epoch : 3, Loss : 1.429193, Accuracy: 0.865000, Test accuracy: 0.882500
Distillation: Epoch : 4, Loss : 1.416509, Accuracy: 0.884000, Test accuracy: 0.890000
Distillation: Epoch : 5, Loss : 1.405184, Accuracy: 0.899000, Test accuracy: 0.894100
Distillation: Epoch : 6, Loss : 1.389715, Accuracy: 0.897000, Test accuracy: 0.897400
Distillation: Epoch : 7, Loss : 1.372464, Accuracy: 0.910000, Test accuracy: 0.897900
Distillation: Epoch : 8, Loss : 1.394786, Accuracy: 0.884000, Test accuracy: 0.901400
Distillation: Epoch : 9, Loss : 1.375837, Accuracy: 0.907000, Test accuracy: 0.902600
Distillation: Epoch : 10, Loss : 1.369600, Accuracy: 0.907000, Test accuracy: 0.903000
Distillation: Epoch : 11, Loss : 1.382163, Accuracy: 0.888000, Test accuracy: 0.904000
Distillation: Epoch : 12, Loss : 1.365708, Accuracy: 0.906000, Test accuracy: 0.905000
Distillation: Epoch : 13, Loss : 1.355334, Accuracy: 0.896000, Test accuracy: 0.904800
Distillation: Epoch : 14, Loss : 1.367443, Accuracy: 0.896000, Test accuracy: 0.908500
Distillation: Epoch : 15, Loss : 1.379661, Accuracy: 0.902000, Test accuracy: 0.908700
Distillation: Epoch : 16, Loss : 1.386755, Accuracy: 0.891000, Test accuracy: 0.911300
Distillation: Epoch : 17, Loss : 1.389348, Accuracy: 0.893000, Test accuracy: 0.913100
Distillation: Epoch : 18, Loss : 1.370604, Accuracy: 0.890000, Test accuracy: 0.913900
Distillation: Epoch : 19, Loss : 1.357334, Accuracy: 0.913000, Test accuracy: 0.916000
Distillation: Epoch : 20, Loss : 1.355714, Accuracy: 0.911000, Test accuracy: 0.915400
Distillation: Epoch : 21, Loss : 1.336823, Accuracy: 0.922000, Test accuracy: 0.918200
Distillation: Epoch : 22, Loss : 1.354634, Accuracy: 0.899000, Test accuracy: 0.920700
Distillation: Epoch : 23, Loss : 1.355516, Accuracy: 0.908000, Test accuracy: 0.921300
Distillation: Epoch : 24, Loss : 1.337593, Accuracy: 0.904000, Test accuracy: 0.922700
Distillation: Epoch : 25, Loss : 1.355407, Accuracy: 0.905000, Test accuracy: 0.926300
Distillation: Epoch : 26, Loss : 1.349561, Accuracy: 0.921000, Test accuracy: 0.929600
Distillation: Epoch : 27, Loss : 1.319576, Accuracy: 0.931000, Test accuracy: 0.931800
Distillation: Epoch : 28, Loss : 1.319457, Accuracy: 0.926000, Test accuracy: 0.935700
Distillation: Epoch : 29, Loss : 1.321698, Accuracy: 0.925000, Test accuracy: 0.938600
Distillation: Epoch : 30, Loss : 1.304018, Accuracy: 0.932000, Test accuracy: 0.942200
Distillation: Epoch : 31, Loss : 1.293728, Accuracy: 0.938000, Test accuracy: 0.943800
Distillation: Epoch : 32, Loss : 1.299267, Accuracy: 0.938000, Test accuracy: 0.946700
Distillation: Epoch : 33, Loss : 1.282990, Accuracy: 0.935000, Test accuracy: 0.947200
Distillation: Epoch : 34, Loss : 1.318818, Accuracy: 0.945000, Test accuracy: 0.949100
Distillation: Epoch : 35, Loss : 1.288397, Accuracy: 0.946000, Test accuracy: 0.950100
Distillation: Epoch : 36, Loss : 1.295914, Accuracy: 0.949000, Test accuracy: 0.949300
Distillation: Epoch : 37, Loss : 1.317160, Accuracy: 0.944000, Test accuracy: 0.950200
Distillation: Epoch : 38, Loss : 1.281136, Accuracy: 0.949000, Test accuracy: 0.951900
Distillation: Epoch : 39, Loss : 1.286930, Accuracy: 0.954000, Test accuracy: 0.952000
Distillation: Epoch : 40, Loss : 1.290448, Accuracy: 0.938000, Test accuracy: 0.952600
Distillation: Epoch : 41, Loss : 1.278423, Accuracy: 0.948000, Test accuracy: 0.953900
Distillation: Epoch : 42, Loss : 1.300582, Accuracy: 0.937000, Test accuracy: 0.953400
Distillation: Epoch : 43, Loss : 1.294923, Accuracy: 0.953000, Test accuracy: 0.952400
Distillation: Epoch : 44, Loss : 1.276351, Accuracy: 0.945000, Test accuracy: 0.954000
Distillation: Epoch : 45, Loss : 1.277625, Accuracy: 0.947000, Test accuracy: 0.954800
Distillation: Epoch : 46, Loss : 1.285354, Accuracy: 0.953000, Test accuracy: 0.954100
Distillation: Epoch : 47, Loss : 1.276117, Accuracy: 0.951000, Test accuracy: 0.954600
Distillation: Epoch : 48, Loss : 1.264549, Accuracy: 0.956000, Test accuracy: 0.956000
Distillation: Epoch : 49, Loss : 1.295211, Accuracy: 0.952000, Test accuracy: 0.955000
Distillation: Epoch : 50, Loss : 1.275162, Accuracy: 0.956000, Test accuracy: 0.956000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.956
Generating confusion matrix for student4
[[ 965.    0.    4.    0.    1.    2.    6.    3.    8.    8.]
 [   0. 1107.    5.    1.    1.    2.    3.   14.    8.    7.]
 [   2.    6.  994.   16.    2.    0.    1.   18.    9.    0.]
 [   0.    3.    2.  968.    0.   11.    0.    4.    6.    6.]
 [   0.    1.   10.    1.  953.    1.    7.   12.   15.   30.]
 [   0.    0.    0.    7.    0.  859.    5.    1.    6.    4.]
 [   9.    1.    3.    0.    4.    5.  934.    0.    7.    1.]
 [   0.    0.    5.    7.    1.    1.    0.  945.    8.    9.]
 [   3.   17.    8.    8.    4.    4.    2.    2.  894.    3.]
 [   1.    0.    1.    2.   16.    7.    0.   29.   13.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.917204, Accuracy: 0.741000, Test accuracy: 0.765100
Distillation: Epoch : 2, Loss : 1.564863, Accuracy: 0.855000, Test accuracy: 0.851700
Distillation: Epoch : 3, Loss : 1.542588, Accuracy: 0.870000, Test accuracy: 0.874500
Distillation: Epoch : 4, Loss : 1.570494, Accuracy: 0.857000, Test accuracy: 0.883000
Distillation: Epoch : 5, Loss : 1.534248, Accuracy: 0.877000, Test accuracy: 0.890600
Distillation: Epoch : 6, Loss : 1.511836, Accuracy: 0.885000, Test accuracy: 0.893700
Distillation: Epoch : 7, Loss : 1.515777, Accuracy: 0.890000, Test accuracy: 0.897300
Distillation: Epoch : 8, Loss : 1.473066, Accuracy: 0.899000, Test accuracy: 0.903000
Distillation: Epoch : 9, Loss : 1.491727, Accuracy: 0.897000, Test accuracy: 0.907600
Distillation: Epoch : 10, Loss : 1.495755, Accuracy: 0.892000, Test accuracy: 0.910900
Distillation: Epoch : 11, Loss : 1.458826, Accuracy: 0.906000, Test accuracy: 0.915600
Distillation: Epoch : 12, Loss : 1.493825, Accuracy: 0.898000, Test accuracy: 0.920200
Distillation: Epoch : 13, Loss : 1.469520, Accuracy: 0.918000, Test accuracy: 0.924400
Distillation: Epoch : 14, Loss : 1.432205, Accuracy: 0.933000, Test accuracy: 0.927700
Distillation: Epoch : 15, Loss : 1.458357, Accuracy: 0.919000, Test accuracy: 0.931700
Distillation: Epoch : 16, Loss : 1.446050, Accuracy: 0.930000, Test accuracy: 0.935800
Distillation: Epoch : 17, Loss : 1.456016, Accuracy: 0.932000, Test accuracy: 0.939400
Distillation: Epoch : 18, Loss : 1.411745, Accuracy: 0.942000, Test accuracy: 0.941600
Distillation: Epoch : 19, Loss : 1.451349, Accuracy: 0.926000, Test accuracy: 0.945100
Distillation: Epoch : 20, Loss : 1.423035, Accuracy: 0.938000, Test accuracy: 0.946900
Distillation: Epoch : 21, Loss : 1.427984, Accuracy: 0.937000, Test accuracy: 0.949800
Distillation: Epoch : 22, Loss : 1.442188, Accuracy: 0.933000, Test accuracy: 0.952100
Distillation: Epoch : 23, Loss : 1.424950, Accuracy: 0.928000, Test accuracy: 0.951800
Distillation: Epoch : 24, Loss : 1.393085, Accuracy: 0.950000, Test accuracy: 0.953300
Distillation: Epoch : 25, Loss : 1.420013, Accuracy: 0.950000, Test accuracy: 0.955100
Distillation: Epoch : 26, Loss : 1.401880, Accuracy: 0.943000, Test accuracy: 0.955700
Distillation: Epoch : 27, Loss : 1.391515, Accuracy: 0.958000, Test accuracy: 0.956100
Distillation: Epoch : 28, Loss : 1.412681, Accuracy: 0.947000, Test accuracy: 0.957500
Distillation: Epoch : 29, Loss : 1.424854, Accuracy: 0.946000, Test accuracy: 0.957400
Distillation: Epoch : 30, Loss : 1.408547, Accuracy: 0.952000, Test accuracy: 0.959200
Distillation: Epoch : 31, Loss : 1.402984, Accuracy: 0.951000, Test accuracy: 0.959500
Distillation: Epoch : 32, Loss : 1.404031, Accuracy: 0.958000, Test accuracy: 0.959100
Distillation: Epoch : 33, Loss : 1.416709, Accuracy: 0.954000, Test accuracy: 0.960300
Distillation: Epoch : 34, Loss : 1.400826, Accuracy: 0.961000, Test accuracy: 0.959900
Distillation: Epoch : 35, Loss : 1.399634, Accuracy: 0.956000, Test accuracy: 0.961400
Distillation: Epoch : 36, Loss : 1.400818, Accuracy: 0.960000, Test accuracy: 0.961300
Distillation: Epoch : 37, Loss : 1.382829, Accuracy: 0.966000, Test accuracy: 0.962100
Distillation: Epoch : 38, Loss : 1.404192, Accuracy: 0.957000, Test accuracy: 0.961500
Distillation: Epoch : 39, Loss : 1.407190, Accuracy: 0.955000, Test accuracy: 0.961600
Distillation: Epoch : 40, Loss : 1.406677, Accuracy: 0.968000, Test accuracy: 0.963200
Distillation: Epoch : 41, Loss : 1.387445, Accuracy: 0.957000, Test accuracy: 0.964800
Distillation: Epoch : 42, Loss : 1.406300, Accuracy: 0.958000, Test accuracy: 0.964500
Distillation: Epoch : 43, Loss : 1.390368, Accuracy: 0.957000, Test accuracy: 0.963800
Distillation: Epoch : 44, Loss : 1.404836, Accuracy: 0.954000, Test accuracy: 0.965400
Distillation: Epoch : 45, Loss : 1.403045, Accuracy: 0.952000, Test accuracy: 0.965400
Distillation: Epoch : 46, Loss : 1.389457, Accuracy: 0.958000, Test accuracy: 0.965300
Distillation: Epoch : 47, Loss : 1.380446, Accuracy: 0.969000, Test accuracy: 0.966000
Distillation: Epoch : 48, Loss : 1.366288, Accuracy: 0.969000, Test accuracy: 0.966300
Distillation: Epoch : 49, Loss : 1.395250, Accuracy: 0.964000, Test accuracy: 0.966200
Distillation: Epoch : 50, Loss : 1.387244, Accuracy: 0.962000, Test accuracy: 0.967000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.967
Generating confusion matrix for student4
[[ 970.    0.    6.    2.    1.    2.    6.    4.    6.    6.]
 [   1. 1120.    4.    0.    0.    1.    2.    4.    1.    7.]
 [   1.    4.  998.    5.    5.    0.    0.   19.   12.    1.]
 [   0.    0.    1.  972.    0.    5.    0.    7.    4.    3.]
 [   0.    1.    4.    2.  954.    1.    3.    4.    8.    7.]
 [   3.    0.    1.    9.    0.  867.   14.    3.    6.   10.]
 [   3.    4.    2.    0.    3.    2.  932.    0.    1.    0.]
 [   1.    0.    3.    5.    1.    1.    0.  971.    4.    5.]
 [   1.    6.   12.   12.    3.   11.    1.    2.  916.    0.]
 [   0.    0.    1.    3.   15.    2.    0.   14.   16.  970.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.030725, Accuracy: 0.772000, Test accuracy: 0.770900
Distillation: Epoch : 2, Loss : 1.834349, Accuracy: 0.851000, Test accuracy: 0.856000
Distillation: Epoch : 3, Loss : 1.804673, Accuracy: 0.857000, Test accuracy: 0.878900
Distillation: Epoch : 4, Loss : 1.766582, Accuracy: 0.893000, Test accuracy: 0.888700
Distillation: Epoch : 5, Loss : 1.781325, Accuracy: 0.875000, Test accuracy: 0.893800
Distillation: Epoch : 6, Loss : 1.783461, Accuracy: 0.889000, Test accuracy: 0.900100
Distillation: Epoch : 7, Loss : 1.767987, Accuracy: 0.907000, Test accuracy: 0.904300
Distillation: Epoch : 8, Loss : 1.752797, Accuracy: 0.911000, Test accuracy: 0.907400
Distillation: Epoch : 9, Loss : 1.755205, Accuracy: 0.916000, Test accuracy: 0.911300
Distillation: Epoch : 10, Loss : 1.770712, Accuracy: 0.908000, Test accuracy: 0.913900
Distillation: Epoch : 11, Loss : 1.741463, Accuracy: 0.910000, Test accuracy: 0.915900
Distillation: Epoch : 12, Loss : 1.745457, Accuracy: 0.916000, Test accuracy: 0.918400
Distillation: Epoch : 13, Loss : 1.749325, Accuracy: 0.916000, Test accuracy: 0.921000
Distillation: Epoch : 14, Loss : 1.733388, Accuracy: 0.913000, Test accuracy: 0.922200
Distillation: Epoch : 15, Loss : 1.718105, Accuracy: 0.924000, Test accuracy: 0.925000
Distillation: Epoch : 16, Loss : 1.728308, Accuracy: 0.930000, Test accuracy: 0.926900
Distillation: Epoch : 17, Loss : 1.735541, Accuracy: 0.902000, Test accuracy: 0.929300
Distillation: Epoch : 18, Loss : 1.721343, Accuracy: 0.913000, Test accuracy: 0.930900
Distillation: Epoch : 19, Loss : 1.748017, Accuracy: 0.929000, Test accuracy: 0.932100
Distillation: Epoch : 20, Loss : 1.728607, Accuracy: 0.923000, Test accuracy: 0.933000
Distillation: Epoch : 21, Loss : 1.730113, Accuracy: 0.924000, Test accuracy: 0.934600
Distillation: Epoch : 22, Loss : 1.730705, Accuracy: 0.936000, Test accuracy: 0.935800
Distillation: Epoch : 23, Loss : 1.725449, Accuracy: 0.934000, Test accuracy: 0.937500
Distillation: Epoch : 24, Loss : 1.702206, Accuracy: 0.953000, Test accuracy: 0.938500
Distillation: Epoch : 25, Loss : 1.707721, Accuracy: 0.943000, Test accuracy: 0.940000
Distillation: Epoch : 26, Loss : 1.724632, Accuracy: 0.939000, Test accuracy: 0.941600
Distillation: Epoch : 27, Loss : 1.714945, Accuracy: 0.946000, Test accuracy: 0.941400
Distillation: Epoch : 28, Loss : 1.704376, Accuracy: 0.938000, Test accuracy: 0.943100
Distillation: Epoch : 29, Loss : 1.732062, Accuracy: 0.939000, Test accuracy: 0.944100
Distillation: Epoch : 30, Loss : 1.698340, Accuracy: 0.948000, Test accuracy: 0.945500
Distillation: Epoch : 31, Loss : 1.725158, Accuracy: 0.939000, Test accuracy: 0.946000
Distillation: Epoch : 32, Loss : 1.696821, Accuracy: 0.938000, Test accuracy: 0.946800
Distillation: Epoch : 33, Loss : 1.714988, Accuracy: 0.935000, Test accuracy: 0.947100
Distillation: Epoch : 34, Loss : 1.729635, Accuracy: 0.937000, Test accuracy: 0.948400
Distillation: Epoch : 35, Loss : 1.728567, Accuracy: 0.935000, Test accuracy: 0.947600
Distillation: Epoch : 36, Loss : 1.712624, Accuracy: 0.944000, Test accuracy: 0.949400
Distillation: Epoch : 37, Loss : 1.712856, Accuracy: 0.953000, Test accuracy: 0.948900
Distillation: Epoch : 38, Loss : 1.719723, Accuracy: 0.952000, Test accuracy: 0.949100
Distillation: Epoch : 39, Loss : 1.692110, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 40, Loss : 1.709006, Accuracy: 0.941000, Test accuracy: 0.949700
Distillation: Epoch : 41, Loss : 1.720007, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 42, Loss : 1.705474, Accuracy: 0.952000, Test accuracy: 0.951700
Distillation: Epoch : 43, Loss : 1.703357, Accuracy: 0.942000, Test accuracy: 0.951100
Distillation: Epoch : 44, Loss : 1.713251, Accuracy: 0.949000, Test accuracy: 0.953400
Distillation: Epoch : 45, Loss : 1.682152, Accuracy: 0.958000, Test accuracy: 0.954000
Distillation: Epoch : 46, Loss : 1.705714, Accuracy: 0.948000, Test accuracy: 0.953900
Distillation: Epoch : 47, Loss : 1.697264, Accuracy: 0.944000, Test accuracy: 0.953400
Distillation: Epoch : 48, Loss : 1.705644, Accuracy: 0.945000, Test accuracy: 0.953800
Distillation: Epoch : 49, Loss : 1.706343, Accuracy: 0.945000, Test accuracy: 0.954200
Distillation: Epoch : 50, Loss : 1.706537, Accuracy: 0.956000, Test accuracy: 0.955700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9557
Generating confusion matrix for student4
[[ 964.    0.    6.    0.    0.    2.    6.    2.    7.    5.]
 [   1. 1110.    5.    0.    0.    1.    3.    7.    2.    7.]
 [   1.    4.  980.   11.    8.    0.    1.   13.    8.    3.]
 [   0.    0.    1.  951.    0.   10.    0.    4.   16.    5.]
 [   2.    1.    8.    4.  937.    3.    3.   12.    8.   18.]
 [   4.    1.    1.   15.    0.  853.   14.    2.   14.    7.]
 [   3.    5.    2.    1.    8.    6.  927.    0.    1.    0.]
 [   1.    0.    9.    7.    0.    1.    0.  974.    3.    6.]
 [   3.   14.   18.   17.    3.   15.    4.    3.  906.    3.]
 [   1.    0.    2.    4.   26.    1.    0.   11.    9.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.140744, Accuracy: 0.761000, Test accuracy: 0.779000
Distillation: Epoch : 2, Loss : 2.053786, Accuracy: 0.839000, Test accuracy: 0.856700
Distillation: Epoch : 3, Loss : 2.037680, Accuracy: 0.866000, Test accuracy: 0.872200
Distillation: Epoch : 4, Loss : 2.029613, Accuracy: 0.880000, Test accuracy: 0.879200
Distillation: Epoch : 5, Loss : 2.031011, Accuracy: 0.872000, Test accuracy: 0.884300
Distillation: Epoch : 6, Loss : 2.021755, Accuracy: 0.891000, Test accuracy: 0.886600
Distillation: Epoch : 7, Loss : 2.026842, Accuracy: 0.886000, Test accuracy: 0.890600
Distillation: Epoch : 8, Loss : 2.026742, Accuracy: 0.898000, Test accuracy: 0.891800
Distillation: Epoch : 9, Loss : 2.019536, Accuracy: 0.891000, Test accuracy: 0.897200
Distillation: Epoch : 10, Loss : 2.006272, Accuracy: 0.907000, Test accuracy: 0.900600
Distillation: Epoch : 11, Loss : 2.005370, Accuracy: 0.911000, Test accuracy: 0.905600
Distillation: Epoch : 12, Loss : 2.011716, Accuracy: 0.901000, Test accuracy: 0.911200
Distillation: Epoch : 13, Loss : 1.997911, Accuracy: 0.913000, Test accuracy: 0.915000
Distillation: Epoch : 14, Loss : 2.002937, Accuracy: 0.902000, Test accuracy: 0.921200
Distillation: Epoch : 15, Loss : 1.997723, Accuracy: 0.915000, Test accuracy: 0.924100
Distillation: Epoch : 16, Loss : 1.990815, Accuracy: 0.919000, Test accuracy: 0.928500
Distillation: Epoch : 17, Loss : 1.998558, Accuracy: 0.927000, Test accuracy: 0.933000
Distillation: Epoch : 18, Loss : 1.986889, Accuracy: 0.929000, Test accuracy: 0.936300
Distillation: Epoch : 19, Loss : 1.972215, Accuracy: 0.940000, Test accuracy: 0.937800
Distillation: Epoch : 20, Loss : 1.983187, Accuracy: 0.932000, Test accuracy: 0.939700
Distillation: Epoch : 21, Loss : 1.975866, Accuracy: 0.941000, Test accuracy: 0.941000
Distillation: Epoch : 22, Loss : 1.980792, Accuracy: 0.949000, Test accuracy: 0.941800
Distillation: Epoch : 23, Loss : 1.995948, Accuracy: 0.934000, Test accuracy: 0.942100
Distillation: Epoch : 24, Loss : 1.973426, Accuracy: 0.940000, Test accuracy: 0.942500
Distillation: Epoch : 25, Loss : 1.988036, Accuracy: 0.933000, Test accuracy: 0.943800
Distillation: Epoch : 26, Loss : 1.976996, Accuracy: 0.941000, Test accuracy: 0.943900
Distillation: Epoch : 27, Loss : 1.978873, Accuracy: 0.950000, Test accuracy: 0.943600
Distillation: Epoch : 28, Loss : 1.983354, Accuracy: 0.953000, Test accuracy: 0.944600
Distillation: Epoch : 29, Loss : 1.972743, Accuracy: 0.937000, Test accuracy: 0.946800
Distillation: Epoch : 30, Loss : 1.961788, Accuracy: 0.955000, Test accuracy: 0.946300
Distillation: Epoch : 31, Loss : 1.982619, Accuracy: 0.934000, Test accuracy: 0.946200
Distillation: Epoch : 32, Loss : 1.988746, Accuracy: 0.950000, Test accuracy: 0.946400
Distillation: Epoch : 33, Loss : 1.986204, Accuracy: 0.939000, Test accuracy: 0.947100
Distillation: Epoch : 34, Loss : 1.977645, Accuracy: 0.942000, Test accuracy: 0.947300
Distillation: Epoch : 35, Loss : 1.976290, Accuracy: 0.948000, Test accuracy: 0.948300
Distillation: Epoch : 36, Loss : 1.986480, Accuracy: 0.932000, Test accuracy: 0.948200
Distillation: Epoch : 37, Loss : 1.975291, Accuracy: 0.939000, Test accuracy: 0.948600
Distillation: Epoch : 38, Loss : 1.975846, Accuracy: 0.960000, Test accuracy: 0.948400
Distillation: Epoch : 39, Loss : 1.966163, Accuracy: 0.946000, Test accuracy: 0.948100
Distillation: Epoch : 40, Loss : 1.982238, Accuracy: 0.947000, Test accuracy: 0.948800
Distillation: Epoch : 41, Loss : 1.977208, Accuracy: 0.936000, Test accuracy: 0.949100
Distillation: Epoch : 42, Loss : 1.970011, Accuracy: 0.952000, Test accuracy: 0.949800
Distillation: Epoch : 43, Loss : 1.964538, Accuracy: 0.960000, Test accuracy: 0.949100
Distillation: Epoch : 44, Loss : 1.986433, Accuracy: 0.936000, Test accuracy: 0.949500
Distillation: Epoch : 45, Loss : 1.980817, Accuracy: 0.937000, Test accuracy: 0.949000
Distillation: Epoch : 46, Loss : 1.972117, Accuracy: 0.943000, Test accuracy: 0.949700
Distillation: Epoch : 47, Loss : 1.982748, Accuracy: 0.950000, Test accuracy: 0.951500
Distillation: Epoch : 48, Loss : 1.980025, Accuracy: 0.955000, Test accuracy: 0.950100
Distillation: Epoch : 49, Loss : 1.976167, Accuracy: 0.938000, Test accuracy: 0.949900
Distillation: Epoch : 50, Loss : 1.977115, Accuracy: 0.960000, Test accuracy: 0.950600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9506
Generating confusion matrix for student4
[[ 967.    0.    5.    0.    1.    1.   12.    4.    6.    7.]
 [   1. 1114.    5.    1.    0.    1.    4.   14.   12.    7.]
 [   1.    5.  976.   10.    3.    0.    0.   14.   10.    1.]
 [   0.    0.    2.  968.    0.    8.    0.    6.    8.    4.]
 [   1.    0.   14.    4.  954.    1.    8.   15.   19.   38.]
 [   1.    0.    1.    8.    0.  861.    9.    1.    8.    8.]
 [   5.    3.    3.    0.    4.    7.  921.    0.    7.    1.]
 [   1.    0.    6.    5.    1.    1.    0.  931.    8.    9.]
 [   3.   13.   19.    9.    5.    6.    4.    2.  880.    0.]
 [   0.    0.    1.    5.   14.    6.    0.   41.   16.  934.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.777151, Accuracy: 0.799000, Test accuracy: 0.802100
Distillation: Epoch : 2, Loss : 0.481845, Accuracy: 0.854000, Test accuracy: 0.876200
Distillation: Epoch : 3, Loss : 0.382755, Accuracy: 0.895000, Test accuracy: 0.889000
Distillation: Epoch : 4, Loss : 0.336275, Accuracy: 0.910000, Test accuracy: 0.898500
Distillation: Epoch : 5, Loss : 0.323002, Accuracy: 0.900000, Test accuracy: 0.904800
Distillation: Epoch : 6, Loss : 0.309005, Accuracy: 0.909000, Test accuracy: 0.909700
Distillation: Epoch : 7, Loss : 0.301751, Accuracy: 0.914000, Test accuracy: 0.912100
Distillation: Epoch : 8, Loss : 0.302215, Accuracy: 0.901000, Test accuracy: 0.914400
Distillation: Epoch : 9, Loss : 0.317279, Accuracy: 0.903000, Test accuracy: 0.915700
Distillation: Epoch : 10, Loss : 0.346356, Accuracy: 0.909000, Test accuracy: 0.919800
Distillation: Epoch : 11, Loss : 0.297480, Accuracy: 0.924000, Test accuracy: 0.922300
Distillation: Epoch : 12, Loss : 0.230810, Accuracy: 0.935000, Test accuracy: 0.925200
Distillation: Epoch : 13, Loss : 0.227155, Accuracy: 0.930000, Test accuracy: 0.927000
Distillation: Epoch : 14, Loss : 0.236199, Accuracy: 0.925000, Test accuracy: 0.929100
Distillation: Epoch : 15, Loss : 0.268671, Accuracy: 0.918000, Test accuracy: 0.930700
Distillation: Epoch : 16, Loss : 0.229990, Accuracy: 0.927000, Test accuracy: 0.933000
Distillation: Epoch : 17, Loss : 0.250542, Accuracy: 0.927000, Test accuracy: 0.935700
Distillation: Epoch : 18, Loss : 0.260760, Accuracy: 0.934000, Test accuracy: 0.937000
Distillation: Epoch : 19, Loss : 0.199744, Accuracy: 0.940000, Test accuracy: 0.939200
Distillation: Epoch : 20, Loss : 0.219220, Accuracy: 0.933000, Test accuracy: 0.941000
Distillation: Epoch : 21, Loss : 0.209340, Accuracy: 0.942000, Test accuracy: 0.941100
Distillation: Epoch : 22, Loss : 0.223774, Accuracy: 0.948000, Test accuracy: 0.941100
Distillation: Epoch : 23, Loss : 0.210392, Accuracy: 0.939000, Test accuracy: 0.943400
Distillation: Epoch : 24, Loss : 0.202008, Accuracy: 0.941000, Test accuracy: 0.942000
Distillation: Epoch : 25, Loss : 0.237430, Accuracy: 0.943000, Test accuracy: 0.944300
Distillation: Epoch : 26, Loss : 0.256222, Accuracy: 0.928000, Test accuracy: 0.945800
Distillation: Epoch : 27, Loss : 0.248125, Accuracy: 0.931000, Test accuracy: 0.945000
Distillation: Epoch : 28, Loss : 0.179962, Accuracy: 0.954000, Test accuracy: 0.948500
Distillation: Epoch : 29, Loss : 0.193676, Accuracy: 0.951000, Test accuracy: 0.946800
Distillation: Epoch : 30, Loss : 0.190644, Accuracy: 0.944000, Test accuracy: 0.946600
Distillation: Epoch : 31, Loss : 0.194561, Accuracy: 0.940000, Test accuracy: 0.946500
Distillation: Epoch : 32, Loss : 0.184959, Accuracy: 0.948000, Test accuracy: 0.948700
Distillation: Epoch : 33, Loss : 0.192205, Accuracy: 0.938000, Test accuracy: 0.948400
Distillation: Epoch : 34, Loss : 0.169327, Accuracy: 0.951000, Test accuracy: 0.948900
Distillation: Epoch : 35, Loss : 0.180089, Accuracy: 0.949000, Test accuracy: 0.948800
Distillation: Epoch : 36, Loss : 0.169359, Accuracy: 0.948000, Test accuracy: 0.948500
Distillation: Epoch : 37, Loss : 0.177154, Accuracy: 0.945000, Test accuracy: 0.949300
Distillation: Epoch : 38, Loss : 0.205488, Accuracy: 0.942000, Test accuracy: 0.950400
Distillation: Epoch : 39, Loss : 0.169789, Accuracy: 0.953000, Test accuracy: 0.950100
Distillation: Epoch : 40, Loss : 0.192916, Accuracy: 0.947000, Test accuracy: 0.950400
Distillation: Epoch : 41, Loss : 0.183072, Accuracy: 0.937000, Test accuracy: 0.949800
Distillation: Epoch : 42, Loss : 0.157123, Accuracy: 0.948000, Test accuracy: 0.949600
Distillation: Epoch : 43, Loss : 0.187306, Accuracy: 0.946000, Test accuracy: 0.951000
Distillation: Epoch : 44, Loss : 0.138255, Accuracy: 0.960000, Test accuracy: 0.951900
Distillation: Epoch : 45, Loss : 0.124787, Accuracy: 0.960000, Test accuracy: 0.951100
Distillation: Epoch : 46, Loss : 0.184008, Accuracy: 0.959000, Test accuracy: 0.951000
Distillation: Epoch : 47, Loss : 0.160789, Accuracy: 0.960000, Test accuracy: 0.954000
Distillation: Epoch : 48, Loss : 0.179414, Accuracy: 0.956000, Test accuracy: 0.952500
Distillation: Epoch : 49, Loss : 0.147486, Accuracy: 0.958000, Test accuracy: 0.952300
Distillation: Epoch : 50, Loss : 0.150779, Accuracy: 0.954000, Test accuracy: 0.953400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9534
Generating confusion matrix for student5
[[ 964.    0.    4.    0.    2.    7.    4.    0.    7.    3.]
 [   0. 1117.    6.    0.    0.    2.    2.    7.    2.    6.]
 [   5.    2.  967.   10.   10.    1.    2.   22.    4.    2.]
 [   2.    1.    8.  950.    2.   21.    1.    6.   15.    7.]
 [   0.    0.    6.    1.  935.    4.    5.    3.    7.   20.]
 [   3.    1.    1.   22.    2.  830.    9.    1.    9.    8.]
 [   3.    4.    5.    0.    6.    6.  931.    0.    4.    1.]
 [   1.    0.   14.   10.    3.    5.    1.  978.    5.    8.]
 [   2.   10.   15.   14.    3.   13.    3.    2.  916.    8.]
 [   0.    0.    6.    3.   19.    3.    0.    9.    5.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.168916, Accuracy: 0.451000, Test accuracy: 0.469900
Distillation: Epoch : 2, Loss : 1.650422, Accuracy: 0.667000, Test accuracy: 0.694500
Distillation: Epoch : 3, Loss : 1.086641, Accuracy: 0.767000, Test accuracy: 0.780600
Distillation: Epoch : 4, Loss : 0.779825, Accuracy: 0.808000, Test accuracy: 0.817200
Distillation: Epoch : 5, Loss : 0.601604, Accuracy: 0.841000, Test accuracy: 0.850200
Distillation: Epoch : 6, Loss : 0.509043, Accuracy: 0.856000, Test accuracy: 0.868400
Distillation: Epoch : 7, Loss : 0.502218, Accuracy: 0.869000, Test accuracy: 0.883000
Distillation: Epoch : 8, Loss : 0.392606, Accuracy: 0.886000, Test accuracy: 0.893300
Distillation: Epoch : 9, Loss : 0.367385, Accuracy: 0.896000, Test accuracy: 0.901800
Distillation: Epoch : 10, Loss : 0.364854, Accuracy: 0.892000, Test accuracy: 0.907900
Distillation: Epoch : 11, Loss : 0.328217, Accuracy: 0.893000, Test accuracy: 0.909300
Distillation: Epoch : 12, Loss : 0.301205, Accuracy: 0.922000, Test accuracy: 0.914900
Distillation: Epoch : 13, Loss : 0.331584, Accuracy: 0.911000, Test accuracy: 0.918300
Distillation: Epoch : 14, Loss : 0.305332, Accuracy: 0.909000, Test accuracy: 0.920700
Distillation: Epoch : 15, Loss : 0.306924, Accuracy: 0.910000, Test accuracy: 0.922300
Distillation: Epoch : 16, Loss : 0.276068, Accuracy: 0.911000, Test accuracy: 0.924400
Distillation: Epoch : 17, Loss : 0.285513, Accuracy: 0.917000, Test accuracy: 0.926100
Distillation: Epoch : 18, Loss : 0.266211, Accuracy: 0.924000, Test accuracy: 0.927300
Distillation: Epoch : 19, Loss : 0.271618, Accuracy: 0.927000, Test accuracy: 0.929100
Distillation: Epoch : 20, Loss : 0.252596, Accuracy: 0.933000, Test accuracy: 0.930700
Distillation: Epoch : 21, Loss : 0.270431, Accuracy: 0.920000, Test accuracy: 0.930700
Distillation: Epoch : 22, Loss : 0.262268, Accuracy: 0.927000, Test accuracy: 0.933100
Distillation: Epoch : 23, Loss : 0.266628, Accuracy: 0.929000, Test accuracy: 0.933800
Distillation: Epoch : 24, Loss : 0.229440, Accuracy: 0.937000, Test accuracy: 0.935100
Distillation: Epoch : 25, Loss : 0.257721, Accuracy: 0.928000, Test accuracy: 0.937100
Distillation: Epoch : 26, Loss : 0.230162, Accuracy: 0.934000, Test accuracy: 0.937300
Distillation: Epoch : 27, Loss : 0.252957, Accuracy: 0.931000, Test accuracy: 0.938000
Distillation: Epoch : 28, Loss : 0.217898, Accuracy: 0.945000, Test accuracy: 0.938300
Distillation: Epoch : 29, Loss : 0.222173, Accuracy: 0.935000, Test accuracy: 0.941100
Distillation: Epoch : 30, Loss : 0.221037, Accuracy: 0.939000, Test accuracy: 0.940300
Distillation: Epoch : 31, Loss : 0.194323, Accuracy: 0.944000, Test accuracy: 0.942600
Distillation: Epoch : 32, Loss : 0.244408, Accuracy: 0.928000, Test accuracy: 0.942900
Distillation: Epoch : 33, Loss : 0.238823, Accuracy: 0.934000, Test accuracy: 0.943900
Distillation: Epoch : 34, Loss : 0.230778, Accuracy: 0.942000, Test accuracy: 0.944300
Distillation: Epoch : 35, Loss : 0.196757, Accuracy: 0.947000, Test accuracy: 0.945000
Distillation: Epoch : 36, Loss : 0.194087, Accuracy: 0.949000, Test accuracy: 0.947000
Distillation: Epoch : 37, Loss : 0.223950, Accuracy: 0.938000, Test accuracy: 0.946300
Distillation: Epoch : 38, Loss : 0.199702, Accuracy: 0.946000, Test accuracy: 0.946800
Distillation: Epoch : 39, Loss : 0.207579, Accuracy: 0.950000, Test accuracy: 0.948000
Distillation: Epoch : 40, Loss : 0.180157, Accuracy: 0.956000, Test accuracy: 0.949200
Distillation: Epoch : 41, Loss : 0.191807, Accuracy: 0.947000, Test accuracy: 0.949300
Distillation: Epoch : 42, Loss : 0.184078, Accuracy: 0.947000, Test accuracy: 0.949500
Distillation: Epoch : 43, Loss : 0.188171, Accuracy: 0.954000, Test accuracy: 0.950400
Distillation: Epoch : 44, Loss : 0.178295, Accuracy: 0.950000, Test accuracy: 0.950600
Distillation: Epoch : 45, Loss : 0.191462, Accuracy: 0.947000, Test accuracy: 0.952200
Distillation: Epoch : 46, Loss : 0.168931, Accuracy: 0.948000, Test accuracy: 0.951800
Distillation: Epoch : 47, Loss : 0.208773, Accuracy: 0.943000, Test accuracy: 0.952500
Distillation: Epoch : 48, Loss : 0.180814, Accuracy: 0.955000, Test accuracy: 0.953500
Distillation: Epoch : 49, Loss : 0.197825, Accuracy: 0.948000, Test accuracy: 0.954900
Distillation: Epoch : 50, Loss : 0.188418, Accuracy: 0.945000, Test accuracy: 0.954300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9543
Generating confusion matrix for student5
[[ 965.    0.    1.    3.    1.    5.    7.    0.    5.    5.]
 [   0. 1117.    3.    0.    3.    2.    4.    8.    0.    6.]
 [   2.    3.  975.   12.    6.    2.    4.   19.    3.    0.]
 [   2.    2.   13.  942.    0.    9.    0.    9.   10.    4.]
 [   0.    0.    7.    1.  937.    1.    8.    7.    8.   15.]
 [   4.    1.    3.   30.    2.  841.    8.    2.    7.    7.]
 [   5.    2.    5.    1.    8.    9.  922.    0.    5.    1.]
 [   1.    0.   10.    9.    2.    4.    0.  971.    4.    8.]
 [   1.   10.   13.   10.    5.   14.    5.    0.  923.   13.]
 [   0.    0.    2.    2.   18.    5.    0.   12.    9.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.445904, Accuracy: 0.780000, Test accuracy: 0.784100
Distillation: Epoch : 2, Loss : 0.755258, Accuracy: 0.870000, Test accuracy: 0.864300
Distillation: Epoch : 3, Loss : 0.724601, Accuracy: 0.856000, Test accuracy: 0.882900
Distillation: Epoch : 4, Loss : 0.657020, Accuracy: 0.874000, Test accuracy: 0.894500
Distillation: Epoch : 5, Loss : 0.635741, Accuracy: 0.898000, Test accuracy: 0.898600
Distillation: Epoch : 6, Loss : 0.622451, Accuracy: 0.898000, Test accuracy: 0.901000
Distillation: Epoch : 7, Loss : 0.620959, Accuracy: 0.904000, Test accuracy: 0.904000
Distillation: Epoch : 8, Loss : 0.618100, Accuracy: 0.892000, Test accuracy: 0.904000
Distillation: Epoch : 9, Loss : 0.640907, Accuracy: 0.900000, Test accuracy: 0.906900
Distillation: Epoch : 10, Loss : 0.600535, Accuracy: 0.904000, Test accuracy: 0.907000
Distillation: Epoch : 11, Loss : 0.636314, Accuracy: 0.896000, Test accuracy: 0.907800
Distillation: Epoch : 12, Loss : 0.614712, Accuracy: 0.897000, Test accuracy: 0.910100
Distillation: Epoch : 13, Loss : 0.628072, Accuracy: 0.901000, Test accuracy: 0.910500
Distillation: Epoch : 14, Loss : 0.593310, Accuracy: 0.918000, Test accuracy: 0.910700
Distillation: Epoch : 15, Loss : 0.605681, Accuracy: 0.902000, Test accuracy: 0.911300
Distillation: Epoch : 16, Loss : 0.592934, Accuracy: 0.903000, Test accuracy: 0.911800
Distillation: Epoch : 17, Loss : 0.568635, Accuracy: 0.915000, Test accuracy: 0.911900
Distillation: Epoch : 18, Loss : 0.598510, Accuracy: 0.905000, Test accuracy: 0.911800
Distillation: Epoch : 19, Loss : 0.607570, Accuracy: 0.894000, Test accuracy: 0.912400
Distillation: Epoch : 20, Loss : 0.564876, Accuracy: 0.922000, Test accuracy: 0.911600
Distillation: Epoch : 21, Loss : 0.621062, Accuracy: 0.892000, Test accuracy: 0.914700
Distillation: Epoch : 22, Loss : 0.580335, Accuracy: 0.920000, Test accuracy: 0.914600
Distillation: Epoch : 23, Loss : 0.611628, Accuracy: 0.895000, Test accuracy: 0.912800
Distillation: Epoch : 24, Loss : 0.556432, Accuracy: 0.918000, Test accuracy: 0.913500
Distillation: Epoch : 25, Loss : 0.624023, Accuracy: 0.895000, Test accuracy: 0.913600
Distillation: Epoch : 26, Loss : 0.556596, Accuracy: 0.919000, Test accuracy: 0.914500
Distillation: Epoch : 27, Loss : 0.648986, Accuracy: 0.898000, Test accuracy: 0.914400
Distillation: Epoch : 28, Loss : 0.567708, Accuracy: 0.919000, Test accuracy: 0.914400
Distillation: Epoch : 29, Loss : 0.630185, Accuracy: 0.900000, Test accuracy: 0.915200
Distillation: Epoch : 30, Loss : 0.606488, Accuracy: 0.914000, Test accuracy: 0.913800
Distillation: Epoch : 31, Loss : 0.589455, Accuracy: 0.922000, Test accuracy: 0.914600
Distillation: Epoch : 32, Loss : 0.567721, Accuracy: 0.921000, Test accuracy: 0.916500
Distillation: Epoch : 33, Loss : 0.599739, Accuracy: 0.926000, Test accuracy: 0.915700
Distillation: Epoch : 34, Loss : 0.604307, Accuracy: 0.891000, Test accuracy: 0.914700
Distillation: Epoch : 35, Loss : 0.566115, Accuracy: 0.907000, Test accuracy: 0.915100
Distillation: Epoch : 36, Loss : 0.565898, Accuracy: 0.918000, Test accuracy: 0.915700
Distillation: Epoch : 37, Loss : 0.576201, Accuracy: 0.919000, Test accuracy: 0.916000
Distillation: Epoch : 38, Loss : 0.612561, Accuracy: 0.901000, Test accuracy: 0.915100
Distillation: Epoch : 39, Loss : 0.568774, Accuracy: 0.933000, Test accuracy: 0.916900
Distillation: Epoch : 40, Loss : 0.598317, Accuracy: 0.920000, Test accuracy: 0.914700
Distillation: Epoch : 41, Loss : 0.580008, Accuracy: 0.912000, Test accuracy: 0.915800
Distillation: Epoch : 42, Loss : 0.570645, Accuracy: 0.918000, Test accuracy: 0.917000
Distillation: Epoch : 43, Loss : 0.605638, Accuracy: 0.911000, Test accuracy: 0.917800
Distillation: Epoch : 44, Loss : 0.593494, Accuracy: 0.910000, Test accuracy: 0.918000
Distillation: Epoch : 45, Loss : 0.592165, Accuracy: 0.909000, Test accuracy: 0.917300
Distillation: Epoch : 46, Loss : 0.580593, Accuracy: 0.913000, Test accuracy: 0.917400
Distillation: Epoch : 47, Loss : 0.571998, Accuracy: 0.912000, Test accuracy: 0.918500
Distillation: Epoch : 48, Loss : 0.593724, Accuracy: 0.919000, Test accuracy: 0.917000
Distillation: Epoch : 49, Loss : 0.586725, Accuracy: 0.910000, Test accuracy: 0.918600
Distillation: Epoch : 50, Loss : 0.613057, Accuracy: 0.901000, Test accuracy: 0.918500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9185
Generating confusion matrix for student5
[[ 960.    0.    9.    5.    1.    9.   10.    2.   11.   13.]
 [   0. 1108.    7.    2.    4.    3.    3.   16.   10.    7.]
 [   1.    3.  922.   24.    7.    3.    7.   26.    9.    1.]
 [   2.    2.   16.  912.    0.   34.    1.    7.   20.   10.]
 [   0.    0.   12.    2.  920.    9.   11.   13.   13.   46.]
 [   6.    3.    3.   25.    1.  778.   18.    1.   26.    7.]
 [   7.    4.   10.    2.    9.   13.  903.    0.   12.    0.]
 [   1.    0.   10.   11.    2.    7.    2.  930.    8.   23.]
 [   3.   15.   36.   20.    5.   29.    3.    0.  857.    7.]
 [   0.    0.    7.    7.   33.    7.    0.   33.    8.  895.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.630900, Accuracy: 0.744000, Test accuracy: 0.739200
Distillation: Epoch : 2, Loss : 0.946797, Accuracy: 0.838000, Test accuracy: 0.848800
Distillation: Epoch : 3, Loss : 0.847252, Accuracy: 0.880000, Test accuracy: 0.876200
Distillation: Epoch : 4, Loss : 0.808777, Accuracy: 0.884000, Test accuracy: 0.889500
Distillation: Epoch : 5, Loss : 0.822951, Accuracy: 0.890000, Test accuracy: 0.895900
Distillation: Epoch : 6, Loss : 0.803355, Accuracy: 0.890000, Test accuracy: 0.900800
Distillation: Epoch : 7, Loss : 0.774613, Accuracy: 0.910000, Test accuracy: 0.904200
Distillation: Epoch : 8, Loss : 0.772695, Accuracy: 0.904000, Test accuracy: 0.906500
Distillation: Epoch : 9, Loss : 0.770672, Accuracy: 0.894000, Test accuracy: 0.907800
Distillation: Epoch : 10, Loss : 0.802447, Accuracy: 0.900000, Test accuracy: 0.910900
Distillation: Epoch : 11, Loss : 0.779389, Accuracy: 0.894000, Test accuracy: 0.910900
Distillation: Epoch : 12, Loss : 0.775064, Accuracy: 0.901000, Test accuracy: 0.913600
Distillation: Epoch : 13, Loss : 0.755759, Accuracy: 0.913000, Test accuracy: 0.915600
Distillation: Epoch : 14, Loss : 0.728836, Accuracy: 0.904000, Test accuracy: 0.916700
Distillation: Epoch : 15, Loss : 0.729413, Accuracy: 0.916000, Test accuracy: 0.919800
Distillation: Epoch : 16, Loss : 0.766011, Accuracy: 0.897000, Test accuracy: 0.920500
Distillation: Epoch : 17, Loss : 0.729819, Accuracy: 0.912000, Test accuracy: 0.922800
Distillation: Epoch : 18, Loss : 0.726064, Accuracy: 0.925000, Test accuracy: 0.923400
Distillation: Epoch : 19, Loss : 0.748816, Accuracy: 0.916000, Test accuracy: 0.925400
Distillation: Epoch : 20, Loss : 0.732508, Accuracy: 0.920000, Test accuracy: 0.928200
Distillation: Epoch : 21, Loss : 0.693048, Accuracy: 0.925000, Test accuracy: 0.927700
Distillation: Epoch : 22, Loss : 0.713801, Accuracy: 0.923000, Test accuracy: 0.929600
Distillation: Epoch : 23, Loss : 0.736714, Accuracy: 0.912000, Test accuracy: 0.931000
Distillation: Epoch : 24, Loss : 0.708725, Accuracy: 0.925000, Test accuracy: 0.932700
Distillation: Epoch : 25, Loss : 0.691793, Accuracy: 0.936000, Test accuracy: 0.933000
Distillation: Epoch : 26, Loss : 0.670569, Accuracy: 0.931000, Test accuracy: 0.935200
Distillation: Epoch : 27, Loss : 0.693863, Accuracy: 0.925000, Test accuracy: 0.936000
Distillation: Epoch : 28, Loss : 0.701696, Accuracy: 0.926000, Test accuracy: 0.936200
Distillation: Epoch : 29, Loss : 0.683773, Accuracy: 0.940000, Test accuracy: 0.938200
Distillation: Epoch : 30, Loss : 0.702548, Accuracy: 0.929000, Test accuracy: 0.938200
Distillation: Epoch : 31, Loss : 0.663079, Accuracy: 0.949000, Test accuracy: 0.939700
Distillation: Epoch : 32, Loss : 0.654769, Accuracy: 0.935000, Test accuracy: 0.938400
Distillation: Epoch : 33, Loss : 0.650618, Accuracy: 0.942000, Test accuracy: 0.940400
Distillation: Epoch : 34, Loss : 0.707656, Accuracy: 0.924000, Test accuracy: 0.941200
Distillation: Epoch : 35, Loss : 0.679827, Accuracy: 0.947000, Test accuracy: 0.942100
Distillation: Epoch : 36, Loss : 0.681196, Accuracy: 0.936000, Test accuracy: 0.943900
Distillation: Epoch : 37, Loss : 0.653139, Accuracy: 0.938000, Test accuracy: 0.944000
Distillation: Epoch : 38, Loss : 0.682042, Accuracy: 0.932000, Test accuracy: 0.944700
Distillation: Epoch : 39, Loss : 0.658364, Accuracy: 0.945000, Test accuracy: 0.945500
Distillation: Epoch : 40, Loss : 0.657337, Accuracy: 0.945000, Test accuracy: 0.945600
Distillation: Epoch : 41, Loss : 0.666234, Accuracy: 0.948000, Test accuracy: 0.947700
Distillation: Epoch : 42, Loss : 0.655639, Accuracy: 0.938000, Test accuracy: 0.946300
Distillation: Epoch : 43, Loss : 0.681315, Accuracy: 0.936000, Test accuracy: 0.948200
Distillation: Epoch : 44, Loss : 0.668431, Accuracy: 0.945000, Test accuracy: 0.948200
Distillation: Epoch : 45, Loss : 0.658110, Accuracy: 0.946000, Test accuracy: 0.949300
Distillation: Epoch : 46, Loss : 0.676829, Accuracy: 0.945000, Test accuracy: 0.950100
Distillation: Epoch : 47, Loss : 0.696339, Accuracy: 0.938000, Test accuracy: 0.950300
Distillation: Epoch : 48, Loss : 0.611849, Accuracy: 0.958000, Test accuracy: 0.949800
Distillation: Epoch : 49, Loss : 0.627022, Accuracy: 0.954000, Test accuracy: 0.950000
Distillation: Epoch : 50, Loss : 0.636189, Accuracy: 0.950000, Test accuracy: 0.951300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9513
Generating confusion matrix for student5
[[ 964.    0.    4.    2.    1.    6.    7.    0.    6.    3.]
 [   0. 1111.    3.    3.    1.    3.    2.    9.    6.    8.]
 [   0.    4.  985.   14.    5.    2.    2.   20.    9.    0.]
 [   1.    2.    6.  943.    0.   17.    1.    4.    9.    9.]
 [   0.    0.   11.    1.  942.    5.    6.    9.   12.   24.]
 [   4.    0.    1.   17.    1.  836.    9.    1.   11.    6.]
 [   5.    4.    3.    1.    6.   10.  930.    0.    8.    2.]
 [   1.    0.    8.    8.    1.    4.    0.  957.    2.    6.]
 [   3.   14.    7.   14.    3.    6.    1.    0.  900.    6.]
 [   2.    0.    4.    7.   22.    3.    0.   28.   11.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.962027, Accuracy: 0.735000, Test accuracy: 0.737200
Distillation: Epoch : 2, Loss : 1.155605, Accuracy: 0.830000, Test accuracy: 0.846100
Distillation: Epoch : 3, Loss : 1.020350, Accuracy: 0.848000, Test accuracy: 0.880500
Distillation: Epoch : 4, Loss : 0.980377, Accuracy: 0.869000, Test accuracy: 0.892600
Distillation: Epoch : 5, Loss : 0.940106, Accuracy: 0.894000, Test accuracy: 0.901200
Distillation: Epoch : 6, Loss : 0.960086, Accuracy: 0.882000, Test accuracy: 0.906100
Distillation: Epoch : 7, Loss : 0.944756, Accuracy: 0.887000, Test accuracy: 0.910800
Distillation: Epoch : 8, Loss : 0.907105, Accuracy: 0.913000, Test accuracy: 0.913900
Distillation: Epoch : 9, Loss : 0.906882, Accuracy: 0.912000, Test accuracy: 0.917300
Distillation: Epoch : 10, Loss : 0.896942, Accuracy: 0.926000, Test accuracy: 0.921400
Distillation: Epoch : 11, Loss : 0.873998, Accuracy: 0.922000, Test accuracy: 0.924700
Distillation: Epoch : 12, Loss : 0.891104, Accuracy: 0.934000, Test accuracy: 0.925900
Distillation: Epoch : 13, Loss : 0.859854, Accuracy: 0.922000, Test accuracy: 0.929100
Distillation: Epoch : 14, Loss : 0.859619, Accuracy: 0.928000, Test accuracy: 0.931400
Distillation: Epoch : 15, Loss : 0.874970, Accuracy: 0.940000, Test accuracy: 0.933700
Distillation: Epoch : 16, Loss : 0.863643, Accuracy: 0.931000, Test accuracy: 0.936900
Distillation: Epoch : 17, Loss : 0.864988, Accuracy: 0.932000, Test accuracy: 0.938500
Distillation: Epoch : 18, Loss : 0.825587, Accuracy: 0.935000, Test accuracy: 0.941400
Distillation: Epoch : 19, Loss : 0.849739, Accuracy: 0.938000, Test accuracy: 0.942400
Distillation: Epoch : 20, Loss : 0.842344, Accuracy: 0.947000, Test accuracy: 0.944200
Distillation: Epoch : 21, Loss : 0.846408, Accuracy: 0.937000, Test accuracy: 0.944500
Distillation: Epoch : 22, Loss : 0.813311, Accuracy: 0.943000, Test accuracy: 0.947800
Distillation: Epoch : 23, Loss : 0.821193, Accuracy: 0.941000, Test accuracy: 0.949300
Distillation: Epoch : 24, Loss : 0.825386, Accuracy: 0.954000, Test accuracy: 0.950100
Distillation: Epoch : 25, Loss : 0.819615, Accuracy: 0.940000, Test accuracy: 0.951700
Distillation: Epoch : 26, Loss : 0.821253, Accuracy: 0.936000, Test accuracy: 0.954400
Distillation: Epoch : 27, Loss : 0.812176, Accuracy: 0.952000, Test accuracy: 0.954500
Distillation: Epoch : 28, Loss : 0.790310, Accuracy: 0.950000, Test accuracy: 0.955800
Distillation: Epoch : 29, Loss : 0.817436, Accuracy: 0.946000, Test accuracy: 0.957000
Distillation: Epoch : 30, Loss : 0.799508, Accuracy: 0.947000, Test accuracy: 0.958000
Distillation: Epoch : 31, Loss : 0.838967, Accuracy: 0.943000, Test accuracy: 0.959600
Distillation: Epoch : 32, Loss : 0.784591, Accuracy: 0.965000, Test accuracy: 0.960600
Distillation: Epoch : 33, Loss : 0.782528, Accuracy: 0.957000, Test accuracy: 0.960900
Distillation: Epoch : 34, Loss : 0.808227, Accuracy: 0.952000, Test accuracy: 0.960500
Distillation: Epoch : 35, Loss : 0.813878, Accuracy: 0.957000, Test accuracy: 0.960900
Distillation: Epoch : 36, Loss : 0.812316, Accuracy: 0.954000, Test accuracy: 0.961500
Distillation: Epoch : 37, Loss : 0.797320, Accuracy: 0.948000, Test accuracy: 0.961800
Distillation: Epoch : 38, Loss : 0.785746, Accuracy: 0.960000, Test accuracy: 0.962700
Distillation: Epoch : 39, Loss : 0.774381, Accuracy: 0.972000, Test accuracy: 0.963400
Distillation: Epoch : 40, Loss : 0.780346, Accuracy: 0.963000, Test accuracy: 0.962400
Distillation: Epoch : 41, Loss : 0.828005, Accuracy: 0.946000, Test accuracy: 0.963600
Distillation: Epoch : 42, Loss : 0.783512, Accuracy: 0.964000, Test accuracy: 0.964200
Distillation: Epoch : 43, Loss : 0.789242, Accuracy: 0.962000, Test accuracy: 0.964300
Distillation: Epoch : 44, Loss : 0.833102, Accuracy: 0.944000, Test accuracy: 0.964800
Distillation: Epoch : 45, Loss : 0.812148, Accuracy: 0.956000, Test accuracy: 0.964800
Distillation: Epoch : 46, Loss : 0.798101, Accuracy: 0.963000, Test accuracy: 0.965000
Distillation: Epoch : 47, Loss : 0.797210, Accuracy: 0.953000, Test accuracy: 0.965000
Distillation: Epoch : 48, Loss : 0.798509, Accuracy: 0.966000, Test accuracy: 0.964500
Distillation: Epoch : 49, Loss : 0.798787, Accuracy: 0.955000, Test accuracy: 0.965300
Distillation: Epoch : 50, Loss : 0.800567, Accuracy: 0.954000, Test accuracy: 0.964200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9642
Generating confusion matrix for student5
[[ 968.    0.    4.    0.    1.    1.    5.    2.    9.    5.]
 [   0. 1118.    7.    1.    2.    1.    3.   11.   12.    8.]
 [   1.    3. 1001.   14.    4.    1.    1.   21.    5.    0.]
 [   0.    1.    2.  965.    0.    6.    1.    3.    3.    5.]
 [   1.    0.    3.    1.  952.    0.    5.    4.    8.   18.]
 [   0.    0.    1.   13.    0.  865.    2.    0.    5.    5.]
 [   5.    5.    1.    0.    3.    5.  937.    0.    8.    0.]
 [   0.    0.    6.    4.    1.    3.    0.  968.    6.    5.]
 [   3.    8.    5.    5.    2.    3.    4.    0.  906.    1.]
 [   2.    0.    2.    7.   17.    7.    0.   19.   12.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.512191, Accuracy: 0.767000, Test accuracy: 0.799000
Distillation: Epoch : 2, Loss : 1.221841, Accuracy: 0.848000, Test accuracy: 0.865200
Distillation: Epoch : 3, Loss : 1.183153, Accuracy: 0.871000, Test accuracy: 0.881500
Distillation: Epoch : 4, Loss : 1.141729, Accuracy: 0.867000, Test accuracy: 0.889200
Distillation: Epoch : 5, Loss : 1.121959, Accuracy: 0.896000, Test accuracy: 0.891700
Distillation: Epoch : 6, Loss : 1.129922, Accuracy: 0.876000, Test accuracy: 0.896800
Distillation: Epoch : 7, Loss : 1.130650, Accuracy: 0.888000, Test accuracy: 0.899400
Distillation: Epoch : 8, Loss : 1.114405, Accuracy: 0.903000, Test accuracy: 0.901500
Distillation: Epoch : 9, Loss : 1.088023, Accuracy: 0.907000, Test accuracy: 0.902100
Distillation: Epoch : 10, Loss : 1.128152, Accuracy: 0.890000, Test accuracy: 0.903300
Distillation: Epoch : 11, Loss : 1.089418, Accuracy: 0.883000, Test accuracy: 0.905800
Distillation: Epoch : 12, Loss : 1.105948, Accuracy: 0.888000, Test accuracy: 0.904100
Distillation: Epoch : 13, Loss : 1.145044, Accuracy: 0.879000, Test accuracy: 0.903300
Distillation: Epoch : 14, Loss : 1.092522, Accuracy: 0.893000, Test accuracy: 0.906000
Distillation: Epoch : 15, Loss : 1.087650, Accuracy: 0.897000, Test accuracy: 0.905900
Distillation: Epoch : 16, Loss : 1.096695, Accuracy: 0.895000, Test accuracy: 0.905900
Distillation: Epoch : 17, Loss : 1.108513, Accuracy: 0.903000, Test accuracy: 0.907300
Distillation: Epoch : 18, Loss : 1.126026, Accuracy: 0.889000, Test accuracy: 0.905500
Distillation: Epoch : 19, Loss : 1.056813, Accuracy: 0.911000, Test accuracy: 0.907000
Distillation: Epoch : 20, Loss : 1.100102, Accuracy: 0.903000, Test accuracy: 0.908100
Distillation: Epoch : 21, Loss : 1.093318, Accuracy: 0.903000, Test accuracy: 0.906000
Distillation: Epoch : 22, Loss : 1.121320, Accuracy: 0.886000, Test accuracy: 0.908100
Distillation: Epoch : 23, Loss : 1.107775, Accuracy: 0.889000, Test accuracy: 0.907700
Distillation: Epoch : 24, Loss : 1.123705, Accuracy: 0.906000, Test accuracy: 0.910500
Distillation: Epoch : 25, Loss : 1.116516, Accuracy: 0.896000, Test accuracy: 0.908800
Distillation: Epoch : 26, Loss : 1.065637, Accuracy: 0.903000, Test accuracy: 0.910000
Distillation: Epoch : 27, Loss : 1.066826, Accuracy: 0.909000, Test accuracy: 0.909000
Distillation: Epoch : 28, Loss : 1.088073, Accuracy: 0.916000, Test accuracy: 0.909000
Distillation: Epoch : 29, Loss : 1.086415, Accuracy: 0.908000, Test accuracy: 0.908900
Distillation: Epoch : 30, Loss : 1.072084, Accuracy: 0.918000, Test accuracy: 0.910400
Distillation: Epoch : 31, Loss : 1.081334, Accuracy: 0.902000, Test accuracy: 0.908700
Distillation: Epoch : 32, Loss : 1.081200, Accuracy: 0.901000, Test accuracy: 0.910500
Distillation: Epoch : 33, Loss : 1.095531, Accuracy: 0.908000, Test accuracy: 0.908700
Distillation: Epoch : 34, Loss : 1.062092, Accuracy: 0.912000, Test accuracy: 0.908600
Distillation: Epoch : 35, Loss : 1.054882, Accuracy: 0.920000, Test accuracy: 0.910500
Distillation: Epoch : 36, Loss : 1.079523, Accuracy: 0.912000, Test accuracy: 0.910400
Distillation: Epoch : 37, Loss : 1.091832, Accuracy: 0.910000, Test accuracy: 0.910900
Distillation: Epoch : 38, Loss : 1.025074, Accuracy: 0.923000, Test accuracy: 0.910800
Distillation: Epoch : 39, Loss : 1.078067, Accuracy: 0.907000, Test accuracy: 0.910300
Distillation: Epoch : 40, Loss : 1.063215, Accuracy: 0.905000, Test accuracy: 0.911200
Distillation: Epoch : 41, Loss : 1.128476, Accuracy: 0.870000, Test accuracy: 0.911400
Distillation: Epoch : 42, Loss : 1.079456, Accuracy: 0.908000, Test accuracy: 0.909200
Distillation: Epoch : 43, Loss : 1.096898, Accuracy: 0.900000, Test accuracy: 0.910300
Distillation: Epoch : 44, Loss : 1.088999, Accuracy: 0.900000, Test accuracy: 0.912100
Distillation: Epoch : 45, Loss : 1.070758, Accuracy: 0.900000, Test accuracy: 0.910400
Distillation: Epoch : 46, Loss : 1.072781, Accuracy: 0.908000, Test accuracy: 0.912100
Distillation: Epoch : 47, Loss : 1.071039, Accuracy: 0.894000, Test accuracy: 0.912100
Distillation: Epoch : 48, Loss : 1.076251, Accuracy: 0.900000, Test accuracy: 0.911800
Distillation: Epoch : 49, Loss : 1.056743, Accuracy: 0.903000, Test accuracy: 0.912800
Distillation: Epoch : 50, Loss : 1.108564, Accuracy: 0.895000, Test accuracy: 0.911900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9119
Generating confusion matrix for student5
[[ 959.    0.   11.    4.    1.    7.   10.    1.   10.   10.]
 [   0. 1105.   11.    3.    2.    4.    4.   24.   10.    5.]
 [   1.    4.  915.   28.    7.    3.    7.   18.   11.    1.]
 [   1.    3.   16.  905.    0.   29.    0.    5.   20.   12.]
 [   0.    0.   17.    2.  925.   11.   10.   20.   23.   52.]
 [   7.    3.    2.   28.    2.  778.   22.    2.   37.    7.]
 [   7.    4.   10.    2.    8.   15.  900.    0.   12.    0.]
 [   1.    1.   10.    9.    1.    7.    2.  905.    7.   16.]
 [   3.   15.   33.   17.    6.   28.    3.    0.  828.    7.]
 [   1.    0.    7.   12.   30.   10.    0.   53.   16.  899.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.988160, Accuracy: 0.629000, Test accuracy: 0.627700
Distillation: Epoch : 2, Loss : 1.360605, Accuracy: 0.858000, Test accuracy: 0.847600
Distillation: Epoch : 3, Loss : 1.294505, Accuracy: 0.873000, Test accuracy: 0.876300
Distillation: Epoch : 4, Loss : 1.287881, Accuracy: 0.882000, Test accuracy: 0.886800
Distillation: Epoch : 5, Loss : 1.263556, Accuracy: 0.888000, Test accuracy: 0.892100
Distillation: Epoch : 6, Loss : 1.275492, Accuracy: 0.876000, Test accuracy: 0.897000
Distillation: Epoch : 7, Loss : 1.284802, Accuracy: 0.892000, Test accuracy: 0.899000
Distillation: Epoch : 8, Loss : 1.268137, Accuracy: 0.891000, Test accuracy: 0.904000
Distillation: Epoch : 9, Loss : 1.227400, Accuracy: 0.894000, Test accuracy: 0.903600
Distillation: Epoch : 10, Loss : 1.243246, Accuracy: 0.903000, Test accuracy: 0.906600
Distillation: Epoch : 11, Loss : 1.242128, Accuracy: 0.912000, Test accuracy: 0.908400
Distillation: Epoch : 12, Loss : 1.222401, Accuracy: 0.901000, Test accuracy: 0.909300
Distillation: Epoch : 13, Loss : 1.268922, Accuracy: 0.895000, Test accuracy: 0.911500
Distillation: Epoch : 14, Loss : 1.274216, Accuracy: 0.900000, Test accuracy: 0.913000
Distillation: Epoch : 15, Loss : 1.237957, Accuracy: 0.900000, Test accuracy: 0.914200
Distillation: Epoch : 16, Loss : 1.225749, Accuracy: 0.912000, Test accuracy: 0.915700
Distillation: Epoch : 17, Loss : 1.223254, Accuracy: 0.918000, Test accuracy: 0.917700
Distillation: Epoch : 18, Loss : 1.202419, Accuracy: 0.918000, Test accuracy: 0.918800
Distillation: Epoch : 19, Loss : 1.215651, Accuracy: 0.922000, Test accuracy: 0.921400
Distillation: Epoch : 20, Loss : 1.197850, Accuracy: 0.912000, Test accuracy: 0.923300
Distillation: Epoch : 21, Loss : 1.184008, Accuracy: 0.912000, Test accuracy: 0.925300
Distillation: Epoch : 22, Loss : 1.200853, Accuracy: 0.926000, Test accuracy: 0.926400
Distillation: Epoch : 23, Loss : 1.181284, Accuracy: 0.922000, Test accuracy: 0.928400
Distillation: Epoch : 24, Loss : 1.189785, Accuracy: 0.921000, Test accuracy: 0.930300
Distillation: Epoch : 25, Loss : 1.206349, Accuracy: 0.901000, Test accuracy: 0.932300
Distillation: Epoch : 26, Loss : 1.192675, Accuracy: 0.928000, Test accuracy: 0.933600
Distillation: Epoch : 27, Loss : 1.209053, Accuracy: 0.916000, Test accuracy: 0.934400
Distillation: Epoch : 28, Loss : 1.201974, Accuracy: 0.914000, Test accuracy: 0.935400
Distillation: Epoch : 29, Loss : 1.185132, Accuracy: 0.929000, Test accuracy: 0.937200
Distillation: Epoch : 30, Loss : 1.189834, Accuracy: 0.931000, Test accuracy: 0.938500
Distillation: Epoch : 31, Loss : 1.160216, Accuracy: 0.938000, Test accuracy: 0.939200
Distillation: Epoch : 32, Loss : 1.161103, Accuracy: 0.934000, Test accuracy: 0.940700
Distillation: Epoch : 33, Loss : 1.155143, Accuracy: 0.932000, Test accuracy: 0.941800
Distillation: Epoch : 34, Loss : 1.144996, Accuracy: 0.943000, Test accuracy: 0.941500
Distillation: Epoch : 35, Loss : 1.148469, Accuracy: 0.953000, Test accuracy: 0.943100
Distillation: Epoch : 36, Loss : 1.156835, Accuracy: 0.946000, Test accuracy: 0.943600
Distillation: Epoch : 37, Loss : 1.183275, Accuracy: 0.936000, Test accuracy: 0.944500
Distillation: Epoch : 38, Loss : 1.153411, Accuracy: 0.949000, Test accuracy: 0.945300
Distillation: Epoch : 39, Loss : 1.149654, Accuracy: 0.942000, Test accuracy: 0.946300
Distillation: Epoch : 40, Loss : 1.143784, Accuracy: 0.954000, Test accuracy: 0.947700
Distillation: Epoch : 41, Loss : 1.175554, Accuracy: 0.926000, Test accuracy: 0.948000
Distillation: Epoch : 42, Loss : 1.145505, Accuracy: 0.940000, Test accuracy: 0.948800
Distillation: Epoch : 43, Loss : 1.170818, Accuracy: 0.949000, Test accuracy: 0.948500
Distillation: Epoch : 44, Loss : 1.195521, Accuracy: 0.938000, Test accuracy: 0.949300
Distillation: Epoch : 45, Loss : 1.183996, Accuracy: 0.931000, Test accuracy: 0.949900
Distillation: Epoch : 46, Loss : 1.137511, Accuracy: 0.945000, Test accuracy: 0.950100
Distillation: Epoch : 47, Loss : 1.151852, Accuracy: 0.954000, Test accuracy: 0.951100
Distillation: Epoch : 48, Loss : 1.122671, Accuracy: 0.949000, Test accuracy: 0.951100
Distillation: Epoch : 49, Loss : 1.137305, Accuracy: 0.958000, Test accuracy: 0.951800
Distillation: Epoch : 50, Loss : 1.135513, Accuracy: 0.950000, Test accuracy: 0.950300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9503
Generating confusion matrix for student5
[[ 959.    0.   13.    4.    0.    5.    8.    1.    6.    3.]
 [   0. 1115.    7.    1.    0.    1.    3.    8.    1.    5.]
 [   1.    2.  976.   12.    6.    0.    0.   21.   12.    0.]
 [   1.    1.    2.  931.    0.   11.    0.   10.    6.    6.]
 [   0.    0.    8.    1.  941.    7.    6.   11.    9.   15.]
 [   3.    2.    0.   23.    1.  846.   16.    3.   11.   15.]
 [  10.    5.    3.    3.    8.   10.  924.    0.    4.    1.]
 [   0.    0.    5.   13.    2.    1.    0.  956.    2.    6.]
 [   5.   10.   15.   18.    5.    8.    1.    0.  904.    7.]
 [   1.    0.    3.    4.   19.    3.    0.   18.   19.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.193857, Accuracy: 0.488000, Test accuracy: 0.503500
Distillation: Epoch : 2, Loss : 1.674063, Accuracy: 0.806000, Test accuracy: 0.805200
Distillation: Epoch : 3, Loss : 1.468757, Accuracy: 0.852000, Test accuracy: 0.857600
Distillation: Epoch : 4, Loss : 1.428289, Accuracy: 0.868000, Test accuracy: 0.879200
Distillation: Epoch : 5, Loss : 1.402268, Accuracy: 0.876000, Test accuracy: 0.891900
Distillation: Epoch : 6, Loss : 1.381564, Accuracy: 0.887000, Test accuracy: 0.900800
Distillation: Epoch : 7, Loss : 1.395758, Accuracy: 0.894000, Test accuracy: 0.908100
Distillation: Epoch : 8, Loss : 1.372513, Accuracy: 0.894000, Test accuracy: 0.912200
Distillation: Epoch : 9, Loss : 1.346122, Accuracy: 0.894000, Test accuracy: 0.916200
Distillation: Epoch : 10, Loss : 1.339946, Accuracy: 0.916000, Test accuracy: 0.920200
Distillation: Epoch : 11, Loss : 1.348952, Accuracy: 0.914000, Test accuracy: 0.922500
Distillation: Epoch : 12, Loss : 1.318641, Accuracy: 0.912000, Test accuracy: 0.926600
Distillation: Epoch : 13, Loss : 1.334961, Accuracy: 0.925000, Test accuracy: 0.928000
Distillation: Epoch : 14, Loss : 1.331777, Accuracy: 0.924000, Test accuracy: 0.931200
Distillation: Epoch : 15, Loss : 1.352459, Accuracy: 0.926000, Test accuracy: 0.932300
Distillation: Epoch : 16, Loss : 1.324480, Accuracy: 0.933000, Test accuracy: 0.934900
Distillation: Epoch : 17, Loss : 1.312484, Accuracy: 0.931000, Test accuracy: 0.936500
Distillation: Epoch : 18, Loss : 1.336480, Accuracy: 0.928000, Test accuracy: 0.938400
Distillation: Epoch : 19, Loss : 1.313925, Accuracy: 0.930000, Test accuracy: 0.939900
Distillation: Epoch : 20, Loss : 1.302422, Accuracy: 0.927000, Test accuracy: 0.942000
Distillation: Epoch : 21, Loss : 1.320348, Accuracy: 0.935000, Test accuracy: 0.945000
Distillation: Epoch : 22, Loss : 1.312418, Accuracy: 0.932000, Test accuracy: 0.945200
Distillation: Epoch : 23, Loss : 1.300954, Accuracy: 0.941000, Test accuracy: 0.947400
Distillation: Epoch : 24, Loss : 1.292978, Accuracy: 0.938000, Test accuracy: 0.946500
Distillation: Epoch : 25, Loss : 1.308584, Accuracy: 0.930000, Test accuracy: 0.948000
Distillation: Epoch : 26, Loss : 1.302657, Accuracy: 0.937000, Test accuracy: 0.949100
Distillation: Epoch : 27, Loss : 1.314188, Accuracy: 0.940000, Test accuracy: 0.949500
Distillation: Epoch : 28, Loss : 1.290170, Accuracy: 0.949000, Test accuracy: 0.949600
Distillation: Epoch : 29, Loss : 1.322817, Accuracy: 0.949000, Test accuracy: 0.950700
Distillation: Epoch : 30, Loss : 1.283725, Accuracy: 0.952000, Test accuracy: 0.951100
Distillation: Epoch : 31, Loss : 1.305774, Accuracy: 0.949000, Test accuracy: 0.951800
Distillation: Epoch : 32, Loss : 1.307041, Accuracy: 0.936000, Test accuracy: 0.952300
Distillation: Epoch : 33, Loss : 1.314707, Accuracy: 0.938000, Test accuracy: 0.953000
Distillation: Epoch : 34, Loss : 1.305177, Accuracy: 0.945000, Test accuracy: 0.954300
Distillation: Epoch : 35, Loss : 1.274045, Accuracy: 0.949000, Test accuracy: 0.953800
Distillation: Epoch : 36, Loss : 1.300518, Accuracy: 0.946000, Test accuracy: 0.955300
Distillation: Epoch : 37, Loss : 1.289558, Accuracy: 0.949000, Test accuracy: 0.955900
Distillation: Epoch : 38, Loss : 1.270217, Accuracy: 0.964000, Test accuracy: 0.954200
Distillation: Epoch : 39, Loss : 1.284886, Accuracy: 0.945000, Test accuracy: 0.953600
Distillation: Epoch : 40, Loss : 1.284058, Accuracy: 0.947000, Test accuracy: 0.956000
Distillation: Epoch : 41, Loss : 1.274348, Accuracy: 0.948000, Test accuracy: 0.955400
Distillation: Epoch : 42, Loss : 1.300078, Accuracy: 0.940000, Test accuracy: 0.956500
Distillation: Epoch : 43, Loss : 1.272917, Accuracy: 0.956000, Test accuracy: 0.955900
Distillation: Epoch : 44, Loss : 1.259149, Accuracy: 0.946000, Test accuracy: 0.956900
Distillation: Epoch : 45, Loss : 1.279667, Accuracy: 0.949000, Test accuracy: 0.956800
Distillation: Epoch : 46, Loss : 1.291872, Accuracy: 0.949000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 1.271977, Accuracy: 0.959000, Test accuracy: 0.956900
Distillation: Epoch : 48, Loss : 1.257900, Accuracy: 0.959000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 1.299635, Accuracy: 0.954000, Test accuracy: 0.957600
Distillation: Epoch : 50, Loss : 1.271572, Accuracy: 0.958000, Test accuracy: 0.957900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9579
Generating confusion matrix for student5
[[ 968.    0.    6.    0.    2.    0.   10.    4.    8.    8.]
 [   1. 1121.    7.    0.    2.    2.    4.   14.    2.    6.]
 [   1.    3.  984.   16.    4.    1.    2.   23.   14.    0.]
 [   0.    1.    4.  966.    0.   10.    0.    6.    3.    9.]
 [   1.    0.    7.    1.  945.    0.    3.    8.    8.   22.]
 [   0.    0.    0.   10.    0.  857.    4.    2.    1.    3.]
 [   6.    4.    4.    0.    6.    9.  933.    0.    6.    1.]
 [   1.    0.    7.    7.    0.    2.    0.  948.    6.    8.]
 [   2.    6.   13.    6.    2.    4.    2.    0.  909.    4.]
 [   0.    0.    0.    4.   21.    7.    0.   23.   17.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.120432, Accuracy: 0.599000, Test accuracy: 0.623000
Distillation: Epoch : 2, Loss : 1.633273, Accuracy: 0.822000, Test accuracy: 0.847200
Distillation: Epoch : 3, Loss : 1.563779, Accuracy: 0.852000, Test accuracy: 0.876900
Distillation: Epoch : 4, Loss : 1.538080, Accuracy: 0.886000, Test accuracy: 0.891800
Distillation: Epoch : 5, Loss : 1.501417, Accuracy: 0.887000, Test accuracy: 0.903100
Distillation: Epoch : 6, Loss : 1.486921, Accuracy: 0.913000, Test accuracy: 0.911400
Distillation: Epoch : 7, Loss : 1.480750, Accuracy: 0.902000, Test accuracy: 0.917300
Distillation: Epoch : 8, Loss : 1.482641, Accuracy: 0.922000, Test accuracy: 0.921400
Distillation: Epoch : 9, Loss : 1.470832, Accuracy: 0.916000, Test accuracy: 0.925000
Distillation: Epoch : 10, Loss : 1.463347, Accuracy: 0.892000, Test accuracy: 0.928900
Distillation: Epoch : 11, Loss : 1.457799, Accuracy: 0.917000, Test accuracy: 0.931100
Distillation: Epoch : 12, Loss : 1.466284, Accuracy: 0.921000, Test accuracy: 0.934200
Distillation: Epoch : 13, Loss : 1.448091, Accuracy: 0.927000, Test accuracy: 0.936500
Distillation: Epoch : 14, Loss : 1.427300, Accuracy: 0.942000, Test accuracy: 0.937800
Distillation: Epoch : 15, Loss : 1.486008, Accuracy: 0.922000, Test accuracy: 0.940200
Distillation: Epoch : 16, Loss : 1.459089, Accuracy: 0.933000, Test accuracy: 0.942200
Distillation: Epoch : 17, Loss : 1.452640, Accuracy: 0.934000, Test accuracy: 0.942800
Distillation: Epoch : 18, Loss : 1.433495, Accuracy: 0.937000, Test accuracy: 0.943400
Distillation: Epoch : 19, Loss : 1.425788, Accuracy: 0.940000, Test accuracy: 0.945600
Distillation: Epoch : 20, Loss : 1.422484, Accuracy: 0.935000, Test accuracy: 0.946900
Distillation: Epoch : 21, Loss : 1.413955, Accuracy: 0.943000, Test accuracy: 0.946900
Distillation: Epoch : 22, Loss : 1.432135, Accuracy: 0.942000, Test accuracy: 0.947900
Distillation: Epoch : 23, Loss : 1.440385, Accuracy: 0.942000, Test accuracy: 0.948900
Distillation: Epoch : 24, Loss : 1.390843, Accuracy: 0.954000, Test accuracy: 0.949900
Distillation: Epoch : 25, Loss : 1.399877, Accuracy: 0.942000, Test accuracy: 0.950100
Distillation: Epoch : 26, Loss : 1.404265, Accuracy: 0.942000, Test accuracy: 0.950900
Distillation: Epoch : 27, Loss : 1.431126, Accuracy: 0.949000, Test accuracy: 0.951700
Distillation: Epoch : 28, Loss : 1.397089, Accuracy: 0.951000, Test accuracy: 0.951200
Distillation: Epoch : 29, Loss : 1.416947, Accuracy: 0.944000, Test accuracy: 0.953000
Distillation: Epoch : 30, Loss : 1.402009, Accuracy: 0.959000, Test accuracy: 0.953100
Distillation: Epoch : 31, Loss : 1.419651, Accuracy: 0.945000, Test accuracy: 0.952200
Distillation: Epoch : 32, Loss : 1.398066, Accuracy: 0.962000, Test accuracy: 0.952500
Distillation: Epoch : 33, Loss : 1.418347, Accuracy: 0.953000, Test accuracy: 0.953000
Distillation: Epoch : 34, Loss : 1.421993, Accuracy: 0.949000, Test accuracy: 0.954100
Distillation: Epoch : 35, Loss : 1.389425, Accuracy: 0.959000, Test accuracy: 0.954100
Distillation: Epoch : 36, Loss : 1.423336, Accuracy: 0.946000, Test accuracy: 0.954200
Distillation: Epoch : 37, Loss : 1.406090, Accuracy: 0.958000, Test accuracy: 0.954500
Distillation: Epoch : 38, Loss : 1.385195, Accuracy: 0.953000, Test accuracy: 0.955400
Distillation: Epoch : 39, Loss : 1.393276, Accuracy: 0.958000, Test accuracy: 0.953800
Distillation: Epoch : 40, Loss : 1.418801, Accuracy: 0.962000, Test accuracy: 0.955100
Distillation: Epoch : 41, Loss : 1.407919, Accuracy: 0.954000, Test accuracy: 0.955200
Distillation: Epoch : 42, Loss : 1.417540, Accuracy: 0.949000, Test accuracy: 0.955400
Distillation: Epoch : 43, Loss : 1.406170, Accuracy: 0.948000, Test accuracy: 0.955600
Distillation: Epoch : 44, Loss : 1.392943, Accuracy: 0.961000, Test accuracy: 0.955900
Distillation: Epoch : 45, Loss : 1.391618, Accuracy: 0.953000, Test accuracy: 0.956000
Distillation: Epoch : 46, Loss : 1.385101, Accuracy: 0.957000, Test accuracy: 0.956200
Distillation: Epoch : 47, Loss : 1.398942, Accuracy: 0.951000, Test accuracy: 0.956500
Distillation: Epoch : 48, Loss : 1.399441, Accuracy: 0.957000, Test accuracy: 0.957800
Distillation: Epoch : 49, Loss : 1.420253, Accuracy: 0.955000, Test accuracy: 0.956400
Distillation: Epoch : 50, Loss : 1.399421, Accuracy: 0.946000, Test accuracy: 0.956800
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9568
Generating confusion matrix for student5
[[ 970.    0.    4.    0.    1.    2.   10.    3.    8.    6.]
 [   1. 1111.    8.    0.    2.    2.    3.   12.   11.    8.]
 [   2.    5.  982.   14.    1.    0.    1.   19.    8.    1.]
 [   0.    3.    2.  967.    0.   11.    0.    4.    5.    6.]
 [   0.    0.   12.    1.  956.    0.    6.    7.   11.   25.]
 [   0.    0.    1.    8.    0.  858.    7.    0.    5.    4.]
 [   5.    1.    2.    0.    6.    9.  928.    0.    7.    0.]
 [   1.    1.    6.    5.    1.    2.    0.  954.    7.   11.]
 [   1.   14.   14.   13.    3.    4.    3.    2.  897.    3.]
 [   0.    0.    1.    2.   12.    4.    0.   27.   15.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.091832, Accuracy: 0.741000, Test accuracy: 0.739000
Distillation: Epoch : 2, Loss : 1.830827, Accuracy: 0.846000, Test accuracy: 0.849800
Distillation: Epoch : 3, Loss : 1.819233, Accuracy: 0.860000, Test accuracy: 0.870500
Distillation: Epoch : 4, Loss : 1.805493, Accuracy: 0.874000, Test accuracy: 0.878200
Distillation: Epoch : 5, Loss : 1.803522, Accuracy: 0.858000, Test accuracy: 0.884100
Distillation: Epoch : 6, Loss : 1.771245, Accuracy: 0.885000, Test accuracy: 0.885500
Distillation: Epoch : 7, Loss : 1.787663, Accuracy: 0.873000, Test accuracy: 0.888400
Distillation: Epoch : 8, Loss : 1.777702, Accuracy: 0.896000, Test accuracy: 0.888700
Distillation: Epoch : 9, Loss : 1.800997, Accuracy: 0.884000, Test accuracy: 0.892100
Distillation: Epoch : 10, Loss : 1.761753, Accuracy: 0.895000, Test accuracy: 0.893400
Distillation: Epoch : 11, Loss : 1.768745, Accuracy: 0.894000, Test accuracy: 0.893500
Distillation: Epoch : 12, Loss : 1.778859, Accuracy: 0.872000, Test accuracy: 0.893000
Distillation: Epoch : 13, Loss : 1.774080, Accuracy: 0.884000, Test accuracy: 0.895600
Distillation: Epoch : 14, Loss : 1.772889, Accuracy: 0.878000, Test accuracy: 0.894600
Distillation: Epoch : 15, Loss : 1.779886, Accuracy: 0.884000, Test accuracy: 0.893900
Distillation: Epoch : 16, Loss : 1.758729, Accuracy: 0.895000, Test accuracy: 0.894300
Distillation: Epoch : 17, Loss : 1.766728, Accuracy: 0.884000, Test accuracy: 0.896200
Distillation: Epoch : 18, Loss : 1.763877, Accuracy: 0.879000, Test accuracy: 0.896200
Distillation: Epoch : 19, Loss : 1.754833, Accuracy: 0.894000, Test accuracy: 0.897000
Distillation: Epoch : 20, Loss : 1.756048, Accuracy: 0.894000, Test accuracy: 0.897000
Distillation: Epoch : 21, Loss : 1.772890, Accuracy: 0.887000, Test accuracy: 0.897500
Distillation: Epoch : 22, Loss : 1.759262, Accuracy: 0.894000, Test accuracy: 0.899100
Distillation: Epoch : 23, Loss : 1.755039, Accuracy: 0.886000, Test accuracy: 0.900000
Distillation: Epoch : 24, Loss : 1.767859, Accuracy: 0.900000, Test accuracy: 0.901100
Distillation: Epoch : 25, Loss : 1.757899, Accuracy: 0.885000, Test accuracy: 0.902000
Distillation: Epoch : 26, Loss : 1.764051, Accuracy: 0.903000, Test accuracy: 0.902600
Distillation: Epoch : 27, Loss : 1.767589, Accuracy: 0.904000, Test accuracy: 0.903100
Distillation: Epoch : 28, Loss : 1.761327, Accuracy: 0.889000, Test accuracy: 0.903400
Distillation: Epoch : 29, Loss : 1.753386, Accuracy: 0.899000, Test accuracy: 0.904400
Distillation: Epoch : 30, Loss : 1.748971, Accuracy: 0.898000, Test accuracy: 0.904700
Distillation: Epoch : 31, Loss : 1.760889, Accuracy: 0.894000, Test accuracy: 0.904000
Distillation: Epoch : 32, Loss : 1.757782, Accuracy: 0.878000, Test accuracy: 0.903300
Distillation: Epoch : 33, Loss : 1.767139, Accuracy: 0.905000, Test accuracy: 0.903800
Distillation: Epoch : 34, Loss : 1.758991, Accuracy: 0.904000, Test accuracy: 0.904500
Distillation: Epoch : 35, Loss : 1.745851, Accuracy: 0.898000, Test accuracy: 0.905100
Distillation: Epoch : 36, Loss : 1.756500, Accuracy: 0.903000, Test accuracy: 0.904700
Distillation: Epoch : 37, Loss : 1.769318, Accuracy: 0.892000, Test accuracy: 0.906400
Distillation: Epoch : 38, Loss : 1.752991, Accuracy: 0.908000, Test accuracy: 0.905900
Distillation: Epoch : 39, Loss : 1.741455, Accuracy: 0.899000, Test accuracy: 0.907100
Distillation: Epoch : 40, Loss : 1.760637, Accuracy: 0.903000, Test accuracy: 0.906700
Distillation: Epoch : 41, Loss : 1.765569, Accuracy: 0.889000, Test accuracy: 0.905400
Distillation: Epoch : 42, Loss : 1.749099, Accuracy: 0.901000, Test accuracy: 0.906700
Distillation: Epoch : 43, Loss : 1.758125, Accuracy: 0.913000, Test accuracy: 0.906500
Distillation: Epoch : 44, Loss : 1.763819, Accuracy: 0.910000, Test accuracy: 0.906000
Distillation: Epoch : 45, Loss : 1.751988, Accuracy: 0.900000, Test accuracy: 0.907500
Distillation: Epoch : 46, Loss : 1.742943, Accuracy: 0.907000, Test accuracy: 0.907100
Distillation: Epoch : 47, Loss : 1.732022, Accuracy: 0.908000, Test accuracy: 0.906200
Distillation: Epoch : 48, Loss : 1.760594, Accuracy: 0.878000, Test accuracy: 0.906800
Distillation: Epoch : 49, Loss : 1.759737, Accuracy: 0.916000, Test accuracy: 0.908100
Distillation: Epoch : 50, Loss : 1.762460, Accuracy: 0.898000, Test accuracy: 0.909400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9094
Generating confusion matrix for student5
[[ 956.    0.   11.    9.    1.    9.    6.    1.    9.    9.]
 [   0. 1100.   20.    3.    0.    5.    3.   23.   12.    6.]
 [   1.    3.  903.   25.    7.    1.    3.   16.   10.    1.]
 [   2.    3.   12.  901.    1.   27.    0.    7.   12.   13.]
 [   0.    1.   24.    4.  913.    7.    9.   31.   16.   82.]
 [   4.    5.    1.   28.    1.  794.   23.    2.   25.    5.]
 [   9.    5.   14.    4.   15.   15.  911.    1.   11.    0.]
 [   1.    0.   16.   10.    1.    5.    0.  882.    3.   11.]
 [   7.   18.   27.   19.   10.   22.    3.    1.  858.    6.]
 [   0.    0.    4.    7.   33.    7.    0.   64.   18.  876.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.227648, Accuracy: 0.473000, Test accuracy: 0.491700
Distillation: Epoch : 2, Loss : 2.069289, Accuracy: 0.819000, Test accuracy: 0.822400
Distillation: Epoch : 3, Loss : 2.032351, Accuracy: 0.850000, Test accuracy: 0.858600
Distillation: Epoch : 4, Loss : 2.040282, Accuracy: 0.873000, Test accuracy: 0.869000
Distillation: Epoch : 5, Loss : 2.032233, Accuracy: 0.874000, Test accuracy: 0.877500
Distillation: Epoch : 6, Loss : 2.030868, Accuracy: 0.879000, Test accuracy: 0.884500
Distillation: Epoch : 7, Loss : 2.024668, Accuracy: 0.869000, Test accuracy: 0.887800
Distillation: Epoch : 8, Loss : 2.023396, Accuracy: 0.902000, Test accuracy: 0.894600
Distillation: Epoch : 9, Loss : 2.019840, Accuracy: 0.885000, Test accuracy: 0.896300
Distillation: Epoch : 10, Loss : 2.012192, Accuracy: 0.898000, Test accuracy: 0.902400
Distillation: Epoch : 11, Loss : 2.003325, Accuracy: 0.909000, Test accuracy: 0.906400
Distillation: Epoch : 12, Loss : 2.013570, Accuracy: 0.914000, Test accuracy: 0.912200
Distillation: Epoch : 13, Loss : 2.000287, Accuracy: 0.905000, Test accuracy: 0.918100
Distillation: Epoch : 14, Loss : 1.994542, Accuracy: 0.911000, Test accuracy: 0.921300
Distillation: Epoch : 15, Loss : 1.996579, Accuracy: 0.913000, Test accuracy: 0.926700
Distillation: Epoch : 16, Loss : 2.003801, Accuracy: 0.920000, Test accuracy: 0.930800
Distillation: Epoch : 17, Loss : 1.987020, Accuracy: 0.929000, Test accuracy: 0.934600
Distillation: Epoch : 18, Loss : 1.987949, Accuracy: 0.933000, Test accuracy: 0.937700
Distillation: Epoch : 19, Loss : 1.980052, Accuracy: 0.917000, Test accuracy: 0.939900
Distillation: Epoch : 20, Loss : 1.988682, Accuracy: 0.932000, Test accuracy: 0.941700
Distillation: Epoch : 21, Loss : 1.983837, Accuracy: 0.932000, Test accuracy: 0.944100
Distillation: Epoch : 22, Loss : 1.998894, Accuracy: 0.919000, Test accuracy: 0.945600
Distillation: Epoch : 23, Loss : 1.995767, Accuracy: 0.925000, Test accuracy: 0.945700
Distillation: Epoch : 24, Loss : 1.994175, Accuracy: 0.934000, Test accuracy: 0.947100
Distillation: Epoch : 25, Loss : 1.981023, Accuracy: 0.938000, Test accuracy: 0.947400
Distillation: Epoch : 26, Loss : 1.988876, Accuracy: 0.947000, Test accuracy: 0.948900
Distillation: Epoch : 27, Loss : 1.974031, Accuracy: 0.944000, Test accuracy: 0.950100
Distillation: Epoch : 28, Loss : 1.980782, Accuracy: 0.942000, Test accuracy: 0.949700
Distillation: Epoch : 29, Loss : 1.978292, Accuracy: 0.932000, Test accuracy: 0.951400
Distillation: Epoch : 30, Loss : 1.982000, Accuracy: 0.940000, Test accuracy: 0.950700
Distillation: Epoch : 31, Loss : 1.980875, Accuracy: 0.948000, Test accuracy: 0.951700
Distillation: Epoch : 32, Loss : 1.982897, Accuracy: 0.943000, Test accuracy: 0.951800
Distillation: Epoch : 33, Loss : 1.975162, Accuracy: 0.955000, Test accuracy: 0.951800
Distillation: Epoch : 34, Loss : 1.983384, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 35, Loss : 1.974426, Accuracy: 0.950000, Test accuracy: 0.953100
Distillation: Epoch : 36, Loss : 1.972429, Accuracy: 0.938000, Test accuracy: 0.952000
Distillation: Epoch : 37, Loss : 1.980565, Accuracy: 0.953000, Test accuracy: 0.953100
Distillation: Epoch : 38, Loss : 1.987181, Accuracy: 0.938000, Test accuracy: 0.953300
Distillation: Epoch : 39, Loss : 1.962465, Accuracy: 0.956000, Test accuracy: 0.952700
Distillation: Epoch : 40, Loss : 1.978100, Accuracy: 0.956000, Test accuracy: 0.953600
Distillation: Epoch : 41, Loss : 1.982524, Accuracy: 0.953000, Test accuracy: 0.954700
Distillation: Epoch : 42, Loss : 1.972208, Accuracy: 0.947000, Test accuracy: 0.954100
Distillation: Epoch : 43, Loss : 1.989663, Accuracy: 0.938000, Test accuracy: 0.953100
Distillation: Epoch : 44, Loss : 1.980778, Accuracy: 0.952000, Test accuracy: 0.955000
Distillation: Epoch : 45, Loss : 1.976092, Accuracy: 0.953000, Test accuracy: 0.954600
Distillation: Epoch : 46, Loss : 1.969845, Accuracy: 0.956000, Test accuracy: 0.954700
Distillation: Epoch : 47, Loss : 1.966719, Accuracy: 0.955000, Test accuracy: 0.954400
Distillation: Epoch : 48, Loss : 1.982293, Accuracy: 0.950000, Test accuracy: 0.954600
Distillation: Epoch : 49, Loss : 1.976596, Accuracy: 0.951000, Test accuracy: 0.955500
Distillation: Epoch : 50, Loss : 1.980030, Accuracy: 0.945000, Test accuracy: 0.955500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9555
Generating confusion matrix for student5
[[ 971.    0.    6.    0.    1.    1.    7.    2.    9.    6.]
 [   0. 1119.    9.    3.    3.    2.    3.   10.   13.    7.]
 [   0.    4.  990.   15.    3.    1.    1.   20.    9.    1.]
 [   0.    0.    3.  956.    0.    9.    0.    3.    5.    8.]
 [   1.    0.    6.    3.  946.    1.    7.    7.    9.   25.]
 [   0.    0.    1.   11.    0.  856.    6.    1.    6.    5.]
 [   4.    5.    1.    0.    6.    4.  928.    0.    5.    1.]
 [   0.    0.    8.   10.    1.    3.    0.  946.    8.    7.]
 [   3.    7.    8.    7.    4.    8.    6.    5.  895.    1.]
 [   1.    0.    0.    5.   18.    7.    0.   34.   15.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.711971, Accuracy: 0.809000, Test accuracy: 0.822100
Distillation: Epoch : 2, Loss : 0.434715, Accuracy: 0.890000, Test accuracy: 0.892200
Distillation: Epoch : 3, Loss : 0.337961, Accuracy: 0.893000, Test accuracy: 0.914000
Distillation: Epoch : 4, Loss : 0.259718, Accuracy: 0.930000, Test accuracy: 0.924500
Distillation: Epoch : 5, Loss : 0.259955, Accuracy: 0.925000, Test accuracy: 0.934700
Distillation: Epoch : 6, Loss : 0.227686, Accuracy: 0.946000, Test accuracy: 0.938500
Distillation: Epoch : 7, Loss : 0.215053, Accuracy: 0.938000, Test accuracy: 0.944300
Distillation: Epoch : 8, Loss : 0.197455, Accuracy: 0.939000, Test accuracy: 0.949000
Distillation: Epoch : 9, Loss : 0.164751, Accuracy: 0.950000, Test accuracy: 0.954100
Distillation: Epoch : 10, Loss : 0.139935, Accuracy: 0.955000, Test accuracy: 0.956100
Distillation: Epoch : 11, Loss : 0.143920, Accuracy: 0.957000, Test accuracy: 0.960100
Distillation: Epoch : 12, Loss : 0.129248, Accuracy: 0.962000, Test accuracy: 0.961500
Distillation: Epoch : 13, Loss : 0.139000, Accuracy: 0.963000, Test accuracy: 0.964000
Distillation: Epoch : 14, Loss : 0.123884, Accuracy: 0.965000, Test accuracy: 0.965000
Distillation: Epoch : 15, Loss : 0.145367, Accuracy: 0.962000, Test accuracy: 0.966900
Distillation: Epoch : 16, Loss : 0.120219, Accuracy: 0.960000, Test accuracy: 0.967000
Distillation: Epoch : 17, Loss : 0.101708, Accuracy: 0.973000, Test accuracy: 0.968600
Distillation: Epoch : 18, Loss : 0.102668, Accuracy: 0.964000, Test accuracy: 0.968800
Distillation: Epoch : 19, Loss : 0.091943, Accuracy: 0.969000, Test accuracy: 0.970500
Distillation: Epoch : 20, Loss : 0.093075, Accuracy: 0.971000, Test accuracy: 0.969600
Distillation: Epoch : 21, Loss : 0.089274, Accuracy: 0.969000, Test accuracy: 0.970000
Distillation: Epoch : 22, Loss : 0.107044, Accuracy: 0.974000, Test accuracy: 0.970300
Distillation: Epoch : 23, Loss : 0.101527, Accuracy: 0.973000, Test accuracy: 0.972600
Distillation: Epoch : 24, Loss : 0.107490, Accuracy: 0.967000, Test accuracy: 0.973000
Distillation: Epoch : 25, Loss : 0.096168, Accuracy: 0.975000, Test accuracy: 0.974200
Distillation: Epoch : 26, Loss : 0.091868, Accuracy: 0.972000, Test accuracy: 0.973200
Distillation: Epoch : 27, Loss : 0.097340, Accuracy: 0.977000, Test accuracy: 0.973500
Distillation: Epoch : 28, Loss : 0.079709, Accuracy: 0.974000, Test accuracy: 0.973200
Distillation: Epoch : 29, Loss : 0.087456, Accuracy: 0.969000, Test accuracy: 0.974700
Distillation: Epoch : 30, Loss : 0.085328, Accuracy: 0.977000, Test accuracy: 0.973900
Distillation: Epoch : 31, Loss : 0.087729, Accuracy: 0.977000, Test accuracy: 0.974500
Distillation: Epoch : 32, Loss : 0.076785, Accuracy: 0.986000, Test accuracy: 0.975100
Distillation: Epoch : 33, Loss : 0.063369, Accuracy: 0.981000, Test accuracy: 0.974900
Distillation: Epoch : 34, Loss : 0.069936, Accuracy: 0.981000, Test accuracy: 0.975800
Distillation: Epoch : 35, Loss : 0.097767, Accuracy: 0.976000, Test accuracy: 0.974200
Distillation: Epoch : 36, Loss : 0.071745, Accuracy: 0.978000, Test accuracy: 0.976400
Distillation: Epoch : 37, Loss : 0.060477, Accuracy: 0.978000, Test accuracy: 0.976300
Distillation: Epoch : 38, Loss : 0.062244, Accuracy: 0.979000, Test accuracy: 0.977500
Distillation: Epoch : 39, Loss : 0.071262, Accuracy: 0.983000, Test accuracy: 0.975200
Distillation: Epoch : 40, Loss : 0.077049, Accuracy: 0.979000, Test accuracy: 0.977000
Distillation: Epoch : 41, Loss : 0.068910, Accuracy: 0.979000, Test accuracy: 0.976700
Distillation: Epoch : 42, Loss : 0.073204, Accuracy: 0.977000, Test accuracy: 0.976200
Distillation: Epoch : 43, Loss : 0.065261, Accuracy: 0.978000, Test accuracy: 0.977800
Distillation: Epoch : 44, Loss : 0.076063, Accuracy: 0.976000, Test accuracy: 0.977900
Distillation: Epoch : 45, Loss : 0.060668, Accuracy: 0.976000, Test accuracy: 0.976500
Distillation: Epoch : 46, Loss : 0.061462, Accuracy: 0.979000, Test accuracy: 0.978700
Distillation: Epoch : 47, Loss : 0.074864, Accuracy: 0.976000, Test accuracy: 0.978600
Distillation: Epoch : 48, Loss : 0.057134, Accuracy: 0.979000, Test accuracy: 0.977500
Distillation: Epoch : 49, Loss : 0.058370, Accuracy: 0.982000, Test accuracy: 0.978300
Distillation: Epoch : 50, Loss : 0.059119, Accuracy: 0.981000, Test accuracy: 0.978300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9783
Generating confusion matrix for student
[[ 974.    1.    6.    1.    2.    2.    6.    1.    6.    4.]
 [   0. 1122.    4.    0.    0.    0.    3.    4.    0.    5.]
 [   0.    3. 1006.    2.    4.    1.    1.   16.    7.    2.]
 [   0.    0.    3.  992.    1.    5.    1.    2.    3.    4.]
 [   0.    0.    2.    1.  965.    0.    4.    2.    2.    2.]
 [   0.    0.    0.    3.    0.  877.    1.    0.    1.    9.]
 [   1.    1.    0.    0.    1.    3.  937.    0.    2.    1.]
 [   1.    0.    2.    3.    1.    1.    0.  993.    1.    5.]
 [   4.    8.    9.    6.    4.    2.    5.    3.  948.    8.]
 [   0.    0.    0.    2.    4.    1.    0.    7.    4.  969.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.102609, Accuracy: 0.715000, Test accuracy: 0.770600
Distillation: Epoch : 2, Loss : 0.482592, Accuracy: 0.851000, Test accuracy: 0.870100
Distillation: Epoch : 3, Loss : 0.398160, Accuracy: 0.889000, Test accuracy: 0.895400
Distillation: Epoch : 4, Loss : 0.357224, Accuracy: 0.900000, Test accuracy: 0.907100
Distillation: Epoch : 5, Loss : 0.320524, Accuracy: 0.908000, Test accuracy: 0.913000
Distillation: Epoch : 6, Loss : 0.301542, Accuracy: 0.902000, Test accuracy: 0.920800
Distillation: Epoch : 7, Loss : 0.301547, Accuracy: 0.912000, Test accuracy: 0.928500
Distillation: Epoch : 8, Loss : 0.240159, Accuracy: 0.931000, Test accuracy: 0.932100
Distillation: Epoch : 9, Loss : 0.282262, Accuracy: 0.925000, Test accuracy: 0.936500
Distillation: Epoch : 10, Loss : 0.219636, Accuracy: 0.942000, Test accuracy: 0.941600
Distillation: Epoch : 11, Loss : 0.201125, Accuracy: 0.946000, Test accuracy: 0.944900
Distillation: Epoch : 12, Loss : 0.199533, Accuracy: 0.941000, Test accuracy: 0.948300
Distillation: Epoch : 13, Loss : 0.203594, Accuracy: 0.941000, Test accuracy: 0.952400
Distillation: Epoch : 14, Loss : 0.159220, Accuracy: 0.962000, Test accuracy: 0.953400
Distillation: Epoch : 15, Loss : 0.188410, Accuracy: 0.953000, Test accuracy: 0.957200
Distillation: Epoch : 16, Loss : 0.170479, Accuracy: 0.952000, Test accuracy: 0.958200
Distillation: Epoch : 17, Loss : 0.164675, Accuracy: 0.957000, Test accuracy: 0.961600
Distillation: Epoch : 18, Loss : 0.164767, Accuracy: 0.963000, Test accuracy: 0.963800
Distillation: Epoch : 19, Loss : 0.150895, Accuracy: 0.958000, Test accuracy: 0.965700
Distillation: Epoch : 20, Loss : 0.111439, Accuracy: 0.973000, Test accuracy: 0.967800
Distillation: Epoch : 21, Loss : 0.144803, Accuracy: 0.964000, Test accuracy: 0.968500
Distillation: Epoch : 22, Loss : 0.113081, Accuracy: 0.974000, Test accuracy: 0.969600
Distillation: Epoch : 23, Loss : 0.154066, Accuracy: 0.960000, Test accuracy: 0.971400
Distillation: Epoch : 24, Loss : 0.112149, Accuracy: 0.970000, Test accuracy: 0.972100
Distillation: Epoch : 25, Loss : 0.132546, Accuracy: 0.973000, Test accuracy: 0.973900
Distillation: Epoch : 26, Loss : 0.117604, Accuracy: 0.971000, Test accuracy: 0.972400
Distillation: Epoch : 27, Loss : 0.114430, Accuracy: 0.976000, Test accuracy: 0.975000
Distillation: Epoch : 28, Loss : 0.121289, Accuracy: 0.971000, Test accuracy: 0.975600
Distillation: Epoch : 29, Loss : 0.115372, Accuracy: 0.974000, Test accuracy: 0.976200
Distillation: Epoch : 30, Loss : 0.104574, Accuracy: 0.970000, Test accuracy: 0.977000
Distillation: Epoch : 31, Loss : 0.103521, Accuracy: 0.978000, Test accuracy: 0.977700
Distillation: Epoch : 32, Loss : 0.103986, Accuracy: 0.975000, Test accuracy: 0.978100
Distillation: Epoch : 33, Loss : 0.122124, Accuracy: 0.971000, Test accuracy: 0.976300
Distillation: Epoch : 34, Loss : 0.106233, Accuracy: 0.975000, Test accuracy: 0.976700
Distillation: Epoch : 35, Loss : 0.091025, Accuracy: 0.982000, Test accuracy: 0.977700
Distillation: Epoch : 36, Loss : 0.109634, Accuracy: 0.977000, Test accuracy: 0.977700
Distillation: Epoch : 37, Loss : 0.095259, Accuracy: 0.984000, Test accuracy: 0.978400
Distillation: Epoch : 38, Loss : 0.102844, Accuracy: 0.978000, Test accuracy: 0.979100
Distillation: Epoch : 39, Loss : 0.085218, Accuracy: 0.981000, Test accuracy: 0.978600
Distillation: Epoch : 40, Loss : 0.109564, Accuracy: 0.973000, Test accuracy: 0.978800
Distillation: Epoch : 41, Loss : 0.073013, Accuracy: 0.983000, Test accuracy: 0.979200
Distillation: Epoch : 42, Loss : 0.102327, Accuracy: 0.978000, Test accuracy: 0.979700
Distillation: Epoch : 43, Loss : 0.080955, Accuracy: 0.983000, Test accuracy: 0.980700
Distillation: Epoch : 44, Loss : 0.094818, Accuracy: 0.979000, Test accuracy: 0.980700
Distillation: Epoch : 45, Loss : 0.074520, Accuracy: 0.986000, Test accuracy: 0.980000
Distillation: Epoch : 46, Loss : 0.079552, Accuracy: 0.981000, Test accuracy: 0.980600
Distillation: Epoch : 47, Loss : 0.092245, Accuracy: 0.981000, Test accuracy: 0.980700
Distillation: Epoch : 48, Loss : 0.100217, Accuracy: 0.975000, Test accuracy: 0.981100
Distillation: Epoch : 49, Loss : 0.079175, Accuracy: 0.983000, Test accuracy: 0.981100
Distillation: Epoch : 50, Loss : 0.107224, Accuracy: 0.978000, Test accuracy: 0.981500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9815
Generating confusion matrix for student
[[ 974.    0.    4.    0.    1.    2.    3.    1.    3.    4.]
 [   0. 1126.    4.    0.    0.    0.    1.    5.    2.    7.]
 [   0.    2. 1016.    2.    1.    1.    0.   13.    6.    0.]
 [   0.    2.    2. 1000.    0.    7.    0.    5.    6.    5.]
 [   0.    1.    0.    1.  970.    0.    3.    0.    2.    9.]
 [   1.    1.    0.    4.    0.  878.    5.    0.    3.    3.]
 [   1.    1.    0.    0.    1.    1.  942.    0.    1.    0.]
 [   1.    0.    3.    1.    0.    1.    0.  992.    2.    7.]
 [   3.    2.    3.    2.    2.    2.    4.    3.  944.    1.]
 [   0.    0.    0.    0.    7.    0.    0.    9.    5.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.137511, Accuracy: 0.806000, Test accuracy: 0.811200
Distillation: Epoch : 2, Loss : 0.729630, Accuracy: 0.861000, Test accuracy: 0.878300
Distillation: Epoch : 3, Loss : 0.633419, Accuracy: 0.882000, Test accuracy: 0.902400
Distillation: Epoch : 4, Loss : 0.581090, Accuracy: 0.916000, Test accuracy: 0.914300
Distillation: Epoch : 5, Loss : 0.561378, Accuracy: 0.919000, Test accuracy: 0.921800
Distillation: Epoch : 6, Loss : 0.560904, Accuracy: 0.935000, Test accuracy: 0.929700
Distillation: Epoch : 7, Loss : 0.525703, Accuracy: 0.942000, Test accuracy: 0.934600
Distillation: Epoch : 8, Loss : 0.531677, Accuracy: 0.934000, Test accuracy: 0.938400
Distillation: Epoch : 9, Loss : 0.520231, Accuracy: 0.947000, Test accuracy: 0.941500
Distillation: Epoch : 10, Loss : 0.516242, Accuracy: 0.943000, Test accuracy: 0.945900
Distillation: Epoch : 11, Loss : 0.483301, Accuracy: 0.951000, Test accuracy: 0.948900
Distillation: Epoch : 12, Loss : 0.483555, Accuracy: 0.947000, Test accuracy: 0.952200
Distillation: Epoch : 13, Loss : 0.467030, Accuracy: 0.951000, Test accuracy: 0.955000
Distillation: Epoch : 14, Loss : 0.478507, Accuracy: 0.954000, Test accuracy: 0.956600
Distillation: Epoch : 15, Loss : 0.502247, Accuracy: 0.938000, Test accuracy: 0.958900
Distillation: Epoch : 16, Loss : 0.455729, Accuracy: 0.955000, Test accuracy: 0.959600
Distillation: Epoch : 17, Loss : 0.475821, Accuracy: 0.944000, Test accuracy: 0.960700
Distillation: Epoch : 18, Loss : 0.431849, Accuracy: 0.962000, Test accuracy: 0.963600
Distillation: Epoch : 19, Loss : 0.459197, Accuracy: 0.970000, Test accuracy: 0.964500
Distillation: Epoch : 20, Loss : 0.433980, Accuracy: 0.962000, Test accuracy: 0.966000
Distillation: Epoch : 21, Loss : 0.413639, Accuracy: 0.971000, Test accuracy: 0.966200
Distillation: Epoch : 22, Loss : 0.435660, Accuracy: 0.962000, Test accuracy: 0.966400
Distillation: Epoch : 23, Loss : 0.448133, Accuracy: 0.964000, Test accuracy: 0.968600
Distillation: Epoch : 24, Loss : 0.430188, Accuracy: 0.973000, Test accuracy: 0.968400
Distillation: Epoch : 25, Loss : 0.439775, Accuracy: 0.966000, Test accuracy: 0.969900
Distillation: Epoch : 26, Loss : 0.443273, Accuracy: 0.962000, Test accuracy: 0.970900
Distillation: Epoch : 27, Loss : 0.433728, Accuracy: 0.967000, Test accuracy: 0.971500
Distillation: Epoch : 28, Loss : 0.397343, Accuracy: 0.972000, Test accuracy: 0.972400
Distillation: Epoch : 29, Loss : 0.412864, Accuracy: 0.975000, Test accuracy: 0.972600
Distillation: Epoch : 30, Loss : 0.427893, Accuracy: 0.964000, Test accuracy: 0.972100
Distillation: Epoch : 31, Loss : 0.434454, Accuracy: 0.966000, Test accuracy: 0.973300
Distillation: Epoch : 32, Loss : 0.420002, Accuracy: 0.974000, Test accuracy: 0.973200
Distillation: Epoch : 33, Loss : 0.411255, Accuracy: 0.975000, Test accuracy: 0.973200
Distillation: Epoch : 34, Loss : 0.418037, Accuracy: 0.973000, Test accuracy: 0.973100
Distillation: Epoch : 35, Loss : 0.424078, Accuracy: 0.962000, Test accuracy: 0.973900
Distillation: Epoch : 36, Loss : 0.426658, Accuracy: 0.970000, Test accuracy: 0.975900
Distillation: Epoch : 37, Loss : 0.447091, Accuracy: 0.963000, Test accuracy: 0.976000
Distillation: Epoch : 38, Loss : 0.433998, Accuracy: 0.968000, Test accuracy: 0.975500
Distillation: Epoch : 39, Loss : 0.413359, Accuracy: 0.971000, Test accuracy: 0.975000
Distillation: Epoch : 40, Loss : 0.401284, Accuracy: 0.977000, Test accuracy: 0.976500
Distillation: Epoch : 41, Loss : 0.408051, Accuracy: 0.970000, Test accuracy: 0.976600
Distillation: Epoch : 42, Loss : 0.394633, Accuracy: 0.976000, Test accuracy: 0.976100
Distillation: Epoch : 43, Loss : 0.426795, Accuracy: 0.972000, Test accuracy: 0.977400
Distillation: Epoch : 44, Loss : 0.407886, Accuracy: 0.979000, Test accuracy: 0.978100
Distillation: Epoch : 45, Loss : 0.422776, Accuracy: 0.964000, Test accuracy: 0.977600
Distillation: Epoch : 46, Loss : 0.415378, Accuracy: 0.974000, Test accuracy: 0.978600
Distillation: Epoch : 47, Loss : 0.433529, Accuracy: 0.968000, Test accuracy: 0.978300
Distillation: Epoch : 48, Loss : 0.456830, Accuracy: 0.974000, Test accuracy: 0.977800
Distillation: Epoch : 49, Loss : 0.391669, Accuracy: 0.976000, Test accuracy: 0.978000
Distillation: Epoch : 50, Loss : 0.438491, Accuracy: 0.971000, Test accuracy: 0.979500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9795
Generating confusion matrix for student
[[ 970.    0.    2.    0.    1.    1.    3.    2.    4.    5.]
 [   0. 1127.    2.    0.    1.    0.    3.    5.    0.    6.]
 [   1.    3. 1016.    6.    1.    1.    0.   21.    5.    1.]
 [   0.    1.    4.  987.    0.    4.    1.    1.    4.    2.]
 [   1.    1.    1.    0.  970.    1.    5.    2.    3.   11.]
 [   0.    0.    0.    4.    0.  879.    3.    0.    3.    3.]
 [   4.    0.    1.    0.    0.    4.  941.    0.    0.    0.]
 [   1.    1.    3.    5.    0.    1.    0.  988.    2.    6.]
 [   3.    2.    3.    7.    2.    1.    2.    1.  944.    2.]
 [   0.    0.    0.    1.    7.    0.    0.    8.    9.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.157308, Accuracy: 0.812000, Test accuracy: 0.833800
Distillation: Epoch : 2, Loss : 0.821958, Accuracy: 0.890000, Test accuracy: 0.891200
Distillation: Epoch : 3, Loss : 0.740636, Accuracy: 0.911000, Test accuracy: 0.910600
Distillation: Epoch : 4, Loss : 0.752325, Accuracy: 0.912000, Test accuracy: 0.920800
Distillation: Epoch : 5, Loss : 0.712455, Accuracy: 0.922000, Test accuracy: 0.930900
Distillation: Epoch : 6, Loss : 0.688293, Accuracy: 0.941000, Test accuracy: 0.937300
Distillation: Epoch : 7, Loss : 0.695198, Accuracy: 0.941000, Test accuracy: 0.942800
Distillation: Epoch : 8, Loss : 0.658953, Accuracy: 0.935000, Test accuracy: 0.946700
Distillation: Epoch : 9, Loss : 0.653633, Accuracy: 0.947000, Test accuracy: 0.951300
Distillation: Epoch : 10, Loss : 0.645684, Accuracy: 0.945000, Test accuracy: 0.953800
Distillation: Epoch : 11, Loss : 0.643809, Accuracy: 0.942000, Test accuracy: 0.956700
Distillation: Epoch : 12, Loss : 0.660657, Accuracy: 0.942000, Test accuracy: 0.958200
Distillation: Epoch : 13, Loss : 0.621017, Accuracy: 0.958000, Test accuracy: 0.958800
Distillation: Epoch : 14, Loss : 0.607581, Accuracy: 0.964000, Test accuracy: 0.961600
Distillation: Epoch : 15, Loss : 0.643268, Accuracy: 0.959000, Test accuracy: 0.963200
Distillation: Epoch : 16, Loss : 0.620068, Accuracy: 0.956000, Test accuracy: 0.964300
Distillation: Epoch : 17, Loss : 0.631735, Accuracy: 0.958000, Test accuracy: 0.965500
Distillation: Epoch : 18, Loss : 0.617163, Accuracy: 0.957000, Test accuracy: 0.966000
Distillation: Epoch : 19, Loss : 0.609858, Accuracy: 0.959000, Test accuracy: 0.966900
Distillation: Epoch : 20, Loss : 0.626384, Accuracy: 0.962000, Test accuracy: 0.968000
Distillation: Epoch : 21, Loss : 0.609162, Accuracy: 0.966000, Test accuracy: 0.969200
Distillation: Epoch : 22, Loss : 0.601007, Accuracy: 0.967000, Test accuracy: 0.969700
Distillation: Epoch : 23, Loss : 0.611904, Accuracy: 0.975000, Test accuracy: 0.971000
Distillation: Epoch : 24, Loss : 0.581867, Accuracy: 0.966000, Test accuracy: 0.970900
Distillation: Epoch : 25, Loss : 0.614682, Accuracy: 0.968000, Test accuracy: 0.972500
Distillation: Epoch : 26, Loss : 0.574647, Accuracy: 0.974000, Test accuracy: 0.972500
Distillation: Epoch : 27, Loss : 0.581555, Accuracy: 0.975000, Test accuracy: 0.972900
Distillation: Epoch : 28, Loss : 0.603249, Accuracy: 0.967000, Test accuracy: 0.973700
Distillation: Epoch : 29, Loss : 0.572073, Accuracy: 0.971000, Test accuracy: 0.974600
Distillation: Epoch : 30, Loss : 0.588389, Accuracy: 0.977000, Test accuracy: 0.974400
Distillation: Epoch : 31, Loss : 0.580633, Accuracy: 0.967000, Test accuracy: 0.974700
Distillation: Epoch : 32, Loss : 0.577746, Accuracy: 0.963000, Test accuracy: 0.975100
Distillation: Epoch : 33, Loss : 0.590337, Accuracy: 0.973000, Test accuracy: 0.976400
Distillation: Epoch : 34, Loss : 0.569843, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 35, Loss : 0.596626, Accuracy: 0.975000, Test accuracy: 0.976100
Distillation: Epoch : 36, Loss : 0.589142, Accuracy: 0.966000, Test accuracy: 0.977200
Distillation: Epoch : 37, Loss : 0.578806, Accuracy: 0.975000, Test accuracy: 0.976000
Distillation: Epoch : 38, Loss : 0.597538, Accuracy: 0.973000, Test accuracy: 0.976900
Distillation: Epoch : 39, Loss : 0.551018, Accuracy: 0.988000, Test accuracy: 0.977600
Distillation: Epoch : 40, Loss : 0.599267, Accuracy: 0.967000, Test accuracy: 0.977600
Distillation: Epoch : 41, Loss : 0.579476, Accuracy: 0.972000, Test accuracy: 0.979000
Distillation: Epoch : 42, Loss : 0.585913, Accuracy: 0.976000, Test accuracy: 0.978400
Distillation: Epoch : 43, Loss : 0.591751, Accuracy: 0.971000, Test accuracy: 0.979100
Distillation: Epoch : 44, Loss : 0.585240, Accuracy: 0.976000, Test accuracy: 0.979000
Distillation: Epoch : 45, Loss : 0.571625, Accuracy: 0.966000, Test accuracy: 0.979000
Distillation: Epoch : 46, Loss : 0.589426, Accuracy: 0.975000, Test accuracy: 0.979200
Distillation: Epoch : 47, Loss : 0.590196, Accuracy: 0.972000, Test accuracy: 0.979600
Distillation: Epoch : 48, Loss : 0.574246, Accuracy: 0.973000, Test accuracy: 0.980100
Distillation: Epoch : 49, Loss : 0.571453, Accuracy: 0.981000, Test accuracy: 0.980400
Distillation: Epoch : 50, Loss : 0.610844, Accuracy: 0.986000, Test accuracy: 0.981100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9811
Generating confusion matrix for student
[[ 972.    0.    6.    0.    1.    1.    4.    2.    4.    4.]
 [   0. 1128.    3.    1.    0.    0.    2.    4.    0.    7.]
 [   1.    2. 1010.    2.    3.    0.    0.   12.    3.    0.]
 [   0.    2.    1.  987.    0.    2.    0.    3.    2.    2.]
 [   0.    0.    1.    0.  966.    0.    2.    3.    4.    8.]
 [   0.    0.    0.    7.    0.  882.    4.    1.    0.    3.]
 [   4.    1.    0.    0.    1.    2.  943.    0.    2.    1.]
 [   0.    0.    4.    5.    0.    0.    0.  993.    1.    2.]
 [   2.    2.    7.    7.    2.    3.    3.    1.  951.    3.]
 [   1.    0.    0.    1.    9.    2.    0.    9.    7.  979.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.914139, Accuracy: 0.609000, Test accuracy: 0.636500
Distillation: Epoch : 2, Loss : 1.183566, Accuracy: 0.797000, Test accuracy: 0.823500
Distillation: Epoch : 3, Loss : 0.999832, Accuracy: 0.868000, Test accuracy: 0.880700
Distillation: Epoch : 4, Loss : 0.918426, Accuracy: 0.899000, Test accuracy: 0.903300
Distillation: Epoch : 5, Loss : 0.897421, Accuracy: 0.909000, Test accuracy: 0.921600
Distillation: Epoch : 6, Loss : 0.861924, Accuracy: 0.926000, Test accuracy: 0.931000
Distillation: Epoch : 7, Loss : 0.831489, Accuracy: 0.944000, Test accuracy: 0.940300
Distillation: Epoch : 8, Loss : 0.814072, Accuracy: 0.946000, Test accuracy: 0.947100
Distillation: Epoch : 9, Loss : 0.805085, Accuracy: 0.942000, Test accuracy: 0.951500
Distillation: Epoch : 10, Loss : 0.803333, Accuracy: 0.952000, Test accuracy: 0.954700
Distillation: Epoch : 11, Loss : 0.823143, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 12, Loss : 0.824441, Accuracy: 0.959000, Test accuracy: 0.962800
Distillation: Epoch : 13, Loss : 0.813216, Accuracy: 0.953000, Test accuracy: 0.965200
Distillation: Epoch : 14, Loss : 0.783461, Accuracy: 0.962000, Test accuracy: 0.967200
Distillation: Epoch : 15, Loss : 0.799549, Accuracy: 0.954000, Test accuracy: 0.969200
Distillation: Epoch : 16, Loss : 0.781444, Accuracy: 0.965000, Test accuracy: 0.970300
Distillation: Epoch : 17, Loss : 0.745334, Accuracy: 0.966000, Test accuracy: 0.971900
Distillation: Epoch : 18, Loss : 0.758324, Accuracy: 0.969000, Test accuracy: 0.972700
Distillation: Epoch : 19, Loss : 0.776785, Accuracy: 0.974000, Test accuracy: 0.972900
Distillation: Epoch : 20, Loss : 0.763717, Accuracy: 0.968000, Test accuracy: 0.972800
Distillation: Epoch : 21, Loss : 0.768449, Accuracy: 0.969000, Test accuracy: 0.973600
Distillation: Epoch : 22, Loss : 0.765474, Accuracy: 0.970000, Test accuracy: 0.974300
Distillation: Epoch : 23, Loss : 0.782922, Accuracy: 0.970000, Test accuracy: 0.974800
Distillation: Epoch : 24, Loss : 0.761816, Accuracy: 0.970000, Test accuracy: 0.975500
Distillation: Epoch : 25, Loss : 0.764526, Accuracy: 0.970000, Test accuracy: 0.975800
Distillation: Epoch : 26, Loss : 0.757512, Accuracy: 0.969000, Test accuracy: 0.975600
Distillation: Epoch : 27, Loss : 0.755636, Accuracy: 0.970000, Test accuracy: 0.976300
Distillation: Epoch : 28, Loss : 0.757594, Accuracy: 0.967000, Test accuracy: 0.976700
Distillation: Epoch : 29, Loss : 0.784188, Accuracy: 0.963000, Test accuracy: 0.976200
Distillation: Epoch : 30, Loss : 0.747793, Accuracy: 0.976000, Test accuracy: 0.976900
Distillation: Epoch : 31, Loss : 0.758871, Accuracy: 0.967000, Test accuracy: 0.977800
Distillation: Epoch : 32, Loss : 0.740074, Accuracy: 0.982000, Test accuracy: 0.977300
Distillation: Epoch : 33, Loss : 0.755400, Accuracy: 0.969000, Test accuracy: 0.977700
Distillation: Epoch : 34, Loss : 0.775102, Accuracy: 0.973000, Test accuracy: 0.978200
Distillation: Epoch : 35, Loss : 0.752505, Accuracy: 0.971000, Test accuracy: 0.977900
Distillation: Epoch : 36, Loss : 0.734918, Accuracy: 0.974000, Test accuracy: 0.978600
Distillation: Epoch : 37, Loss : 0.748479, Accuracy: 0.981000, Test accuracy: 0.979700
Distillation: Epoch : 38, Loss : 0.761071, Accuracy: 0.984000, Test accuracy: 0.979800
Distillation: Epoch : 39, Loss : 0.757981, Accuracy: 0.975000, Test accuracy: 0.979200
Distillation: Epoch : 40, Loss : 0.735040, Accuracy: 0.978000, Test accuracy: 0.980200
Distillation: Epoch : 41, Loss : 0.750937, Accuracy: 0.979000, Test accuracy: 0.980500
Distillation: Epoch : 42, Loss : 0.746696, Accuracy: 0.977000, Test accuracy: 0.980200
Distillation: Epoch : 43, Loss : 0.763840, Accuracy: 0.977000, Test accuracy: 0.980500
Distillation: Epoch : 44, Loss : 0.744924, Accuracy: 0.981000, Test accuracy: 0.980500
Distillation: Epoch : 45, Loss : 0.761648, Accuracy: 0.974000, Test accuracy: 0.980400
Distillation: Epoch : 46, Loss : 0.768073, Accuracy: 0.971000, Test accuracy: 0.981500
Distillation: Epoch : 47, Loss : 0.751381, Accuracy: 0.972000, Test accuracy: 0.981000
Distillation: Epoch : 48, Loss : 0.747957, Accuracy: 0.981000, Test accuracy: 0.980900
Distillation: Epoch : 49, Loss : 0.748746, Accuracy: 0.980000, Test accuracy: 0.981500
Distillation: Epoch : 50, Loss : 0.726314, Accuracy: 0.980000, Test accuracy: 0.980800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9808
Generating confusion matrix for student
[[ 973.    0.    5.    0.    2.    1.    5.    0.    7.    6.]
 [   0. 1128.    0.    0.    0.    0.    2.    5.    0.    7.]
 [   0.    3. 1019.    4.    2.    0.    0.   12.    8.    0.]
 [   0.    1.    1.  985.    0.    4.    0.    1.    2.    0.]
 [   1.    0.    2.    0.  956.    0.    1.    1.    5.    3.]
 [   1.    0.    1.    7.    0.  881.    2.    1.    2.    5.]
 [   4.    1.    0.    0.    4.    4.  945.    0.    1.    0.]
 [   0.    0.    2.    6.    0.    0.    0.  999.    3.    3.]
 [   0.    2.    2.    3.    2.    1.    3.    1.  938.    1.]
 [   1.    0.    0.    5.   16.    1.    0.    8.    8.  984.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.445029, Accuracy: 0.785000, Test accuracy: 0.794200
Distillation: Epoch : 2, Loss : 1.182749, Accuracy: 0.859000, Test accuracy: 0.867100
Distillation: Epoch : 3, Loss : 1.123387, Accuracy: 0.871000, Test accuracy: 0.890300
Distillation: Epoch : 4, Loss : 1.121769, Accuracy: 0.903000, Test accuracy: 0.903700
Distillation: Epoch : 5, Loss : 1.080818, Accuracy: 0.903000, Test accuracy: 0.912000
Distillation: Epoch : 6, Loss : 1.067138, Accuracy: 0.894000, Test accuracy: 0.920500
Distillation: Epoch : 7, Loss : 1.063406, Accuracy: 0.921000, Test accuracy: 0.928600
Distillation: Epoch : 8, Loss : 1.020428, Accuracy: 0.929000, Test accuracy: 0.934200
Distillation: Epoch : 9, Loss : 1.002421, Accuracy: 0.933000, Test accuracy: 0.941100
Distillation: Epoch : 10, Loss : 1.011921, Accuracy: 0.938000, Test accuracy: 0.944700
Distillation: Epoch : 11, Loss : 0.992593, Accuracy: 0.942000, Test accuracy: 0.948500
Distillation: Epoch : 12, Loss : 0.982725, Accuracy: 0.953000, Test accuracy: 0.951800
Distillation: Epoch : 13, Loss : 0.987891, Accuracy: 0.954000, Test accuracy: 0.953900
Distillation: Epoch : 14, Loss : 0.963410, Accuracy: 0.962000, Test accuracy: 0.956100
Distillation: Epoch : 15, Loss : 0.977222, Accuracy: 0.963000, Test accuracy: 0.957400
Distillation: Epoch : 16, Loss : 0.985322, Accuracy: 0.941000, Test accuracy: 0.959500
Distillation: Epoch : 17, Loss : 0.950921, Accuracy: 0.962000, Test accuracy: 0.960200
Distillation: Epoch : 18, Loss : 0.982829, Accuracy: 0.958000, Test accuracy: 0.961900
Distillation: Epoch : 19, Loss : 0.968420, Accuracy: 0.960000, Test accuracy: 0.962900
Distillation: Epoch : 20, Loss : 0.957235, Accuracy: 0.955000, Test accuracy: 0.964300
Distillation: Epoch : 21, Loss : 0.984769, Accuracy: 0.936000, Test accuracy: 0.964800
Distillation: Epoch : 22, Loss : 0.940450, Accuracy: 0.967000, Test accuracy: 0.966500
Distillation: Epoch : 23, Loss : 0.946540, Accuracy: 0.964000, Test accuracy: 0.967600
Distillation: Epoch : 24, Loss : 0.946138, Accuracy: 0.961000, Test accuracy: 0.966800
Distillation: Epoch : 25, Loss : 0.964894, Accuracy: 0.959000, Test accuracy: 0.968000
Distillation: Epoch : 26, Loss : 0.951680, Accuracy: 0.966000, Test accuracy: 0.970000
Distillation: Epoch : 27, Loss : 0.958211, Accuracy: 0.967000, Test accuracy: 0.969400
Distillation: Epoch : 28, Loss : 0.961189, Accuracy: 0.971000, Test accuracy: 0.970700
Distillation: Epoch : 29, Loss : 0.950819, Accuracy: 0.964000, Test accuracy: 0.971900
Distillation: Epoch : 30, Loss : 0.941201, Accuracy: 0.972000, Test accuracy: 0.970300
Distillation: Epoch : 31, Loss : 0.925921, Accuracy: 0.971000, Test accuracy: 0.972200
Distillation: Epoch : 32, Loss : 0.938222, Accuracy: 0.972000, Test accuracy: 0.972200
Distillation: Epoch : 33, Loss : 0.935587, Accuracy: 0.966000, Test accuracy: 0.972400
Distillation: Epoch : 34, Loss : 0.910570, Accuracy: 0.974000, Test accuracy: 0.972700
Distillation: Epoch : 35, Loss : 0.909646, Accuracy: 0.977000, Test accuracy: 0.972100
Distillation: Epoch : 36, Loss : 0.955032, Accuracy: 0.966000, Test accuracy: 0.973400
Distillation: Epoch : 37, Loss : 0.934075, Accuracy: 0.967000, Test accuracy: 0.973000
Distillation: Epoch : 38, Loss : 0.970595, Accuracy: 0.970000, Test accuracy: 0.973200
Distillation: Epoch : 39, Loss : 0.937327, Accuracy: 0.967000, Test accuracy: 0.973400
Distillation: Epoch : 40, Loss : 0.926890, Accuracy: 0.968000, Test accuracy: 0.973400
Distillation: Epoch : 41, Loss : 0.941502, Accuracy: 0.974000, Test accuracy: 0.973600
Distillation: Epoch : 42, Loss : 0.945230, Accuracy: 0.965000, Test accuracy: 0.974900
Distillation: Epoch : 43, Loss : 0.939723, Accuracy: 0.964000, Test accuracy: 0.974300
Distillation: Epoch : 44, Loss : 0.897383, Accuracy: 0.983000, Test accuracy: 0.976400
Distillation: Epoch : 45, Loss : 0.915627, Accuracy: 0.968000, Test accuracy: 0.976400
Distillation: Epoch : 46, Loss : 0.929299, Accuracy: 0.970000, Test accuracy: 0.975600
Distillation: Epoch : 47, Loss : 0.937458, Accuracy: 0.968000, Test accuracy: 0.976800
Distillation: Epoch : 48, Loss : 0.900096, Accuracy: 0.979000, Test accuracy: 0.976600
Distillation: Epoch : 49, Loss : 0.934503, Accuracy: 0.979000, Test accuracy: 0.976400
Distillation: Epoch : 50, Loss : 0.903261, Accuracy: 0.989000, Test accuracy: 0.976100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9761
Generating confusion matrix for student
[[ 972.    0.    3.    1.    1.    2.    5.    0.    4.    5.]
 [   0. 1121.    1.    0.    0.    1.    3.    7.    1.    4.]
 [   0.    5. 1014.    3.    4.    0.    0.   16.    6.    1.]
 [   0.    2.    0.  977.    0.    5.    1.    3.    4.    5.]
 [   0.    0.    2.    0.  956.    0.    7.    2.    3.    5.]
 [   1.    0.    0.   11.    0.  877.    7.    0.    2.    4.]
 [   2.    2.    0.    0.    2.    2.  933.    0.    0.    1.]
 [   1.    0.    5.    6.    1.    0.    0.  984.    2.    2.]
 [   4.    5.    7.   10.    3.    4.    2.    1.  946.    1.]
 [   0.    0.    0.    2.   15.    1.    0.   15.    6.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.555793, Accuracy: 0.765000, Test accuracy: 0.773000
Distillation: Epoch : 2, Loss : 1.371187, Accuracy: 0.826000, Test accuracy: 0.864200
Distillation: Epoch : 3, Loss : 1.290654, Accuracy: 0.889000, Test accuracy: 0.895800
Distillation: Epoch : 4, Loss : 1.244771, Accuracy: 0.908000, Test accuracy: 0.908300
Distillation: Epoch : 5, Loss : 1.214674, Accuracy: 0.918000, Test accuracy: 0.918900
Distillation: Epoch : 6, Loss : 1.205706, Accuracy: 0.932000, Test accuracy: 0.928000
Distillation: Epoch : 7, Loss : 1.186998, Accuracy: 0.930000, Test accuracy: 0.935000
Distillation: Epoch : 8, Loss : 1.162340, Accuracy: 0.933000, Test accuracy: 0.940900
Distillation: Epoch : 9, Loss : 1.174710, Accuracy: 0.944000, Test accuracy: 0.946400
Distillation: Epoch : 10, Loss : 1.150009, Accuracy: 0.953000, Test accuracy: 0.953000
Distillation: Epoch : 11, Loss : 1.126149, Accuracy: 0.957000, Test accuracy: 0.955400
Distillation: Epoch : 12, Loss : 1.154755, Accuracy: 0.952000, Test accuracy: 0.958500
Distillation: Epoch : 13, Loss : 1.150890, Accuracy: 0.950000, Test accuracy: 0.959800
Distillation: Epoch : 14, Loss : 1.156077, Accuracy: 0.952000, Test accuracy: 0.961500
Distillation: Epoch : 15, Loss : 1.163928, Accuracy: 0.965000, Test accuracy: 0.963600
Distillation: Epoch : 16, Loss : 1.131247, Accuracy: 0.950000, Test accuracy: 0.964000
Distillation: Epoch : 17, Loss : 1.107114, Accuracy: 0.975000, Test accuracy: 0.965700
Distillation: Epoch : 18, Loss : 1.108776, Accuracy: 0.969000, Test accuracy: 0.966100
Distillation: Epoch : 19, Loss : 1.129712, Accuracy: 0.958000, Test accuracy: 0.967900
Distillation: Epoch : 20, Loss : 1.133213, Accuracy: 0.968000, Test accuracy: 0.968500
Distillation: Epoch : 21, Loss : 1.121939, Accuracy: 0.968000, Test accuracy: 0.969900
Distillation: Epoch : 22, Loss : 1.082411, Accuracy: 0.973000, Test accuracy: 0.970600
Distillation: Epoch : 23, Loss : 1.129465, Accuracy: 0.960000, Test accuracy: 0.971200
Distillation: Epoch : 24, Loss : 1.076162, Accuracy: 0.977000, Test accuracy: 0.972100
Distillation: Epoch : 25, Loss : 1.124409, Accuracy: 0.972000, Test accuracy: 0.972900
Distillation: Epoch : 26, Loss : 1.102766, Accuracy: 0.979000, Test accuracy: 0.973500
Distillation: Epoch : 27, Loss : 1.107009, Accuracy: 0.968000, Test accuracy: 0.973700
Distillation: Epoch : 28, Loss : 1.097002, Accuracy: 0.965000, Test accuracy: 0.974600
Distillation: Epoch : 29, Loss : 1.102897, Accuracy: 0.966000, Test accuracy: 0.975300
Distillation: Epoch : 30, Loss : 1.091143, Accuracy: 0.969000, Test accuracy: 0.974400
Distillation: Epoch : 31, Loss : 1.079622, Accuracy: 0.977000, Test accuracy: 0.975500
Distillation: Epoch : 32, Loss : 1.083219, Accuracy: 0.968000, Test accuracy: 0.975300
Distillation: Epoch : 33, Loss : 1.088272, Accuracy: 0.984000, Test accuracy: 0.976000
Distillation: Epoch : 34, Loss : 1.084142, Accuracy: 0.980000, Test accuracy: 0.976600
Distillation: Epoch : 35, Loss : 1.108369, Accuracy: 0.973000, Test accuracy: 0.976400
Distillation: Epoch : 36, Loss : 1.096007, Accuracy: 0.976000, Test accuracy: 0.977200
Distillation: Epoch : 37, Loss : 1.094039, Accuracy: 0.972000, Test accuracy: 0.977400
Distillation: Epoch : 38, Loss : 1.078030, Accuracy: 0.967000, Test accuracy: 0.977400
Distillation: Epoch : 39, Loss : 1.121334, Accuracy: 0.979000, Test accuracy: 0.978700
Distillation: Epoch : 40, Loss : 1.071694, Accuracy: 0.981000, Test accuracy: 0.978500
Distillation: Epoch : 41, Loss : 1.083470, Accuracy: 0.977000, Test accuracy: 0.978400
Distillation: Epoch : 42, Loss : 1.073807, Accuracy: 0.977000, Test accuracy: 0.979300
Distillation: Epoch : 43, Loss : 1.114342, Accuracy: 0.980000, Test accuracy: 0.979400
Distillation: Epoch : 44, Loss : 1.092294, Accuracy: 0.978000, Test accuracy: 0.980100
Distillation: Epoch : 45, Loss : 1.092996, Accuracy: 0.979000, Test accuracy: 0.980000
Distillation: Epoch : 46, Loss : 1.081443, Accuracy: 0.980000, Test accuracy: 0.979900
Distillation: Epoch : 47, Loss : 1.083069, Accuracy: 0.979000, Test accuracy: 0.980600
Distillation: Epoch : 48, Loss : 1.101025, Accuracy: 0.979000, Test accuracy: 0.980200
Distillation: Epoch : 49, Loss : 1.091233, Accuracy: 0.981000, Test accuracy: 0.981100
Distillation: Epoch : 50, Loss : 1.091839, Accuracy: 0.983000, Test accuracy: 0.980600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9806
Generating confusion matrix for student
[[ 971.    0.    5.    1.    0.    2.    6.    2.    5.    4.]
 [   0. 1127.    2.    0.    1.    0.    4.    6.    1.    6.]
 [   0.    3. 1016.    1.    2.    0.    0.    9.    7.    0.]
 [   0.    2.    1.  992.    0.    1.    0.    3.    2.    2.]
 [   0.    0.    0.    0.  964.    0.    2.    3.    5.    8.]
 [   3.    0.    0.    4.    0.  878.    9.    0.    2.    3.]
 [   4.    2.    0.    0.    2.    2.  934.    0.    1.    0.]
 [   1.    0.    2.    2.    0.    1.    0. 1001.    1.    5.]
 [   1.    1.    6.    9.    2.    6.    3.    1.  942.    0.]
 [   0.    0.    0.    1.   11.    2.    0.    3.    8.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.785658, Accuracy: 0.693000, Test accuracy: 0.720400
Distillation: Epoch : 2, Loss : 1.486878, Accuracy: 0.824000, Test accuracy: 0.845000
Distillation: Epoch : 3, Loss : 1.388241, Accuracy: 0.901000, Test accuracy: 0.888700
Distillation: Epoch : 4, Loss : 1.351387, Accuracy: 0.919000, Test accuracy: 0.908900
Distillation: Epoch : 5, Loss : 1.397701, Accuracy: 0.900000, Test accuracy: 0.922400
Distillation: Epoch : 6, Loss : 1.314151, Accuracy: 0.916000, Test accuracy: 0.932600
Distillation: Epoch : 7, Loss : 1.293193, Accuracy: 0.935000, Test accuracy: 0.942700
Distillation: Epoch : 8, Loss : 1.313117, Accuracy: 0.938000, Test accuracy: 0.948500
Distillation: Epoch : 9, Loss : 1.279141, Accuracy: 0.952000, Test accuracy: 0.952300
Distillation: Epoch : 10, Loss : 1.288911, Accuracy: 0.943000, Test accuracy: 0.955600
Distillation: Epoch : 11, Loss : 1.286047, Accuracy: 0.963000, Test accuracy: 0.956900
Distillation: Epoch : 12, Loss : 1.265032, Accuracy: 0.962000, Test accuracy: 0.960600
Distillation: Epoch : 13, Loss : 1.279559, Accuracy: 0.957000, Test accuracy: 0.962400
Distillation: Epoch : 14, Loss : 1.231631, Accuracy: 0.969000, Test accuracy: 0.965600
Distillation: Epoch : 15, Loss : 1.281899, Accuracy: 0.955000, Test accuracy: 0.966900
Distillation: Epoch : 16, Loss : 1.285686, Accuracy: 0.965000, Test accuracy: 0.968300
Distillation: Epoch : 17, Loss : 1.248491, Accuracy: 0.972000, Test accuracy: 0.969200
Distillation: Epoch : 18, Loss : 1.261794, Accuracy: 0.966000, Test accuracy: 0.970200
Distillation: Epoch : 19, Loss : 1.242065, Accuracy: 0.970000, Test accuracy: 0.970700
Distillation: Epoch : 20, Loss : 1.252172, Accuracy: 0.968000, Test accuracy: 0.971600
Distillation: Epoch : 21, Loss : 1.269241, Accuracy: 0.962000, Test accuracy: 0.973700
Distillation: Epoch : 22, Loss : 1.221693, Accuracy: 0.969000, Test accuracy: 0.973100
Distillation: Epoch : 23, Loss : 1.229260, Accuracy: 0.979000, Test accuracy: 0.973900
Distillation: Epoch : 24, Loss : 1.260258, Accuracy: 0.967000, Test accuracy: 0.973900
Distillation: Epoch : 25, Loss : 1.243598, Accuracy: 0.965000, Test accuracy: 0.974600
Distillation: Epoch : 26, Loss : 1.245052, Accuracy: 0.969000, Test accuracy: 0.974900
Distillation: Epoch : 27, Loss : 1.244398, Accuracy: 0.981000, Test accuracy: 0.974900
Distillation: Epoch : 28, Loss : 1.258450, Accuracy: 0.972000, Test accuracy: 0.975700
Distillation: Epoch : 29, Loss : 1.248735, Accuracy: 0.967000, Test accuracy: 0.975700
Distillation: Epoch : 30, Loss : 1.272328, Accuracy: 0.974000, Test accuracy: 0.976000
Distillation: Epoch : 31, Loss : 1.206770, Accuracy: 0.971000, Test accuracy: 0.976600
Distillation: Epoch : 32, Loss : 1.239505, Accuracy: 0.981000, Test accuracy: 0.976300
Distillation: Epoch : 33, Loss : 1.246891, Accuracy: 0.976000, Test accuracy: 0.977000
Distillation: Epoch : 34, Loss : 1.252187, Accuracy: 0.980000, Test accuracy: 0.976900
Distillation: Epoch : 35, Loss : 1.257848, Accuracy: 0.974000, Test accuracy: 0.977100
Distillation: Epoch : 36, Loss : 1.211115, Accuracy: 0.978000, Test accuracy: 0.977000
Distillation: Epoch : 37, Loss : 1.274145, Accuracy: 0.979000, Test accuracy: 0.977300
Distillation: Epoch : 38, Loss : 1.234119, Accuracy: 0.986000, Test accuracy: 0.977300
Distillation: Epoch : 39, Loss : 1.253664, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 40, Loss : 1.234385, Accuracy: 0.977000, Test accuracy: 0.977600
Distillation: Epoch : 41, Loss : 1.248906, Accuracy: 0.976000, Test accuracy: 0.977600
Distillation: Epoch : 42, Loss : 1.226292, Accuracy: 0.978000, Test accuracy: 0.977800
Distillation: Epoch : 43, Loss : 1.236719, Accuracy: 0.980000, Test accuracy: 0.977800
Distillation: Epoch : 44, Loss : 1.235533, Accuracy: 0.977000, Test accuracy: 0.978100
Distillation: Epoch : 45, Loss : 1.224668, Accuracy: 0.978000, Test accuracy: 0.978300
Distillation: Epoch : 46, Loss : 1.252213, Accuracy: 0.980000, Test accuracy: 0.978300
Distillation: Epoch : 47, Loss : 1.232228, Accuracy: 0.981000, Test accuracy: 0.978300
Distillation: Epoch : 48, Loss : 1.208490, Accuracy: 0.980000, Test accuracy: 0.978300
Distillation: Epoch : 49, Loss : 1.244568, Accuracy: 0.982000, Test accuracy: 0.978900
Distillation: Epoch : 50, Loss : 1.225172, Accuracy: 0.974000, Test accuracy: 0.978000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.978
Generating confusion matrix for student
[[ 972.    1.    7.    1.    0.    2.    6.    0.    5.    5.]
 [   0. 1122.    0.    0.    0.    0.    3.    7.    1.    4.]
 [   2.    5. 1017.    8.    5.    0.    1.   10.    6.    0.]
 [   0.    1.    0.  980.    0.    5.    0.    0.    2.    6.]
 [   0.    0.    3.    0.  961.    0.    2.    4.    4.    3.]
 [   0.    0.    0.    7.    0.  879.    8.    1.    0.    3.]
 [   4.    1.    0.    0.    2.    4.  935.    0.    4.    1.]
 [   1.    0.    0.    2.    1.    1.    0.  988.    1.    2.]
 [   1.    5.    5.    9.    2.    1.    3.    2.  942.    1.]
 [   0.    0.    0.    3.   11.    0.    0.   16.    9.  984.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.758779, Accuracy: 0.777000, Test accuracy: 0.783100
Distillation: Epoch : 2, Loss : 1.566148, Accuracy: 0.864000, Test accuracy: 0.865000
Distillation: Epoch : 3, Loss : 1.515839, Accuracy: 0.887000, Test accuracy: 0.899300
Distillation: Epoch : 4, Loss : 1.506228, Accuracy: 0.912000, Test accuracy: 0.915100
Distillation: Epoch : 5, Loss : 1.471201, Accuracy: 0.926000, Test accuracy: 0.926900
Distillation: Epoch : 6, Loss : 1.434094, Accuracy: 0.934000, Test accuracy: 0.935200
Distillation: Epoch : 7, Loss : 1.438283, Accuracy: 0.941000, Test accuracy: 0.944600
Distillation: Epoch : 8, Loss : 1.413314, Accuracy: 0.939000, Test accuracy: 0.949200
Distillation: Epoch : 9, Loss : 1.427190, Accuracy: 0.953000, Test accuracy: 0.953900
Distillation: Epoch : 10, Loss : 1.420550, Accuracy: 0.942000, Test accuracy: 0.955800
Distillation: Epoch : 11, Loss : 1.397494, Accuracy: 0.952000, Test accuracy: 0.959600
Distillation: Epoch : 12, Loss : 1.410857, Accuracy: 0.961000, Test accuracy: 0.963300
Distillation: Epoch : 13, Loss : 1.385963, Accuracy: 0.955000, Test accuracy: 0.966000
Distillation: Epoch : 14, Loss : 1.384290, Accuracy: 0.969000, Test accuracy: 0.967600
Distillation: Epoch : 15, Loss : 1.390321, Accuracy: 0.963000, Test accuracy: 0.968700
Distillation: Epoch : 16, Loss : 1.399118, Accuracy: 0.964000, Test accuracy: 0.969400
Distillation: Epoch : 17, Loss : 1.391591, Accuracy: 0.967000, Test accuracy: 0.969700
Distillation: Epoch : 18, Loss : 1.373014, Accuracy: 0.969000, Test accuracy: 0.971000
Distillation: Epoch : 19, Loss : 1.383663, Accuracy: 0.968000, Test accuracy: 0.971100
Distillation: Epoch : 20, Loss : 1.389916, Accuracy: 0.970000, Test accuracy: 0.971500
Distillation: Epoch : 21, Loss : 1.394250, Accuracy: 0.970000, Test accuracy: 0.972800
Distillation: Epoch : 22, Loss : 1.372998, Accuracy: 0.966000, Test accuracy: 0.973100
Distillation: Epoch : 23, Loss : 1.391449, Accuracy: 0.965000, Test accuracy: 0.973900
Distillation: Epoch : 24, Loss : 1.389801, Accuracy: 0.978000, Test accuracy: 0.974800
Distillation: Epoch : 25, Loss : 1.378240, Accuracy: 0.969000, Test accuracy: 0.975300
Distillation: Epoch : 26, Loss : 1.360341, Accuracy: 0.983000, Test accuracy: 0.975100
Distillation: Epoch : 27, Loss : 1.384240, Accuracy: 0.976000, Test accuracy: 0.975000
Distillation: Epoch : 28, Loss : 1.375022, Accuracy: 0.968000, Test accuracy: 0.975800
Distillation: Epoch : 29, Loss : 1.380948, Accuracy: 0.971000, Test accuracy: 0.976200
Distillation: Epoch : 30, Loss : 1.371233, Accuracy: 0.974000, Test accuracy: 0.975700
Distillation: Epoch : 31, Loss : 1.373359, Accuracy: 0.983000, Test accuracy: 0.976500
Distillation: Epoch : 32, Loss : 1.387613, Accuracy: 0.973000, Test accuracy: 0.976700
Distillation: Epoch : 33, Loss : 1.390556, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 34, Loss : 1.368080, Accuracy: 0.974000, Test accuracy: 0.977000
Distillation: Epoch : 35, Loss : 1.374586, Accuracy: 0.965000, Test accuracy: 0.977200
Distillation: Epoch : 36, Loss : 1.374089, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 37, Loss : 1.372435, Accuracy: 0.978000, Test accuracy: 0.977000
Distillation: Epoch : 38, Loss : 1.364096, Accuracy: 0.968000, Test accuracy: 0.977600
Distillation: Epoch : 39, Loss : 1.373632, Accuracy: 0.973000, Test accuracy: 0.977400
Distillation: Epoch : 40, Loss : 1.367132, Accuracy: 0.977000, Test accuracy: 0.977800
Distillation: Epoch : 41, Loss : 1.348706, Accuracy: 0.986000, Test accuracy: 0.977500
Distillation: Epoch : 42, Loss : 1.368105, Accuracy: 0.978000, Test accuracy: 0.978300
Distillation: Epoch : 43, Loss : 1.383274, Accuracy: 0.975000, Test accuracy: 0.978000
Distillation: Epoch : 44, Loss : 1.371169, Accuracy: 0.975000, Test accuracy: 0.977700
Distillation: Epoch : 45, Loss : 1.381602, Accuracy: 0.972000, Test accuracy: 0.979000
Distillation: Epoch : 46, Loss : 1.376459, Accuracy: 0.984000, Test accuracy: 0.978400
Distillation: Epoch : 47, Loss : 1.392121, Accuracy: 0.971000, Test accuracy: 0.979300
Distillation: Epoch : 48, Loss : 1.368810, Accuracy: 0.977000, Test accuracy: 0.979100
Distillation: Epoch : 49, Loss : 1.360990, Accuracy: 0.982000, Test accuracy: 0.979300
Distillation: Epoch : 50, Loss : 1.376555, Accuracy: 0.975000, Test accuracy: 0.979100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9791
Generating confusion matrix for student
[[ 971.    0.    5.    0.    1.    1.    5.    1.    5.    5.]
 [   0. 1120.    2.    0.    0.    0.    3.    5.    0.    6.]
 [   1.    5. 1011.    4.    2.    0.    0.   15.    6.    0.]
 [   0.    1.    0.  991.    1.    4.    0.    3.    2.    4.]
 [   2.    1.    2.    0.  962.    1.    4.    2.    4.    1.]
 [   0.    0.    0.    6.    0.  881.    9.    0.    1.    3.]
 [   1.    1.    1.    0.    2.    3.  935.    0.    1.    0.]
 [   1.    0.    2.    3.    0.    0.    0.  991.    4.    4.]
 [   4.    7.    9.    3.    2.    0.    2.    2.  944.    1.]
 [   0.    0.    0.    3.   12.    2.    0.    9.    7.  985.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.921083, Accuracy: 0.794000, Test accuracy: 0.799300
Distillation: Epoch : 2, Loss : 1.811107, Accuracy: 0.846000, Test accuracy: 0.877800
Distillation: Epoch : 3, Loss : 1.790272, Accuracy: 0.888000, Test accuracy: 0.902600
Distillation: Epoch : 4, Loss : 1.760783, Accuracy: 0.908000, Test accuracy: 0.915100
Distillation: Epoch : 5, Loss : 1.746436, Accuracy: 0.924000, Test accuracy: 0.924100
Distillation: Epoch : 6, Loss : 1.731850, Accuracy: 0.921000, Test accuracy: 0.930600
Distillation: Epoch : 7, Loss : 1.737172, Accuracy: 0.921000, Test accuracy: 0.938600
Distillation: Epoch : 8, Loss : 1.751571, Accuracy: 0.939000, Test accuracy: 0.943900
Distillation: Epoch : 9, Loss : 1.725910, Accuracy: 0.949000, Test accuracy: 0.948800
Distillation: Epoch : 10, Loss : 1.710800, Accuracy: 0.951000, Test accuracy: 0.953400
Distillation: Epoch : 11, Loss : 1.688336, Accuracy: 0.954000, Test accuracy: 0.957100
Distillation: Epoch : 12, Loss : 1.704807, Accuracy: 0.950000, Test accuracy: 0.956900
Distillation: Epoch : 13, Loss : 1.697677, Accuracy: 0.953000, Test accuracy: 0.960100
Distillation: Epoch : 14, Loss : 1.699969, Accuracy: 0.958000, Test accuracy: 0.961400
Distillation: Epoch : 15, Loss : 1.692307, Accuracy: 0.966000, Test accuracy: 0.962600
Distillation: Epoch : 16, Loss : 1.693537, Accuracy: 0.960000, Test accuracy: 0.962800
Distillation: Epoch : 17, Loss : 1.696463, Accuracy: 0.963000, Test accuracy: 0.964800
Distillation: Epoch : 18, Loss : 1.694275, Accuracy: 0.965000, Test accuracy: 0.966100
Distillation: Epoch : 19, Loss : 1.690634, Accuracy: 0.957000, Test accuracy: 0.965500
Distillation: Epoch : 20, Loss : 1.689136, Accuracy: 0.976000, Test accuracy: 0.967000
Distillation: Epoch : 21, Loss : 1.701517, Accuracy: 0.971000, Test accuracy: 0.968000
Distillation: Epoch : 22, Loss : 1.701471, Accuracy: 0.971000, Test accuracy: 0.967200
Distillation: Epoch : 23, Loss : 1.701554, Accuracy: 0.969000, Test accuracy: 0.968500
Distillation: Epoch : 24, Loss : 1.680276, Accuracy: 0.963000, Test accuracy: 0.968900
Distillation: Epoch : 25, Loss : 1.695223, Accuracy: 0.961000, Test accuracy: 0.969800
Distillation: Epoch : 26, Loss : 1.696188, Accuracy: 0.965000, Test accuracy: 0.970400
Distillation: Epoch : 27, Loss : 1.686035, Accuracy: 0.975000, Test accuracy: 0.969700
Distillation: Epoch : 28, Loss : 1.700098, Accuracy: 0.964000, Test accuracy: 0.971300
Distillation: Epoch : 29, Loss : 1.691214, Accuracy: 0.973000, Test accuracy: 0.970800
Distillation: Epoch : 30, Loss : 1.701428, Accuracy: 0.961000, Test accuracy: 0.971700
Distillation: Epoch : 31, Loss : 1.675408, Accuracy: 0.971000, Test accuracy: 0.972700
Distillation: Epoch : 32, Loss : 1.684495, Accuracy: 0.970000, Test accuracy: 0.971300
Distillation: Epoch : 33, Loss : 1.694975, Accuracy: 0.971000, Test accuracy: 0.971900
Distillation: Epoch : 34, Loss : 1.686033, Accuracy: 0.975000, Test accuracy: 0.973500
Distillation: Epoch : 35, Loss : 1.676493, Accuracy: 0.976000, Test accuracy: 0.972800
Distillation: Epoch : 36, Loss : 1.679625, Accuracy: 0.975000, Test accuracy: 0.972400
Distillation: Epoch : 37, Loss : 1.674612, Accuracy: 0.972000, Test accuracy: 0.973700
Distillation: Epoch : 38, Loss : 1.696269, Accuracy: 0.968000, Test accuracy: 0.973600
Distillation: Epoch : 39, Loss : 1.691380, Accuracy: 0.972000, Test accuracy: 0.973800
Distillation: Epoch : 40, Loss : 1.675000, Accuracy: 0.975000, Test accuracy: 0.974200
Distillation: Epoch : 41, Loss : 1.679575, Accuracy: 0.969000, Test accuracy: 0.975000
Distillation: Epoch : 42, Loss : 1.688817, Accuracy: 0.974000, Test accuracy: 0.975000
Distillation: Epoch : 43, Loss : 1.685912, Accuracy: 0.978000, Test accuracy: 0.975400
Distillation: Epoch : 44, Loss : 1.685747, Accuracy: 0.966000, Test accuracy: 0.975200
Distillation: Epoch : 45, Loss : 1.677072, Accuracy: 0.973000, Test accuracy: 0.976100
Distillation: Epoch : 46, Loss : 1.669996, Accuracy: 0.975000, Test accuracy: 0.975400
Distillation: Epoch : 47, Loss : 1.684160, Accuracy: 0.975000, Test accuracy: 0.976100
Distillation: Epoch : 48, Loss : 1.660547, Accuracy: 0.977000, Test accuracy: 0.975700
Distillation: Epoch : 49, Loss : 1.674746, Accuracy: 0.974000, Test accuracy: 0.976300
Distillation: Epoch : 50, Loss : 1.675375, Accuracy: 0.979000, Test accuracy: 0.975500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9755
Generating confusion matrix for student
[[ 972.    0.    7.    0.    0.    1.    6.    2.    7.    6.]
 [   1. 1118.    1.    0.    1.    1.    3.    6.    0.    7.]
 [   0.    5. 1014.    5.    3.    1.    1.   17.    9.    1.]
 [   0.    0.    1.  983.    0.    4.    0.    3.    3.    2.]
 [   0.    0.    1.    0.  965.    0.    3.    4.    6.    7.]
 [   2.    0.    0.    8.    0.  873.    5.    0.    1.    2.]
 [   2.    4.    0.    0.    1.    4.  938.    0.    0.    1.]
 [   1.    0.    3.    5.    0.    1.    0.  975.    2.    3.]
 [   1.    8.    5.    7.    2.    4.    2.    3.  938.    1.]
 [   1.    0.    0.    2.   10.    3.    0.   18.    8.  979.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.167023, Accuracy: 0.716000, Test accuracy: 0.712900
Distillation: Epoch : 2, Loss : 2.053224, Accuracy: 0.846000, Test accuracy: 0.854500
Distillation: Epoch : 3, Loss : 2.034139, Accuracy: 0.885000, Test accuracy: 0.901600
Distillation: Epoch : 4, Loss : 2.005671, Accuracy: 0.931000, Test accuracy: 0.922500
Distillation: Epoch : 5, Loss : 1.989728, Accuracy: 0.931000, Test accuracy: 0.933900
Distillation: Epoch : 6, Loss : 1.989235, Accuracy: 0.933000, Test accuracy: 0.941200
Distillation: Epoch : 7, Loss : 1.991058, Accuracy: 0.942000, Test accuracy: 0.946800
Distillation: Epoch : 8, Loss : 1.989330, Accuracy: 0.946000, Test accuracy: 0.952000
Distillation: Epoch : 9, Loss : 1.983007, Accuracy: 0.941000, Test accuracy: 0.955400
Distillation: Epoch : 10, Loss : 1.970749, Accuracy: 0.952000, Test accuracy: 0.957900
Distillation: Epoch : 11, Loss : 1.968479, Accuracy: 0.961000, Test accuracy: 0.960200
Distillation: Epoch : 12, Loss : 1.970154, Accuracy: 0.960000, Test accuracy: 0.961100
Distillation: Epoch : 13, Loss : 1.974921, Accuracy: 0.952000, Test accuracy: 0.962600
Distillation: Epoch : 14, Loss : 1.969232, Accuracy: 0.961000, Test accuracy: 0.964100
Distillation: Epoch : 15, Loss : 1.969347, Accuracy: 0.957000, Test accuracy: 0.966500
Distillation: Epoch : 16, Loss : 1.976018, Accuracy: 0.953000, Test accuracy: 0.967500
Distillation: Epoch : 17, Loss : 1.971357, Accuracy: 0.963000, Test accuracy: 0.968200
Distillation: Epoch : 18, Loss : 1.959435, Accuracy: 0.959000, Test accuracy: 0.968000
Distillation: Epoch : 19, Loss : 1.967922, Accuracy: 0.969000, Test accuracy: 0.970300
Distillation: Epoch : 20, Loss : 1.971043, Accuracy: 0.969000, Test accuracy: 0.970800
Distillation: Epoch : 21, Loss : 1.970322, Accuracy: 0.960000, Test accuracy: 0.970700
Distillation: Epoch : 22, Loss : 1.963554, Accuracy: 0.973000, Test accuracy: 0.971400
Distillation: Epoch : 23, Loss : 1.971791, Accuracy: 0.963000, Test accuracy: 0.971400
Distillation: Epoch : 24, Loss : 1.957787, Accuracy: 0.965000, Test accuracy: 0.971700
Distillation: Epoch : 25, Loss : 1.964064, Accuracy: 0.965000, Test accuracy: 0.972700
Distillation: Epoch : 26, Loss : 1.963411, Accuracy: 0.966000, Test accuracy: 0.973400
Distillation: Epoch : 27, Loss : 1.968572, Accuracy: 0.963000, Test accuracy: 0.973900
Distillation: Epoch : 28, Loss : 1.957872, Accuracy: 0.968000, Test accuracy: 0.974500
Distillation: Epoch : 29, Loss : 1.967149, Accuracy: 0.974000, Test accuracy: 0.974500
Distillation: Epoch : 30, Loss : 1.960450, Accuracy: 0.971000, Test accuracy: 0.974600
Distillation: Epoch : 31, Loss : 1.969999, Accuracy: 0.972000, Test accuracy: 0.975500
Distillation: Epoch : 32, Loss : 1.964005, Accuracy: 0.962000, Test accuracy: 0.976000
Distillation: Epoch : 33, Loss : 1.962043, Accuracy: 0.982000, Test accuracy: 0.975300
Distillation: Epoch : 34, Loss : 1.964911, Accuracy: 0.975000, Test accuracy: 0.975500
Distillation: Epoch : 35, Loss : 1.957951, Accuracy: 0.976000, Test accuracy: 0.975500
Distillation: Epoch : 36, Loss : 1.966322, Accuracy: 0.973000, Test accuracy: 0.976200
Distillation: Epoch : 37, Loss : 1.957157, Accuracy: 0.966000, Test accuracy: 0.976400
Distillation: Epoch : 38, Loss : 1.964332, Accuracy: 0.968000, Test accuracy: 0.976600
Distillation: Epoch : 39, Loss : 1.963000, Accuracy: 0.971000, Test accuracy: 0.976700
Distillation: Epoch : 40, Loss : 1.954066, Accuracy: 0.977000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 1.954787, Accuracy: 0.976000, Test accuracy: 0.977300
Distillation: Epoch : 42, Loss : 1.956612, Accuracy: 0.979000, Test accuracy: 0.977200
Distillation: Epoch : 43, Loss : 1.961030, Accuracy: 0.973000, Test accuracy: 0.977400
Distillation: Epoch : 44, Loss : 1.947955, Accuracy: 0.978000, Test accuracy: 0.976900
Distillation: Epoch : 45, Loss : 1.951295, Accuracy: 0.971000, Test accuracy: 0.977100
Distillation: Epoch : 46, Loss : 1.958189, Accuracy: 0.980000, Test accuracy: 0.976900
Distillation: Epoch : 47, Loss : 1.969711, Accuracy: 0.968000, Test accuracy: 0.977400
Distillation: Epoch : 48, Loss : 1.960770, Accuracy: 0.981000, Test accuracy: 0.977300
Distillation: Epoch : 49, Loss : 1.955131, Accuracy: 0.974000, Test accuracy: 0.977700
Distillation: Epoch : 50, Loss : 1.966040, Accuracy: 0.972000, Test accuracy: 0.977900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9779
Generating confusion matrix for student
[[ 974.    0.    5.    1.    1.    1.    2.    1.    4.    7.]
 [   0. 1124.    1.    0.    0.    0.    3.    7.    2.    6.]
 [   0.    4. 1014.    3.    2.    0.    1.   14.    6.    0.]
 [   0.    1.    2.  983.    0.    4.    0.    3.    2.    5.]
 [   0.    0.    1.    0.  961.    0.    2.    5.    4.    6.]
 [   1.    0.    0.    9.    0.  881.    4.    0.    1.    1.]
 [   4.    3.    0.    0.    3.    2.  945.    0.    1.    2.]
 [   0.    0.    4.    5.    0.    1.    0.  983.    3.    2.]
 [   0.    3.    5.    5.    2.    3.    1.    2.  939.    5.]
 [   1.    0.    0.    4.   13.    0.    0.   13.   12.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.624326, Accuracy: 0.857000, Test accuracy: 0.839500
Distillation: Epoch : 2, Loss : 0.431533, Accuracy: 0.873000, Test accuracy: 0.883100
Distillation: Epoch : 3, Loss : 0.365039, Accuracy: 0.890000, Test accuracy: 0.897800
Distillation: Epoch : 4, Loss : 0.372342, Accuracy: 0.894000, Test accuracy: 0.905700
Distillation: Epoch : 5, Loss : 0.333865, Accuracy: 0.905000, Test accuracy: 0.910400
Distillation: Epoch : 6, Loss : 0.371618, Accuracy: 0.882000, Test accuracy: 0.912100
Distillation: Epoch : 7, Loss : 0.365001, Accuracy: 0.900000, Test accuracy: 0.914200
Distillation: Epoch : 8, Loss : 0.297601, Accuracy: 0.905000, Test accuracy: 0.916700
Distillation: Epoch : 9, Loss : 0.304206, Accuracy: 0.907000, Test accuracy: 0.915900
Distillation: Epoch : 10, Loss : 0.257123, Accuracy: 0.922000, Test accuracy: 0.917600
Distillation: Epoch : 11, Loss : 0.321033, Accuracy: 0.895000, Test accuracy: 0.920600
Distillation: Epoch : 12, Loss : 0.305580, Accuracy: 0.927000, Test accuracy: 0.921100
Distillation: Epoch : 13, Loss : 0.271295, Accuracy: 0.916000, Test accuracy: 0.922800
Distillation: Epoch : 14, Loss : 0.327329, Accuracy: 0.913000, Test accuracy: 0.924400
Distillation: Epoch : 15, Loss : 0.292533, Accuracy: 0.919000, Test accuracy: 0.924200
Distillation: Epoch : 16, Loss : 0.275231, Accuracy: 0.914000, Test accuracy: 0.926400
Distillation: Epoch : 17, Loss : 0.281935, Accuracy: 0.917000, Test accuracy: 0.926100
Distillation: Epoch : 18, Loss : 0.238579, Accuracy: 0.921000, Test accuracy: 0.926800
Distillation: Epoch : 19, Loss : 0.336364, Accuracy: 0.903000, Test accuracy: 0.927700
Distillation: Epoch : 20, Loss : 0.276371, Accuracy: 0.919000, Test accuracy: 0.928800
Distillation: Epoch : 21, Loss : 0.267155, Accuracy: 0.925000, Test accuracy: 0.929300
Distillation: Epoch : 22, Loss : 0.286108, Accuracy: 0.910000, Test accuracy: 0.931000
Distillation: Epoch : 23, Loss : 0.257168, Accuracy: 0.925000, Test accuracy: 0.931200
Distillation: Epoch : 24, Loss : 0.255529, Accuracy: 0.931000, Test accuracy: 0.929900
Distillation: Epoch : 25, Loss : 0.246832, Accuracy: 0.934000, Test accuracy: 0.932300
Distillation: Epoch : 26, Loss : 0.240151, Accuracy: 0.928000, Test accuracy: 0.934700
Distillation: Epoch : 27, Loss : 0.237632, Accuracy: 0.934000, Test accuracy: 0.934100
Distillation: Epoch : 28, Loss : 0.222070, Accuracy: 0.940000, Test accuracy: 0.935300
Distillation: Epoch : 29, Loss : 0.259779, Accuracy: 0.926000, Test accuracy: 0.938400
Distillation: Epoch : 30, Loss : 0.207849, Accuracy: 0.932000, Test accuracy: 0.937800
Distillation: Epoch : 31, Loss : 0.275247, Accuracy: 0.924000, Test accuracy: 0.938400
Distillation: Epoch : 32, Loss : 0.243332, Accuracy: 0.933000, Test accuracy: 0.938200
Distillation: Epoch : 33, Loss : 0.288459, Accuracy: 0.917000, Test accuracy: 0.939900
Distillation: Epoch : 34, Loss : 0.252365, Accuracy: 0.926000, Test accuracy: 0.940700
Distillation: Epoch : 35, Loss : 0.197729, Accuracy: 0.938000, Test accuracy: 0.941900
Distillation: Epoch : 36, Loss : 0.194648, Accuracy: 0.945000, Test accuracy: 0.941900
Distillation: Epoch : 37, Loss : 0.205378, Accuracy: 0.941000, Test accuracy: 0.942800
Distillation: Epoch : 38, Loss : 0.198913, Accuracy: 0.937000, Test accuracy: 0.944700
Distillation: Epoch : 39, Loss : 0.247154, Accuracy: 0.939000, Test accuracy: 0.944900
Distillation: Epoch : 40, Loss : 0.197918, Accuracy: 0.943000, Test accuracy: 0.945500
Distillation: Epoch : 41, Loss : 0.178721, Accuracy: 0.949000, Test accuracy: 0.948200
Distillation: Epoch : 42, Loss : 0.181619, Accuracy: 0.951000, Test accuracy: 0.948700
Distillation: Epoch : 43, Loss : 0.146614, Accuracy: 0.960000, Test accuracy: 0.948800
Distillation: Epoch : 44, Loss : 0.184541, Accuracy: 0.949000, Test accuracy: 0.948000
Distillation: Epoch : 45, Loss : 0.178372, Accuracy: 0.944000, Test accuracy: 0.949500
Distillation: Epoch : 46, Loss : 0.182094, Accuracy: 0.949000, Test accuracy: 0.951700
Distillation: Epoch : 47, Loss : 0.207752, Accuracy: 0.943000, Test accuracy: 0.952200
Distillation: Epoch : 48, Loss : 0.223226, Accuracy: 0.944000, Test accuracy: 0.953100
Distillation: Epoch : 49, Loss : 0.143433, Accuracy: 0.965000, Test accuracy: 0.952300
Distillation: Epoch : 50, Loss : 0.132035, Accuracy: 0.955000, Test accuracy: 0.954200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9542
Generating confusion matrix for student2
[[ 968.    0.    6.    1.    0.    8.    6.    0.    5.    8.]
 [   0. 1117.    4.    0.    3.    1.    3.    9.    2.    6.]
 [   1.    3.  979.   11.   12.    1.    6.   20.    5.    1.]
 [   2.    2.    9.  969.    2.   11.    2.    5.    9.    5.]
 [   0.    0.    5.    1.  928.    2.    5.    5.    6.   19.]
 [   5.    1.    1.   10.    0.  837.    9.    2.   19.    7.]
 [   2.    3.    5.    2.    7.   14.  923.    0.   11.    0.]
 [   1.    2.    8.    8.    2.    5.    1.  975.    5.   17.]
 [   1.    7.   13.    7.    5.   11.    3.    1.  907.    7.]
 [   0.    0.    2.    1.   23.    2.    0.   11.    5.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.028342, Accuracy: 0.786000, Test accuracy: 0.798100
Distillation: Epoch : 2, Loss : 0.568906, Accuracy: 0.848000, Test accuracy: 0.861900
Distillation: Epoch : 3, Loss : 0.467060, Accuracy: 0.879000, Test accuracy: 0.883600
Distillation: Epoch : 4, Loss : 0.426158, Accuracy: 0.883000, Test accuracy: 0.894500
Distillation: Epoch : 5, Loss : 0.356075, Accuracy: 0.895000, Test accuracy: 0.900400
Distillation: Epoch : 6, Loss : 0.348704, Accuracy: 0.903000, Test accuracy: 0.905100
Distillation: Epoch : 7, Loss : 0.324338, Accuracy: 0.918000, Test accuracy: 0.906000
Distillation: Epoch : 8, Loss : 0.379333, Accuracy: 0.906000, Test accuracy: 0.909800
Distillation: Epoch : 9, Loss : 0.339838, Accuracy: 0.892000, Test accuracy: 0.909400
Distillation: Epoch : 10, Loss : 0.353800, Accuracy: 0.912000, Test accuracy: 0.911000
Distillation: Epoch : 11, Loss : 0.290522, Accuracy: 0.919000, Test accuracy: 0.911800
Distillation: Epoch : 12, Loss : 0.318556, Accuracy: 0.899000, Test accuracy: 0.914000
Distillation: Epoch : 13, Loss : 0.302369, Accuracy: 0.928000, Test accuracy: 0.913600
Distillation: Epoch : 14, Loss : 0.344783, Accuracy: 0.912000, Test accuracy: 0.915000
Distillation: Epoch : 15, Loss : 0.313353, Accuracy: 0.909000, Test accuracy: 0.916300
Distillation: Epoch : 16, Loss : 0.304017, Accuracy: 0.906000, Test accuracy: 0.916800
Distillation: Epoch : 17, Loss : 0.305969, Accuracy: 0.919000, Test accuracy: 0.917300
Distillation: Epoch : 18, Loss : 0.327845, Accuracy: 0.917000, Test accuracy: 0.918700
Distillation: Epoch : 19, Loss : 0.294859, Accuracy: 0.918000, Test accuracy: 0.919000
Distillation: Epoch : 20, Loss : 0.321460, Accuracy: 0.912000, Test accuracy: 0.919500
Distillation: Epoch : 21, Loss : 0.340713, Accuracy: 0.903000, Test accuracy: 0.921000
Distillation: Epoch : 22, Loss : 0.268286, Accuracy: 0.929000, Test accuracy: 0.919700
Distillation: Epoch : 23, Loss : 0.238995, Accuracy: 0.935000, Test accuracy: 0.920900
Distillation: Epoch : 24, Loss : 0.309247, Accuracy: 0.908000, Test accuracy: 0.920500
Distillation: Epoch : 25, Loss : 0.295365, Accuracy: 0.925000, Test accuracy: 0.921500
Distillation: Epoch : 26, Loss : 0.298836, Accuracy: 0.924000, Test accuracy: 0.923700
Distillation: Epoch : 27, Loss : 0.282308, Accuracy: 0.926000, Test accuracy: 0.922600
Distillation: Epoch : 28, Loss : 0.244695, Accuracy: 0.931000, Test accuracy: 0.924100
Distillation: Epoch : 29, Loss : 0.318709, Accuracy: 0.916000, Test accuracy: 0.923200
Distillation: Epoch : 30, Loss : 0.267169, Accuracy: 0.926000, Test accuracy: 0.925400
Distillation: Epoch : 31, Loss : 0.264035, Accuracy: 0.928000, Test accuracy: 0.925400
Distillation: Epoch : 32, Loss : 0.275545, Accuracy: 0.918000, Test accuracy: 0.927100
Distillation: Epoch : 33, Loss : 0.284379, Accuracy: 0.923000, Test accuracy: 0.925400
Distillation: Epoch : 34, Loss : 0.248132, Accuracy: 0.929000, Test accuracy: 0.927800
Distillation: Epoch : 35, Loss : 0.337191, Accuracy: 0.906000, Test accuracy: 0.927400
Distillation: Epoch : 36, Loss : 0.244684, Accuracy: 0.936000, Test accuracy: 0.929400
Distillation: Epoch : 37, Loss : 0.273174, Accuracy: 0.916000, Test accuracy: 0.928300
Distillation: Epoch : 38, Loss : 0.329277, Accuracy: 0.914000, Test accuracy: 0.929400
Distillation: Epoch : 39, Loss : 0.287588, Accuracy: 0.917000, Test accuracy: 0.931300
Distillation: Epoch : 40, Loss : 0.250097, Accuracy: 0.933000, Test accuracy: 0.930400
Distillation: Epoch : 41, Loss : 0.291426, Accuracy: 0.929000, Test accuracy: 0.930300
Distillation: Epoch : 42, Loss : 0.207096, Accuracy: 0.944000, Test accuracy: 0.932000
Distillation: Epoch : 43, Loss : 0.258367, Accuracy: 0.934000, Test accuracy: 0.932700
Distillation: Epoch : 44, Loss : 0.292429, Accuracy: 0.927000, Test accuracy: 0.934800
Distillation: Epoch : 45, Loss : 0.271698, Accuracy: 0.931000, Test accuracy: 0.933900
Distillation: Epoch : 46, Loss : 0.267546, Accuracy: 0.941000, Test accuracy: 0.935800
Distillation: Epoch : 47, Loss : 0.256144, Accuracy: 0.935000, Test accuracy: 0.935200
Distillation: Epoch : 48, Loss : 0.255803, Accuracy: 0.931000, Test accuracy: 0.935900
Distillation: Epoch : 49, Loss : 0.213050, Accuracy: 0.950000, Test accuracy: 0.937300
Distillation: Epoch : 50, Loss : 0.244950, Accuracy: 0.932000, Test accuracy: 0.936100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9361
Generating confusion matrix for student2
[[ 963.    0.    9.    2.    1.    7.    9.    1.    9.   11.]
 [   0. 1116.   10.    1.    3.    2.    3.    8.    7.    7.]
 [   2.    4.  933.   14.    8.    3.    5.   18.    8.    1.]
 [   1.    1.   16.  938.    0.   27.    0.    7.   15.   10.]
 [   0.    0.    7.    1.  927.    7.    6.    6.    9.   25.]
 [   5.    1.    2.   18.    0.  798.   12.    0.   17.    6.]
 [   5.    3.   10.    1.    8.   10.  916.    0.    9.    0.]
 [   2.    2.   11.    9.    3.    3.    3.  958.    6.   17.]
 [   2.    8.   29.   17.    6.   30.    4.    2.  888.    8.]
 [   0.    0.    5.    9.   26.    5.    0.   28.    6.  924.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.680077, Accuracy: 0.754000, Test accuracy: 0.768200
Distillation: Epoch : 2, Loss : 0.917995, Accuracy: 0.840000, Test accuracy: 0.853200
Distillation: Epoch : 3, Loss : 0.719889, Accuracy: 0.876000, Test accuracy: 0.884700
Distillation: Epoch : 4, Loss : 0.643885, Accuracy: 0.904000, Test accuracy: 0.899400
Distillation: Epoch : 5, Loss : 0.595297, Accuracy: 0.907000, Test accuracy: 0.911100
Distillation: Epoch : 6, Loss : 0.610286, Accuracy: 0.910000, Test accuracy: 0.918100
Distillation: Epoch : 7, Loss : 0.592852, Accuracy: 0.922000, Test accuracy: 0.924300
Distillation: Epoch : 8, Loss : 0.599134, Accuracy: 0.912000, Test accuracy: 0.928900
Distillation: Epoch : 9, Loss : 0.558060, Accuracy: 0.915000, Test accuracy: 0.932500
Distillation: Epoch : 10, Loss : 0.566117, Accuracy: 0.910000, Test accuracy: 0.935000
Distillation: Epoch : 11, Loss : 0.519829, Accuracy: 0.947000, Test accuracy: 0.938000
Distillation: Epoch : 12, Loss : 0.536410, Accuracy: 0.932000, Test accuracy: 0.938300
Distillation: Epoch : 13, Loss : 0.506728, Accuracy: 0.948000, Test accuracy: 0.942100
Distillation: Epoch : 14, Loss : 0.490940, Accuracy: 0.945000, Test accuracy: 0.943100
Distillation: Epoch : 15, Loss : 0.469072, Accuracy: 0.954000, Test accuracy: 0.946200
Distillation: Epoch : 16, Loss : 0.516083, Accuracy: 0.939000, Test accuracy: 0.947300
Distillation: Epoch : 17, Loss : 0.490641, Accuracy: 0.945000, Test accuracy: 0.947400
Distillation: Epoch : 18, Loss : 0.515359, Accuracy: 0.937000, Test accuracy: 0.949200
Distillation: Epoch : 19, Loss : 0.488002, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 20, Loss : 0.507840, Accuracy: 0.940000, Test accuracy: 0.951700
Distillation: Epoch : 21, Loss : 0.520296, Accuracy: 0.948000, Test accuracy: 0.952400
Distillation: Epoch : 22, Loss : 0.465683, Accuracy: 0.946000, Test accuracy: 0.953100
Distillation: Epoch : 23, Loss : 0.479275, Accuracy: 0.957000, Test accuracy: 0.955000
Distillation: Epoch : 24, Loss : 0.495364, Accuracy: 0.942000, Test accuracy: 0.955100
Distillation: Epoch : 25, Loss : 0.479601, Accuracy: 0.950000, Test accuracy: 0.956600
Distillation: Epoch : 26, Loss : 0.482126, Accuracy: 0.946000, Test accuracy: 0.956900
Distillation: Epoch : 27, Loss : 0.499234, Accuracy: 0.951000, Test accuracy: 0.957100
Distillation: Epoch : 28, Loss : 0.456490, Accuracy: 0.962000, Test accuracy: 0.957900
Distillation: Epoch : 29, Loss : 0.464201, Accuracy: 0.956000, Test accuracy: 0.958500
Distillation: Epoch : 30, Loss : 0.490140, Accuracy: 0.947000, Test accuracy: 0.958900
Distillation: Epoch : 31, Loss : 0.482820, Accuracy: 0.947000, Test accuracy: 0.959800
Distillation: Epoch : 32, Loss : 0.487421, Accuracy: 0.960000, Test accuracy: 0.961100
Distillation: Epoch : 33, Loss : 0.456625, Accuracy: 0.963000, Test accuracy: 0.961300
Distillation: Epoch : 34, Loss : 0.434738, Accuracy: 0.963000, Test accuracy: 0.960600
Distillation: Epoch : 35, Loss : 0.466373, Accuracy: 0.960000, Test accuracy: 0.961200
Distillation: Epoch : 36, Loss : 0.449305, Accuracy: 0.968000, Test accuracy: 0.961900
Distillation: Epoch : 37, Loss : 0.473075, Accuracy: 0.946000, Test accuracy: 0.962700
Distillation: Epoch : 38, Loss : 0.455257, Accuracy: 0.954000, Test accuracy: 0.963200
Distillation: Epoch : 39, Loss : 0.442322, Accuracy: 0.958000, Test accuracy: 0.963000
Distillation: Epoch : 40, Loss : 0.486575, Accuracy: 0.950000, Test accuracy: 0.964100
Distillation: Epoch : 41, Loss : 0.455664, Accuracy: 0.952000, Test accuracy: 0.964100
Distillation: Epoch : 42, Loss : 0.454314, Accuracy: 0.950000, Test accuracy: 0.964400
Distillation: Epoch : 43, Loss : 0.468648, Accuracy: 0.953000, Test accuracy: 0.964800
Distillation: Epoch : 44, Loss : 0.454667, Accuracy: 0.961000, Test accuracy: 0.964700
Distillation: Epoch : 45, Loss : 0.444950, Accuracy: 0.971000, Test accuracy: 0.965100
Distillation: Epoch : 46, Loss : 0.427110, Accuracy: 0.969000, Test accuracy: 0.964400
Distillation: Epoch : 47, Loss : 0.458754, Accuracy: 0.961000, Test accuracy: 0.965200
Distillation: Epoch : 48, Loss : 0.463625, Accuracy: 0.958000, Test accuracy: 0.965100
Distillation: Epoch : 49, Loss : 0.434304, Accuracy: 0.958000, Test accuracy: 0.965300
Distillation: Epoch : 50, Loss : 0.450602, Accuracy: 0.957000, Test accuracy: 0.965800
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9658
Generating confusion matrix for student2
[[ 967.    0.    4.    0.    2.    1.    6.    3.    7.    8.]
 [   0. 1123.    5.    0.    2.    1.    3.    8.    4.    6.]
 [   1.    4.  991.   10.    1.    0.    0.   20.   11.    1.]
 [   0.    3.    3.  978.    0.    5.    1.    4.    6.    3.]
 [   1.    0.    6.    1.  960.    0.    6.    5.    8.   19.]
 [   1.    0.    1.    7.    0.  869.    4.    0.    4.    5.]
 [   5.    1.    3.    0.    4.    5.  935.    0.    8.    0.]
 [   3.    0.    5.    4.    2.    1.    0.  969.    6.   12.]
 [   2.    3.   13.    5.    2.    7.    3.    2.  914.    3.]
 [   0.    1.    1.    5.    9.    3.    0.   17.    6.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.540892, Accuracy: 0.748000, Test accuracy: 0.761500
Distillation: Epoch : 2, Loss : 1.017003, Accuracy: 0.808000, Test accuracy: 0.837100
Distillation: Epoch : 3, Loss : 0.890225, Accuracy: 0.849000, Test accuracy: 0.867900
Distillation: Epoch : 4, Loss : 0.837492, Accuracy: 0.878000, Test accuracy: 0.881500
Distillation: Epoch : 5, Loss : 0.837785, Accuracy: 0.871000, Test accuracy: 0.889800
Distillation: Epoch : 6, Loss : 0.782222, Accuracy: 0.903000, Test accuracy: 0.896500
Distillation: Epoch : 7, Loss : 0.787447, Accuracy: 0.904000, Test accuracy: 0.900300
Distillation: Epoch : 8, Loss : 0.772030, Accuracy: 0.888000, Test accuracy: 0.902800
Distillation: Epoch : 9, Loss : 0.742804, Accuracy: 0.915000, Test accuracy: 0.905100
Distillation: Epoch : 10, Loss : 0.792122, Accuracy: 0.895000, Test accuracy: 0.907500
Distillation: Epoch : 11, Loss : 0.813365, Accuracy: 0.889000, Test accuracy: 0.909600
Distillation: Epoch : 12, Loss : 0.748195, Accuracy: 0.907000, Test accuracy: 0.910700
Distillation: Epoch : 13, Loss : 0.744510, Accuracy: 0.909000, Test accuracy: 0.913000
Distillation: Epoch : 14, Loss : 0.765497, Accuracy: 0.909000, Test accuracy: 0.912900
Distillation: Epoch : 15, Loss : 0.764243, Accuracy: 0.897000, Test accuracy: 0.914600
Distillation: Epoch : 16, Loss : 0.763272, Accuracy: 0.901000, Test accuracy: 0.915400
Distillation: Epoch : 17, Loss : 0.723688, Accuracy: 0.915000, Test accuracy: 0.917400
Distillation: Epoch : 18, Loss : 0.703015, Accuracy: 0.931000, Test accuracy: 0.918000
Distillation: Epoch : 19, Loss : 0.674865, Accuracy: 0.939000, Test accuracy: 0.919000
Distillation: Epoch : 20, Loss : 0.722709, Accuracy: 0.916000, Test accuracy: 0.920100
Distillation: Epoch : 21, Loss : 0.686956, Accuracy: 0.918000, Test accuracy: 0.922800
Distillation: Epoch : 22, Loss : 0.714666, Accuracy: 0.932000, Test accuracy: 0.924000
Distillation: Epoch : 23, Loss : 0.699482, Accuracy: 0.928000, Test accuracy: 0.924700
Distillation: Epoch : 24, Loss : 0.703984, Accuracy: 0.927000, Test accuracy: 0.927100
Distillation: Epoch : 25, Loss : 0.681860, Accuracy: 0.941000, Test accuracy: 0.928500
Distillation: Epoch : 26, Loss : 0.734892, Accuracy: 0.924000, Test accuracy: 0.931600
Distillation: Epoch : 27, Loss : 0.690321, Accuracy: 0.942000, Test accuracy: 0.932500
Distillation: Epoch : 28, Loss : 0.684744, Accuracy: 0.930000, Test accuracy: 0.934000
Distillation: Epoch : 29, Loss : 0.671267, Accuracy: 0.930000, Test accuracy: 0.934800
Distillation: Epoch : 30, Loss : 0.678439, Accuracy: 0.930000, Test accuracy: 0.938000
Distillation: Epoch : 31, Loss : 0.690668, Accuracy: 0.930000, Test accuracy: 0.940000
Distillation: Epoch : 32, Loss : 0.716642, Accuracy: 0.935000, Test accuracy: 0.939800
Distillation: Epoch : 33, Loss : 0.661916, Accuracy: 0.929000, Test accuracy: 0.942200
Distillation: Epoch : 34, Loss : 0.637289, Accuracy: 0.948000, Test accuracy: 0.943300
Distillation: Epoch : 35, Loss : 0.703149, Accuracy: 0.927000, Test accuracy: 0.946300
Distillation: Epoch : 36, Loss : 0.649040, Accuracy: 0.936000, Test accuracy: 0.947000
Distillation: Epoch : 37, Loss : 0.657898, Accuracy: 0.953000, Test accuracy: 0.948000
Distillation: Epoch : 38, Loss : 0.628171, Accuracy: 0.948000, Test accuracy: 0.949300
Distillation: Epoch : 39, Loss : 0.633124, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 40, Loss : 0.658364, Accuracy: 0.948000, Test accuracy: 0.951000
Distillation: Epoch : 41, Loss : 0.670421, Accuracy: 0.936000, Test accuracy: 0.951700
Distillation: Epoch : 42, Loss : 0.637305, Accuracy: 0.953000, Test accuracy: 0.952500
Distillation: Epoch : 43, Loss : 0.617460, Accuracy: 0.953000, Test accuracy: 0.954700
Distillation: Epoch : 44, Loss : 0.608324, Accuracy: 0.951000, Test accuracy: 0.956800
Distillation: Epoch : 45, Loss : 0.649373, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 46, Loss : 0.650417, Accuracy: 0.948000, Test accuracy: 0.957800
Distillation: Epoch : 47, Loss : 0.609429, Accuracy: 0.960000, Test accuracy: 0.958700
Distillation: Epoch : 48, Loss : 0.594070, Accuracy: 0.971000, Test accuracy: 0.959200
Distillation: Epoch : 49, Loss : 0.594621, Accuracy: 0.958000, Test accuracy: 0.961200
Distillation: Epoch : 50, Loss : 0.632868, Accuracy: 0.948000, Test accuracy: 0.961700
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9617
Generating confusion matrix for student2
[[ 962.    0.    5.    0.    1.    0.    6.    3.    6.    7.]
 [   0. 1124.    3.    1.    2.    1.    3.    9.    3.    5.]
 [   1.    2.  986.    9.    6.    0.    0.   21.    9.    1.]
 [   0.    2.    4.  970.    0.    9.    0.    3.    8.    5.]
 [   1.    0.    8.    0.  952.    0.    5.    7.    8.   12.]
 [   1.    0.    0.    8.    0.  854.    5.    2.    7.    3.]
 [   7.    3.    2.    0.    5.    6.  936.    0.    2.    0.]
 [   1.    0.    2.    3.    0.    4.    0.  952.    4.    6.]
 [   5.    4.   21.   13.    2.   11.    3.    3.  915.    4.]
 [   2.    0.    1.    6.   14.    7.    0.   28.   12.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.658083, Accuracy: 0.757000, Test accuracy: 0.760900
Distillation: Epoch : 2, Loss : 1.149844, Accuracy: 0.825000, Test accuracy: 0.845100
Distillation: Epoch : 3, Loss : 1.017124, Accuracy: 0.867000, Test accuracy: 0.878700
Distillation: Epoch : 4, Loss : 0.964746, Accuracy: 0.881000, Test accuracy: 0.895100
Distillation: Epoch : 5, Loss : 0.938834, Accuracy: 0.899000, Test accuracy: 0.906300
Distillation: Epoch : 6, Loss : 0.937961, Accuracy: 0.899000, Test accuracy: 0.913800
Distillation: Epoch : 7, Loss : 0.905513, Accuracy: 0.912000, Test accuracy: 0.918100
Distillation: Epoch : 8, Loss : 0.859511, Accuracy: 0.931000, Test accuracy: 0.923700
Distillation: Epoch : 9, Loss : 0.913450, Accuracy: 0.921000, Test accuracy: 0.925500
Distillation: Epoch : 10, Loss : 0.896302, Accuracy: 0.910000, Test accuracy: 0.929400
Distillation: Epoch : 11, Loss : 0.869711, Accuracy: 0.920000, Test accuracy: 0.932600
Distillation: Epoch : 12, Loss : 0.850694, Accuracy: 0.930000, Test accuracy: 0.935300
Distillation: Epoch : 13, Loss : 0.850810, Accuracy: 0.930000, Test accuracy: 0.937600
Distillation: Epoch : 14, Loss : 0.859608, Accuracy: 0.930000, Test accuracy: 0.939400
Distillation: Epoch : 15, Loss : 0.829144, Accuracy: 0.948000, Test accuracy: 0.941600
Distillation: Epoch : 16, Loss : 0.852416, Accuracy: 0.944000, Test accuracy: 0.943300
Distillation: Epoch : 17, Loss : 0.838598, Accuracy: 0.933000, Test accuracy: 0.945600
Distillation: Epoch : 18, Loss : 0.839045, Accuracy: 0.937000, Test accuracy: 0.946700
Distillation: Epoch : 19, Loss : 0.843684, Accuracy: 0.944000, Test accuracy: 0.947500
Distillation: Epoch : 20, Loss : 0.851437, Accuracy: 0.940000, Test accuracy: 0.949700
Distillation: Epoch : 21, Loss : 0.815175, Accuracy: 0.944000, Test accuracy: 0.950100
Distillation: Epoch : 22, Loss : 0.793226, Accuracy: 0.952000, Test accuracy: 0.952100
Distillation: Epoch : 23, Loss : 0.811309, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 24, Loss : 0.828309, Accuracy: 0.939000, Test accuracy: 0.953000
Distillation: Epoch : 25, Loss : 0.821395, Accuracy: 0.946000, Test accuracy: 0.954100
Distillation: Epoch : 26, Loss : 0.810054, Accuracy: 0.947000, Test accuracy: 0.954800
Distillation: Epoch : 27, Loss : 0.802008, Accuracy: 0.955000, Test accuracy: 0.955300
Distillation: Epoch : 28, Loss : 0.801153, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 29, Loss : 0.818127, Accuracy: 0.958000, Test accuracy: 0.956500
Distillation: Epoch : 30, Loss : 0.818924, Accuracy: 0.942000, Test accuracy: 0.957400
Distillation: Epoch : 31, Loss : 0.828725, Accuracy: 0.957000, Test accuracy: 0.957900
Distillation: Epoch : 32, Loss : 0.811149, Accuracy: 0.949000, Test accuracy: 0.958200
Distillation: Epoch : 33, Loss : 0.812097, Accuracy: 0.954000, Test accuracy: 0.957900
Distillation: Epoch : 34, Loss : 0.793632, Accuracy: 0.947000, Test accuracy: 0.958800
Distillation: Epoch : 35, Loss : 0.830974, Accuracy: 0.954000, Test accuracy: 0.959100
Distillation: Epoch : 36, Loss : 0.810026, Accuracy: 0.959000, Test accuracy: 0.959000
Distillation: Epoch : 37, Loss : 0.800923, Accuracy: 0.955000, Test accuracy: 0.960100
Distillation: Epoch : 38, Loss : 0.783564, Accuracy: 0.954000, Test accuracy: 0.960700
Distillation: Epoch : 39, Loss : 0.787402, Accuracy: 0.960000, Test accuracy: 0.960400
Distillation: Epoch : 40, Loss : 0.795253, Accuracy: 0.975000, Test accuracy: 0.961000
Distillation: Epoch : 41, Loss : 0.812206, Accuracy: 0.949000, Test accuracy: 0.961600
Distillation: Epoch : 42, Loss : 0.808604, Accuracy: 0.956000, Test accuracy: 0.961900
Distillation: Epoch : 43, Loss : 0.773129, Accuracy: 0.968000, Test accuracy: 0.962100
Distillation: Epoch : 44, Loss : 0.791707, Accuracy: 0.957000, Test accuracy: 0.962800
Distillation: Epoch : 45, Loss : 0.786026, Accuracy: 0.967000, Test accuracy: 0.963300
Distillation: Epoch : 46, Loss : 0.809686, Accuracy: 0.945000, Test accuracy: 0.963300
Distillation: Epoch : 47, Loss : 0.797456, Accuracy: 0.969000, Test accuracy: 0.964200
Distillation: Epoch : 48, Loss : 0.780062, Accuracy: 0.961000, Test accuracy: 0.964700
Distillation: Epoch : 49, Loss : 0.793165, Accuracy: 0.955000, Test accuracy: 0.964900
Distillation: Epoch : 50, Loss : 0.780732, Accuracy: 0.958000, Test accuracy: 0.964600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9646
Generating confusion matrix for student2
[[ 970.    0.    4.    0.    1.    1.    7.    2.    7.    7.]
 [   0. 1122.    6.    0.    2.    1.    3.    9.    5.    5.]
 [   1.    4.  994.   12.    0.    0.    0.   23.    7.    0.]
 [   0.    1.    2.  970.    0.    6.    0.    6.    7.    3.]
 [   0.    0.    7.    1.  953.    0.    5.   10.    8.   18.]
 [   0.    0.    0.    9.    1.  873.    7.    1.    5.    8.]
 [   5.    3.    2.    0.    8.    3.  933.    0.    2.    0.]
 [   1.    0.    4.    7.    3.    1.    0.  959.    6.   10.]
 [   3.    5.   12.    9.    2.    3.    3.    2.  915.    1.]
 [   0.    0.    1.    2.   12.    4.    0.   16.   12.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.773767, Accuracy: 0.755000, Test accuracy: 0.747300
Distillation: Epoch : 2, Loss : 1.337376, Accuracy: 0.812000, Test accuracy: 0.828700
Distillation: Epoch : 3, Loss : 1.219343, Accuracy: 0.849000, Test accuracy: 0.864400
Distillation: Epoch : 4, Loss : 1.144483, Accuracy: 0.883000, Test accuracy: 0.879800
Distillation: Epoch : 5, Loss : 1.135655, Accuracy: 0.886000, Test accuracy: 0.891100
Distillation: Epoch : 6, Loss : 1.130597, Accuracy: 0.878000, Test accuracy: 0.898200
Distillation: Epoch : 7, Loss : 1.070660, Accuracy: 0.907000, Test accuracy: 0.904100
Distillation: Epoch : 8, Loss : 1.084231, Accuracy: 0.896000, Test accuracy: 0.907600
Distillation: Epoch : 9, Loss : 1.080108, Accuracy: 0.912000, Test accuracy: 0.910900
Distillation: Epoch : 10, Loss : 1.127144, Accuracy: 0.893000, Test accuracy: 0.914100
Distillation: Epoch : 11, Loss : 1.065655, Accuracy: 0.918000, Test accuracy: 0.918200
Distillation: Epoch : 12, Loss : 1.042953, Accuracy: 0.910000, Test accuracy: 0.920400
Distillation: Epoch : 13, Loss : 1.072805, Accuracy: 0.912000, Test accuracy: 0.924000
Distillation: Epoch : 14, Loss : 1.056865, Accuracy: 0.925000, Test accuracy: 0.928500
Distillation: Epoch : 15, Loss : 1.039877, Accuracy: 0.909000, Test accuracy: 0.930800
Distillation: Epoch : 16, Loss : 1.006099, Accuracy: 0.934000, Test accuracy: 0.933800
Distillation: Epoch : 17, Loss : 1.045689, Accuracy: 0.920000, Test accuracy: 0.936900
Distillation: Epoch : 18, Loss : 1.038451, Accuracy: 0.928000, Test accuracy: 0.939100
Distillation: Epoch : 19, Loss : 1.014727, Accuracy: 0.931000, Test accuracy: 0.941800
Distillation: Epoch : 20, Loss : 0.997659, Accuracy: 0.947000, Test accuracy: 0.944300
Distillation: Epoch : 21, Loss : 0.978692, Accuracy: 0.949000, Test accuracy: 0.946800
Distillation: Epoch : 22, Loss : 0.958923, Accuracy: 0.951000, Test accuracy: 0.949100
Distillation: Epoch : 23, Loss : 0.968352, Accuracy: 0.953000, Test accuracy: 0.950400
Distillation: Epoch : 24, Loss : 0.976901, Accuracy: 0.950000, Test accuracy: 0.952400
Distillation: Epoch : 25, Loss : 0.996980, Accuracy: 0.948000, Test accuracy: 0.953900
Distillation: Epoch : 26, Loss : 0.984736, Accuracy: 0.941000, Test accuracy: 0.955300
Distillation: Epoch : 27, Loss : 0.967225, Accuracy: 0.954000, Test accuracy: 0.956900
Distillation: Epoch : 28, Loss : 0.963639, Accuracy: 0.961000, Test accuracy: 0.959000
Distillation: Epoch : 29, Loss : 0.970825, Accuracy: 0.961000, Test accuracy: 0.959100
Distillation: Epoch : 30, Loss : 0.979807, Accuracy: 0.954000, Test accuracy: 0.959900
Distillation: Epoch : 31, Loss : 1.008725, Accuracy: 0.953000, Test accuracy: 0.961800
Distillation: Epoch : 32, Loss : 0.974383, Accuracy: 0.951000, Test accuracy: 0.963200
Distillation: Epoch : 33, Loss : 0.977944, Accuracy: 0.955000, Test accuracy: 0.964200
Distillation: Epoch : 34, Loss : 0.979284, Accuracy: 0.950000, Test accuracy: 0.965300
Distillation: Epoch : 35, Loss : 0.978872, Accuracy: 0.951000, Test accuracy: 0.965400
Distillation: Epoch : 36, Loss : 0.957454, Accuracy: 0.965000, Test accuracy: 0.965400
Distillation: Epoch : 37, Loss : 0.967014, Accuracy: 0.956000, Test accuracy: 0.966200
Distillation: Epoch : 38, Loss : 0.950132, Accuracy: 0.966000, Test accuracy: 0.966900
Distillation: Epoch : 39, Loss : 0.958410, Accuracy: 0.960000, Test accuracy: 0.966400
Distillation: Epoch : 40, Loss : 0.957242, Accuracy: 0.959000, Test accuracy: 0.967100
Distillation: Epoch : 41, Loss : 0.958237, Accuracy: 0.969000, Test accuracy: 0.968000
Distillation: Epoch : 42, Loss : 0.946742, Accuracy: 0.968000, Test accuracy: 0.968000
Distillation: Epoch : 43, Loss : 0.942684, Accuracy: 0.958000, Test accuracy: 0.969000
Distillation: Epoch : 44, Loss : 0.957305, Accuracy: 0.962000, Test accuracy: 0.969700
Distillation: Epoch : 45, Loss : 0.948729, Accuracy: 0.958000, Test accuracy: 0.970500
Distillation: Epoch : 46, Loss : 0.938155, Accuracy: 0.958000, Test accuracy: 0.970500
Distillation: Epoch : 47, Loss : 0.946109, Accuracy: 0.967000, Test accuracy: 0.970200
Distillation: Epoch : 48, Loss : 0.947330, Accuracy: 0.961000, Test accuracy: 0.971000
Distillation: Epoch : 49, Loss : 0.937928, Accuracy: 0.969000, Test accuracy: 0.970600
Distillation: Epoch : 50, Loss : 0.951480, Accuracy: 0.959000, Test accuracy: 0.971100
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9711
Generating confusion matrix for student2
[[ 969.    0.    6.    0.    0.    1.    5.    2.    7.    6.]
 [   0. 1124.    5.    0.    0.    1.    2.    9.    2.    5.]
 [   1.    5.  997.    6.    6.    1.    0.   21.    9.    1.]
 [   0.    0.    2.  986.    0.    4.    0.    3.    5.    4.]
 [   0.    0.    6.    0.  954.    0.    3.    3.    7.   10.]
 [   2.    0.    0.    7.    0.  874.    4.    1.    4.    3.]
 [   4.    3.    2.    0.    2.    3.  941.    0.    0.    0.]
 [   1.    0.    2.    4.    1.    1.    0.  974.    6.    7.]
 [   3.    3.   12.    5.    3.    4.    3.    2.  921.    2.]
 [   0.    0.    0.    2.   16.    3.    0.   13.   13.  971.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.845548, Accuracy: 0.717000, Test accuracy: 0.747200
Distillation: Epoch : 2, Loss : 1.447710, Accuracy: 0.802000, Test accuracy: 0.832400
Distillation: Epoch : 3, Loss : 1.360826, Accuracy: 0.833000, Test accuracy: 0.864700
Distillation: Epoch : 4, Loss : 1.336472, Accuracy: 0.856000, Test accuracy: 0.881000
Distillation: Epoch : 5, Loss : 1.275041, Accuracy: 0.884000, Test accuracy: 0.890600
Distillation: Epoch : 6, Loss : 1.257424, Accuracy: 0.895000, Test accuracy: 0.895700
Distillation: Epoch : 7, Loss : 1.246483, Accuracy: 0.904000, Test accuracy: 0.899000
Distillation: Epoch : 8, Loss : 1.253384, Accuracy: 0.890000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 1.217439, Accuracy: 0.915000, Test accuracy: 0.905100
Distillation: Epoch : 10, Loss : 1.257353, Accuracy: 0.893000, Test accuracy: 0.907200
Distillation: Epoch : 11, Loss : 1.225877, Accuracy: 0.902000, Test accuracy: 0.910200
Distillation: Epoch : 12, Loss : 1.251030, Accuracy: 0.899000, Test accuracy: 0.911100
Distillation: Epoch : 13, Loss : 1.209037, Accuracy: 0.904000, Test accuracy: 0.914400
Distillation: Epoch : 14, Loss : 1.231251, Accuracy: 0.892000, Test accuracy: 0.916500
Distillation: Epoch : 15, Loss : 1.213884, Accuracy: 0.906000, Test accuracy: 0.919400
Distillation: Epoch : 16, Loss : 1.201773, Accuracy: 0.909000, Test accuracy: 0.921600
Distillation: Epoch : 17, Loss : 1.174563, Accuracy: 0.931000, Test accuracy: 0.924200
Distillation: Epoch : 18, Loss : 1.208838, Accuracy: 0.926000, Test accuracy: 0.927200
Distillation: Epoch : 19, Loss : 1.186274, Accuracy: 0.928000, Test accuracy: 0.930100
Distillation: Epoch : 20, Loss : 1.161299, Accuracy: 0.938000, Test accuracy: 0.933000
Distillation: Epoch : 21, Loss : 1.165266, Accuracy: 0.923000, Test accuracy: 0.936200
Distillation: Epoch : 22, Loss : 1.165365, Accuracy: 0.925000, Test accuracy: 0.937600
Distillation: Epoch : 23, Loss : 1.162078, Accuracy: 0.936000, Test accuracy: 0.939300
Distillation: Epoch : 24, Loss : 1.132412, Accuracy: 0.931000, Test accuracy: 0.942600
Distillation: Epoch : 25, Loss : 1.141036, Accuracy: 0.937000, Test accuracy: 0.944600
Distillation: Epoch : 26, Loss : 1.160266, Accuracy: 0.927000, Test accuracy: 0.948100
Distillation: Epoch : 27, Loss : 1.156874, Accuracy: 0.945000, Test accuracy: 0.949000
Distillation: Epoch : 28, Loss : 1.153040, Accuracy: 0.929000, Test accuracy: 0.951600
Distillation: Epoch : 29, Loss : 1.126795, Accuracy: 0.951000, Test accuracy: 0.953000
Distillation: Epoch : 30, Loss : 1.165743, Accuracy: 0.935000, Test accuracy: 0.954400
Distillation: Epoch : 31, Loss : 1.136934, Accuracy: 0.947000, Test accuracy: 0.955100
Distillation: Epoch : 32, Loss : 1.133944, Accuracy: 0.961000, Test accuracy: 0.956200
Distillation: Epoch : 33, Loss : 1.139802, Accuracy: 0.951000, Test accuracy: 0.957200
Distillation: Epoch : 34, Loss : 1.133129, Accuracy: 0.943000, Test accuracy: 0.958300
Distillation: Epoch : 35, Loss : 1.129628, Accuracy: 0.956000, Test accuracy: 0.959200
Distillation: Epoch : 36, Loss : 1.122405, Accuracy: 0.945000, Test accuracy: 0.960200
Distillation: Epoch : 37, Loss : 1.107636, Accuracy: 0.945000, Test accuracy: 0.960500
Distillation: Epoch : 38, Loss : 1.135720, Accuracy: 0.960000, Test accuracy: 0.961500
Distillation: Epoch : 39, Loss : 1.121479, Accuracy: 0.955000, Test accuracy: 0.962400
Distillation: Epoch : 40, Loss : 1.099669, Accuracy: 0.959000, Test accuracy: 0.962600
Distillation: Epoch : 41, Loss : 1.146806, Accuracy: 0.957000, Test accuracy: 0.963800
Distillation: Epoch : 42, Loss : 1.138981, Accuracy: 0.949000, Test accuracy: 0.964700
Distillation: Epoch : 43, Loss : 1.142435, Accuracy: 0.957000, Test accuracy: 0.964700
Distillation: Epoch : 44, Loss : 1.111750, Accuracy: 0.956000, Test accuracy: 0.965600
Distillation: Epoch : 45, Loss : 1.105464, Accuracy: 0.958000, Test accuracy: 0.965800
Distillation: Epoch : 46, Loss : 1.095325, Accuracy: 0.956000, Test accuracy: 0.966300
Distillation: Epoch : 47, Loss : 1.113711, Accuracy: 0.966000, Test accuracy: 0.967400
Distillation: Epoch : 48, Loss : 1.109660, Accuracy: 0.967000, Test accuracy: 0.967100
Distillation: Epoch : 49, Loss : 1.105893, Accuracy: 0.961000, Test accuracy: 0.967500
Distillation: Epoch : 50, Loss : 1.124328, Accuracy: 0.960000, Test accuracy: 0.968000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.968
Generating confusion matrix for student2
[[ 969.    0.    5.    0.    1.    0.    5.    1.    7.    4.]
 [   1. 1124.    5.    1.    1.    1.    3.   12.    3.    7.]
 [   0.    2. 1005.    8.    5.    0.    0.   20.   10.    1.]
 [   0.    1.    0.  976.    0.    4.    1.    3.    2.    6.]
 [   0.    0.    6.    3.  953.    0.    2.   11.    7.   15.]
 [   2.    0.    0.    6.    0.  875.    7.    1.    3.    4.]
 [   5.    3.    1.    0.    5.    4.  937.    0.    1.    0.]
 [   1.    0.    4.    5.    2.    3.    0.  958.    3.    6.]
 [   2.    5.    5.    8.    3.    2.    3.    2.  921.    4.]
 [   0.    0.    1.    3.   12.    3.    0.   20.   17.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.022208, Accuracy: 0.688000, Test accuracy: 0.727300
Distillation: Epoch : 2, Loss : 1.593393, Accuracy: 0.808000, Test accuracy: 0.823600
Distillation: Epoch : 3, Loss : 1.466028, Accuracy: 0.858000, Test accuracy: 0.861100
Distillation: Epoch : 4, Loss : 1.396093, Accuracy: 0.899000, Test accuracy: 0.881300
Distillation: Epoch : 5, Loss : 1.394022, Accuracy: 0.909000, Test accuracy: 0.896800
Distillation: Epoch : 6, Loss : 1.359728, Accuracy: 0.907000, Test accuracy: 0.906100
Distillation: Epoch : 7, Loss : 1.356649, Accuracy: 0.909000, Test accuracy: 0.912400
Distillation: Epoch : 8, Loss : 1.353484, Accuracy: 0.909000, Test accuracy: 0.918700
Distillation: Epoch : 9, Loss : 1.350065, Accuracy: 0.916000, Test accuracy: 0.923800
Distillation: Epoch : 10, Loss : 1.346431, Accuracy: 0.924000, Test accuracy: 0.927900
Distillation: Epoch : 11, Loss : 1.341342, Accuracy: 0.920000, Test accuracy: 0.931100
Distillation: Epoch : 12, Loss : 1.319992, Accuracy: 0.928000, Test accuracy: 0.935800
Distillation: Epoch : 13, Loss : 1.298736, Accuracy: 0.938000, Test accuracy: 0.938600
Distillation: Epoch : 14, Loss : 1.341028, Accuracy: 0.931000, Test accuracy: 0.941400
Distillation: Epoch : 15, Loss : 1.304186, Accuracy: 0.944000, Test accuracy: 0.944300
Distillation: Epoch : 16, Loss : 1.300296, Accuracy: 0.941000, Test accuracy: 0.946500
Distillation: Epoch : 17, Loss : 1.282850, Accuracy: 0.945000, Test accuracy: 0.947900
Distillation: Epoch : 18, Loss : 1.304586, Accuracy: 0.943000, Test accuracy: 0.950100
Distillation: Epoch : 19, Loss : 1.309132, Accuracy: 0.938000, Test accuracy: 0.951700
Distillation: Epoch : 20, Loss : 1.304844, Accuracy: 0.939000, Test accuracy: 0.953100
Distillation: Epoch : 21, Loss : 1.260274, Accuracy: 0.939000, Test accuracy: 0.954300
Distillation: Epoch : 22, Loss : 1.284261, Accuracy: 0.963000, Test accuracy: 0.954400
Distillation: Epoch : 23, Loss : 1.291723, Accuracy: 0.954000, Test accuracy: 0.956000
Distillation: Epoch : 24, Loss : 1.262549, Accuracy: 0.958000, Test accuracy: 0.956900
Distillation: Epoch : 25, Loss : 1.283602, Accuracy: 0.959000, Test accuracy: 0.957700
Distillation: Epoch : 26, Loss : 1.281748, Accuracy: 0.963000, Test accuracy: 0.958600
Distillation: Epoch : 27, Loss : 1.281718, Accuracy: 0.946000, Test accuracy: 0.959200
Distillation: Epoch : 28, Loss : 1.280622, Accuracy: 0.957000, Test accuracy: 0.959900
Distillation: Epoch : 29, Loss : 1.298349, Accuracy: 0.953000, Test accuracy: 0.960000
Distillation: Epoch : 30, Loss : 1.275252, Accuracy: 0.957000, Test accuracy: 0.960600
Distillation: Epoch : 31, Loss : 1.251368, Accuracy: 0.955000, Test accuracy: 0.961500
Distillation: Epoch : 32, Loss : 1.284544, Accuracy: 0.967000, Test accuracy: 0.961900
Distillation: Epoch : 33, Loss : 1.252730, Accuracy: 0.961000, Test accuracy: 0.962700
Distillation: Epoch : 34, Loss : 1.284597, Accuracy: 0.963000, Test accuracy: 0.962900
Distillation: Epoch : 35, Loss : 1.256231, Accuracy: 0.964000, Test accuracy: 0.963200
Distillation: Epoch : 36, Loss : 1.240863, Accuracy: 0.967000, Test accuracy: 0.963500
Distillation: Epoch : 37, Loss : 1.256309, Accuracy: 0.950000, Test accuracy: 0.963900
Distillation: Epoch : 38, Loss : 1.267785, Accuracy: 0.948000, Test accuracy: 0.964400
Distillation: Epoch : 39, Loss : 1.241268, Accuracy: 0.965000, Test accuracy: 0.965700
Distillation: Epoch : 40, Loss : 1.270090, Accuracy: 0.955000, Test accuracy: 0.965500
Distillation: Epoch : 41, Loss : 1.282583, Accuracy: 0.959000, Test accuracy: 0.965300
Distillation: Epoch : 42, Loss : 1.262977, Accuracy: 0.959000, Test accuracy: 0.967000
Distillation: Epoch : 43, Loss : 1.244560, Accuracy: 0.966000, Test accuracy: 0.966500
Distillation: Epoch : 44, Loss : 1.257753, Accuracy: 0.961000, Test accuracy: 0.966700
Distillation: Epoch : 45, Loss : 1.278430, Accuracy: 0.959000, Test accuracy: 0.967600
Distillation: Epoch : 46, Loss : 1.253318, Accuracy: 0.970000, Test accuracy: 0.967900
Distillation: Epoch : 47, Loss : 1.241817, Accuracy: 0.963000, Test accuracy: 0.967100
Distillation: Epoch : 48, Loss : 1.256364, Accuracy: 0.965000, Test accuracy: 0.968200
Distillation: Epoch : 49, Loss : 1.264349, Accuracy: 0.970000, Test accuracy: 0.968900
Distillation: Epoch : 50, Loss : 1.254698, Accuracy: 0.974000, Test accuracy: 0.969200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9692
Generating confusion matrix for student2
[[ 971.    0.    4.    0.    2.    1.    9.    0.    7.    6.]
 [   2. 1124.    5.    0.    0.    0.    4.    9.    1.    5.]
 [   1.    4. 1006.    8.    4.    1.    0.   18.    7.    0.]
 [   0.    2.    0.  965.    0.    4.    1.    2.    5.    0.]
 [   0.    0.    8.    1.  961.    0.    4.   10.    8.   16.]
 [   0.    0.    0.   17.    0.  869.    4.    0.    4.    5.]
 [   4.    2.    2.    0.    3.    3.  933.    0.    4.    0.]
 [   1.    0.    4.    4.    0.    1.    0.  971.    3.    7.]
 [   1.    3.    2.   11.    2.    6.    3.    2.  926.    4.]
 [   0.    0.    1.    4.   10.    7.    0.   16.    9.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.932335, Accuracy: 0.743000, Test accuracy: 0.783500
Distillation: Epoch : 2, Loss : 1.616721, Accuracy: 0.826000, Test accuracy: 0.838200
Distillation: Epoch : 3, Loss : 1.555669, Accuracy: 0.867000, Test accuracy: 0.871800
Distillation: Epoch : 4, Loss : 1.573720, Accuracy: 0.845000, Test accuracy: 0.886600
Distillation: Epoch : 5, Loss : 1.532447, Accuracy: 0.891000, Test accuracy: 0.893400
Distillation: Epoch : 6, Loss : 1.501588, Accuracy: 0.891000, Test accuracy: 0.899400
Distillation: Epoch : 7, Loss : 1.487942, Accuracy: 0.891000, Test accuracy: 0.904800
Distillation: Epoch : 8, Loss : 1.463850, Accuracy: 0.901000, Test accuracy: 0.906800
Distillation: Epoch : 9, Loss : 1.492842, Accuracy: 0.895000, Test accuracy: 0.912000
Distillation: Epoch : 10, Loss : 1.469694, Accuracy: 0.913000, Test accuracy: 0.914800
Distillation: Epoch : 11, Loss : 1.471333, Accuracy: 0.907000, Test accuracy: 0.918400
Distillation: Epoch : 12, Loss : 1.462323, Accuracy: 0.907000, Test accuracy: 0.920700
Distillation: Epoch : 13, Loss : 1.469580, Accuracy: 0.916000, Test accuracy: 0.924800
Distillation: Epoch : 14, Loss : 1.460398, Accuracy: 0.920000, Test accuracy: 0.927600
Distillation: Epoch : 15, Loss : 1.455058, Accuracy: 0.930000, Test accuracy: 0.929600
Distillation: Epoch : 16, Loss : 1.449467, Accuracy: 0.920000, Test accuracy: 0.932100
Distillation: Epoch : 17, Loss : 1.450886, Accuracy: 0.933000, Test accuracy: 0.934400
Distillation: Epoch : 18, Loss : 1.443248, Accuracy: 0.927000, Test accuracy: 0.935600
Distillation: Epoch : 19, Loss : 1.444659, Accuracy: 0.935000, Test accuracy: 0.938300
Distillation: Epoch : 20, Loss : 1.435675, Accuracy: 0.939000, Test accuracy: 0.939100
Distillation: Epoch : 21, Loss : 1.426008, Accuracy: 0.943000, Test accuracy: 0.941200
Distillation: Epoch : 22, Loss : 1.424785, Accuracy: 0.945000, Test accuracy: 0.942100
Distillation: Epoch : 23, Loss : 1.430751, Accuracy: 0.927000, Test accuracy: 0.943300
Distillation: Epoch : 24, Loss : 1.432721, Accuracy: 0.942000, Test accuracy: 0.944400
Distillation: Epoch : 25, Loss : 1.429505, Accuracy: 0.946000, Test accuracy: 0.944600
Distillation: Epoch : 26, Loss : 1.430052, Accuracy: 0.942000, Test accuracy: 0.944900
Distillation: Epoch : 27, Loss : 1.442573, Accuracy: 0.946000, Test accuracy: 0.946300
Distillation: Epoch : 28, Loss : 1.447263, Accuracy: 0.938000, Test accuracy: 0.948000
Distillation: Epoch : 29, Loss : 1.427897, Accuracy: 0.933000, Test accuracy: 0.948000
Distillation: Epoch : 30, Loss : 1.401432, Accuracy: 0.951000, Test accuracy: 0.948900
Distillation: Epoch : 31, Loss : 1.402729, Accuracy: 0.952000, Test accuracy: 0.949800
Distillation: Epoch : 32, Loss : 1.416995, Accuracy: 0.954000, Test accuracy: 0.951000
Distillation: Epoch : 33, Loss : 1.407139, Accuracy: 0.952000, Test accuracy: 0.950500
Distillation: Epoch : 34, Loss : 1.412216, Accuracy: 0.953000, Test accuracy: 0.951100
Distillation: Epoch : 35, Loss : 1.429418, Accuracy: 0.942000, Test accuracy: 0.951500
Distillation: Epoch : 36, Loss : 1.412934, Accuracy: 0.950000, Test accuracy: 0.951400
Distillation: Epoch : 37, Loss : 1.404409, Accuracy: 0.945000, Test accuracy: 0.952100
Distillation: Epoch : 38, Loss : 1.442434, Accuracy: 0.931000, Test accuracy: 0.952200
Distillation: Epoch : 39, Loss : 1.412857, Accuracy: 0.938000, Test accuracy: 0.953100
Distillation: Epoch : 40, Loss : 1.422002, Accuracy: 0.939000, Test accuracy: 0.953600
Distillation: Epoch : 41, Loss : 1.429071, Accuracy: 0.939000, Test accuracy: 0.953700
Distillation: Epoch : 42, Loss : 1.422736, Accuracy: 0.946000, Test accuracy: 0.954200
Distillation: Epoch : 43, Loss : 1.418752, Accuracy: 0.942000, Test accuracy: 0.954200
Distillation: Epoch : 44, Loss : 1.421435, Accuracy: 0.950000, Test accuracy: 0.954500
Distillation: Epoch : 45, Loss : 1.391625, Accuracy: 0.956000, Test accuracy: 0.955500
Distillation: Epoch : 46, Loss : 1.419781, Accuracy: 0.954000, Test accuracy: 0.955600
Distillation: Epoch : 47, Loss : 1.412654, Accuracy: 0.950000, Test accuracy: 0.956000
Distillation: Epoch : 48, Loss : 1.427310, Accuracy: 0.954000, Test accuracy: 0.956200
Distillation: Epoch : 49, Loss : 1.388057, Accuracy: 0.949000, Test accuracy: 0.956100
Distillation: Epoch : 50, Loss : 1.431435, Accuracy: 0.957000, Test accuracy: 0.956700
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9567
Generating confusion matrix for student2
[[ 967.    0.    8.    4.    0.    4.    6.    2.    6.    6.]
 [   1. 1112.    6.    0.    0.    1.    3.    8.    2.    5.]
 [   1.    3.  983.   11.    6.    1.    3.   19.   17.    2.]
 [   0.    0.    4.  961.    1.   11.    0.    6.    4.   11.]
 [   0.    0.    5.    0.  946.    0.    2.    6.   10.   12.]
 [   2.    2.    0.   10.    1.  854.   20.    4.    6.    7.]
 [   4.    5.    3.    0.    5.    6.  921.    0.    2.    0.]
 [   1.    0.    5.    8.    0.    2.    0.  959.    4.    7.]
 [   4.   13.   17.   10.    4.    9.    3.    3.  909.    4.]
 [   0.    0.    1.    6.   19.    4.    0.   21.   14.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.036014, Accuracy: 0.709000, Test accuracy: 0.750500
Distillation: Epoch : 2, Loss : 1.875359, Accuracy: 0.812000, Test accuracy: 0.828300
Distillation: Epoch : 3, Loss : 1.804980, Accuracy: 0.850000, Test accuracy: 0.857700
Distillation: Epoch : 4, Loss : 1.805812, Accuracy: 0.868000, Test accuracy: 0.869000
Distillation: Epoch : 5, Loss : 1.777005, Accuracy: 0.872000, Test accuracy: 0.876500
Distillation: Epoch : 6, Loss : 1.798724, Accuracy: 0.854000, Test accuracy: 0.882100
Distillation: Epoch : 7, Loss : 1.791096, Accuracy: 0.894000, Test accuracy: 0.886400
Distillation: Epoch : 8, Loss : 1.768520, Accuracy: 0.889000, Test accuracy: 0.889600
Distillation: Epoch : 9, Loss : 1.774255, Accuracy: 0.891000, Test accuracy: 0.893100
Distillation: Epoch : 10, Loss : 1.773713, Accuracy: 0.900000, Test accuracy: 0.894600
Distillation: Epoch : 11, Loss : 1.774303, Accuracy: 0.879000, Test accuracy: 0.897800
Distillation: Epoch : 12, Loss : 1.781847, Accuracy: 0.895000, Test accuracy: 0.898400
Distillation: Epoch : 13, Loss : 1.773080, Accuracy: 0.879000, Test accuracy: 0.899900
Distillation: Epoch : 14, Loss : 1.761981, Accuracy: 0.882000, Test accuracy: 0.902500
Distillation: Epoch : 15, Loss : 1.759874, Accuracy: 0.889000, Test accuracy: 0.902100
Distillation: Epoch : 16, Loss : 1.754504, Accuracy: 0.898000, Test accuracy: 0.903800
Distillation: Epoch : 17, Loss : 1.761696, Accuracy: 0.899000, Test accuracy: 0.906200
Distillation: Epoch : 18, Loss : 1.775270, Accuracy: 0.902000, Test accuracy: 0.907600
Distillation: Epoch : 19, Loss : 1.747488, Accuracy: 0.910000, Test accuracy: 0.909500
Distillation: Epoch : 20, Loss : 1.764537, Accuracy: 0.902000, Test accuracy: 0.911700
Distillation: Epoch : 21, Loss : 1.751813, Accuracy: 0.902000, Test accuracy: 0.914700
Distillation: Epoch : 22, Loss : 1.740796, Accuracy: 0.903000, Test accuracy: 0.915500
Distillation: Epoch : 23, Loss : 1.734646, Accuracy: 0.908000, Test accuracy: 0.917900
Distillation: Epoch : 24, Loss : 1.731938, Accuracy: 0.918000, Test accuracy: 0.920800
Distillation: Epoch : 25, Loss : 1.730478, Accuracy: 0.924000, Test accuracy: 0.923400
Distillation: Epoch : 26, Loss : 1.731784, Accuracy: 0.918000, Test accuracy: 0.925500
Distillation: Epoch : 27, Loss : 1.732477, Accuracy: 0.929000, Test accuracy: 0.929700
Distillation: Epoch : 28, Loss : 1.743647, Accuracy: 0.920000, Test accuracy: 0.930800
Distillation: Epoch : 29, Loss : 1.746579, Accuracy: 0.939000, Test accuracy: 0.934200
Distillation: Epoch : 30, Loss : 1.723360, Accuracy: 0.930000, Test accuracy: 0.935300
Distillation: Epoch : 31, Loss : 1.738306, Accuracy: 0.923000, Test accuracy: 0.938100
Distillation: Epoch : 32, Loss : 1.723803, Accuracy: 0.940000, Test accuracy: 0.940700
Distillation: Epoch : 33, Loss : 1.725700, Accuracy: 0.945000, Test accuracy: 0.941100
Distillation: Epoch : 34, Loss : 1.712701, Accuracy: 0.938000, Test accuracy: 0.942000
Distillation: Epoch : 35, Loss : 1.694475, Accuracy: 0.937000, Test accuracy: 0.944100
Distillation: Epoch : 36, Loss : 1.708202, Accuracy: 0.932000, Test accuracy: 0.945500
Distillation: Epoch : 37, Loss : 1.691418, Accuracy: 0.949000, Test accuracy: 0.946800
Distillation: Epoch : 38, Loss : 1.714873, Accuracy: 0.941000, Test accuracy: 0.948100
Distillation: Epoch : 39, Loss : 1.698046, Accuracy: 0.947000, Test accuracy: 0.948600
Distillation: Epoch : 40, Loss : 1.716955, Accuracy: 0.948000, Test accuracy: 0.949800
Distillation: Epoch : 41, Loss : 1.717581, Accuracy: 0.942000, Test accuracy: 0.950300
Distillation: Epoch : 42, Loss : 1.675136, Accuracy: 0.932000, Test accuracy: 0.950400
Distillation: Epoch : 43, Loss : 1.689177, Accuracy: 0.947000, Test accuracy: 0.951100
Distillation: Epoch : 44, Loss : 1.711196, Accuracy: 0.948000, Test accuracy: 0.952000
Distillation: Epoch : 45, Loss : 1.708355, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 46, Loss : 1.702989, Accuracy: 0.948000, Test accuracy: 0.953600
Distillation: Epoch : 47, Loss : 1.705688, Accuracy: 0.939000, Test accuracy: 0.953700
Distillation: Epoch : 48, Loss : 1.705391, Accuracy: 0.954000, Test accuracy: 0.955500
Distillation: Epoch : 49, Loss : 1.690749, Accuracy: 0.963000, Test accuracy: 0.955900
Distillation: Epoch : 50, Loss : 1.698628, Accuracy: 0.952000, Test accuracy: 0.955800
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9558
Generating confusion matrix for student2
[[ 968.    0.    9.    2.    0.    1.    6.    2.    7.    5.]
 [   1. 1117.    8.    0.    2.    1.    4.   10.    2.    7.]
 [   0.    5.  986.    9.    2.    0.    1.   20.   11.    1.]
 [   0.    0.    2.  966.    0.   16.    0.    6.   11.   14.]
 [   0.    0.    6.    1.  948.    2.    2.   11.    7.   17.]
 [   1.    0.    0.   14.    0.  855.   19.    3.   10.    6.]
 [   6.    5.    3.    0.   10.    7.  923.    0.    0.    0.]
 [   1.    0.    6.    5.    1.    2.    0.  935.    2.    5.]
 [   2.    8.   12.   10.    2.    7.    3.    3.  910.    4.]
 [   1.    0.    0.    3.   17.    1.    0.   38.   14.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.159407, Accuracy: 0.732000, Test accuracy: 0.751400
Distillation: Epoch : 2, Loss : 2.059880, Accuracy: 0.814000, Test accuracy: 0.835100
Distillation: Epoch : 3, Loss : 2.043897, Accuracy: 0.855000, Test accuracy: 0.858200
Distillation: Epoch : 4, Loss : 2.036965, Accuracy: 0.867000, Test accuracy: 0.871300
Distillation: Epoch : 5, Loss : 2.038229, Accuracy: 0.873000, Test accuracy: 0.882000
Distillation: Epoch : 6, Loss : 2.033010, Accuracy: 0.864000, Test accuracy: 0.883800
Distillation: Epoch : 7, Loss : 2.023443, Accuracy: 0.879000, Test accuracy: 0.889300
Distillation: Epoch : 8, Loss : 2.027187, Accuracy: 0.882000, Test accuracy: 0.892000
Distillation: Epoch : 9, Loss : 2.010770, Accuracy: 0.905000, Test accuracy: 0.894800
Distillation: Epoch : 10, Loss : 2.014401, Accuracy: 0.889000, Test accuracy: 0.897300
Distillation: Epoch : 11, Loss : 2.009632, Accuracy: 0.902000, Test accuracy: 0.899700
Distillation: Epoch : 12, Loss : 2.019856, Accuracy: 0.870000, Test accuracy: 0.903400
Distillation: Epoch : 13, Loss : 2.003886, Accuracy: 0.923000, Test accuracy: 0.905000
Distillation: Epoch : 14, Loss : 2.018390, Accuracy: 0.891000, Test accuracy: 0.907400
Distillation: Epoch : 15, Loss : 2.009075, Accuracy: 0.894000, Test accuracy: 0.910800
Distillation: Epoch : 16, Loss : 2.001609, Accuracy: 0.912000, Test accuracy: 0.914400
Distillation: Epoch : 17, Loss : 2.003261, Accuracy: 0.909000, Test accuracy: 0.917500
Distillation: Epoch : 18, Loss : 2.007989, Accuracy: 0.906000, Test accuracy: 0.920800
Distillation: Epoch : 19, Loss : 1.993268, Accuracy: 0.912000, Test accuracy: 0.923100
Distillation: Epoch : 20, Loss : 1.996716, Accuracy: 0.903000, Test accuracy: 0.926700
Distillation: Epoch : 21, Loss : 1.989845, Accuracy: 0.921000, Test accuracy: 0.929200
Distillation: Epoch : 22, Loss : 1.995396, Accuracy: 0.919000, Test accuracy: 0.932100
Distillation: Epoch : 23, Loss : 1.985272, Accuracy: 0.931000, Test accuracy: 0.934700
Distillation: Epoch : 24, Loss : 1.989725, Accuracy: 0.925000, Test accuracy: 0.936900
Distillation: Epoch : 25, Loss : 1.985379, Accuracy: 0.934000, Test accuracy: 0.939200
Distillation: Epoch : 26, Loss : 1.975896, Accuracy: 0.937000, Test accuracy: 0.940100
Distillation: Epoch : 27, Loss : 1.983781, Accuracy: 0.940000, Test accuracy: 0.942900
Distillation: Epoch : 28, Loss : 1.981610, Accuracy: 0.943000, Test accuracy: 0.944200
Distillation: Epoch : 29, Loss : 1.981123, Accuracy: 0.958000, Test accuracy: 0.944800
Distillation: Epoch : 30, Loss : 1.983912, Accuracy: 0.931000, Test accuracy: 0.947100
Distillation: Epoch : 31, Loss : 1.977993, Accuracy: 0.949000, Test accuracy: 0.948700
Distillation: Epoch : 32, Loss : 1.986755, Accuracy: 0.947000, Test accuracy: 0.950400
Distillation: Epoch : 33, Loss : 1.973244, Accuracy: 0.940000, Test accuracy: 0.950200
Distillation: Epoch : 34, Loss : 1.975427, Accuracy: 0.958000, Test accuracy: 0.951000
Distillation: Epoch : 35, Loss : 1.977974, Accuracy: 0.930000, Test accuracy: 0.952500
Distillation: Epoch : 36, Loss : 1.978811, Accuracy: 0.940000, Test accuracy: 0.954100
Distillation: Epoch : 37, Loss : 1.969192, Accuracy: 0.965000, Test accuracy: 0.954400
Distillation: Epoch : 38, Loss : 1.971710, Accuracy: 0.945000, Test accuracy: 0.956100
Distillation: Epoch : 39, Loss : 1.980750, Accuracy: 0.941000, Test accuracy: 0.956000
Distillation: Epoch : 40, Loss : 1.985958, Accuracy: 0.943000, Test accuracy: 0.956700
Distillation: Epoch : 41, Loss : 1.979908, Accuracy: 0.956000, Test accuracy: 0.957800
Distillation: Epoch : 42, Loss : 1.978282, Accuracy: 0.957000, Test accuracy: 0.958500
Distillation: Epoch : 43, Loss : 1.963791, Accuracy: 0.972000, Test accuracy: 0.958500
Distillation: Epoch : 44, Loss : 1.963635, Accuracy: 0.962000, Test accuracy: 0.959100
Distillation: Epoch : 45, Loss : 1.971827, Accuracy: 0.956000, Test accuracy: 0.959600
Distillation: Epoch : 46, Loss : 1.977861, Accuracy: 0.953000, Test accuracy: 0.960500
Distillation: Epoch : 47, Loss : 1.970301, Accuracy: 0.966000, Test accuracy: 0.960800
Distillation: Epoch : 48, Loss : 1.973823, Accuracy: 0.952000, Test accuracy: 0.961300
Distillation: Epoch : 49, Loss : 1.976018, Accuracy: 0.949000, Test accuracy: 0.962000
Distillation: Epoch : 50, Loss : 1.976773, Accuracy: 0.960000, Test accuracy: 0.962300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9623
Generating confusion matrix for student2
[[ 968.    0.    4.    0.    1.    1.    5.    2.    6.    6.]
 [   0. 1124.    8.    1.    1.    1.    3.   14.    3.    6.]
 [   1.    2. 1001.   12.    3.    1.    1.   19.   12.    0.]
 [   1.    1.    0.  971.    0.    4.    1.    4.    6.    3.]
 [   0.    1.    7.    2.  953.    1.    2.   17.    7.   18.]
 [   1.    0.    1.    9.    0.  864.    6.    1.    6.    9.]
 [   7.    5.    2.    0.    5.    5.  936.    0.    2.    2.]
 [   1.    0.    4.    8.    0.    3.    0.  940.    3.    5.]
 [   1.    2.    5.    5.    2.    7.    4.    3.  911.    5.]
 [   0.    0.    0.    2.   17.    5.    0.   28.   18.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.788452, Accuracy: 0.820000, Test accuracy: 0.803000
Distillation: Epoch : 2, Loss : 0.500428, Accuracy: 0.864000, Test accuracy: 0.870500
Distillation: Epoch : 3, Loss : 0.414204, Accuracy: 0.877000, Test accuracy: 0.891600
Distillation: Epoch : 4, Loss : 0.378639, Accuracy: 0.887000, Test accuracy: 0.901200
Distillation: Epoch : 5, Loss : 0.334133, Accuracy: 0.894000, Test accuracy: 0.906500
Distillation: Epoch : 6, Loss : 0.338536, Accuracy: 0.908000, Test accuracy: 0.910600
Distillation: Epoch : 7, Loss : 0.354806, Accuracy: 0.893000, Test accuracy: 0.914200
Distillation: Epoch : 8, Loss : 0.320660, Accuracy: 0.908000, Test accuracy: 0.915900
Distillation: Epoch : 9, Loss : 0.312977, Accuracy: 0.902000, Test accuracy: 0.917400
Distillation: Epoch : 10, Loss : 0.318817, Accuracy: 0.901000, Test accuracy: 0.918000
Distillation: Epoch : 11, Loss : 0.349057, Accuracy: 0.903000, Test accuracy: 0.921600
Distillation: Epoch : 12, Loss : 0.265856, Accuracy: 0.924000, Test accuracy: 0.922100
Distillation: Epoch : 13, Loss : 0.255160, Accuracy: 0.921000, Test accuracy: 0.923100
Distillation: Epoch : 14, Loss : 0.277969, Accuracy: 0.914000, Test accuracy: 0.923700
Distillation: Epoch : 15, Loss : 0.261460, Accuracy: 0.922000, Test accuracy: 0.927100
Distillation: Epoch : 16, Loss : 0.259207, Accuracy: 0.932000, Test accuracy: 0.928200
Distillation: Epoch : 17, Loss : 0.271357, Accuracy: 0.918000, Test accuracy: 0.929500
Distillation: Epoch : 18, Loss : 0.261060, Accuracy: 0.925000, Test accuracy: 0.931300
Distillation: Epoch : 19, Loss : 0.216746, Accuracy: 0.933000, Test accuracy: 0.931300
Distillation: Epoch : 20, Loss : 0.255654, Accuracy: 0.922000, Test accuracy: 0.934100
Distillation: Epoch : 21, Loss : 0.282508, Accuracy: 0.922000, Test accuracy: 0.934300
Distillation: Epoch : 22, Loss : 0.190312, Accuracy: 0.939000, Test accuracy: 0.936700
Distillation: Epoch : 23, Loss : 0.242720, Accuracy: 0.929000, Test accuracy: 0.937400
Distillation: Epoch : 24, Loss : 0.227023, Accuracy: 0.933000, Test accuracy: 0.938400
Distillation: Epoch : 25, Loss : 0.183772, Accuracy: 0.950000, Test accuracy: 0.939700
Distillation: Epoch : 26, Loss : 0.174639, Accuracy: 0.947000, Test accuracy: 0.940200
Distillation: Epoch : 27, Loss : 0.191983, Accuracy: 0.952000, Test accuracy: 0.943400
Distillation: Epoch : 28, Loss : 0.234078, Accuracy: 0.933000, Test accuracy: 0.942700
Distillation: Epoch : 29, Loss : 0.172413, Accuracy: 0.951000, Test accuracy: 0.944800
Distillation: Epoch : 30, Loss : 0.190272, Accuracy: 0.938000, Test accuracy: 0.945100
Distillation: Epoch : 31, Loss : 0.191633, Accuracy: 0.945000, Test accuracy: 0.944800
Distillation: Epoch : 32, Loss : 0.212542, Accuracy: 0.942000, Test accuracy: 0.946300
Distillation: Epoch : 33, Loss : 0.196870, Accuracy: 0.950000, Test accuracy: 0.946400
Distillation: Epoch : 34, Loss : 0.192388, Accuracy: 0.944000, Test accuracy: 0.948100
Distillation: Epoch : 35, Loss : 0.214537, Accuracy: 0.937000, Test accuracy: 0.949900
Distillation: Epoch : 36, Loss : 0.198046, Accuracy: 0.945000, Test accuracy: 0.950600
Distillation: Epoch : 37, Loss : 0.203168, Accuracy: 0.943000, Test accuracy: 0.950700
Distillation: Epoch : 38, Loss : 0.215033, Accuracy: 0.936000, Test accuracy: 0.951100
Distillation: Epoch : 39, Loss : 0.140402, Accuracy: 0.956000, Test accuracy: 0.951000
Distillation: Epoch : 40, Loss : 0.188491, Accuracy: 0.947000, Test accuracy: 0.952800
Distillation: Epoch : 41, Loss : 0.145322, Accuracy: 0.950000, Test accuracy: 0.952700
Distillation: Epoch : 42, Loss : 0.173233, Accuracy: 0.952000, Test accuracy: 0.953100
Distillation: Epoch : 43, Loss : 0.143669, Accuracy: 0.957000, Test accuracy: 0.954000
Distillation: Epoch : 44, Loss : 0.135964, Accuracy: 0.961000, Test accuracy: 0.954600
Distillation: Epoch : 45, Loss : 0.166984, Accuracy: 0.949000, Test accuracy: 0.953000
Distillation: Epoch : 46, Loss : 0.139364, Accuracy: 0.961000, Test accuracy: 0.954300
Distillation: Epoch : 47, Loss : 0.180413, Accuracy: 0.949000, Test accuracy: 0.954800
Distillation: Epoch : 48, Loss : 0.105099, Accuracy: 0.970000, Test accuracy: 0.955200
Distillation: Epoch : 49, Loss : 0.180859, Accuracy: 0.944000, Test accuracy: 0.955800
Distillation: Epoch : 50, Loss : 0.167091, Accuracy: 0.961000, Test accuracy: 0.956500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9565
Generating confusion matrix for student3
[[ 965.    0.    5.    2.    1.    4.    8.    0.    8.    5.]
 [   0. 1112.    7.    0.    2.    2.    3.    7.    3.    7.]
 [   2.    4.  973.    7.    4.    0.    2.   20.    8.    2.]
 [   2.    0.    6.  970.    0.   15.    1.    7.   14.   14.]
 [   1.    0.    3.    1.  944.    1.    5.    1.    6.   12.]
 [   1.    1.    0.    3.    0.  849.    9.    1.    9.    3.]
 [   5.    4.    5.    1.    5.    8.  927.    0.    8.    0.]
 [   1.    1.   10.    9.    3.    1.    1.  968.    6.    9.]
 [   3.   13.   18.   15.    4.    9.    2.    3.  904.    4.]
 [   0.    0.    5.    2.   19.    3.    0.   21.    8.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.362574, Accuracy: 0.800000, Test accuracy: 0.812300
Distillation: Epoch : 2, Loss : 0.636608, Accuracy: 0.871000, Test accuracy: 0.871200
Distillation: Epoch : 3, Loss : 0.441358, Accuracy: 0.892000, Test accuracy: 0.892100
Distillation: Epoch : 4, Loss : 0.442676, Accuracy: 0.879000, Test accuracy: 0.904200
Distillation: Epoch : 5, Loss : 0.305694, Accuracy: 0.931000, Test accuracy: 0.912600
Distillation: Epoch : 6, Loss : 0.324902, Accuracy: 0.897000, Test accuracy: 0.918800
Distillation: Epoch : 7, Loss : 0.299871, Accuracy: 0.914000, Test accuracy: 0.922200
Distillation: Epoch : 8, Loss : 0.270372, Accuracy: 0.928000, Test accuracy: 0.927000
Distillation: Epoch : 9, Loss : 0.268356, Accuracy: 0.937000, Test accuracy: 0.931300
Distillation: Epoch : 10, Loss : 0.238363, Accuracy: 0.931000, Test accuracy: 0.934300
Distillation: Epoch : 11, Loss : 0.248985, Accuracy: 0.934000, Test accuracy: 0.936100
Distillation: Epoch : 12, Loss : 0.256520, Accuracy: 0.937000, Test accuracy: 0.938200
Distillation: Epoch : 13, Loss : 0.252676, Accuracy: 0.939000, Test accuracy: 0.940300
Distillation: Epoch : 14, Loss : 0.223871, Accuracy: 0.936000, Test accuracy: 0.941500
Distillation: Epoch : 15, Loss : 0.203178, Accuracy: 0.948000, Test accuracy: 0.942500
Distillation: Epoch : 16, Loss : 0.240840, Accuracy: 0.943000, Test accuracy: 0.944200
Distillation: Epoch : 17, Loss : 0.235870, Accuracy: 0.938000, Test accuracy: 0.944100
Distillation: Epoch : 18, Loss : 0.198877, Accuracy: 0.953000, Test accuracy: 0.945900
Distillation: Epoch : 19, Loss : 0.226120, Accuracy: 0.940000, Test accuracy: 0.946300
Distillation: Epoch : 20, Loss : 0.209268, Accuracy: 0.945000, Test accuracy: 0.946500
Distillation: Epoch : 21, Loss : 0.194451, Accuracy: 0.943000, Test accuracy: 0.947700
Distillation: Epoch : 22, Loss : 0.216129, Accuracy: 0.944000, Test accuracy: 0.948800
Distillation: Epoch : 23, Loss : 0.258381, Accuracy: 0.939000, Test accuracy: 0.949000
Distillation: Epoch : 24, Loss : 0.242681, Accuracy: 0.934000, Test accuracy: 0.950000
Distillation: Epoch : 25, Loss : 0.182190, Accuracy: 0.951000, Test accuracy: 0.951400
Distillation: Epoch : 26, Loss : 0.180770, Accuracy: 0.956000, Test accuracy: 0.951800
Distillation: Epoch : 27, Loss : 0.168212, Accuracy: 0.959000, Test accuracy: 0.952500
Distillation: Epoch : 28, Loss : 0.202403, Accuracy: 0.953000, Test accuracy: 0.953000
Distillation: Epoch : 29, Loss : 0.202517, Accuracy: 0.933000, Test accuracy: 0.953400
Distillation: Epoch : 30, Loss : 0.157825, Accuracy: 0.956000, Test accuracy: 0.954100
Distillation: Epoch : 31, Loss : 0.181487, Accuracy: 0.960000, Test accuracy: 0.954900
Distillation: Epoch : 32, Loss : 0.154295, Accuracy: 0.958000, Test accuracy: 0.955900
Distillation: Epoch : 33, Loss : 0.216450, Accuracy: 0.942000, Test accuracy: 0.956100
Distillation: Epoch : 34, Loss : 0.183389, Accuracy: 0.946000, Test accuracy: 0.956400
Distillation: Epoch : 35, Loss : 0.223101, Accuracy: 0.933000, Test accuracy: 0.957900
Distillation: Epoch : 36, Loss : 0.178712, Accuracy: 0.957000, Test accuracy: 0.958100
Distillation: Epoch : 37, Loss : 0.151660, Accuracy: 0.965000, Test accuracy: 0.958700
Distillation: Epoch : 38, Loss : 0.163079, Accuracy: 0.961000, Test accuracy: 0.959200
Distillation: Epoch : 39, Loss : 0.165935, Accuracy: 0.948000, Test accuracy: 0.959300
Distillation: Epoch : 40, Loss : 0.169296, Accuracy: 0.956000, Test accuracy: 0.958900
Distillation: Epoch : 41, Loss : 0.155092, Accuracy: 0.965000, Test accuracy: 0.960400
Distillation: Epoch : 42, Loss : 0.149229, Accuracy: 0.963000, Test accuracy: 0.960300
Distillation: Epoch : 43, Loss : 0.147191, Accuracy: 0.966000, Test accuracy: 0.961300
Distillation: Epoch : 44, Loss : 0.172021, Accuracy: 0.956000, Test accuracy: 0.961300
Distillation: Epoch : 45, Loss : 0.148797, Accuracy: 0.958000, Test accuracy: 0.961800
Distillation: Epoch : 46, Loss : 0.152508, Accuracy: 0.960000, Test accuracy: 0.962200
Distillation: Epoch : 47, Loss : 0.195131, Accuracy: 0.952000, Test accuracy: 0.963300
Distillation: Epoch : 48, Loss : 0.167954, Accuracy: 0.954000, Test accuracy: 0.961600
Distillation: Epoch : 49, Loss : 0.145086, Accuracy: 0.961000, Test accuracy: 0.962800
Distillation: Epoch : 50, Loss : 0.196116, Accuracy: 0.955000, Test accuracy: 0.963200
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9632
Generating confusion matrix for student3
[[ 969.    0.    4.    0.    1.    1.    9.    3.    5.   11.]
 [   0. 1120.    2.    0.    1.    1.    3.    5.    2.    7.]
 [   1.    4.  982.   10.    2.    0.    0.   22.   10.    1.]
 [   0.    0.    3.  973.    0.    8.    1.    5.    6.    3.]
 [   0.    1.    5.    0.  947.    0.    6.    2.    4.   13.]
 [   0.    0.    2.    8.    0.  854.    2.    0.    2.    4.]
 [   3.    3.    4.    0.    6.    7.  934.    0.    2.    1.]
 [   2.    0.    8.    4.    2.    2.    0.  969.    7.   11.]
 [   5.    7.   21.   11.    2.   14.    3.    3.  930.    4.]
 [   0.    0.    1.    4.   21.    5.    0.   19.    6.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.668453, Accuracy: 0.725000, Test accuracy: 0.737700
Distillation: Epoch : 2, Loss : 1.019843, Accuracy: 0.805000, Test accuracy: 0.818400
Distillation: Epoch : 3, Loss : 0.814059, Accuracy: 0.834000, Test accuracy: 0.858400
Distillation: Epoch : 4, Loss : 0.682586, Accuracy: 0.882000, Test accuracy: 0.879000
Distillation: Epoch : 5, Loss : 0.662116, Accuracy: 0.890000, Test accuracy: 0.893600
Distillation: Epoch : 6, Loss : 0.642380, Accuracy: 0.896000, Test accuracy: 0.901100
Distillation: Epoch : 7, Loss : 0.651011, Accuracy: 0.896000, Test accuracy: 0.908700
Distillation: Epoch : 8, Loss : 0.649355, Accuracy: 0.886000, Test accuracy: 0.913800
Distillation: Epoch : 9, Loss : 0.605707, Accuracy: 0.898000, Test accuracy: 0.919000
Distillation: Epoch : 10, Loss : 0.566285, Accuracy: 0.921000, Test accuracy: 0.920400
Distillation: Epoch : 11, Loss : 0.596811, Accuracy: 0.907000, Test accuracy: 0.923900
Distillation: Epoch : 12, Loss : 0.532799, Accuracy: 0.922000, Test accuracy: 0.925600
Distillation: Epoch : 13, Loss : 0.581171, Accuracy: 0.900000, Test accuracy: 0.928900
Distillation: Epoch : 14, Loss : 0.504160, Accuracy: 0.935000, Test accuracy: 0.930900
Distillation: Epoch : 15, Loss : 0.550061, Accuracy: 0.922000, Test accuracy: 0.932600
Distillation: Epoch : 16, Loss : 0.543758, Accuracy: 0.930000, Test accuracy: 0.934200
Distillation: Epoch : 17, Loss : 0.519984, Accuracy: 0.932000, Test accuracy: 0.935000
Distillation: Epoch : 18, Loss : 0.518248, Accuracy: 0.938000, Test accuracy: 0.936600
Distillation: Epoch : 19, Loss : 0.545315, Accuracy: 0.924000, Test accuracy: 0.938100
Distillation: Epoch : 20, Loss : 0.506426, Accuracy: 0.938000, Test accuracy: 0.939600
Distillation: Epoch : 21, Loss : 0.537938, Accuracy: 0.928000, Test accuracy: 0.939100
Distillation: Epoch : 22, Loss : 0.520541, Accuracy: 0.942000, Test accuracy: 0.941600
Distillation: Epoch : 23, Loss : 0.529732, Accuracy: 0.933000, Test accuracy: 0.941400
Distillation: Epoch : 24, Loss : 0.483496, Accuracy: 0.946000, Test accuracy: 0.942200
Distillation: Epoch : 25, Loss : 0.492210, Accuracy: 0.942000, Test accuracy: 0.943900
Distillation: Epoch : 26, Loss : 0.502848, Accuracy: 0.950000, Test accuracy: 0.944900
Distillation: Epoch : 27, Loss : 0.493232, Accuracy: 0.940000, Test accuracy: 0.945300
Distillation: Epoch : 28, Loss : 0.492845, Accuracy: 0.947000, Test accuracy: 0.946500
Distillation: Epoch : 29, Loss : 0.501299, Accuracy: 0.948000, Test accuracy: 0.948000
Distillation: Epoch : 30, Loss : 0.510316, Accuracy: 0.947000, Test accuracy: 0.948100
Distillation: Epoch : 31, Loss : 0.523623, Accuracy: 0.936000, Test accuracy: 0.948700
Distillation: Epoch : 32, Loss : 0.520188, Accuracy: 0.932000, Test accuracy: 0.950000
Distillation: Epoch : 33, Loss : 0.521073, Accuracy: 0.951000, Test accuracy: 0.950400
Distillation: Epoch : 34, Loss : 0.490395, Accuracy: 0.952000, Test accuracy: 0.950800
Distillation: Epoch : 35, Loss : 0.468186, Accuracy: 0.959000, Test accuracy: 0.951300
Distillation: Epoch : 36, Loss : 0.463255, Accuracy: 0.955000, Test accuracy: 0.951700
Distillation: Epoch : 37, Loss : 0.503263, Accuracy: 0.934000, Test accuracy: 0.952500
Distillation: Epoch : 38, Loss : 0.458295, Accuracy: 0.956000, Test accuracy: 0.952000
Distillation: Epoch : 39, Loss : 0.467685, Accuracy: 0.950000, Test accuracy: 0.952700
Distillation: Epoch : 40, Loss : 0.515163, Accuracy: 0.927000, Test accuracy: 0.953300
Distillation: Epoch : 41, Loss : 0.487847, Accuracy: 0.947000, Test accuracy: 0.953900
Distillation: Epoch : 42, Loss : 0.474170, Accuracy: 0.957000, Test accuracy: 0.953800
Distillation: Epoch : 43, Loss : 0.487497, Accuracy: 0.941000, Test accuracy: 0.954400
Distillation: Epoch : 44, Loss : 0.489833, Accuracy: 0.938000, Test accuracy: 0.954900
Distillation: Epoch : 45, Loss : 0.451301, Accuracy: 0.955000, Test accuracy: 0.955100
Distillation: Epoch : 46, Loss : 0.478978, Accuracy: 0.952000, Test accuracy: 0.956200
Distillation: Epoch : 47, Loss : 0.482954, Accuracy: 0.949000, Test accuracy: 0.955700
Distillation: Epoch : 48, Loss : 0.482810, Accuracy: 0.947000, Test accuracy: 0.955200
Distillation: Epoch : 49, Loss : 0.489984, Accuracy: 0.945000, Test accuracy: 0.956400
Distillation: Epoch : 50, Loss : 0.456826, Accuracy: 0.960000, Test accuracy: 0.957300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9573
Generating confusion matrix for student3
[[ 969.    0.    7.    1.    1.    3.   10.    2.    8.    8.]
 [   0. 1112.    4.    0.    0.    1.    3.    6.    4.    6.]
 [   0.    3.  981.   11.    3.    0.    3.   25.    8.    1.]
 [   0.    2.    8.  972.    1.   18.    0.    3.   13.    8.]
 [   0.    0.    5.    1.  955.    0.    2.    2.    5.   10.]
 [   2.    0.    1.    6.    0.  842.   10.    0.   14.    5.]
 [   4.    3.    4.    0.    2.    4.  927.    0.    3.    0.]
 [   3.    0.    6.    4.    3.    2.    0.  957.    5.   11.]
 [   2.   15.   16.   10.    2.   17.    3.    3.  906.    8.]
 [   0.    0.    0.    5.   15.    5.    0.   30.    8.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.695899, Accuracy: 0.747000, Test accuracy: 0.751500
Distillation: Epoch : 2, Loss : 1.080849, Accuracy: 0.825000, Test accuracy: 0.822900
Distillation: Epoch : 3, Loss : 0.918585, Accuracy: 0.857000, Test accuracy: 0.856000
Distillation: Epoch : 4, Loss : 0.866076, Accuracy: 0.867000, Test accuracy: 0.874000
Distillation: Epoch : 5, Loss : 0.853562, Accuracy: 0.868000, Test accuracy: 0.884700
Distillation: Epoch : 6, Loss : 0.841468, Accuracy: 0.875000, Test accuracy: 0.893600
Distillation: Epoch : 7, Loss : 0.799981, Accuracy: 0.895000, Test accuracy: 0.896900
Distillation: Epoch : 8, Loss : 0.820824, Accuracy: 0.884000, Test accuracy: 0.900900
Distillation: Epoch : 9, Loss : 0.799588, Accuracy: 0.881000, Test accuracy: 0.902900
Distillation: Epoch : 10, Loss : 0.813004, Accuracy: 0.889000, Test accuracy: 0.906100
Distillation: Epoch : 11, Loss : 0.776358, Accuracy: 0.895000, Test accuracy: 0.906900
Distillation: Epoch : 12, Loss : 0.763842, Accuracy: 0.908000, Test accuracy: 0.907900
Distillation: Epoch : 13, Loss : 0.752756, Accuracy: 0.905000, Test accuracy: 0.908300
Distillation: Epoch : 14, Loss : 0.756771, Accuracy: 0.900000, Test accuracy: 0.910100
Distillation: Epoch : 15, Loss : 0.773537, Accuracy: 0.905000, Test accuracy: 0.912000
Distillation: Epoch : 16, Loss : 0.752136, Accuracy: 0.911000, Test accuracy: 0.913600
Distillation: Epoch : 17, Loss : 0.750218, Accuracy: 0.914000, Test accuracy: 0.913400
Distillation: Epoch : 18, Loss : 0.738301, Accuracy: 0.907000, Test accuracy: 0.915200
Distillation: Epoch : 19, Loss : 0.768366, Accuracy: 0.907000, Test accuracy: 0.916000
Distillation: Epoch : 20, Loss : 0.743634, Accuracy: 0.908000, Test accuracy: 0.918000
Distillation: Epoch : 21, Loss : 0.769397, Accuracy: 0.921000, Test accuracy: 0.917800
Distillation: Epoch : 22, Loss : 0.746519, Accuracy: 0.914000, Test accuracy: 0.919600
Distillation: Epoch : 23, Loss : 0.727489, Accuracy: 0.915000, Test accuracy: 0.921100
Distillation: Epoch : 24, Loss : 0.758075, Accuracy: 0.900000, Test accuracy: 0.921900
Distillation: Epoch : 25, Loss : 0.736811, Accuracy: 0.903000, Test accuracy: 0.921900
Distillation: Epoch : 26, Loss : 0.735344, Accuracy: 0.901000, Test accuracy: 0.922000
Distillation: Epoch : 27, Loss : 0.709592, Accuracy: 0.914000, Test accuracy: 0.923700
Distillation: Epoch : 28, Loss : 0.730315, Accuracy: 0.921000, Test accuracy: 0.924400
Distillation: Epoch : 29, Loss : 0.692823, Accuracy: 0.934000, Test accuracy: 0.924100
Distillation: Epoch : 30, Loss : 0.719597, Accuracy: 0.921000, Test accuracy: 0.926600
Distillation: Epoch : 31, Loss : 0.714446, Accuracy: 0.922000, Test accuracy: 0.926700
Distillation: Epoch : 32, Loss : 0.730346, Accuracy: 0.914000, Test accuracy: 0.927500
Distillation: Epoch : 33, Loss : 0.686482, Accuracy: 0.929000, Test accuracy: 0.928600
Distillation: Epoch : 34, Loss : 0.683503, Accuracy: 0.933000, Test accuracy: 0.928200
Distillation: Epoch : 35, Loss : 0.715557, Accuracy: 0.934000, Test accuracy: 0.928900
Distillation: Epoch : 36, Loss : 0.708373, Accuracy: 0.929000, Test accuracy: 0.930000
Distillation: Epoch : 37, Loss : 0.679488, Accuracy: 0.928000, Test accuracy: 0.931300
Distillation: Epoch : 38, Loss : 0.713643, Accuracy: 0.924000, Test accuracy: 0.932100
Distillation: Epoch : 39, Loss : 0.689764, Accuracy: 0.928000, Test accuracy: 0.932700
Distillation: Epoch : 40, Loss : 0.692497, Accuracy: 0.931000, Test accuracy: 0.932800
Distillation: Epoch : 41, Loss : 0.693267, Accuracy: 0.938000, Test accuracy: 0.934400
Distillation: Epoch : 42, Loss : 0.672936, Accuracy: 0.926000, Test accuracy: 0.935000
Distillation: Epoch : 43, Loss : 0.686157, Accuracy: 0.934000, Test accuracy: 0.935200
Distillation: Epoch : 44, Loss : 0.708030, Accuracy: 0.934000, Test accuracy: 0.935800
Distillation: Epoch : 45, Loss : 0.684829, Accuracy: 0.939000, Test accuracy: 0.936600
Distillation: Epoch : 46, Loss : 0.656889, Accuracy: 0.950000, Test accuracy: 0.938500
Distillation: Epoch : 47, Loss : 0.686239, Accuracy: 0.937000, Test accuracy: 0.938300
Distillation: Epoch : 48, Loss : 0.673327, Accuracy: 0.945000, Test accuracy: 0.940100
Distillation: Epoch : 49, Loss : 0.688381, Accuracy: 0.928000, Test accuracy: 0.940000
Distillation: Epoch : 50, Loss : 0.699741, Accuracy: 0.935000, Test accuracy: 0.941200
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9412
Generating confusion matrix for student3
[[ 964.    0.    7.    4.    1.    7.    5.    2.    7.    5.]
 [   0. 1118.    5.    1.    2.    2.    3.   16.    4.    5.]
 [   0.    4.  966.   16.    5.    1.    5.   19.    6.    0.]
 [   1.    2.   10.  941.    0.   17.    2.    1.   13.    8.]
 [   0.    0.   10.    3.  932.    3.    9.   14.   11.   30.]
 [   4.    2.    1.   17.    0.  814.   13.    3.   22.    3.]
 [   8.    4.    7.    2.    6.   14.  919.    0.    6.    1.]
 [   1.    1.    7.    9.    2.    5.    0.  945.    7.   21.]
 [   1.    4.   15.   14.    6.   23.    2.    0.  887.   10.]
 [   1.    0.    4.    3.   28.    6.    0.   28.   11.  926.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.945303, Accuracy: 0.735000, Test accuracy: 0.747200
Distillation: Epoch : 2, Loss : 1.316875, Accuracy: 0.811000, Test accuracy: 0.828800
Distillation: Epoch : 3, Loss : 1.113475, Accuracy: 0.840000, Test accuracy: 0.858500
Distillation: Epoch : 4, Loss : 0.984497, Accuracy: 0.875000, Test accuracy: 0.878500
Distillation: Epoch : 5, Loss : 1.001923, Accuracy: 0.872000, Test accuracy: 0.893100
Distillation: Epoch : 6, Loss : 0.951801, Accuracy: 0.899000, Test accuracy: 0.902400
Distillation: Epoch : 7, Loss : 0.919807, Accuracy: 0.894000, Test accuracy: 0.907600
Distillation: Epoch : 8, Loss : 0.919443, Accuracy: 0.914000, Test accuracy: 0.913200
Distillation: Epoch : 9, Loss : 0.928841, Accuracy: 0.900000, Test accuracy: 0.916800
Distillation: Epoch : 10, Loss : 0.909129, Accuracy: 0.907000, Test accuracy: 0.918500
Distillation: Epoch : 11, Loss : 0.887046, Accuracy: 0.911000, Test accuracy: 0.921100
Distillation: Epoch : 12, Loss : 0.864949, Accuracy: 0.910000, Test accuracy: 0.924600
Distillation: Epoch : 13, Loss : 0.889065, Accuracy: 0.922000, Test accuracy: 0.926100
Distillation: Epoch : 14, Loss : 0.863812, Accuracy: 0.925000, Test accuracy: 0.928200
Distillation: Epoch : 15, Loss : 0.830103, Accuracy: 0.934000, Test accuracy: 0.929500
Distillation: Epoch : 16, Loss : 0.859826, Accuracy: 0.923000, Test accuracy: 0.932600
Distillation: Epoch : 17, Loss : 0.853144, Accuracy: 0.924000, Test accuracy: 0.934800
Distillation: Epoch : 18, Loss : 0.872972, Accuracy: 0.935000, Test accuracy: 0.936700
Distillation: Epoch : 19, Loss : 0.876218, Accuracy: 0.932000, Test accuracy: 0.939100
Distillation: Epoch : 20, Loss : 0.864662, Accuracy: 0.925000, Test accuracy: 0.940300
Distillation: Epoch : 21, Loss : 0.842731, Accuracy: 0.934000, Test accuracy: 0.942600
Distillation: Epoch : 22, Loss : 0.839945, Accuracy: 0.939000, Test accuracy: 0.944000
Distillation: Epoch : 23, Loss : 0.848077, Accuracy: 0.938000, Test accuracy: 0.944500
Distillation: Epoch : 24, Loss : 0.847857, Accuracy: 0.934000, Test accuracy: 0.946400
Distillation: Epoch : 25, Loss : 0.841869, Accuracy: 0.933000, Test accuracy: 0.948100
Distillation: Epoch : 26, Loss : 0.806879, Accuracy: 0.938000, Test accuracy: 0.948400
Distillation: Epoch : 27, Loss : 0.811264, Accuracy: 0.954000, Test accuracy: 0.949000
Distillation: Epoch : 28, Loss : 0.828253, Accuracy: 0.950000, Test accuracy: 0.949100
Distillation: Epoch : 29, Loss : 0.810607, Accuracy: 0.947000, Test accuracy: 0.950800
Distillation: Epoch : 30, Loss : 0.818726, Accuracy: 0.955000, Test accuracy: 0.951400
Distillation: Epoch : 31, Loss : 0.812478, Accuracy: 0.951000, Test accuracy: 0.952300
Distillation: Epoch : 32, Loss : 0.804943, Accuracy: 0.944000, Test accuracy: 0.953100
Distillation: Epoch : 33, Loss : 0.804627, Accuracy: 0.942000, Test accuracy: 0.954500
Distillation: Epoch : 34, Loss : 0.801873, Accuracy: 0.960000, Test accuracy: 0.954900
Distillation: Epoch : 35, Loss : 0.793475, Accuracy: 0.952000, Test accuracy: 0.955000
Distillation: Epoch : 36, Loss : 0.807981, Accuracy: 0.946000, Test accuracy: 0.955700
Distillation: Epoch : 37, Loss : 0.786102, Accuracy: 0.952000, Test accuracy: 0.956100
Distillation: Epoch : 38, Loss : 0.796194, Accuracy: 0.950000, Test accuracy: 0.955900
Distillation: Epoch : 39, Loss : 0.795824, Accuracy: 0.954000, Test accuracy: 0.956700
Distillation: Epoch : 40, Loss : 0.793284, Accuracy: 0.952000, Test accuracy: 0.957500
Distillation: Epoch : 41, Loss : 0.802513, Accuracy: 0.956000, Test accuracy: 0.957500
Distillation: Epoch : 42, Loss : 0.779355, Accuracy: 0.956000, Test accuracy: 0.958300
Distillation: Epoch : 43, Loss : 0.819617, Accuracy: 0.952000, Test accuracy: 0.958700
Distillation: Epoch : 44, Loss : 0.803822, Accuracy: 0.955000, Test accuracy: 0.958500
Distillation: Epoch : 45, Loss : 0.825009, Accuracy: 0.944000, Test accuracy: 0.959300
Distillation: Epoch : 46, Loss : 0.781637, Accuracy: 0.960000, Test accuracy: 0.958800
Distillation: Epoch : 47, Loss : 0.811544, Accuracy: 0.965000, Test accuracy: 0.959800
Distillation: Epoch : 48, Loss : 0.799911, Accuracy: 0.965000, Test accuracy: 0.960600
Distillation: Epoch : 49, Loss : 0.807141, Accuracy: 0.950000, Test accuracy: 0.960200
Distillation: Epoch : 50, Loss : 0.781663, Accuracy: 0.957000, Test accuracy: 0.960300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9603
Generating confusion matrix for student3
[[ 968.    1.    7.    1.    2.    1.    4.    4.    6.    8.]
 [   1. 1125.    5.    1.    2.    0.    3.   10.    5.    5.]
 [   0.    4.  995.    6.    3.    2.    0.   23.    8.    1.]
 [   1.    0.    6.  969.    0.    7.    1.    3.    7.    1.]
 [   1.    0.    6.    1.  951.    0.    3.    5.    8.   15.]
 [   2.    0.    1.    6.    0.  862.    8.    0.   18.    8.]
 [   3.    3.    1.    0.    5.    4.  936.    0.    3.    1.]
 [   2.    1.    5.    5.    2.    3.    0.  953.    7.   11.]
 [   0.    1.    5.   17.    2.    9.    3.    2.  895.   10.]
 [   2.    0.    1.    4.   15.    4.    0.   28.   17.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.833504, Accuracy: 0.758000, Test accuracy: 0.753100
Distillation: Epoch : 2, Loss : 1.386764, Accuracy: 0.785000, Test accuracy: 0.821900
Distillation: Epoch : 3, Loss : 1.251037, Accuracy: 0.831000, Test accuracy: 0.856700
Distillation: Epoch : 4, Loss : 1.188159, Accuracy: 0.859000, Test accuracy: 0.873300
Distillation: Epoch : 5, Loss : 1.171496, Accuracy: 0.876000, Test accuracy: 0.882900
Distillation: Epoch : 6, Loss : 1.140124, Accuracy: 0.882000, Test accuracy: 0.890200
Distillation: Epoch : 7, Loss : 1.113513, Accuracy: 0.892000, Test accuracy: 0.893800
Distillation: Epoch : 8, Loss : 1.095819, Accuracy: 0.897000, Test accuracy: 0.897200
Distillation: Epoch : 9, Loss : 1.113527, Accuracy: 0.895000, Test accuracy: 0.900100
Distillation: Epoch : 10, Loss : 1.084112, Accuracy: 0.898000, Test accuracy: 0.901900
Distillation: Epoch : 11, Loss : 1.143270, Accuracy: 0.878000, Test accuracy: 0.902300
Distillation: Epoch : 12, Loss : 1.055219, Accuracy: 0.906000, Test accuracy: 0.905200
Distillation: Epoch : 13, Loss : 1.072715, Accuracy: 0.890000, Test accuracy: 0.905700
Distillation: Epoch : 14, Loss : 1.107960, Accuracy: 0.887000, Test accuracy: 0.907600
Distillation: Epoch : 15, Loss : 1.072076, Accuracy: 0.904000, Test accuracy: 0.909500
Distillation: Epoch : 16, Loss : 1.070697, Accuracy: 0.906000, Test accuracy: 0.910100
Distillation: Epoch : 17, Loss : 1.083302, Accuracy: 0.895000, Test accuracy: 0.911400
Distillation: Epoch : 18, Loss : 1.089109, Accuracy: 0.904000, Test accuracy: 0.911500
Distillation: Epoch : 19, Loss : 1.064306, Accuracy: 0.914000, Test accuracy: 0.912100
Distillation: Epoch : 20, Loss : 1.065311, Accuracy: 0.913000, Test accuracy: 0.914000
Distillation: Epoch : 21, Loss : 1.084560, Accuracy: 0.901000, Test accuracy: 0.914800
Distillation: Epoch : 22, Loss : 1.083259, Accuracy: 0.923000, Test accuracy: 0.915700
Distillation: Epoch : 23, Loss : 1.067344, Accuracy: 0.909000, Test accuracy: 0.916700
Distillation: Epoch : 24, Loss : 1.075817, Accuracy: 0.901000, Test accuracy: 0.919300
Distillation: Epoch : 25, Loss : 1.057250, Accuracy: 0.908000, Test accuracy: 0.919600
Distillation: Epoch : 26, Loss : 1.071610, Accuracy: 0.910000, Test accuracy: 0.921300
Distillation: Epoch : 27, Loss : 1.030792, Accuracy: 0.924000, Test accuracy: 0.922200
Distillation: Epoch : 28, Loss : 1.064413, Accuracy: 0.906000, Test accuracy: 0.922300
Distillation: Epoch : 29, Loss : 1.056493, Accuracy: 0.916000, Test accuracy: 0.923700
Distillation: Epoch : 30, Loss : 1.055224, Accuracy: 0.916000, Test accuracy: 0.925300
Distillation: Epoch : 31, Loss : 1.065353, Accuracy: 0.910000, Test accuracy: 0.925800
Distillation: Epoch : 32, Loss : 1.036584, Accuracy: 0.924000, Test accuracy: 0.928800
Distillation: Epoch : 33, Loss : 1.058803, Accuracy: 0.921000, Test accuracy: 0.928600
Distillation: Epoch : 34, Loss : 1.039157, Accuracy: 0.920000, Test accuracy: 0.930000
Distillation: Epoch : 35, Loss : 1.037033, Accuracy: 0.912000, Test accuracy: 0.931400
Distillation: Epoch : 36, Loss : 1.044025, Accuracy: 0.921000, Test accuracy: 0.933600
Distillation: Epoch : 37, Loss : 1.017350, Accuracy: 0.929000, Test accuracy: 0.934700
Distillation: Epoch : 38, Loss : 1.006003, Accuracy: 0.925000, Test accuracy: 0.936100
Distillation: Epoch : 39, Loss : 0.998481, Accuracy: 0.923000, Test accuracy: 0.936700
Distillation: Epoch : 40, Loss : 1.026775, Accuracy: 0.926000, Test accuracy: 0.938400
Distillation: Epoch : 41, Loss : 1.025820, Accuracy: 0.923000, Test accuracy: 0.938600
Distillation: Epoch : 42, Loss : 1.031052, Accuracy: 0.924000, Test accuracy: 0.939600
Distillation: Epoch : 43, Loss : 1.018889, Accuracy: 0.932000, Test accuracy: 0.940700
Distillation: Epoch : 44, Loss : 1.027418, Accuracy: 0.941000, Test accuracy: 0.942100
Distillation: Epoch : 45, Loss : 1.025454, Accuracy: 0.938000, Test accuracy: 0.942600
Distillation: Epoch : 46, Loss : 1.009288, Accuracy: 0.937000, Test accuracy: 0.944200
Distillation: Epoch : 47, Loss : 0.993645, Accuracy: 0.936000, Test accuracy: 0.944900
Distillation: Epoch : 48, Loss : 0.986351, Accuracy: 0.932000, Test accuracy: 0.946100
Distillation: Epoch : 49, Loss : 0.989579, Accuracy: 0.945000, Test accuracy: 0.947100
Distillation: Epoch : 50, Loss : 0.993227, Accuracy: 0.934000, Test accuracy: 0.948800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9488
Generating confusion matrix for student3
[[ 964.    0.    6.    6.    0.    7.    7.    1.    8.    6.]
 [   1. 1110.    4.    0.    3.    2.    3.   17.    8.    7.]
 [   2.    3.  970.   13.    6.    0.    1.   18.    9.    1.]
 [   0.    2.    2.  952.    0.   12.    0.    4.    7.   13.]
 [   0.    1.   10.    3.  940.    0.    6.   11.   15.   32.]
 [   5.    2.    0.   13.    0.  847.    8.    1.   15.    4.]
 [   6.    4.    6.    1.    8.    9.  932.    0.    5.    0.]
 [   1.    0.   12.    8.    0.    3.    0.  943.    3.    6.]
 [   1.   13.   17.   10.    4.   10.    1.    0.  891.    1.]
 [   0.    0.    5.    4.   21.    2.    0.   33.   13.  939.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.926321, Accuracy: 0.732000, Test accuracy: 0.745900
Distillation: Epoch : 2, Loss : 1.459051, Accuracy: 0.823000, Test accuracy: 0.827800
Distillation: Epoch : 3, Loss : 1.377557, Accuracy: 0.842000, Test accuracy: 0.856400
Distillation: Epoch : 4, Loss : 1.346382, Accuracy: 0.864000, Test accuracy: 0.870800
Distillation: Epoch : 5, Loss : 1.260413, Accuracy: 0.888000, Test accuracy: 0.882000
Distillation: Epoch : 6, Loss : 1.277640, Accuracy: 0.873000, Test accuracy: 0.885900
Distillation: Epoch : 7, Loss : 1.289946, Accuracy: 0.868000, Test accuracy: 0.890500
Distillation: Epoch : 8, Loss : 1.296646, Accuracy: 0.865000, Test accuracy: 0.894600
Distillation: Epoch : 9, Loss : 1.290859, Accuracy: 0.872000, Test accuracy: 0.895600
Distillation: Epoch : 10, Loss : 1.264505, Accuracy: 0.885000, Test accuracy: 0.898400
Distillation: Epoch : 11, Loss : 1.236824, Accuracy: 0.905000, Test accuracy: 0.900900
Distillation: Epoch : 12, Loss : 1.248666, Accuracy: 0.907000, Test accuracy: 0.902700
Distillation: Epoch : 13, Loss : 1.262771, Accuracy: 0.896000, Test accuracy: 0.903300
Distillation: Epoch : 14, Loss : 1.235554, Accuracy: 0.904000, Test accuracy: 0.904600
Distillation: Epoch : 15, Loss : 1.239035, Accuracy: 0.894000, Test accuracy: 0.905500
Distillation: Epoch : 16, Loss : 1.259629, Accuracy: 0.895000, Test accuracy: 0.907200
Distillation: Epoch : 17, Loss : 1.227757, Accuracy: 0.900000, Test accuracy: 0.908900
Distillation: Epoch : 18, Loss : 1.234868, Accuracy: 0.904000, Test accuracy: 0.910700
Distillation: Epoch : 19, Loss : 1.234185, Accuracy: 0.893000, Test accuracy: 0.909500
Distillation: Epoch : 20, Loss : 1.206682, Accuracy: 0.898000, Test accuracy: 0.910000
Distillation: Epoch : 21, Loss : 1.236880, Accuracy: 0.908000, Test accuracy: 0.911400
Distillation: Epoch : 22, Loss : 1.238161, Accuracy: 0.923000, Test accuracy: 0.912000
Distillation: Epoch : 23, Loss : 1.204084, Accuracy: 0.915000, Test accuracy: 0.913600
Distillation: Epoch : 24, Loss : 1.230028, Accuracy: 0.911000, Test accuracy: 0.914200
Distillation: Epoch : 25, Loss : 1.204676, Accuracy: 0.904000, Test accuracy: 0.916200
Distillation: Epoch : 26, Loss : 1.207938, Accuracy: 0.914000, Test accuracy: 0.916100
Distillation: Epoch : 27, Loss : 1.228681, Accuracy: 0.906000, Test accuracy: 0.917800
Distillation: Epoch : 28, Loss : 1.212072, Accuracy: 0.908000, Test accuracy: 0.917400
Distillation: Epoch : 29, Loss : 1.210991, Accuracy: 0.910000, Test accuracy: 0.918900
Distillation: Epoch : 30, Loss : 1.236619, Accuracy: 0.911000, Test accuracy: 0.920900
Distillation: Epoch : 31, Loss : 1.218069, Accuracy: 0.902000, Test accuracy: 0.920200
Distillation: Epoch : 32, Loss : 1.195377, Accuracy: 0.924000, Test accuracy: 0.920700
Distillation: Epoch : 33, Loss : 1.213324, Accuracy: 0.920000, Test accuracy: 0.921500
Distillation: Epoch : 34, Loss : 1.204701, Accuracy: 0.917000, Test accuracy: 0.922500
Distillation: Epoch : 35, Loss : 1.193428, Accuracy: 0.919000, Test accuracy: 0.924200
Distillation: Epoch : 36, Loss : 1.192893, Accuracy: 0.926000, Test accuracy: 0.923900
Distillation: Epoch : 37, Loss : 1.199600, Accuracy: 0.918000, Test accuracy: 0.924800
Distillation: Epoch : 38, Loss : 1.209647, Accuracy: 0.923000, Test accuracy: 0.926600
Distillation: Epoch : 39, Loss : 1.214800, Accuracy: 0.909000, Test accuracy: 0.927600
Distillation: Epoch : 40, Loss : 1.189994, Accuracy: 0.920000, Test accuracy: 0.928500
Distillation: Epoch : 41, Loss : 1.188241, Accuracy: 0.913000, Test accuracy: 0.929400
Distillation: Epoch : 42, Loss : 1.178242, Accuracy: 0.923000, Test accuracy: 0.930700
Distillation: Epoch : 43, Loss : 1.202735, Accuracy: 0.920000, Test accuracy: 0.930900
Distillation: Epoch : 44, Loss : 1.177553, Accuracy: 0.939000, Test accuracy: 0.932600
Distillation: Epoch : 45, Loss : 1.178303, Accuracy: 0.922000, Test accuracy: 0.933700
Distillation: Epoch : 46, Loss : 1.181243, Accuracy: 0.935000, Test accuracy: 0.933800
Distillation: Epoch : 47, Loss : 1.164208, Accuracy: 0.941000, Test accuracy: 0.936700
Distillation: Epoch : 48, Loss : 1.148481, Accuracy: 0.926000, Test accuracy: 0.937400
Distillation: Epoch : 49, Loss : 1.192282, Accuracy: 0.927000, Test accuracy: 0.938700
Distillation: Epoch : 50, Loss : 1.176332, Accuracy: 0.943000, Test accuracy: 0.939700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9397
Generating confusion matrix for student3
[[ 965.    0.   11.    6.    0.    7.    9.    1.    8.    7.]
 [   0. 1113.    7.    2.    1.    2.    3.   20.    7.    7.]
 [   1.    4.  948.   17.    9.    1.    4.   20.    8.    0.]
 [   1.    2.    4.  941.    0.   13.    0.    5.    9.   12.]
 [   0.    0.   17.    2.  930.    6.    9.   17.   14.   36.]
 [   3.    4.    0.   15.    0.  834.   16.    2.   14.    3.]
 [   7.    4.   10.    3.    8.    8.  915.    0.    7.    1.]
 [   1.    0.   11.    8.    1.    4.    0.  929.    5.    8.]
 [   2.    8.   21.   12.    7.   13.    2.    1.  890.    3.]
 [   0.    0.    3.    4.   26.    4.    0.   33.   12.  932.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.113657, Accuracy: 0.690000, Test accuracy: 0.698300
Distillation: Epoch : 2, Loss : 1.683814, Accuracy: 0.772000, Test accuracy: 0.809600
Distillation: Epoch : 3, Loss : 1.492863, Accuracy: 0.834000, Test accuracy: 0.843700
Distillation: Epoch : 4, Loss : 1.422069, Accuracy: 0.859000, Test accuracy: 0.870500
Distillation: Epoch : 5, Loss : 1.402372, Accuracy: 0.886000, Test accuracy: 0.883800
Distillation: Epoch : 6, Loss : 1.412228, Accuracy: 0.883000, Test accuracy: 0.892500
Distillation: Epoch : 7, Loss : 1.385884, Accuracy: 0.902000, Test accuracy: 0.898500
Distillation: Epoch : 8, Loss : 1.368901, Accuracy: 0.895000, Test accuracy: 0.903500
Distillation: Epoch : 9, Loss : 1.355692, Accuracy: 0.894000, Test accuracy: 0.906000
Distillation: Epoch : 10, Loss : 1.368273, Accuracy: 0.886000, Test accuracy: 0.910300
Distillation: Epoch : 11, Loss : 1.366497, Accuracy: 0.906000, Test accuracy: 0.912100
Distillation: Epoch : 12, Loss : 1.390452, Accuracy: 0.886000, Test accuracy: 0.915700
Distillation: Epoch : 13, Loss : 1.358696, Accuracy: 0.904000, Test accuracy: 0.918500
Distillation: Epoch : 14, Loss : 1.363652, Accuracy: 0.907000, Test accuracy: 0.920400
Distillation: Epoch : 15, Loss : 1.357220, Accuracy: 0.913000, Test accuracy: 0.921600
Distillation: Epoch : 16, Loss : 1.336682, Accuracy: 0.923000, Test accuracy: 0.923200
Distillation: Epoch : 17, Loss : 1.359232, Accuracy: 0.881000, Test accuracy: 0.926100
Distillation: Epoch : 18, Loss : 1.329033, Accuracy: 0.921000, Test accuracy: 0.927800
Distillation: Epoch : 19, Loss : 1.338203, Accuracy: 0.912000, Test accuracy: 0.929700
Distillation: Epoch : 20, Loss : 1.310826, Accuracy: 0.922000, Test accuracy: 0.930800
Distillation: Epoch : 21, Loss : 1.328845, Accuracy: 0.923000, Test accuracy: 0.932400
Distillation: Epoch : 22, Loss : 1.336275, Accuracy: 0.917000, Test accuracy: 0.933800
Distillation: Epoch : 23, Loss : 1.332219, Accuracy: 0.927000, Test accuracy: 0.935500
Distillation: Epoch : 24, Loss : 1.313966, Accuracy: 0.924000, Test accuracy: 0.936600
Distillation: Epoch : 25, Loss : 1.320276, Accuracy: 0.926000, Test accuracy: 0.936700
Distillation: Epoch : 26, Loss : 1.304622, Accuracy: 0.937000, Test accuracy: 0.938300
Distillation: Epoch : 27, Loss : 1.291727, Accuracy: 0.939000, Test accuracy: 0.938600
Distillation: Epoch : 28, Loss : 1.305919, Accuracy: 0.942000, Test accuracy: 0.940100
Distillation: Epoch : 29, Loss : 1.310808, Accuracy: 0.938000, Test accuracy: 0.940900
Distillation: Epoch : 30, Loss : 1.297834, Accuracy: 0.942000, Test accuracy: 0.941900
Distillation: Epoch : 31, Loss : 1.309681, Accuracy: 0.941000, Test accuracy: 0.942200
Distillation: Epoch : 32, Loss : 1.293153, Accuracy: 0.935000, Test accuracy: 0.943500
Distillation: Epoch : 33, Loss : 1.302478, Accuracy: 0.939000, Test accuracy: 0.944400
Distillation: Epoch : 34, Loss : 1.307510, Accuracy: 0.943000, Test accuracy: 0.945300
Distillation: Epoch : 35, Loss : 1.299831, Accuracy: 0.937000, Test accuracy: 0.946300
Distillation: Epoch : 36, Loss : 1.320063, Accuracy: 0.930000, Test accuracy: 0.947400
Distillation: Epoch : 37, Loss : 1.303571, Accuracy: 0.943000, Test accuracy: 0.946900
Distillation: Epoch : 38, Loss : 1.274817, Accuracy: 0.949000, Test accuracy: 0.948500
Distillation: Epoch : 39, Loss : 1.296529, Accuracy: 0.941000, Test accuracy: 0.948500
Distillation: Epoch : 40, Loss : 1.318985, Accuracy: 0.945000, Test accuracy: 0.949300
Distillation: Epoch : 41, Loss : 1.272670, Accuracy: 0.951000, Test accuracy: 0.950000
Distillation: Epoch : 42, Loss : 1.277164, Accuracy: 0.945000, Test accuracy: 0.950500
Distillation: Epoch : 43, Loss : 1.304412, Accuracy: 0.947000, Test accuracy: 0.951600
Distillation: Epoch : 44, Loss : 1.272740, Accuracy: 0.959000, Test accuracy: 0.951800
Distillation: Epoch : 45, Loss : 1.290290, Accuracy: 0.936000, Test accuracy: 0.953000
Distillation: Epoch : 46, Loss : 1.282634, Accuracy: 0.958000, Test accuracy: 0.953000
Distillation: Epoch : 47, Loss : 1.313388, Accuracy: 0.952000, Test accuracy: 0.953900
Distillation: Epoch : 48, Loss : 1.312704, Accuracy: 0.940000, Test accuracy: 0.954100
Distillation: Epoch : 49, Loss : 1.288459, Accuracy: 0.940000, Test accuracy: 0.953300
Distillation: Epoch : 50, Loss : 1.274413, Accuracy: 0.952000, Test accuracy: 0.953300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9533
Generating confusion matrix for student3
[[ 972.    1.    7.    3.    1.    3.    8.    2.    9.    5.]
 [   1. 1113.    6.    0.    1.    1.    4.   12.    5.    6.]
 [   0.    5.  987.    9.    3.    0.    0.   19.   11.    3.]
 [   0.    0.    2.  965.    0.   13.    1.    3.   22.   14.]
 [   0.    1.    8.    1.  951.    0.    2.   12.   12.   10.]
 [   1.    0.    0.    8.    0.  850.   16.    2.   11.    4.]
 [   5.    4.    4.    1.    6.   10.  919.    0.    4.    0.]
 [   1.    1.    4.    5.    1.    2.    0.  947.    5.   14.]
 [   0.   10.   12.   14.    3.   10.    8.    0.  878.    2.]
 [   0.    0.    2.    4.   16.    3.    0.   31.   17.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.039527, Accuracy: 0.703000, Test accuracy: 0.709900
Distillation: Epoch : 2, Loss : 1.671661, Accuracy: 0.808000, Test accuracy: 0.808100
Distillation: Epoch : 3, Loss : 1.633290, Accuracy: 0.830000, Test accuracy: 0.844700
Distillation: Epoch : 4, Loss : 1.570388, Accuracy: 0.852000, Test accuracy: 0.865800
Distillation: Epoch : 5, Loss : 1.524500, Accuracy: 0.881000, Test accuracy: 0.877900
Distillation: Epoch : 6, Loss : 1.540722, Accuracy: 0.885000, Test accuracy: 0.886700
Distillation: Epoch : 7, Loss : 1.507556, Accuracy: 0.879000, Test accuracy: 0.891900
Distillation: Epoch : 8, Loss : 1.511443, Accuracy: 0.880000, Test accuracy: 0.896100
Distillation: Epoch : 9, Loss : 1.478751, Accuracy: 0.914000, Test accuracy: 0.900200
Distillation: Epoch : 10, Loss : 1.483939, Accuracy: 0.908000, Test accuracy: 0.903200
Distillation: Epoch : 11, Loss : 1.484614, Accuracy: 0.897000, Test accuracy: 0.906300
Distillation: Epoch : 12, Loss : 1.490759, Accuracy: 0.907000, Test accuracy: 0.909900
Distillation: Epoch : 13, Loss : 1.468192, Accuracy: 0.916000, Test accuracy: 0.911800
Distillation: Epoch : 14, Loss : 1.485681, Accuracy: 0.901000, Test accuracy: 0.913600
Distillation: Epoch : 15, Loss : 1.492808, Accuracy: 0.889000, Test accuracy: 0.915200
Distillation: Epoch : 16, Loss : 1.470999, Accuracy: 0.907000, Test accuracy: 0.916500
Distillation: Epoch : 17, Loss : 1.487871, Accuracy: 0.906000, Test accuracy: 0.919100
Distillation: Epoch : 18, Loss : 1.485356, Accuracy: 0.906000, Test accuracy: 0.921300
Distillation: Epoch : 19, Loss : 1.454643, Accuracy: 0.915000, Test accuracy: 0.923900
Distillation: Epoch : 20, Loss : 1.453862, Accuracy: 0.930000, Test accuracy: 0.926000
Distillation: Epoch : 21, Loss : 1.455187, Accuracy: 0.917000, Test accuracy: 0.927800
Distillation: Epoch : 22, Loss : 1.432282, Accuracy: 0.928000, Test accuracy: 0.929600
Distillation: Epoch : 23, Loss : 1.426481, Accuracy: 0.924000, Test accuracy: 0.931000
Distillation: Epoch : 24, Loss : 1.424256, Accuracy: 0.921000, Test accuracy: 0.931300
Distillation: Epoch : 25, Loss : 1.429646, Accuracy: 0.936000, Test accuracy: 0.933800
Distillation: Epoch : 26, Loss : 1.453677, Accuracy: 0.934000, Test accuracy: 0.934900
Distillation: Epoch : 27, Loss : 1.415439, Accuracy: 0.947000, Test accuracy: 0.937100
Distillation: Epoch : 28, Loss : 1.412464, Accuracy: 0.944000, Test accuracy: 0.937900
Distillation: Epoch : 29, Loss : 1.424051, Accuracy: 0.933000, Test accuracy: 0.939400
Distillation: Epoch : 30, Loss : 1.443116, Accuracy: 0.933000, Test accuracy: 0.940100
Distillation: Epoch : 31, Loss : 1.437733, Accuracy: 0.925000, Test accuracy: 0.941400
Distillation: Epoch : 32, Loss : 1.457187, Accuracy: 0.937000, Test accuracy: 0.942600
Distillation: Epoch : 33, Loss : 1.415308, Accuracy: 0.929000, Test accuracy: 0.942700
Distillation: Epoch : 34, Loss : 1.413901, Accuracy: 0.935000, Test accuracy: 0.944900
Distillation: Epoch : 35, Loss : 1.391546, Accuracy: 0.939000, Test accuracy: 0.945200
Distillation: Epoch : 36, Loss : 1.433576, Accuracy: 0.935000, Test accuracy: 0.946100
Distillation: Epoch : 37, Loss : 1.426778, Accuracy: 0.935000, Test accuracy: 0.947500
Distillation: Epoch : 38, Loss : 1.413091, Accuracy: 0.952000, Test accuracy: 0.948400
Distillation: Epoch : 39, Loss : 1.427283, Accuracy: 0.942000, Test accuracy: 0.949800
Distillation: Epoch : 40, Loss : 1.404271, Accuracy: 0.943000, Test accuracy: 0.950100
Distillation: Epoch : 41, Loss : 1.396595, Accuracy: 0.942000, Test accuracy: 0.950900
Distillation: Epoch : 42, Loss : 1.411127, Accuracy: 0.953000, Test accuracy: 0.950700
Distillation: Epoch : 43, Loss : 1.415225, Accuracy: 0.949000, Test accuracy: 0.951600
Distillation: Epoch : 44, Loss : 1.407442, Accuracy: 0.959000, Test accuracy: 0.952300
Distillation: Epoch : 45, Loss : 1.419730, Accuracy: 0.942000, Test accuracy: 0.951300
Distillation: Epoch : 46, Loss : 1.435489, Accuracy: 0.942000, Test accuracy: 0.952900
Distillation: Epoch : 47, Loss : 1.410483, Accuracy: 0.953000, Test accuracy: 0.953600
Distillation: Epoch : 48, Loss : 1.403507, Accuracy: 0.964000, Test accuracy: 0.953900
Distillation: Epoch : 49, Loss : 1.422067, Accuracy: 0.937000, Test accuracy: 0.954400
Distillation: Epoch : 50, Loss : 1.414644, Accuracy: 0.950000, Test accuracy: 0.955100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9551
Generating confusion matrix for student3
[[ 970.    0.    8.    2.    0.    2.   10.    2.    8.    6.]
 [   1. 1116.    6.    0.    2.    1.    4.    9.    5.    7.]
 [   0.    4.  987.    8.    6.    0.    3.   21.   15.    1.]
 [   0.    0.    2.  962.    0.   10.    0.    4.    8.   15.]
 [   0.    0.    5.    2.  947.    0.    3.    9.   13.   14.]
 [   2.    0.    0.   16.    0.  860.   15.    2.    9.    5.]
 [   6.    4.    4.    1.    5.    5.  920.    0.    2.    0.]
 [   1.    0.    4.    5.    1.    2.    0.  945.    7.    9.]
 [   0.   11.   15.    8.    3.    8.    3.    3.  893.    1.]
 [   0.    0.    1.    6.   18.    4.    0.   33.   14.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.112378, Accuracy: 0.714000, Test accuracy: 0.722400
Distillation: Epoch : 2, Loss : 1.899403, Accuracy: 0.809000, Test accuracy: 0.818100
Distillation: Epoch : 3, Loss : 1.829401, Accuracy: 0.839000, Test accuracy: 0.850800
Distillation: Epoch : 4, Loss : 1.814340, Accuracy: 0.854000, Test accuracy: 0.864700
Distillation: Epoch : 5, Loss : 1.795629, Accuracy: 0.864000, Test accuracy: 0.872500
Distillation: Epoch : 6, Loss : 1.802116, Accuracy: 0.875000, Test accuracy: 0.878800
Distillation: Epoch : 7, Loss : 1.782725, Accuracy: 0.885000, Test accuracy: 0.882300
Distillation: Epoch : 8, Loss : 1.787365, Accuracy: 0.876000, Test accuracy: 0.885100
Distillation: Epoch : 9, Loss : 1.800430, Accuracy: 0.872000, Test accuracy: 0.887800
Distillation: Epoch : 10, Loss : 1.781724, Accuracy: 0.890000, Test accuracy: 0.890200
Distillation: Epoch : 11, Loss : 1.785352, Accuracy: 0.871000, Test accuracy: 0.891300
Distillation: Epoch : 12, Loss : 1.763213, Accuracy: 0.887000, Test accuracy: 0.894900
Distillation: Epoch : 13, Loss : 1.761177, Accuracy: 0.889000, Test accuracy: 0.895200
Distillation: Epoch : 14, Loss : 1.760673, Accuracy: 0.891000, Test accuracy: 0.896200
Distillation: Epoch : 15, Loss : 1.789433, Accuracy: 0.891000, Test accuracy: 0.897400
Distillation: Epoch : 16, Loss : 1.778021, Accuracy: 0.903000, Test accuracy: 0.898000
Distillation: Epoch : 17, Loss : 1.754441, Accuracy: 0.898000, Test accuracy: 0.899100
Distillation: Epoch : 18, Loss : 1.774534, Accuracy: 0.884000, Test accuracy: 0.899400
Distillation: Epoch : 19, Loss : 1.756797, Accuracy: 0.900000, Test accuracy: 0.900400
Distillation: Epoch : 20, Loss : 1.744576, Accuracy: 0.894000, Test accuracy: 0.903400
Distillation: Epoch : 21, Loss : 1.775687, Accuracy: 0.877000, Test accuracy: 0.904000
Distillation: Epoch : 22, Loss : 1.756577, Accuracy: 0.891000, Test accuracy: 0.904900
Distillation: Epoch : 23, Loss : 1.754968, Accuracy: 0.904000, Test accuracy: 0.906600
Distillation: Epoch : 24, Loss : 1.763528, Accuracy: 0.903000, Test accuracy: 0.906900
Distillation: Epoch : 25, Loss : 1.771294, Accuracy: 0.891000, Test accuracy: 0.907900
Distillation: Epoch : 26, Loss : 1.761033, Accuracy: 0.901000, Test accuracy: 0.909300
Distillation: Epoch : 27, Loss : 1.754181, Accuracy: 0.893000, Test accuracy: 0.910400
Distillation: Epoch : 28, Loss : 1.752436, Accuracy: 0.904000, Test accuracy: 0.911200
Distillation: Epoch : 29, Loss : 1.756538, Accuracy: 0.907000, Test accuracy: 0.915700
Distillation: Epoch : 30, Loss : 1.752236, Accuracy: 0.901000, Test accuracy: 0.916100
Distillation: Epoch : 31, Loss : 1.756948, Accuracy: 0.905000, Test accuracy: 0.916000
Distillation: Epoch : 32, Loss : 1.743746, Accuracy: 0.917000, Test accuracy: 0.918800
Distillation: Epoch : 33, Loss : 1.742381, Accuracy: 0.919000, Test accuracy: 0.919300
Distillation: Epoch : 34, Loss : 1.736409, Accuracy: 0.919000, Test accuracy: 0.921700
Distillation: Epoch : 35, Loss : 1.742344, Accuracy: 0.922000, Test accuracy: 0.923300
Distillation: Epoch : 36, Loss : 1.752639, Accuracy: 0.923000, Test accuracy: 0.926000
Distillation: Epoch : 37, Loss : 1.741354, Accuracy: 0.917000, Test accuracy: 0.926900
Distillation: Epoch : 38, Loss : 1.739103, Accuracy: 0.929000, Test accuracy: 0.927700
Distillation: Epoch : 39, Loss : 1.732280, Accuracy: 0.920000, Test accuracy: 0.929900
Distillation: Epoch : 40, Loss : 1.745137, Accuracy: 0.918000, Test accuracy: 0.930700
Distillation: Epoch : 41, Loss : 1.727945, Accuracy: 0.926000, Test accuracy: 0.932700
Distillation: Epoch : 42, Loss : 1.717672, Accuracy: 0.931000, Test accuracy: 0.933800
Distillation: Epoch : 43, Loss : 1.722541, Accuracy: 0.930000, Test accuracy: 0.935200
Distillation: Epoch : 44, Loss : 1.718994, Accuracy: 0.941000, Test accuracy: 0.936700
Distillation: Epoch : 45, Loss : 1.733234, Accuracy: 0.931000, Test accuracy: 0.938300
Distillation: Epoch : 46, Loss : 1.714067, Accuracy: 0.935000, Test accuracy: 0.938900
Distillation: Epoch : 47, Loss : 1.730069, Accuracy: 0.934000, Test accuracy: 0.940500
Distillation: Epoch : 48, Loss : 1.726176, Accuracy: 0.937000, Test accuracy: 0.940600
Distillation: Epoch : 49, Loss : 1.711599, Accuracy: 0.950000, Test accuracy: 0.941300
Distillation: Epoch : 50, Loss : 1.731564, Accuracy: 0.932000, Test accuracy: 0.942000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.942
Generating confusion matrix for student3
[[ 960.    0.   11.    3.    1.    7.    4.    2.    7.   11.]
 [   1. 1120.    4.    3.    0.    4.    2.   18.    7.    6.]
 [   3.    6.  969.   20.    2.    0.    2.   22.   11.    2.]
 [   1.    0.   10.  936.    0.    9.    0.    3.   12.    3.]
 [   1.    2.   17.    1.  945.    1.    9.   26.    7.   23.]
 [   4.    1.    0.   16.    0.  824.   13.    1.   27.    3.]
 [   7.    4.    1.    1.    9.   13.  926.    0.    1.    1.]
 [   1.    0.    4.   11.    1.    5.    0.  915.    2.   10.]
 [   1.    2.   15.   18.    5.   21.    2.    2.  884.    9.]
 [   1.    0.    1.    1.   19.    8.    0.   39.   16.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.215985, Accuracy: 0.603000, Test accuracy: 0.616500
Distillation: Epoch : 2, Loss : 2.087661, Accuracy: 0.786000, Test accuracy: 0.793300
Distillation: Epoch : 3, Loss : 2.054957, Accuracy: 0.801000, Test accuracy: 0.836400
Distillation: Epoch : 4, Loss : 2.035015, Accuracy: 0.865000, Test accuracy: 0.852900
Distillation: Epoch : 5, Loss : 2.038142, Accuracy: 0.861000, Test accuracy: 0.862900
Distillation: Epoch : 6, Loss : 2.035065, Accuracy: 0.864000, Test accuracy: 0.869700
Distillation: Epoch : 7, Loss : 2.031081, Accuracy: 0.871000, Test accuracy: 0.875100
Distillation: Epoch : 8, Loss : 2.033446, Accuracy: 0.870000, Test accuracy: 0.879800
Distillation: Epoch : 9, Loss : 2.035667, Accuracy: 0.875000, Test accuracy: 0.881800
Distillation: Epoch : 10, Loss : 2.038332, Accuracy: 0.863000, Test accuracy: 0.884600
Distillation: Epoch : 11, Loss : 2.024986, Accuracy: 0.886000, Test accuracy: 0.886700
Distillation: Epoch : 12, Loss : 2.015540, Accuracy: 0.890000, Test accuracy: 0.888500
Distillation: Epoch : 13, Loss : 2.015738, Accuracy: 0.879000, Test accuracy: 0.889900
Distillation: Epoch : 14, Loss : 2.017012, Accuracy: 0.874000, Test accuracy: 0.890900
Distillation: Epoch : 15, Loss : 2.030998, Accuracy: 0.867000, Test accuracy: 0.893100
Distillation: Epoch : 16, Loss : 2.019773, Accuracy: 0.895000, Test accuracy: 0.892400
Distillation: Epoch : 17, Loss : 2.017055, Accuracy: 0.888000, Test accuracy: 0.893300
Distillation: Epoch : 18, Loss : 2.014163, Accuracy: 0.880000, Test accuracy: 0.895300
Distillation: Epoch : 19, Loss : 2.017787, Accuracy: 0.885000, Test accuracy: 0.893900
Distillation: Epoch : 20, Loss : 2.013103, Accuracy: 0.883000, Test accuracy: 0.896500
Distillation: Epoch : 21, Loss : 2.014192, Accuracy: 0.890000, Test accuracy: 0.895400
Distillation: Epoch : 22, Loss : 2.013301, Accuracy: 0.891000, Test accuracy: 0.897600
Distillation: Epoch : 23, Loss : 2.019911, Accuracy: 0.888000, Test accuracy: 0.896800
Distillation: Epoch : 24, Loss : 2.020425, Accuracy: 0.898000, Test accuracy: 0.899000
Distillation: Epoch : 25, Loss : 2.021863, Accuracy: 0.895000, Test accuracy: 0.900400
Distillation: Epoch : 26, Loss : 2.010389, Accuracy: 0.886000, Test accuracy: 0.901700
Distillation: Epoch : 27, Loss : 2.009784, Accuracy: 0.892000, Test accuracy: 0.903100
Distillation: Epoch : 28, Loss : 2.001332, Accuracy: 0.879000, Test accuracy: 0.905100
Distillation: Epoch : 29, Loss : 2.017834, Accuracy: 0.896000, Test accuracy: 0.905300
Distillation: Epoch : 30, Loss : 1.999740, Accuracy: 0.921000, Test accuracy: 0.906300
Distillation: Epoch : 31, Loss : 2.017729, Accuracy: 0.894000, Test accuracy: 0.910100
Distillation: Epoch : 32, Loss : 2.012203, Accuracy: 0.901000, Test accuracy: 0.911900
Distillation: Epoch : 33, Loss : 2.002999, Accuracy: 0.900000, Test accuracy: 0.913900
Distillation: Epoch : 34, Loss : 1.990359, Accuracy: 0.916000, Test accuracy: 0.915700
Distillation: Epoch : 35, Loss : 2.002709, Accuracy: 0.907000, Test accuracy: 0.916800
Distillation: Epoch : 36, Loss : 1.996489, Accuracy: 0.921000, Test accuracy: 0.918200
Distillation: Epoch : 37, Loss : 2.003908, Accuracy: 0.904000, Test accuracy: 0.920200
Distillation: Epoch : 38, Loss : 1.994597, Accuracy: 0.908000, Test accuracy: 0.921000
Distillation: Epoch : 39, Loss : 2.003739, Accuracy: 0.897000, Test accuracy: 0.922100
Distillation: Epoch : 40, Loss : 2.003318, Accuracy: 0.917000, Test accuracy: 0.924500
Distillation: Epoch : 41, Loss : 1.976655, Accuracy: 0.918000, Test accuracy: 0.924800
Distillation: Epoch : 42, Loss : 1.996946, Accuracy: 0.900000, Test accuracy: 0.925900
Distillation: Epoch : 43, Loss : 1.999881, Accuracy: 0.918000, Test accuracy: 0.927200
Distillation: Epoch : 44, Loss : 1.999888, Accuracy: 0.910000, Test accuracy: 0.930800
Distillation: Epoch : 45, Loss : 1.983559, Accuracy: 0.913000, Test accuracy: 0.931800
Distillation: Epoch : 46, Loss : 2.000408, Accuracy: 0.913000, Test accuracy: 0.933900
Distillation: Epoch : 47, Loss : 1.994781, Accuracy: 0.903000, Test accuracy: 0.934000
Distillation: Epoch : 48, Loss : 1.984520, Accuracy: 0.925000, Test accuracy: 0.935700
Distillation: Epoch : 49, Loss : 1.990144, Accuracy: 0.943000, Test accuracy: 0.937400
Distillation: Epoch : 50, Loss : 1.982857, Accuracy: 0.927000, Test accuracy: 0.937100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9371
Generating confusion matrix for student3
[[ 966.    0.    9.    6.    0.    7.   16.    4.    6.    6.]
 [   0. 1109.    8.    2.    0.    2.    3.   14.    7.    5.]
 [   1.    4.  945.   17.    6.    1.    1.   20.   15.    1.]
 [   0.    5.    7.  936.    0.   21.    0.    6.   10.   12.]
 [   0.    0.   12.    2.  949.    0.    5.   18.   15.   34.]
 [   0.    3.    0.   21.    1.  828.   16.    1.   15.    9.]
 [   9.    4.   15.    2.    5.   10.  914.    0.    7.    0.]
 [   1.    0.   10.    6.    0.    2.    0.  914.    6.    9.]
 [   3.   10.   24.   10.    4.   17.    3.    4.  880.    3.]
 [   0.    0.    2.    8.   17.    4.    0.   47.   13.  930.]]
</confusion_matrix>
