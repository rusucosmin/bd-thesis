Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.145189, Accuracy: 0.976000, Test accuracy: 0.964900
Starting training epoch 1
Epoch : 2, Loss : 0.128899, Accuracy: 0.952000, Test accuracy: 0.975100
Starting training epoch 2
Epoch : 3, Loss : 0.046958, Accuracy: 0.980000, Test accuracy: 0.980200
Starting training epoch 3
Epoch : 4, Loss : 0.037933, Accuracy: 0.988000, Test accuracy: 0.984700
Starting training epoch 4
Epoch : 5, Loss : 0.023132, Accuracy: 0.992000, Test accuracy: 0.988000
Starting training epoch 5
Epoch : 6, Loss : 0.013275, Accuracy: 0.996000, Test accuracy: 0.989300
Starting training epoch 6
Epoch : 7, Loss : 0.016209, Accuracy: 0.992000, Test accuracy: 0.988800
Starting training epoch 7
Epoch : 8, Loss : 0.016608, Accuracy: 0.992000, Test accuracy: 0.990100
Starting training epoch 8
Epoch : 9, Loss : 0.008689, Accuracy: 1.000000, Test accuracy: 0.991400
Starting training epoch 9
Epoch : 10, Loss : 0.005702, Accuracy: 1.000000, Test accuracy: 0.990300
Starting training epoch 10
Epoch : 11, Loss : 0.002733, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 11
Epoch : 12, Loss : 0.001370, Accuracy: 1.000000, Test accuracy: 0.991100
Starting training epoch 12
Epoch : 13, Loss : 0.007203, Accuracy: 0.996000, Test accuracy: 0.991600
Starting training epoch 13
Epoch : 14, Loss : 0.002136, Accuracy: 1.000000, Test accuracy: 0.991700
Starting training epoch 14
Epoch : 15, Loss : 0.003418, Accuracy: 1.000000, Test accuracy: 0.990900
Starting training epoch 15
Epoch : 16, Loss : 0.001119, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 16
Epoch : 17, Loss : 0.001045, Accuracy: 1.000000, Test accuracy: 0.991500
Starting training epoch 17
Epoch : 18, Loss : 0.001623, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 18
Epoch : 19, Loss : 0.001885, Accuracy: 1.000000, Test accuracy: 0.991400
Starting training epoch 19
Epoch : 20, Loss : 0.001741, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 20
Epoch : 21, Loss : 0.006294, Accuracy: 0.996000, Test accuracy: 0.992200
Starting training epoch 21
Epoch : 22, Loss : 0.000687, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 22
Epoch : 23, Loss : 0.000420, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 23
Epoch : 24, Loss : 0.000512, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 24
Epoch : 25, Loss : 0.001444, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 25
Epoch : 26, Loss : 0.000060, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 26
Epoch : 27, Loss : 0.000217, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 27
Epoch : 28, Loss : 0.001520, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 28
Epoch : 29, Loss : 0.000697, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 29
Epoch : 30, Loss : 0.000313, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 30
Epoch : 31, Loss : 0.000562, Accuracy: 1.000000, Test accuracy: 0.991700
Starting training epoch 31
Epoch : 32, Loss : 0.000156, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 32
Epoch : 33, Loss : 0.000100, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 33
Epoch : 34, Loss : 0.000080, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 34
Epoch : 35, Loss : 0.000552, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 35
Epoch : 36, Loss : 0.000078, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 36
Epoch : 37, Loss : 0.000252, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 37
Epoch : 38, Loss : 0.000136, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 38
Epoch : 39, Loss : 0.000365, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 39
Epoch : 40, Loss : 0.000042, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 40
Epoch : 41, Loss : 0.000228, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 41
Epoch : 42, Loss : 0.000013, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 42
Epoch : 43, Loss : 0.000042, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 43
Epoch : 44, Loss : 0.000364, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 44
Epoch : 45, Loss : 0.000789, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 45
Epoch : 46, Loss : 0.000026, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 46
Epoch : 47, Loss : 0.000044, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 47
Epoch : 48, Loss : 0.000032, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 48
Epoch : 49, Loss : 0.000012, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 49
Epoch : 50, Loss : 0.000048, Accuracy: 1.000000, Test accuracy: 0.992900
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 0.842478, Accuracy: 0.768000, Test accuracy: 0.804300
Starting training epoch 1
Epoch : 2, Loss : 0.357031, Accuracy: 0.900000, Test accuracy: 0.881800
Starting training epoch 2
Epoch : 3, Loss : 0.372550, Accuracy: 0.872000, Test accuracy: 0.899200
Starting training epoch 3
Epoch : 4, Loss : 0.425251, Accuracy: 0.864000, Test accuracy: 0.909600
Starting training epoch 4
Epoch : 5, Loss : 0.336033, Accuracy: 0.908000, Test accuracy: 0.918600
Starting training epoch 5
Epoch : 6, Loss : 0.235871, Accuracy: 0.936000, Test accuracy: 0.921500
Starting training epoch 6
Epoch : 7, Loss : 0.243823, Accuracy: 0.944000, Test accuracy: 0.926100
Starting training epoch 7
Epoch : 8, Loss : 0.164533, Accuracy: 0.956000, Test accuracy: 0.928700
Starting training epoch 8
Epoch : 9, Loss : 0.200611, Accuracy: 0.936000, Test accuracy: 0.931200
Starting training epoch 9
Epoch : 10, Loss : 0.220544, Accuracy: 0.944000, Test accuracy: 0.933900
Starting training epoch 10
Epoch : 11, Loss : 0.212505, Accuracy: 0.952000, Test accuracy: 0.935300
Starting training epoch 11
Epoch : 12, Loss : 0.286647, Accuracy: 0.936000, Test accuracy: 0.937900
Starting training epoch 12
Epoch : 13, Loss : 0.344864, Accuracy: 0.888000, Test accuracy: 0.940700
Starting training epoch 13
Epoch : 14, Loss : 0.307630, Accuracy: 0.920000, Test accuracy: 0.941300
Starting training epoch 14
Epoch : 15, Loss : 0.159786, Accuracy: 0.940000, Test accuracy: 0.942800
Starting training epoch 15
Epoch : 16, Loss : 0.135398, Accuracy: 0.956000, Test accuracy: 0.946900
Starting training epoch 16
Epoch : 17, Loss : 0.200829, Accuracy: 0.956000, Test accuracy: 0.949300
Starting training epoch 17
Epoch : 18, Loss : 0.163521, Accuracy: 0.952000, Test accuracy: 0.950200
Starting training epoch 18
Epoch : 19, Loss : 0.165665, Accuracy: 0.948000, Test accuracy: 0.950300
Starting training epoch 19
Epoch : 20, Loss : 0.119021, Accuracy: 0.960000, Test accuracy: 0.951400
Starting training epoch 20
Epoch : 21, Loss : 0.186552, Accuracy: 0.948000, Test accuracy: 0.951700
Starting training epoch 21
Epoch : 22, Loss : 0.147141, Accuracy: 0.952000, Test accuracy: 0.953800
Starting training epoch 22
Epoch : 23, Loss : 0.139329, Accuracy: 0.952000, Test accuracy: 0.956600
Starting training epoch 23
Epoch : 24, Loss : 0.112285, Accuracy: 0.976000, Test accuracy: 0.957300
Starting training epoch 24
Epoch : 25, Loss : 0.146924, Accuracy: 0.952000, Test accuracy: 0.957400
Starting training epoch 25
Epoch : 26, Loss : 0.139596, Accuracy: 0.956000, Test accuracy: 0.959100
Starting training epoch 26
Epoch : 27, Loss : 0.116969, Accuracy: 0.972000, Test accuracy: 0.960500
Starting training epoch 27
Epoch : 28, Loss : 0.109911, Accuracy: 0.968000, Test accuracy: 0.959500
Starting training epoch 28
Epoch : 29, Loss : 0.114095, Accuracy: 0.960000, Test accuracy: 0.961000
Starting training epoch 29
Epoch : 30, Loss : 0.168051, Accuracy: 0.956000, Test accuracy: 0.962100
Starting training epoch 30
Epoch : 31, Loss : 0.074568, Accuracy: 0.980000, Test accuracy: 0.963200
Starting training epoch 31
Epoch : 32, Loss : 0.095471, Accuracy: 0.980000, Test accuracy: 0.963300
Starting training epoch 32
Epoch : 33, Loss : 0.161539, Accuracy: 0.924000, Test accuracy: 0.963800
Starting training epoch 33
Epoch : 34, Loss : 0.098648, Accuracy: 0.964000, Test accuracy: 0.963900
Starting training epoch 34
Epoch : 35, Loss : 0.129983, Accuracy: 0.948000, Test accuracy: 0.963900
Starting training epoch 35
Epoch : 36, Loss : 0.118077, Accuracy: 0.972000, Test accuracy: 0.964200
Starting training epoch 36
Epoch : 37, Loss : 0.138072, Accuracy: 0.952000, Test accuracy: 0.964100
Starting training epoch 37
Epoch : 38, Loss : 0.107300, Accuracy: 0.968000, Test accuracy: 0.964100
Starting training epoch 38
Epoch : 39, Loss : 0.102744, Accuracy: 0.972000, Test accuracy: 0.965500
Starting training epoch 39
Epoch : 40, Loss : 0.107925, Accuracy: 0.964000, Test accuracy: 0.964600
Starting training epoch 40
Epoch : 41, Loss : 0.076245, Accuracy: 0.964000, Test accuracy: 0.965800
Starting training epoch 41
Epoch : 42, Loss : 0.124514, Accuracy: 0.972000, Test accuracy: 0.965800
Starting training epoch 42
Epoch : 43, Loss : 0.110397, Accuracy: 0.972000, Test accuracy: 0.966100
Starting training epoch 43
Epoch : 44, Loss : 0.098557, Accuracy: 0.968000, Test accuracy: 0.966500
Starting training epoch 44
Epoch : 45, Loss : 0.166652, Accuracy: 0.972000, Test accuracy: 0.966400
Starting training epoch 45
Epoch : 46, Loss : 0.138674, Accuracy: 0.960000, Test accuracy: 0.967400
Starting training epoch 46
Epoch : 47, Loss : 0.070946, Accuracy: 0.980000, Test accuracy: 0.966500
Starting training epoch 47
Epoch : 48, Loss : 0.112722, Accuracy: 0.968000, Test accuracy: 0.968200
Starting training epoch 48
Epoch : 49, Loss : 0.099692, Accuracy: 0.960000, Test accuracy: 0.968200
Starting training epoch 49
Epoch : 50, Loss : 0.060493, Accuracy: 0.972000, Test accuracy: 0.968200
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 0.954683, Accuracy: 0.760000, Test accuracy: 0.793000
Starting training opoch 1
Epoch : 2, Loss : 0.485203, Accuracy: 0.844000, Test accuracy: 0.875500
Starting training opoch 2
Epoch : 3, Loss : 0.381037, Accuracy: 0.888000, Test accuracy: 0.893100
Starting training opoch 3
Epoch : 4, Loss : 0.446435, Accuracy: 0.868000, Test accuracy: 0.901400
Starting training opoch 4
Epoch : 5, Loss : 0.374231, Accuracy: 0.868000, Test accuracy: 0.907300
Starting training opoch 5
Epoch : 6, Loss : 0.365895, Accuracy: 0.908000, Test accuracy: 0.911800
Starting training opoch 6
Epoch : 7, Loss : 0.430917, Accuracy: 0.876000, Test accuracy: 0.914800
Starting training opoch 7
Epoch : 8, Loss : 0.272074, Accuracy: 0.928000, Test accuracy: 0.917200
Starting training opoch 8
Epoch : 9, Loss : 0.262475, Accuracy: 0.908000, Test accuracy: 0.921400
Starting training opoch 9
Epoch : 10, Loss : 0.259432, Accuracy: 0.932000, Test accuracy: 0.923300
Starting training opoch 10
Epoch : 11, Loss : 0.231207, Accuracy: 0.928000, Test accuracy: 0.928000
Starting training opoch 11
Epoch : 12, Loss : 0.241593, Accuracy: 0.928000, Test accuracy: 0.929000
Starting training opoch 12
Epoch : 13, Loss : 0.275772, Accuracy: 0.912000, Test accuracy: 0.931600
Starting training opoch 13
Epoch : 14, Loss : 0.208053, Accuracy: 0.944000, Test accuracy: 0.936000
Starting training opoch 14
Epoch : 15, Loss : 0.221519, Accuracy: 0.932000, Test accuracy: 0.936000
Starting training opoch 15
Epoch : 16, Loss : 0.214521, Accuracy: 0.956000, Test accuracy: 0.939400
Starting training opoch 16
Epoch : 17, Loss : 0.290939, Accuracy: 0.928000, Test accuracy: 0.941100
Starting training opoch 17
Epoch : 18, Loss : 0.181786, Accuracy: 0.952000, Test accuracy: 0.942600
Starting training opoch 18
Epoch : 19, Loss : 0.247654, Accuracy: 0.920000, Test accuracy: 0.944700
Starting training opoch 19
Epoch : 20, Loss : 0.158821, Accuracy: 0.952000, Test accuracy: 0.946200
Starting training opoch 20
Epoch : 21, Loss : 0.186374, Accuracy: 0.944000, Test accuracy: 0.947900
Starting training opoch 21
Epoch : 22, Loss : 0.164776, Accuracy: 0.948000, Test accuracy: 0.948700
Starting training opoch 22
Epoch : 23, Loss : 0.156457, Accuracy: 0.948000, Test accuracy: 0.950900
Starting training opoch 23
Epoch : 24, Loss : 0.208390, Accuracy: 0.932000, Test accuracy: 0.951500
Starting training opoch 24
Epoch : 25, Loss : 0.161214, Accuracy: 0.956000, Test accuracy: 0.953100
Starting training opoch 25
Epoch : 26, Loss : 0.229855, Accuracy: 0.940000, Test accuracy: 0.955100
Starting training opoch 26
Epoch : 27, Loss : 0.166430, Accuracy: 0.964000, Test accuracy: 0.953800
Starting training opoch 27
Epoch : 28, Loss : 0.164306, Accuracy: 0.968000, Test accuracy: 0.954200
Starting training opoch 28
Epoch : 29, Loss : 0.095911, Accuracy: 0.968000, Test accuracy: 0.957200
Starting training opoch 29
Epoch : 30, Loss : 0.176735, Accuracy: 0.952000, Test accuracy: 0.957400
Starting training opoch 30
Epoch : 31, Loss : 0.157258, Accuracy: 0.956000, Test accuracy: 0.956100
Starting training opoch 31
Epoch : 32, Loss : 0.162587, Accuracy: 0.960000, Test accuracy: 0.958500
Starting training opoch 32
Epoch : 33, Loss : 0.124708, Accuracy: 0.964000, Test accuracy: 0.958600
Starting training opoch 33
Epoch : 34, Loss : 0.269415, Accuracy: 0.920000, Test accuracy: 0.958700
Starting training opoch 34
Epoch : 35, Loss : 0.138401, Accuracy: 0.964000, Test accuracy: 0.960300
Starting training opoch 35
Epoch : 36, Loss : 0.149322, Accuracy: 0.944000, Test accuracy: 0.958800
Starting training opoch 36
Epoch : 37, Loss : 0.122749, Accuracy: 0.956000, Test accuracy: 0.959900
Starting training opoch 37
Epoch : 38, Loss : 0.188914, Accuracy: 0.960000, Test accuracy: 0.960800
Starting training opoch 38
Epoch : 39, Loss : 0.114363, Accuracy: 0.968000, Test accuracy: 0.960000
Starting training opoch 39
Epoch : 40, Loss : 0.129386, Accuracy: 0.964000, Test accuracy: 0.959400
Starting training opoch 40
Epoch : 41, Loss : 0.154998, Accuracy: 0.960000, Test accuracy: 0.961400
Starting training opoch 41
Epoch : 42, Loss : 0.151156, Accuracy: 0.972000, Test accuracy: 0.961800
Starting training opoch 42
Epoch : 43, Loss : 0.108314, Accuracy: 0.968000, Test accuracy: 0.962800
Starting training opoch 43
Epoch : 44, Loss : 0.115311, Accuracy: 0.968000, Test accuracy: 0.963600
Starting training opoch 44
Epoch : 45, Loss : 0.136163, Accuracy: 0.964000, Test accuracy: 0.963400
Starting training opoch 45
Epoch : 46, Loss : 0.119423, Accuracy: 0.956000, Test accuracy: 0.962800
Starting training opoch 46
Epoch : 47, Loss : 0.191825, Accuracy: 0.952000, Test accuracy: 0.963800
Starting training opoch 47
Epoch : 48, Loss : 0.113189, Accuracy: 0.968000, Test accuracy: 0.963700
Starting training opoch 48
Epoch : 49, Loss : 0.204989, Accuracy: 0.956000, Test accuracy: 0.964600
Starting training opoch 49
Epoch : 50, Loss : 0.114753, Accuracy: 0.960000, Test accuracy: 0.963200
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.704222, Accuracy: 0.812000, Test accuracy: 0.827500
Starting training epoch 1
Epoch : 2, Loss : 0.336725, Accuracy: 0.900000, Test accuracy: 0.882700
Starting training epoch 2
Epoch : 3, Loss : 0.277441, Accuracy: 0.940000, Test accuracy: 0.902800
Starting training epoch 3
Epoch : 4, Loss : 0.300911, Accuracy: 0.920000, Test accuracy: 0.916000
Starting training epoch 4
Epoch : 5, Loss : 0.347941, Accuracy: 0.888000, Test accuracy: 0.923500
Starting training epoch 5
Epoch : 6, Loss : 0.193165, Accuracy: 0.948000, Test accuracy: 0.931800
Starting training epoch 6
Epoch : 7, Loss : 0.160000, Accuracy: 0.960000, Test accuracy: 0.938100
Starting training epoch 7
Epoch : 8, Loss : 0.275407, Accuracy: 0.916000, Test accuracy: 0.944700
Starting training epoch 8
Epoch : 9, Loss : 0.126156, Accuracy: 0.968000, Test accuracy: 0.948500
Starting training epoch 9
Epoch : 10, Loss : 0.186960, Accuracy: 0.944000, Test accuracy: 0.953700
Starting training epoch 10
Epoch : 11, Loss : 0.188641, Accuracy: 0.936000, Test accuracy: 0.957600
Starting training epoch 11
Epoch : 12, Loss : 0.102933, Accuracy: 0.972000, Test accuracy: 0.958200
Starting training epoch 12
Epoch : 13, Loss : 0.177010, Accuracy: 0.932000, Test accuracy: 0.960500
Starting training epoch 13
Epoch : 14, Loss : 0.125878, Accuracy: 0.944000, Test accuracy: 0.962300
Starting training epoch 14
Epoch : 15, Loss : 0.134760, Accuracy: 0.968000, Test accuracy: 0.965700
Starting training epoch 15
Epoch : 16, Loss : 0.185478, Accuracy: 0.964000, Test accuracy: 0.966000
Starting training epoch 16
Epoch : 17, Loss : 0.104513, Accuracy: 0.976000, Test accuracy: 0.967500
Starting training epoch 17
Epoch : 18, Loss : 0.158172, Accuracy: 0.960000, Test accuracy: 0.968100
Starting training epoch 18
Epoch : 19, Loss : 0.170328, Accuracy: 0.952000, Test accuracy: 0.969600
Starting training epoch 19
Epoch : 20, Loss : 0.160351, Accuracy: 0.944000, Test accuracy: 0.969500
Starting training epoch 20
Epoch : 21, Loss : 0.115753, Accuracy: 0.964000, Test accuracy: 0.970800
Starting training epoch 21
Epoch : 22, Loss : 0.198173, Accuracy: 0.952000, Test accuracy: 0.972000
Starting training epoch 22
Epoch : 23, Loss : 0.066993, Accuracy: 0.980000, Test accuracy: 0.971000
Starting training epoch 23
Epoch : 24, Loss : 0.104207, Accuracy: 0.968000, Test accuracy: 0.972200
Starting training epoch 24
Epoch : 25, Loss : 0.086224, Accuracy: 0.968000, Test accuracy: 0.972900
Starting training epoch 25
Epoch : 26, Loss : 0.146510, Accuracy: 0.960000, Test accuracy: 0.973800
Starting training epoch 26
Epoch : 27, Loss : 0.135162, Accuracy: 0.960000, Test accuracy: 0.974400
Starting training epoch 27
Epoch : 28, Loss : 0.062139, Accuracy: 0.984000, Test accuracy: 0.973900
Starting training epoch 28
Epoch : 29, Loss : 0.137995, Accuracy: 0.968000, Test accuracy: 0.973400
Starting training epoch 29
Epoch : 30, Loss : 0.151340, Accuracy: 0.948000, Test accuracy: 0.975100
Starting training epoch 30
Epoch : 31, Loss : 0.084606, Accuracy: 0.972000, Test accuracy: 0.975200
Starting training epoch 31
Epoch : 32, Loss : 0.049255, Accuracy: 0.988000, Test accuracy: 0.975400
Starting training epoch 32
Epoch : 33, Loss : 0.038920, Accuracy: 0.996000, Test accuracy: 0.974500
Starting training epoch 33
Epoch : 34, Loss : 0.202415, Accuracy: 0.936000, Test accuracy: 0.975600
Starting training epoch 34
Epoch : 35, Loss : 0.072355, Accuracy: 0.968000, Test accuracy: 0.976800
Starting training epoch 35
Epoch : 36, Loss : 0.032610, Accuracy: 0.992000, Test accuracy: 0.977000
Starting training epoch 36
Epoch : 37, Loss : 0.106324, Accuracy: 0.980000, Test accuracy: 0.977800
Starting training epoch 37
Epoch : 38, Loss : 0.053158, Accuracy: 0.984000, Test accuracy: 0.977200
Starting training epoch 38
Epoch : 39, Loss : 0.118454, Accuracy: 0.976000, Test accuracy: 0.978200
Starting training epoch 39
Epoch : 40, Loss : 0.078116, Accuracy: 0.972000, Test accuracy: 0.977700
Starting training epoch 40
Epoch : 41, Loss : 0.129375, Accuracy: 0.956000, Test accuracy: 0.978100
Starting training epoch 41
Epoch : 42, Loss : 0.078023, Accuracy: 0.980000, Test accuracy: 0.978000
Starting training epoch 42
Epoch : 43, Loss : 0.080083, Accuracy: 0.972000, Test accuracy: 0.977600
Starting training epoch 43
Epoch : 44, Loss : 0.112033, Accuracy: 0.956000, Test accuracy: 0.977800
Starting training epoch 44
Epoch : 45, Loss : 0.066537, Accuracy: 0.980000, Test accuracy: 0.978600
Starting training epoch 45
Epoch : 46, Loss : 0.058558, Accuracy: 0.976000, Test accuracy: 0.978200
Starting training epoch 46
Epoch : 47, Loss : 0.041439, Accuracy: 0.980000, Test accuracy: 0.978600
Starting training epoch 47
Epoch : 48, Loss : 0.072839, Accuracy: 0.976000, Test accuracy: 0.978600
Starting training epoch 48
Epoch : 49, Loss : 0.072251, Accuracy: 0.968000, Test accuracy: 0.978000
Starting training epoch 49
Epoch : 50, Loss : 0.037557, Accuracy: 0.992000, Test accuracy: 0.978400
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.574951, Accuracy: 0.888000, Test accuracy: 0.838200
Starting training opoch 1
Epoch : 2, Loss : 0.467427, Accuracy: 0.876000, Test accuracy: 0.886500
Starting training opoch 2
Epoch : 3, Loss : 0.356273, Accuracy: 0.900000, Test accuracy: 0.899500
Starting training opoch 3
Epoch : 4, Loss : 0.324754, Accuracy: 0.920000, Test accuracy: 0.907300
Starting training opoch 4
Epoch : 5, Loss : 0.294696, Accuracy: 0.920000, Test accuracy: 0.910400
Starting training opoch 5
Epoch : 6, Loss : 0.339168, Accuracy: 0.904000, Test accuracy: 0.910500
Starting training opoch 6
Epoch : 7, Loss : 0.250297, Accuracy: 0.920000, Test accuracy: 0.915000
Starting training opoch 7
Epoch : 8, Loss : 0.246033, Accuracy: 0.928000, Test accuracy: 0.918500
Starting training opoch 8
Epoch : 9, Loss : 0.284531, Accuracy: 0.912000, Test accuracy: 0.919400
Starting training opoch 9
Epoch : 10, Loss : 0.177326, Accuracy: 0.960000, Test accuracy: 0.924000
Starting training opoch 10
Epoch : 11, Loss : 0.217263, Accuracy: 0.924000, Test accuracy: 0.925100
Starting training opoch 11
Epoch : 12, Loss : 0.219122, Accuracy: 0.940000, Test accuracy: 0.928200
Starting training opoch 12
Epoch : 13, Loss : 0.275276, Accuracy: 0.904000, Test accuracy: 0.931300
Starting training opoch 13
Epoch : 14, Loss : 0.185286, Accuracy: 0.952000, Test accuracy: 0.933400
Starting training opoch 14
Epoch : 15, Loss : 0.149775, Accuracy: 0.964000, Test accuracy: 0.938200
Starting training opoch 15
Epoch : 16, Loss : 0.199639, Accuracy: 0.936000, Test accuracy: 0.938900
Starting training opoch 16
Epoch : 17, Loss : 0.238669, Accuracy: 0.904000, Test accuracy: 0.941400
Starting training opoch 17
Epoch : 18, Loss : 0.164996, Accuracy: 0.952000, Test accuracy: 0.944100
Starting training opoch 18
Epoch : 19, Loss : 0.235818, Accuracy: 0.936000, Test accuracy: 0.944500
Starting training opoch 19
Epoch : 20, Loss : 0.202166, Accuracy: 0.944000, Test accuracy: 0.946500
Starting training opoch 20
Epoch : 21, Loss : 0.168130, Accuracy: 0.936000, Test accuracy: 0.948100
Starting training opoch 21
Epoch : 22, Loss : 0.269904, Accuracy: 0.928000, Test accuracy: 0.950700
Starting training opoch 22
Epoch : 23, Loss : 0.211934, Accuracy: 0.944000, Test accuracy: 0.952500
Starting training opoch 23
Epoch : 24, Loss : 0.097202, Accuracy: 0.984000, Test accuracy: 0.953800
Starting training opoch 24
Epoch : 25, Loss : 0.190590, Accuracy: 0.952000, Test accuracy: 0.954300
Starting training opoch 25
Epoch : 26, Loss : 0.150492, Accuracy: 0.960000, Test accuracy: 0.955400
Starting training opoch 26
Epoch : 27, Loss : 0.136399, Accuracy: 0.956000, Test accuracy: 0.957700
Starting training opoch 27
Epoch : 28, Loss : 0.125706, Accuracy: 0.968000, Test accuracy: 0.958400
Starting training opoch 28
Epoch : 29, Loss : 0.174450, Accuracy: 0.952000, Test accuracy: 0.959200
Starting training opoch 29
Epoch : 30, Loss : 0.140853, Accuracy: 0.948000, Test accuracy: 0.959800
Starting training opoch 30
Epoch : 31, Loss : 0.152840, Accuracy: 0.940000, Test accuracy: 0.960200
Starting training opoch 31
Epoch : 32, Loss : 0.098901, Accuracy: 0.976000, Test accuracy: 0.962100
Starting training opoch 32
Epoch : 33, Loss : 0.224188, Accuracy: 0.956000, Test accuracy: 0.962500
Starting training opoch 33
Epoch : 34, Loss : 0.165400, Accuracy: 0.960000, Test accuracy: 0.962400
Starting training opoch 34
Epoch : 35, Loss : 0.176643, Accuracy: 0.960000, Test accuracy: 0.963400
Starting training opoch 35
Epoch : 36, Loss : 0.135316, Accuracy: 0.956000, Test accuracy: 0.963800
Starting training opoch 36
Epoch : 37, Loss : 0.110428, Accuracy: 0.960000, Test accuracy: 0.965400
Starting training opoch 37
Epoch : 38, Loss : 0.151717, Accuracy: 0.960000, Test accuracy: 0.965800
Starting training opoch 38
Epoch : 39, Loss : 0.154383, Accuracy: 0.968000, Test accuracy: 0.966400
Starting training opoch 39
Epoch : 40, Loss : 0.051489, Accuracy: 0.984000, Test accuracy: 0.967200
Starting training opoch 40
Epoch : 41, Loss : 0.090302, Accuracy: 0.976000, Test accuracy: 0.967100
Starting training opoch 41
Epoch : 42, Loss : 0.198082, Accuracy: 0.940000, Test accuracy: 0.968000
Starting training opoch 42
Epoch : 43, Loss : 0.094186, Accuracy: 0.976000, Test accuracy: 0.968300
Starting training opoch 43
Epoch : 44, Loss : 0.062806, Accuracy: 0.976000, Test accuracy: 0.969400
Starting training opoch 44
Epoch : 45, Loss : 0.131765, Accuracy: 0.972000, Test accuracy: 0.968700
Starting training opoch 45
Epoch : 46, Loss : 0.123477, Accuracy: 0.980000, Test accuracy: 0.968600
Starting training opoch 46
Epoch : 47, Loss : 0.088181, Accuracy: 0.976000, Test accuracy: 0.970200
Starting training opoch 47
Epoch : 48, Loss : 0.084391, Accuracy: 0.976000, Test accuracy: 0.969400
Starting training opoch 48
Epoch : 49, Loss : 0.056377, Accuracy: 0.980000, Test accuracy: 0.969500
Starting training opoch 49
Epoch : 50, Loss : 0.128894, Accuracy: 0.968000, Test accuracy: 0.969500
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.833750, Accuracy: 0.796000, Test accuracy: 0.812100
Starting training opoch 1
Epoch : 2, Loss : 0.501634, Accuracy: 0.856000, Test accuracy: 0.876300
Starting training opoch 2
Epoch : 3, Loss : 0.319239, Accuracy: 0.892000, Test accuracy: 0.892700
Starting training opoch 3
Epoch : 4, Loss : 0.326082, Accuracy: 0.892000, Test accuracy: 0.904400
Starting training opoch 4
Epoch : 5, Loss : 0.340741, Accuracy: 0.900000, Test accuracy: 0.911600
Starting training opoch 5
Epoch : 6, Loss : 0.305378, Accuracy: 0.920000, Test accuracy: 0.915700
Starting training opoch 6
Epoch : 7, Loss : 0.246752, Accuracy: 0.904000, Test accuracy: 0.920100
Starting training opoch 7
Epoch : 8, Loss : 0.277802, Accuracy: 0.908000, Test accuracy: 0.923200
Starting training opoch 8
Epoch : 9, Loss : 0.170047, Accuracy: 0.956000, Test accuracy: 0.926200
Starting training opoch 9
Epoch : 10, Loss : 0.210587, Accuracy: 0.944000, Test accuracy: 0.929400
Starting training opoch 10
Epoch : 11, Loss : 0.367572, Accuracy: 0.892000, Test accuracy: 0.930200
Starting training opoch 11
Epoch : 12, Loss : 0.304374, Accuracy: 0.932000, Test accuracy: 0.932200
Starting training opoch 12
Epoch : 13, Loss : 0.170113, Accuracy: 0.948000, Test accuracy: 0.936500
Starting training opoch 13
Epoch : 14, Loss : 0.202803, Accuracy: 0.944000, Test accuracy: 0.938700
Starting training opoch 14
Epoch : 15, Loss : 0.189757, Accuracy: 0.932000, Test accuracy: 0.938400
Starting training opoch 15
Epoch : 16, Loss : 0.185021, Accuracy: 0.948000, Test accuracy: 0.940700
Starting training opoch 16
Epoch : 17, Loss : 0.178813, Accuracy: 0.960000, Test accuracy: 0.942800
Starting training opoch 17
Epoch : 18, Loss : 0.165525, Accuracy: 0.964000, Test accuracy: 0.943900
Starting training opoch 18
Epoch : 19, Loss : 0.208315, Accuracy: 0.940000, Test accuracy: 0.945200
Starting training opoch 19
Epoch : 20, Loss : 0.119915, Accuracy: 0.972000, Test accuracy: 0.946700
Starting training opoch 20
Epoch : 21, Loss : 0.163184, Accuracy: 0.952000, Test accuracy: 0.947800
Starting training opoch 21
Epoch : 22, Loss : 0.305381, Accuracy: 0.924000, Test accuracy: 0.948900
Starting training opoch 22
Epoch : 23, Loss : 0.141854, Accuracy: 0.960000, Test accuracy: 0.949200
Starting training opoch 23
Epoch : 24, Loss : 0.242815, Accuracy: 0.936000, Test accuracy: 0.949500
Starting training opoch 24
Epoch : 25, Loss : 0.163300, Accuracy: 0.956000, Test accuracy: 0.951800
Starting training opoch 25
Epoch : 26, Loss : 0.209217, Accuracy: 0.948000, Test accuracy: 0.953100
Starting training opoch 26
Epoch : 27, Loss : 0.145789, Accuracy: 0.952000, Test accuracy: 0.954000
Starting training opoch 27
Epoch : 28, Loss : 0.189568, Accuracy: 0.956000, Test accuracy: 0.955200
Starting training opoch 28
Epoch : 29, Loss : 0.092250, Accuracy: 0.976000, Test accuracy: 0.954400
Starting training opoch 29
Epoch : 30, Loss : 0.116125, Accuracy: 0.968000, Test accuracy: 0.956200
Starting training opoch 30
Epoch : 31, Loss : 0.154782, Accuracy: 0.940000, Test accuracy: 0.956300
Starting training opoch 31
Epoch : 32, Loss : 0.139377, Accuracy: 0.952000, Test accuracy: 0.956400
Starting training opoch 32
Epoch : 33, Loss : 0.152977, Accuracy: 0.940000, Test accuracy: 0.957100
Starting training opoch 33
Epoch : 34, Loss : 0.112064, Accuracy: 0.964000, Test accuracy: 0.957400
Starting training opoch 34
Epoch : 35, Loss : 0.127421, Accuracy: 0.964000, Test accuracy: 0.957700
Starting training opoch 35
Epoch : 36, Loss : 0.149410, Accuracy: 0.956000, Test accuracy: 0.958800
Starting training opoch 36
Epoch : 37, Loss : 0.129078, Accuracy: 0.964000, Test accuracy: 0.958800
Starting training opoch 37
Epoch : 38, Loss : 0.201937, Accuracy: 0.956000, Test accuracy: 0.958000
Starting training opoch 38
Epoch : 39, Loss : 0.110931, Accuracy: 0.960000, Test accuracy: 0.959600
Starting training opoch 39
Epoch : 40, Loss : 0.145223, Accuracy: 0.960000, Test accuracy: 0.958800
Starting training opoch 40
Epoch : 41, Loss : 0.115119, Accuracy: 0.976000, Test accuracy: 0.959400
Starting training opoch 41
Epoch : 42, Loss : 0.102717, Accuracy: 0.980000, Test accuracy: 0.960400
Starting training opoch 42
Epoch : 43, Loss : 0.159545, Accuracy: 0.976000, Test accuracy: 0.960400
Starting training opoch 43
Epoch : 44, Loss : 0.180050, Accuracy: 0.960000, Test accuracy: 0.960600
Starting training opoch 44
Epoch : 45, Loss : 0.172028, Accuracy: 0.952000, Test accuracy: 0.961100
Starting training opoch 45
Epoch : 46, Loss : 0.149977, Accuracy: 0.956000, Test accuracy: 0.961300
Starting training opoch 46
Epoch : 47, Loss : 0.144908, Accuracy: 0.956000, Test accuracy: 0.960800
Starting training opoch 47
Epoch : 48, Loss : 0.143911, Accuracy: 0.960000, Test accuracy: 0.961300
Starting training opoch 48
Epoch : 49, Loss : 0.067834, Accuracy: 0.984000, Test accuracy: 0.962000
Starting training opoch 49
Epoch : 50, Loss : 0.105577, Accuracy: 0.976000, Test accuracy: 0.961400
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9929
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.683129, Accuracy: 0.812000, Test accuracy: 0.826000
Distillation: Epoch : 2, Loss : 0.424737, Accuracy: 0.884000, Test accuracy: 0.885300
Distillation: Epoch : 3, Loss : 0.376811, Accuracy: 0.884000, Test accuracy: 0.900900
Distillation: Epoch : 4, Loss : 0.360789, Accuracy: 0.906000, Test accuracy: 0.907100
Distillation: Epoch : 5, Loss : 0.313787, Accuracy: 0.895000, Test accuracy: 0.909400
Distillation: Epoch : 6, Loss : 0.320602, Accuracy: 0.910000, Test accuracy: 0.911700
Distillation: Epoch : 7, Loss : 0.349593, Accuracy: 0.906000, Test accuracy: 0.914400
Distillation: Epoch : 8, Loss : 0.307027, Accuracy: 0.917000, Test accuracy: 0.916000
Distillation: Epoch : 9, Loss : 0.272303, Accuracy: 0.918000, Test accuracy: 0.916400
Distillation: Epoch : 10, Loss : 0.307969, Accuracy: 0.908000, Test accuracy: 0.918700
Distillation: Epoch : 11, Loss : 0.260540, Accuracy: 0.925000, Test accuracy: 0.921200
Distillation: Epoch : 12, Loss : 0.279138, Accuracy: 0.920000, Test accuracy: 0.922900
Distillation: Epoch : 13, Loss : 0.292623, Accuracy: 0.920000, Test accuracy: 0.927700
Distillation: Epoch : 14, Loss : 0.260820, Accuracy: 0.924000, Test accuracy: 0.929500
Distillation: Epoch : 15, Loss : 0.257191, Accuracy: 0.928000, Test accuracy: 0.930400
Distillation: Epoch : 16, Loss : 0.247048, Accuracy: 0.926000, Test accuracy: 0.933000
Distillation: Epoch : 17, Loss : 0.210557, Accuracy: 0.929000, Test accuracy: 0.935200
Distillation: Epoch : 18, Loss : 0.224532, Accuracy: 0.944000, Test accuracy: 0.937800
Distillation: Epoch : 19, Loss : 0.228559, Accuracy: 0.934000, Test accuracy: 0.940600
Distillation: Epoch : 20, Loss : 0.180244, Accuracy: 0.947000, Test accuracy: 0.941500
Distillation: Epoch : 21, Loss : 0.167964, Accuracy: 0.951000, Test accuracy: 0.943600
Distillation: Epoch : 22, Loss : 0.236577, Accuracy: 0.935000, Test accuracy: 0.945700
Distillation: Epoch : 23, Loss : 0.200083, Accuracy: 0.940000, Test accuracy: 0.948300
Distillation: Epoch : 24, Loss : 0.200415, Accuracy: 0.950000, Test accuracy: 0.949300
Distillation: Epoch : 25, Loss : 0.193074, Accuracy: 0.947000, Test accuracy: 0.951400
Distillation: Epoch : 26, Loss : 0.189040, Accuracy: 0.954000, Test accuracy: 0.952500
Distillation: Epoch : 27, Loss : 0.147978, Accuracy: 0.958000, Test accuracy: 0.953800
Distillation: Epoch : 28, Loss : 0.152870, Accuracy: 0.948000, Test accuracy: 0.954300
Distillation: Epoch : 29, Loss : 0.133739, Accuracy: 0.958000, Test accuracy: 0.955600
Distillation: Epoch : 30, Loss : 0.161295, Accuracy: 0.955000, Test accuracy: 0.956900
Distillation: Epoch : 31, Loss : 0.115192, Accuracy: 0.965000, Test accuracy: 0.957000
Distillation: Epoch : 32, Loss : 0.179133, Accuracy: 0.955000, Test accuracy: 0.958000
Distillation: Epoch : 33, Loss : 0.147330, Accuracy: 0.960000, Test accuracy: 0.958100
Distillation: Epoch : 34, Loss : 0.119827, Accuracy: 0.960000, Test accuracy: 0.958900
Distillation: Epoch : 35, Loss : 0.173663, Accuracy: 0.954000, Test accuracy: 0.959800
Distillation: Epoch : 36, Loss : 0.104452, Accuracy: 0.967000, Test accuracy: 0.959900
Distillation: Epoch : 37, Loss : 0.141760, Accuracy: 0.959000, Test accuracy: 0.961100
Distillation: Epoch : 38, Loss : 0.109402, Accuracy: 0.969000, Test accuracy: 0.961000
Distillation: Epoch : 39, Loss : 0.184362, Accuracy: 0.952000, Test accuracy: 0.961400
Distillation: Epoch : 40, Loss : 0.132435, Accuracy: 0.963000, Test accuracy: 0.962100
Distillation: Epoch : 41, Loss : 0.137025, Accuracy: 0.956000, Test accuracy: 0.962800
Distillation: Epoch : 42, Loss : 0.137474, Accuracy: 0.963000, Test accuracy: 0.962200
Distillation: Epoch : 43, Loss : 0.139074, Accuracy: 0.962000, Test accuracy: 0.963600
Distillation: Epoch : 44, Loss : 0.149542, Accuracy: 0.963000, Test accuracy: 0.962900
Distillation: Epoch : 45, Loss : 0.114215, Accuracy: 0.966000, Test accuracy: 0.964900
Distillation: Epoch : 46, Loss : 0.123176, Accuracy: 0.963000, Test accuracy: 0.965300
Distillation: Epoch : 47, Loss : 0.132121, Accuracy: 0.962000, Test accuracy: 0.965100
Distillation: Epoch : 48, Loss : 0.099537, Accuracy: 0.965000, Test accuracy: 0.965300
Distillation: Epoch : 49, Loss : 0.106156, Accuracy: 0.974000, Test accuracy: 0.965000
Distillation: Epoch : 50, Loss : 0.100417, Accuracy: 0.966000, Test accuracy: 0.965200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9652
Generating confusion matrix for student4
[[ 970.    0.    2.    0.    4.    1.    9.    2.    6.    6.]
 [   0. 1119.    7.    0.    2.    1.    3.    8.    6.    9.]
 [   1.    4.  986.   12.    4.    1.    4.   18.   10.    1.]
 [   0.    2.    8.  975.    2.    8.    0.    6.    7.    8.]
 [   0.    0.    4.    0.  954.    0.    3.    4.    4.   17.]
 [   2.    0.    0.    7.    0.  870.    6.    0.    2.    2.]
 [   2.    1.    3.    0.    1.    4.  929.    0.    7.    0.]
 [   1.    1.    8.    6.    2.    3.    0.  977.    5.   12.]
 [   4.    8.   12.    6.    4.    2.    4.    3.  923.    5.]
 [   0.    0.    2.    4.    9.    2.    0.   10.    4.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.008823, Accuracy: 0.782000, Test accuracy: 0.792700
Distillation: Epoch : 2, Loss : 0.485326, Accuracy: 0.865000, Test accuracy: 0.874800
Distillation: Epoch : 3, Loss : 0.429897, Accuracy: 0.894000, Test accuracy: 0.894900
Distillation: Epoch : 4, Loss : 0.362296, Accuracy: 0.895000, Test accuracy: 0.905400
Distillation: Epoch : 5, Loss : 0.350374, Accuracy: 0.899000, Test accuracy: 0.911600
Distillation: Epoch : 6, Loss : 0.309455, Accuracy: 0.914000, Test accuracy: 0.916300
Distillation: Epoch : 7, Loss : 0.332089, Accuracy: 0.913000, Test accuracy: 0.919700
Distillation: Epoch : 8, Loss : 0.319798, Accuracy: 0.921000, Test accuracy: 0.924900
Distillation: Epoch : 9, Loss : 0.282275, Accuracy: 0.921000, Test accuracy: 0.927900
Distillation: Epoch : 10, Loss : 0.259139, Accuracy: 0.935000, Test accuracy: 0.931600
Distillation: Epoch : 11, Loss : 0.278837, Accuracy: 0.917000, Test accuracy: 0.934500
Distillation: Epoch : 12, Loss : 0.296969, Accuracy: 0.924000, Test accuracy: 0.936700
Distillation: Epoch : 13, Loss : 0.223200, Accuracy: 0.941000, Test accuracy: 0.940400
Distillation: Epoch : 14, Loss : 0.211238, Accuracy: 0.939000, Test accuracy: 0.942800
Distillation: Epoch : 15, Loss : 0.210944, Accuracy: 0.935000, Test accuracy: 0.945800
Distillation: Epoch : 16, Loss : 0.222715, Accuracy: 0.941000, Test accuracy: 0.949100
Distillation: Epoch : 17, Loss : 0.197765, Accuracy: 0.953000, Test accuracy: 0.951300
Distillation: Epoch : 18, Loss : 0.201592, Accuracy: 0.947000, Test accuracy: 0.952700
Distillation: Epoch : 19, Loss : 0.251274, Accuracy: 0.924000, Test accuracy: 0.953500
Distillation: Epoch : 20, Loss : 0.171025, Accuracy: 0.957000, Test accuracy: 0.955900
Distillation: Epoch : 21, Loss : 0.214222, Accuracy: 0.941000, Test accuracy: 0.957800
Distillation: Epoch : 22, Loss : 0.184397, Accuracy: 0.954000, Test accuracy: 0.959700
Distillation: Epoch : 23, Loss : 0.155584, Accuracy: 0.966000, Test accuracy: 0.958700
Distillation: Epoch : 24, Loss : 0.151612, Accuracy: 0.961000, Test accuracy: 0.961600
Distillation: Epoch : 25, Loss : 0.166801, Accuracy: 0.959000, Test accuracy: 0.964000
Distillation: Epoch : 26, Loss : 0.161034, Accuracy: 0.968000, Test accuracy: 0.964000
Distillation: Epoch : 27, Loss : 0.161793, Accuracy: 0.962000, Test accuracy: 0.965000
Distillation: Epoch : 28, Loss : 0.162278, Accuracy: 0.960000, Test accuracy: 0.966200
Distillation: Epoch : 29, Loss : 0.163071, Accuracy: 0.954000, Test accuracy: 0.967400
Distillation: Epoch : 30, Loss : 0.163160, Accuracy: 0.964000, Test accuracy: 0.967600
Distillation: Epoch : 31, Loss : 0.121734, Accuracy: 0.969000, Test accuracy: 0.968400
Distillation: Epoch : 32, Loss : 0.138681, Accuracy: 0.964000, Test accuracy: 0.969100
Distillation: Epoch : 33, Loss : 0.132993, Accuracy: 0.968000, Test accuracy: 0.969400
Distillation: Epoch : 34, Loss : 0.126571, Accuracy: 0.972000, Test accuracy: 0.970500
Distillation: Epoch : 35, Loss : 0.140674, Accuracy: 0.963000, Test accuracy: 0.970700
Distillation: Epoch : 36, Loss : 0.123505, Accuracy: 0.970000, Test accuracy: 0.970500
Distillation: Epoch : 37, Loss : 0.151258, Accuracy: 0.968000, Test accuracy: 0.971700
Distillation: Epoch : 38, Loss : 0.135487, Accuracy: 0.976000, Test accuracy: 0.971700
Distillation: Epoch : 39, Loss : 0.146778, Accuracy: 0.957000, Test accuracy: 0.972700
Distillation: Epoch : 40, Loss : 0.144580, Accuracy: 0.968000, Test accuracy: 0.973000
Distillation: Epoch : 41, Loss : 0.139812, Accuracy: 0.962000, Test accuracy: 0.973000
Distillation: Epoch : 42, Loss : 0.109682, Accuracy: 0.973000, Test accuracy: 0.972100
Distillation: Epoch : 43, Loss : 0.130292, Accuracy: 0.976000, Test accuracy: 0.973100
Distillation: Epoch : 44, Loss : 0.159765, Accuracy: 0.962000, Test accuracy: 0.973700
Distillation: Epoch : 45, Loss : 0.132269, Accuracy: 0.974000, Test accuracy: 0.972700
Distillation: Epoch : 46, Loss : 0.134240, Accuracy: 0.967000, Test accuracy: 0.973300
Distillation: Epoch : 47, Loss : 0.130332, Accuracy: 0.965000, Test accuracy: 0.973900
Distillation: Epoch : 48, Loss : 0.151746, Accuracy: 0.967000, Test accuracy: 0.974600
Distillation: Epoch : 49, Loss : 0.125746, Accuracy: 0.970000, Test accuracy: 0.974400
Distillation: Epoch : 50, Loss : 0.132664, Accuracy: 0.971000, Test accuracy: 0.973900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9739
Generating confusion matrix for student4
[[ 972.    0.    3.    0.    1.    2.    7.    1.    5.    6.]
 [   0. 1120.    5.    0.    3.    1.    4.    4.    1.    6.]
 [   1.    3.  993.    4.    3.    0.    1.   15.    3.    1.]
 [   0.    1.    4.  983.    0.    7.    0.    4.    6.    3.]
 [   0.    0.    4.    0.  960.    0.    1.    0.    3.    5.]
 [   1.    0.    1.    7.    0.  872.    5.    0.    5.    1.]
 [   0.    2.    1.    0.    3.    2.  937.    0.    0.    0.]
 [   3.    0.    3.    5.    1.    1.    0.  986.    3.   10.]
 [   3.    9.   17.    9.    3.    5.    3.    2.  941.    2.]
 [   0.    0.    1.    2.    8.    2.    0.   16.    7.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.287060, Accuracy: 0.779000, Test accuracy: 0.801000
Distillation: Epoch : 2, Loss : 0.748301, Accuracy: 0.871000, Test accuracy: 0.881500
Distillation: Epoch : 3, Loss : 0.698184, Accuracy: 0.902000, Test accuracy: 0.898700
Distillation: Epoch : 4, Loss : 0.659072, Accuracy: 0.909000, Test accuracy: 0.907200
Distillation: Epoch : 5, Loss : 0.694320, Accuracy: 0.887000, Test accuracy: 0.912000
Distillation: Epoch : 6, Loss : 0.655977, Accuracy: 0.915000, Test accuracy: 0.914200
Distillation: Epoch : 7, Loss : 0.638042, Accuracy: 0.907000, Test accuracy: 0.919500
Distillation: Epoch : 8, Loss : 0.592454, Accuracy: 0.929000, Test accuracy: 0.924300
Distillation: Epoch : 9, Loss : 0.616423, Accuracy: 0.914000, Test accuracy: 0.928000
Distillation: Epoch : 10, Loss : 0.601767, Accuracy: 0.928000, Test accuracy: 0.929000
Distillation: Epoch : 11, Loss : 0.614895, Accuracy: 0.927000, Test accuracy: 0.933300
Distillation: Epoch : 12, Loss : 0.554193, Accuracy: 0.930000, Test accuracy: 0.937000
Distillation: Epoch : 13, Loss : 0.552270, Accuracy: 0.931000, Test accuracy: 0.938800
Distillation: Epoch : 14, Loss : 0.581632, Accuracy: 0.937000, Test accuracy: 0.941300
Distillation: Epoch : 15, Loss : 0.542181, Accuracy: 0.942000, Test accuracy: 0.943400
Distillation: Epoch : 16, Loss : 0.546599, Accuracy: 0.944000, Test accuracy: 0.946400
Distillation: Epoch : 17, Loss : 0.552973, Accuracy: 0.932000, Test accuracy: 0.949500
Distillation: Epoch : 18, Loss : 0.522832, Accuracy: 0.944000, Test accuracy: 0.951000
Distillation: Epoch : 19, Loss : 0.536728, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 20, Loss : 0.526874, Accuracy: 0.951000, Test accuracy: 0.955600
Distillation: Epoch : 21, Loss : 0.515622, Accuracy: 0.951000, Test accuracy: 0.957600
Distillation: Epoch : 22, Loss : 0.522480, Accuracy: 0.955000, Test accuracy: 0.958600
Distillation: Epoch : 23, Loss : 0.509262, Accuracy: 0.957000, Test accuracy: 0.960400
Distillation: Epoch : 24, Loss : 0.518077, Accuracy: 0.951000, Test accuracy: 0.960700
Distillation: Epoch : 25, Loss : 0.497952, Accuracy: 0.958000, Test accuracy: 0.960900
Distillation: Epoch : 26, Loss : 0.514244, Accuracy: 0.963000, Test accuracy: 0.961900
Distillation: Epoch : 27, Loss : 0.498339, Accuracy: 0.959000, Test accuracy: 0.962100
Distillation: Epoch : 28, Loss : 0.480120, Accuracy: 0.962000, Test accuracy: 0.962400
Distillation: Epoch : 29, Loss : 0.479112, Accuracy: 0.965000, Test accuracy: 0.962900
Distillation: Epoch : 30, Loss : 0.482539, Accuracy: 0.960000, Test accuracy: 0.964500
Distillation: Epoch : 31, Loss : 0.469882, Accuracy: 0.976000, Test accuracy: 0.965400
Distillation: Epoch : 32, Loss : 0.460340, Accuracy: 0.968000, Test accuracy: 0.964800
Distillation: Epoch : 33, Loss : 0.495318, Accuracy: 0.961000, Test accuracy: 0.965100
Distillation: Epoch : 34, Loss : 0.480661, Accuracy: 0.961000, Test accuracy: 0.966300
Distillation: Epoch : 35, Loss : 0.491747, Accuracy: 0.963000, Test accuracy: 0.966400
Distillation: Epoch : 36, Loss : 0.493050, Accuracy: 0.958000, Test accuracy: 0.966200
Distillation: Epoch : 37, Loss : 0.485690, Accuracy: 0.976000, Test accuracy: 0.967600
Distillation: Epoch : 38, Loss : 0.477476, Accuracy: 0.959000, Test accuracy: 0.968300
Distillation: Epoch : 39, Loss : 0.509320, Accuracy: 0.953000, Test accuracy: 0.967400
Distillation: Epoch : 40, Loss : 0.471986, Accuracy: 0.968000, Test accuracy: 0.967800
Distillation: Epoch : 41, Loss : 0.486888, Accuracy: 0.957000, Test accuracy: 0.967700
Distillation: Epoch : 42, Loss : 0.486815, Accuracy: 0.963000, Test accuracy: 0.968100
Distillation: Epoch : 43, Loss : 0.473844, Accuracy: 0.968000, Test accuracy: 0.968100
Distillation: Epoch : 44, Loss : 0.499657, Accuracy: 0.960000, Test accuracy: 0.968200
Distillation: Epoch : 45, Loss : 0.484530, Accuracy: 0.962000, Test accuracy: 0.969200
Distillation: Epoch : 46, Loss : 0.492844, Accuracy: 0.965000, Test accuracy: 0.968800
Distillation: Epoch : 47, Loss : 0.491981, Accuracy: 0.966000, Test accuracy: 0.969200
Distillation: Epoch : 48, Loss : 0.469373, Accuracy: 0.970000, Test accuracy: 0.969100
Distillation: Epoch : 49, Loss : 0.486926, Accuracy: 0.964000, Test accuracy: 0.969200
Distillation: Epoch : 50, Loss : 0.493594, Accuracy: 0.963000, Test accuracy: 0.969500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9695
Generating confusion matrix for student4
[[ 970.    0.    2.    0.    0.    2.    6.    1.    6.    4.]
 [   1. 1124.    9.    1.    3.    2.    3.    7.    4.    8.]
 [   0.    2.  991.    7.    2.    1.    0.   14.    3.    0.]
 [   0.    1.    3.  962.    0.    3.    1.    2.    3.    5.]
 [   3.    1.    4.    1.  964.    0.    8.    1.    7.   17.]
 [   0.    0.    2.   13.    0.  870.    3.    0.    2.    5.]
 [   1.    3.    0.    0.    2.    4.  932.    0.    5.    1.]
 [   1.    0.    7.   10.    1.    1.    0.  988.    8.    6.]
 [   3.    4.   12.   11.    3.    4.    5.    2.  934.    3.]
 [   1.    0.    2.    5.    7.    5.    0.   13.    2.  960.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.465110, Accuracy: 0.790000, Test accuracy: 0.783800
Distillation: Epoch : 2, Loss : 0.955887, Accuracy: 0.843000, Test accuracy: 0.868200
Distillation: Epoch : 3, Loss : 0.912781, Accuracy: 0.869000, Test accuracy: 0.890000
Distillation: Epoch : 4, Loss : 0.818783, Accuracy: 0.912000, Test accuracy: 0.894200
Distillation: Epoch : 5, Loss : 0.850919, Accuracy: 0.891000, Test accuracy: 0.899400
Distillation: Epoch : 6, Loss : 0.857399, Accuracy: 0.890000, Test accuracy: 0.900000
Distillation: Epoch : 7, Loss : 0.873346, Accuracy: 0.880000, Test accuracy: 0.900400
Distillation: Epoch : 8, Loss : 0.822866, Accuracy: 0.915000, Test accuracy: 0.905200
Distillation: Epoch : 9, Loss : 0.816569, Accuracy: 0.913000, Test accuracy: 0.905100
Distillation: Epoch : 10, Loss : 0.826123, Accuracy: 0.907000, Test accuracy: 0.905300
Distillation: Epoch : 11, Loss : 0.822387, Accuracy: 0.902000, Test accuracy: 0.906900
Distillation: Epoch : 12, Loss : 0.841839, Accuracy: 0.900000, Test accuracy: 0.907600
Distillation: Epoch : 13, Loss : 0.835376, Accuracy: 0.909000, Test accuracy: 0.908200
Distillation: Epoch : 14, Loss : 0.820059, Accuracy: 0.912000, Test accuracy: 0.910400
Distillation: Epoch : 15, Loss : 0.801069, Accuracy: 0.905000, Test accuracy: 0.909400
Distillation: Epoch : 16, Loss : 0.821924, Accuracy: 0.902000, Test accuracy: 0.911400
Distillation: Epoch : 17, Loss : 0.805599, Accuracy: 0.907000, Test accuracy: 0.911800
Distillation: Epoch : 18, Loss : 0.794978, Accuracy: 0.910000, Test accuracy: 0.911300
Distillation: Epoch : 19, Loss : 0.819982, Accuracy: 0.904000, Test accuracy: 0.912000
Distillation: Epoch : 20, Loss : 0.794752, Accuracy: 0.911000, Test accuracy: 0.912900
Distillation: Epoch : 21, Loss : 0.814863, Accuracy: 0.909000, Test accuracy: 0.913300
Distillation: Epoch : 22, Loss : 0.814080, Accuracy: 0.911000, Test accuracy: 0.913600
Distillation: Epoch : 23, Loss : 0.819684, Accuracy: 0.911000, Test accuracy: 0.913800
Distillation: Epoch : 24, Loss : 0.789557, Accuracy: 0.909000, Test accuracy: 0.913800
Distillation: Epoch : 25, Loss : 0.836821, Accuracy: 0.912000, Test accuracy: 0.917100
Distillation: Epoch : 26, Loss : 0.776606, Accuracy: 0.933000, Test accuracy: 0.918400
Distillation: Epoch : 27, Loss : 0.801314, Accuracy: 0.921000, Test accuracy: 0.921600
Distillation: Epoch : 28, Loss : 0.807040, Accuracy: 0.913000, Test accuracy: 0.921800
Distillation: Epoch : 29, Loss : 0.798223, Accuracy: 0.920000, Test accuracy: 0.923900
Distillation: Epoch : 30, Loss : 0.785942, Accuracy: 0.906000, Test accuracy: 0.928300
Distillation: Epoch : 31, Loss : 0.771086, Accuracy: 0.928000, Test accuracy: 0.930600
Distillation: Epoch : 32, Loss : 0.765649, Accuracy: 0.934000, Test accuracy: 0.932200
Distillation: Epoch : 33, Loss : 0.740357, Accuracy: 0.945000, Test accuracy: 0.935700
Distillation: Epoch : 34, Loss : 0.764348, Accuracy: 0.924000, Test accuracy: 0.938800
Distillation: Epoch : 35, Loss : 0.737580, Accuracy: 0.934000, Test accuracy: 0.940400
Distillation: Epoch : 36, Loss : 0.717804, Accuracy: 0.931000, Test accuracy: 0.943100
Distillation: Epoch : 37, Loss : 0.753003, Accuracy: 0.929000, Test accuracy: 0.944300
Distillation: Epoch : 38, Loss : 0.734442, Accuracy: 0.940000, Test accuracy: 0.947300
Distillation: Epoch : 39, Loss : 0.732539, Accuracy: 0.940000, Test accuracy: 0.947300
Distillation: Epoch : 40, Loss : 0.716850, Accuracy: 0.939000, Test accuracy: 0.950200
Distillation: Epoch : 41, Loss : 0.709851, Accuracy: 0.950000, Test accuracy: 0.951900
Distillation: Epoch : 42, Loss : 0.706570, Accuracy: 0.948000, Test accuracy: 0.953200
Distillation: Epoch : 43, Loss : 0.698538, Accuracy: 0.945000, Test accuracy: 0.954000
Distillation: Epoch : 44, Loss : 0.691554, Accuracy: 0.948000, Test accuracy: 0.954600
Distillation: Epoch : 45, Loss : 0.674921, Accuracy: 0.956000, Test accuracy: 0.955800
Distillation: Epoch : 46, Loss : 0.712109, Accuracy: 0.945000, Test accuracy: 0.956400
Distillation: Epoch : 47, Loss : 0.685424, Accuracy: 0.954000, Test accuracy: 0.956600
Distillation: Epoch : 48, Loss : 0.685626, Accuracy: 0.938000, Test accuracy: 0.957600
Distillation: Epoch : 49, Loss : 0.695287, Accuracy: 0.951000, Test accuracy: 0.958200
Distillation: Epoch : 50, Loss : 0.681774, Accuracy: 0.964000, Test accuracy: 0.958100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9581
Generating confusion matrix for student4
[[ 967.    0.    3.    0.    1.    1.    7.    2.    7.    5.]
 [   1. 1117.   12.    1.    2.    1.    4.    8.   12.    6.]
 [   2.    4.  968.    5.    1.    0.    1.   15.    7.    1.]
 [   0.    0.    6.  964.    0.    5.    0.    6.    5.    5.]
 [   1.    0.    8.    0.  947.    0.    7.    2.    6.   23.]
 [   0.    0.    0.   18.    0.  871.    8.    0.    7.    6.]
 [   6.    4.    3.    0.    4.    4.  929.    0.    6.    1.]
 [   1.    0.   10.    6.    2.    2.    0.  972.   12.   14.]
 [   2.   10.   21.   12.    4.    4.    2.    2.  902.    4.]
 [   0.    0.    1.    4.   21.    4.    0.   21.   10.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.650503, Accuracy: 0.763000, Test accuracy: 0.771500
Distillation: Epoch : 2, Loss : 1.145987, Accuracy: 0.843000, Test accuracy: 0.859000
Distillation: Epoch : 3, Loss : 1.073028, Accuracy: 0.879000, Test accuracy: 0.877500
Distillation: Epoch : 4, Loss : 1.077357, Accuracy: 0.864000, Test accuracy: 0.890400
Distillation: Epoch : 5, Loss : 1.028861, Accuracy: 0.899000, Test accuracy: 0.897800
Distillation: Epoch : 6, Loss : 1.023942, Accuracy: 0.888000, Test accuracy: 0.903600
Distillation: Epoch : 7, Loss : 1.015802, Accuracy: 0.894000, Test accuracy: 0.907300
Distillation: Epoch : 8, Loss : 0.992942, Accuracy: 0.904000, Test accuracy: 0.912000
Distillation: Epoch : 9, Loss : 0.977657, Accuracy: 0.914000, Test accuracy: 0.915500
Distillation: Epoch : 10, Loss : 1.011181, Accuracy: 0.901000, Test accuracy: 0.920400
Distillation: Epoch : 11, Loss : 0.988145, Accuracy: 0.921000, Test accuracy: 0.924800
Distillation: Epoch : 12, Loss : 0.939774, Accuracy: 0.917000, Test accuracy: 0.928700
Distillation: Epoch : 13, Loss : 0.932241, Accuracy: 0.932000, Test accuracy: 0.932300
Distillation: Epoch : 14, Loss : 0.905240, Accuracy: 0.943000, Test accuracy: 0.937500
Distillation: Epoch : 15, Loss : 0.941364, Accuracy: 0.941000, Test accuracy: 0.942100
Distillation: Epoch : 16, Loss : 0.897269, Accuracy: 0.932000, Test accuracy: 0.945500
Distillation: Epoch : 17, Loss : 0.919573, Accuracy: 0.935000, Test accuracy: 0.946100
Distillation: Epoch : 18, Loss : 0.898263, Accuracy: 0.950000, Test accuracy: 0.949200
Distillation: Epoch : 19, Loss : 0.894693, Accuracy: 0.939000, Test accuracy: 0.950800
Distillation: Epoch : 20, Loss : 0.908692, Accuracy: 0.947000, Test accuracy: 0.953200
Distillation: Epoch : 21, Loss : 0.888597, Accuracy: 0.946000, Test accuracy: 0.954300
Distillation: Epoch : 22, Loss : 0.873524, Accuracy: 0.950000, Test accuracy: 0.956000
Distillation: Epoch : 23, Loss : 0.861727, Accuracy: 0.951000, Test accuracy: 0.956600
Distillation: Epoch : 24, Loss : 0.871281, Accuracy: 0.949000, Test accuracy: 0.957100
Distillation: Epoch : 25, Loss : 0.871292, Accuracy: 0.949000, Test accuracy: 0.959500
Distillation: Epoch : 26, Loss : 0.858527, Accuracy: 0.963000, Test accuracy: 0.959700
Distillation: Epoch : 27, Loss : 0.888760, Accuracy: 0.953000, Test accuracy: 0.960800
Distillation: Epoch : 28, Loss : 0.867308, Accuracy: 0.960000, Test accuracy: 0.961200
Distillation: Epoch : 29, Loss : 0.863063, Accuracy: 0.946000, Test accuracy: 0.962100
Distillation: Epoch : 30, Loss : 0.847954, Accuracy: 0.963000, Test accuracy: 0.963800
Distillation: Epoch : 31, Loss : 0.861068, Accuracy: 0.955000, Test accuracy: 0.963400
Distillation: Epoch : 32, Loss : 0.859320, Accuracy: 0.952000, Test accuracy: 0.964400
Distillation: Epoch : 33, Loss : 0.853408, Accuracy: 0.957000, Test accuracy: 0.964800
Distillation: Epoch : 34, Loss : 0.847937, Accuracy: 0.956000, Test accuracy: 0.964700
Distillation: Epoch : 35, Loss : 0.867349, Accuracy: 0.967000, Test accuracy: 0.965500
Distillation: Epoch : 36, Loss : 0.836217, Accuracy: 0.964000, Test accuracy: 0.965200
Distillation: Epoch : 37, Loss : 0.849641, Accuracy: 0.959000, Test accuracy: 0.965300
Distillation: Epoch : 38, Loss : 0.847155, Accuracy: 0.968000, Test accuracy: 0.966400
Distillation: Epoch : 39, Loss : 0.855627, Accuracy: 0.962000, Test accuracy: 0.966300
Distillation: Epoch : 40, Loss : 0.825535, Accuracy: 0.975000, Test accuracy: 0.966900
Distillation: Epoch : 41, Loss : 0.855983, Accuracy: 0.959000, Test accuracy: 0.967200
Distillation: Epoch : 42, Loss : 0.834461, Accuracy: 0.970000, Test accuracy: 0.967500
Distillation: Epoch : 43, Loss : 0.844294, Accuracy: 0.964000, Test accuracy: 0.968000
Distillation: Epoch : 44, Loss : 0.853844, Accuracy: 0.957000, Test accuracy: 0.967900
Distillation: Epoch : 45, Loss : 0.853794, Accuracy: 0.959000, Test accuracy: 0.968300
Distillation: Epoch : 46, Loss : 0.834225, Accuracy: 0.960000, Test accuracy: 0.968700
Distillation: Epoch : 47, Loss : 0.818384, Accuracy: 0.972000, Test accuracy: 0.968600
Distillation: Epoch : 48, Loss : 0.823987, Accuracy: 0.975000, Test accuracy: 0.969100
Distillation: Epoch : 49, Loss : 0.833389, Accuracy: 0.974000, Test accuracy: 0.969700
Distillation: Epoch : 50, Loss : 0.841278, Accuracy: 0.966000, Test accuracy: 0.969600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9696
Generating confusion matrix for student4
[[ 969.    0.    3.    0.    1.    1.    3.    3.    6.    3.]
 [   1. 1122.    3.    0.    0.    0.    3.    5.    0.    7.]
 [   1.    4.  990.    5.    1.    0.    1.   12.    3.    1.]
 [   0.    0.    4.  967.    0.    5.    0.    3.    6.    7.]
 [   2.    0.    4.    1.  960.    2.    6.    3.    5.    6.]
 [   0.    0.    1.   14.    0.  869.    5.    0.    2.    6.]
 [   3.    2.    1.    0.    3.    5.  938.    0.    3.    1.]
 [   1.    0.   10.    8.    0.    2.    0.  981.    3.    7.]
 [   3.    7.   13.   14.    3.    5.    2.    4.  936.    7.]
 [   0.    0.    3.    1.   14.    3.    0.   17.   10.  964.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.983695, Accuracy: 0.728000, Test accuracy: 0.769000
Distillation: Epoch : 2, Loss : 1.332920, Accuracy: 0.839000, Test accuracy: 0.852000
Distillation: Epoch : 3, Loss : 1.230839, Accuracy: 0.878000, Test accuracy: 0.877500
Distillation: Epoch : 4, Loss : 1.229777, Accuracy: 0.886000, Test accuracy: 0.885800
Distillation: Epoch : 5, Loss : 1.182646, Accuracy: 0.882000, Test accuracy: 0.894700
Distillation: Epoch : 6, Loss : 1.218694, Accuracy: 0.891000, Test accuracy: 0.899600
Distillation: Epoch : 7, Loss : 1.145982, Accuracy: 0.914000, Test accuracy: 0.902500
Distillation: Epoch : 8, Loss : 1.153263, Accuracy: 0.904000, Test accuracy: 0.905700
Distillation: Epoch : 9, Loss : 1.136882, Accuracy: 0.900000, Test accuracy: 0.907200
Distillation: Epoch : 10, Loss : 1.129488, Accuracy: 0.914000, Test accuracy: 0.911300
Distillation: Epoch : 11, Loss : 1.137447, Accuracy: 0.907000, Test accuracy: 0.912700
Distillation: Epoch : 12, Loss : 1.113805, Accuracy: 0.912000, Test accuracy: 0.915000
Distillation: Epoch : 13, Loss : 1.106311, Accuracy: 0.914000, Test accuracy: 0.916300
Distillation: Epoch : 14, Loss : 1.132787, Accuracy: 0.909000, Test accuracy: 0.919600
Distillation: Epoch : 15, Loss : 1.108208, Accuracy: 0.908000, Test accuracy: 0.922200
Distillation: Epoch : 16, Loss : 1.114075, Accuracy: 0.918000, Test accuracy: 0.926500
Distillation: Epoch : 17, Loss : 1.119764, Accuracy: 0.924000, Test accuracy: 0.926600
Distillation: Epoch : 18, Loss : 1.098180, Accuracy: 0.924000, Test accuracy: 0.929400
Distillation: Epoch : 19, Loss : 1.097066, Accuracy: 0.921000, Test accuracy: 0.931000
Distillation: Epoch : 20, Loss : 1.073184, Accuracy: 0.927000, Test accuracy: 0.933000
Distillation: Epoch : 21, Loss : 1.100034, Accuracy: 0.925000, Test accuracy: 0.935100
Distillation: Epoch : 22, Loss : 1.105424, Accuracy: 0.930000, Test accuracy: 0.936200
Distillation: Epoch : 23, Loss : 1.076251, Accuracy: 0.930000, Test accuracy: 0.936500
Distillation: Epoch : 24, Loss : 1.082699, Accuracy: 0.930000, Test accuracy: 0.939700
Distillation: Epoch : 25, Loss : 1.064777, Accuracy: 0.946000, Test accuracy: 0.942600
Distillation: Epoch : 26, Loss : 1.055899, Accuracy: 0.937000, Test accuracy: 0.943400
Distillation: Epoch : 27, Loss : 1.087065, Accuracy: 0.936000, Test accuracy: 0.947400
Distillation: Epoch : 28, Loss : 1.078552, Accuracy: 0.940000, Test accuracy: 0.949100
Distillation: Epoch : 29, Loss : 1.046677, Accuracy: 0.948000, Test accuracy: 0.949100
Distillation: Epoch : 30, Loss : 1.069045, Accuracy: 0.936000, Test accuracy: 0.949600
Distillation: Epoch : 31, Loss : 1.053015, Accuracy: 0.951000, Test accuracy: 0.952100
Distillation: Epoch : 32, Loss : 1.065560, Accuracy: 0.944000, Test accuracy: 0.954100
Distillation: Epoch : 33, Loss : 1.024525, Accuracy: 0.950000, Test accuracy: 0.954400
Distillation: Epoch : 34, Loss : 1.049343, Accuracy: 0.946000, Test accuracy: 0.954400
Distillation: Epoch : 35, Loss : 1.061566, Accuracy: 0.948000, Test accuracy: 0.955200
Distillation: Epoch : 36, Loss : 1.053183, Accuracy: 0.940000, Test accuracy: 0.956900
Distillation: Epoch : 37, Loss : 1.054275, Accuracy: 0.955000, Test accuracy: 0.956600
Distillation: Epoch : 38, Loss : 1.042222, Accuracy: 0.964000, Test accuracy: 0.958100
Distillation: Epoch : 39, Loss : 1.040157, Accuracy: 0.956000, Test accuracy: 0.958500
Distillation: Epoch : 40, Loss : 1.040391, Accuracy: 0.952000, Test accuracy: 0.959500
Distillation: Epoch : 41, Loss : 1.022944, Accuracy: 0.958000, Test accuracy: 0.960700
Distillation: Epoch : 42, Loss : 1.051822, Accuracy: 0.962000, Test accuracy: 0.960800
Distillation: Epoch : 43, Loss : 1.036732, Accuracy: 0.953000, Test accuracy: 0.961300
Distillation: Epoch : 44, Loss : 1.039771, Accuracy: 0.953000, Test accuracy: 0.962300
Distillation: Epoch : 45, Loss : 1.043449, Accuracy: 0.952000, Test accuracy: 0.962400
Distillation: Epoch : 46, Loss : 1.009677, Accuracy: 0.957000, Test accuracy: 0.962400
Distillation: Epoch : 47, Loss : 1.018588, Accuracy: 0.974000, Test accuracy: 0.963500
Distillation: Epoch : 48, Loss : 1.035755, Accuracy: 0.958000, Test accuracy: 0.963100
Distillation: Epoch : 49, Loss : 1.041070, Accuracy: 0.959000, Test accuracy: 0.964200
Distillation: Epoch : 50, Loss : 1.027115, Accuracy: 0.962000, Test accuracy: 0.965200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9652
Generating confusion matrix for student4
[[ 969.    0.    3.    0.    0.    2.    3.    1.    6.    4.]
 [   3. 1117.    8.    0.    1.    0.    4.   10.    3.    6.]
 [   0.    5.  974.    6.    2.    2.    0.    9.    5.    0.]
 [   0.    0.   11.  966.    0.    3.    0.    3.    2.    7.]
 [   1.    0.    6.    1.  950.    1.    7.    7.    8.   12.]
 [   0.    1.    0.   12.    0.  872.    3.    1.    4.    2.]
 [   5.    4.    2.    0.    7.    3.  936.    0.    3.    0.]
 [   1.    0.   12.   13.    2.    3.    0.  980.    6.   12.]
 [   1.    8.   13.    9.    3.    2.    5.    2.  929.    7.]
 [   0.    0.    3.    3.   17.    4.    0.   15.    8.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.086264, Accuracy: 0.670000, Test accuracy: 0.675600
Distillation: Epoch : 2, Loss : 1.465419, Accuracy: 0.831000, Test accuracy: 0.828200
Distillation: Epoch : 3, Loss : 1.448977, Accuracy: 0.823000, Test accuracy: 0.850000
Distillation: Epoch : 4, Loss : 1.383202, Accuracy: 0.850000, Test accuracy: 0.866900
Distillation: Epoch : 5, Loss : 1.383791, Accuracy: 0.853000, Test accuracy: 0.878200
Distillation: Epoch : 6, Loss : 1.344600, Accuracy: 0.877000, Test accuracy: 0.889500
Distillation: Epoch : 7, Loss : 1.316508, Accuracy: 0.873000, Test accuracy: 0.896000
Distillation: Epoch : 8, Loss : 1.293244, Accuracy: 0.899000, Test accuracy: 0.900600
Distillation: Epoch : 9, Loss : 1.306995, Accuracy: 0.906000, Test accuracy: 0.904000
Distillation: Epoch : 10, Loss : 1.317499, Accuracy: 0.900000, Test accuracy: 0.909700
Distillation: Epoch : 11, Loss : 1.278981, Accuracy: 0.909000, Test accuracy: 0.913100
Distillation: Epoch : 12, Loss : 1.281181, Accuracy: 0.920000, Test accuracy: 0.917400
Distillation: Epoch : 13, Loss : 1.279190, Accuracy: 0.918000, Test accuracy: 0.921100
Distillation: Epoch : 14, Loss : 1.289241, Accuracy: 0.916000, Test accuracy: 0.926100
Distillation: Epoch : 15, Loss : 1.249607, Accuracy: 0.928000, Test accuracy: 0.929700
Distillation: Epoch : 16, Loss : 1.241844, Accuracy: 0.924000, Test accuracy: 0.932400
Distillation: Epoch : 17, Loss : 1.240219, Accuracy: 0.939000, Test accuracy: 0.935900
Distillation: Epoch : 18, Loss : 1.260468, Accuracy: 0.939000, Test accuracy: 0.938900
Distillation: Epoch : 19, Loss : 1.251303, Accuracy: 0.931000, Test accuracy: 0.941300
Distillation: Epoch : 20, Loss : 1.251102, Accuracy: 0.934000, Test accuracy: 0.942800
Distillation: Epoch : 21, Loss : 1.244249, Accuracy: 0.939000, Test accuracy: 0.943200
Distillation: Epoch : 22, Loss : 1.229447, Accuracy: 0.953000, Test accuracy: 0.945200
Distillation: Epoch : 23, Loss : 1.229655, Accuracy: 0.944000, Test accuracy: 0.946300
Distillation: Epoch : 24, Loss : 1.221670, Accuracy: 0.942000, Test accuracy: 0.949700
Distillation: Epoch : 25, Loss : 1.223115, Accuracy: 0.948000, Test accuracy: 0.950800
Distillation: Epoch : 26, Loss : 1.208792, Accuracy: 0.940000, Test accuracy: 0.952000
Distillation: Epoch : 27, Loss : 1.215368, Accuracy: 0.937000, Test accuracy: 0.952900
Distillation: Epoch : 28, Loss : 1.228886, Accuracy: 0.948000, Test accuracy: 0.952800
Distillation: Epoch : 29, Loss : 1.220061, Accuracy: 0.941000, Test accuracy: 0.953000
Distillation: Epoch : 30, Loss : 1.224428, Accuracy: 0.961000, Test accuracy: 0.954000
Distillation: Epoch : 31, Loss : 1.198605, Accuracy: 0.948000, Test accuracy: 0.955600
Distillation: Epoch : 32, Loss : 1.232875, Accuracy: 0.946000, Test accuracy: 0.955600
Distillation: Epoch : 33, Loss : 1.196617, Accuracy: 0.961000, Test accuracy: 0.956700
Distillation: Epoch : 34, Loss : 1.220280, Accuracy: 0.950000, Test accuracy: 0.956600
Distillation: Epoch : 35, Loss : 1.187328, Accuracy: 0.955000, Test accuracy: 0.956800
Distillation: Epoch : 36, Loss : 1.220526, Accuracy: 0.954000, Test accuracy: 0.956500
Distillation: Epoch : 37, Loss : 1.191020, Accuracy: 0.958000, Test accuracy: 0.957600
Distillation: Epoch : 38, Loss : 1.172451, Accuracy: 0.970000, Test accuracy: 0.957200
Distillation: Epoch : 39, Loss : 1.199454, Accuracy: 0.951000, Test accuracy: 0.957600
Distillation: Epoch : 40, Loss : 1.215773, Accuracy: 0.950000, Test accuracy: 0.958800
Distillation: Epoch : 41, Loss : 1.208559, Accuracy: 0.950000, Test accuracy: 0.958900
Distillation: Epoch : 42, Loss : 1.196827, Accuracy: 0.964000, Test accuracy: 0.959900
Distillation: Epoch : 43, Loss : 1.199493, Accuracy: 0.957000, Test accuracy: 0.959000
Distillation: Epoch : 44, Loss : 1.201654, Accuracy: 0.952000, Test accuracy: 0.958900
Distillation: Epoch : 45, Loss : 1.195337, Accuracy: 0.954000, Test accuracy: 0.958800
Distillation: Epoch : 46, Loss : 1.176796, Accuracy: 0.971000, Test accuracy: 0.959500
Distillation: Epoch : 47, Loss : 1.185280, Accuracy: 0.959000, Test accuracy: 0.960700
Distillation: Epoch : 48, Loss : 1.173086, Accuracy: 0.958000, Test accuracy: 0.959900
Distillation: Epoch : 49, Loss : 1.213479, Accuracy: 0.946000, Test accuracy: 0.960300
Distillation: Epoch : 50, Loss : 1.200807, Accuracy: 0.955000, Test accuracy: 0.961100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9611
Generating confusion matrix for student4
[[ 966.    0.    5.    0.    0.    2.    6.    1.    6.    3.]
 [   0. 1121.   12.    3.    1.    1.    4.   10.    8.    8.]
 [   0.    3.  981.   12.    3.    1.    0.   12.    6.    1.]
 [   0.    1.    3.  945.    0.    4.    1.    1.    5.    5.]
 [   3.    0.    9.    2.  962.    1.   11.    4.    9.   28.]
 [   0.    0.    1.   20.    0.  864.    5.    0.    4.    6.]
 [   2.    5.    0.    0.    2.    4.  925.    0.    7.    0.]
 [   1.    0.   13.   11.    1.    2.    0.  988.    9.   14.]
 [   4.    5.    7.   12.    5.    6.    6.    2.  916.    1.]
 [   4.    0.    1.    5.    8.    7.    0.   10.    4.  943.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.823314, Accuracy: 0.749000, Test accuracy: 0.771400
Distillation: Epoch : 2, Loss : 1.542608, Accuracy: 0.869000, Test accuracy: 0.856300
Distillation: Epoch : 3, Loss : 1.487282, Accuracy: 0.869000, Test accuracy: 0.872500
Distillation: Epoch : 4, Loss : 1.483212, Accuracy: 0.880000, Test accuracy: 0.881600
Distillation: Epoch : 5, Loss : 1.479255, Accuracy: 0.873000, Test accuracy: 0.885500
Distillation: Epoch : 6, Loss : 1.468338, Accuracy: 0.869000, Test accuracy: 0.891100
Distillation: Epoch : 7, Loss : 1.462206, Accuracy: 0.878000, Test accuracy: 0.895200
Distillation: Epoch : 8, Loss : 1.462527, Accuracy: 0.892000, Test accuracy: 0.898000
Distillation: Epoch : 9, Loss : 1.422840, Accuracy: 0.902000, Test accuracy: 0.903200
Distillation: Epoch : 10, Loss : 1.449277, Accuracy: 0.912000, Test accuracy: 0.905500
Distillation: Epoch : 11, Loss : 1.434079, Accuracy: 0.902000, Test accuracy: 0.909900
Distillation: Epoch : 12, Loss : 1.405621, Accuracy: 0.917000, Test accuracy: 0.911500
Distillation: Epoch : 13, Loss : 1.414530, Accuracy: 0.918000, Test accuracy: 0.914100
Distillation: Epoch : 14, Loss : 1.431247, Accuracy: 0.907000, Test accuracy: 0.919000
Distillation: Epoch : 15, Loss : 1.419148, Accuracy: 0.920000, Test accuracy: 0.921500
Distillation: Epoch : 16, Loss : 1.423384, Accuracy: 0.902000, Test accuracy: 0.922300
Distillation: Epoch : 17, Loss : 1.406965, Accuracy: 0.919000, Test accuracy: 0.924800
Distillation: Epoch : 18, Loss : 1.394713, Accuracy: 0.921000, Test accuracy: 0.927400
Distillation: Epoch : 19, Loss : 1.402756, Accuracy: 0.916000, Test accuracy: 0.930000
Distillation: Epoch : 20, Loss : 1.417237, Accuracy: 0.920000, Test accuracy: 0.930000
Distillation: Epoch : 21, Loss : 1.417052, Accuracy: 0.919000, Test accuracy: 0.933000
Distillation: Epoch : 22, Loss : 1.383183, Accuracy: 0.932000, Test accuracy: 0.934900
Distillation: Epoch : 23, Loss : 1.402571, Accuracy: 0.935000, Test accuracy: 0.938100
Distillation: Epoch : 24, Loss : 1.364445, Accuracy: 0.933000, Test accuracy: 0.938700
Distillation: Epoch : 25, Loss : 1.386221, Accuracy: 0.932000, Test accuracy: 0.942500
Distillation: Epoch : 26, Loss : 1.378911, Accuracy: 0.945000, Test accuracy: 0.943600
Distillation: Epoch : 27, Loss : 1.391147, Accuracy: 0.950000, Test accuracy: 0.944400
Distillation: Epoch : 28, Loss : 1.381705, Accuracy: 0.957000, Test accuracy: 0.945300
Distillation: Epoch : 29, Loss : 1.378669, Accuracy: 0.944000, Test accuracy: 0.947000
Distillation: Epoch : 30, Loss : 1.376195, Accuracy: 0.940000, Test accuracy: 0.948300
Distillation: Epoch : 31, Loss : 1.342125, Accuracy: 0.944000, Test accuracy: 0.948000
Distillation: Epoch : 32, Loss : 1.363055, Accuracy: 0.948000, Test accuracy: 0.948800
Distillation: Epoch : 33, Loss : 1.339388, Accuracy: 0.945000, Test accuracy: 0.949100
Distillation: Epoch : 34, Loss : 1.374714, Accuracy: 0.946000, Test accuracy: 0.950900
Distillation: Epoch : 35, Loss : 1.349772, Accuracy: 0.952000, Test accuracy: 0.950700
Distillation: Epoch : 36, Loss : 1.385923, Accuracy: 0.940000, Test accuracy: 0.952000
Distillation: Epoch : 37, Loss : 1.378082, Accuracy: 0.937000, Test accuracy: 0.952900
Distillation: Epoch : 38, Loss : 1.367300, Accuracy: 0.955000, Test accuracy: 0.953600
Distillation: Epoch : 39, Loss : 1.367933, Accuracy: 0.949000, Test accuracy: 0.953200
Distillation: Epoch : 40, Loss : 1.364218, Accuracy: 0.964000, Test accuracy: 0.954800
Distillation: Epoch : 41, Loss : 1.357836, Accuracy: 0.939000, Test accuracy: 0.955500
Distillation: Epoch : 42, Loss : 1.351438, Accuracy: 0.946000, Test accuracy: 0.955300
Distillation: Epoch : 43, Loss : 1.365576, Accuracy: 0.949000, Test accuracy: 0.955400
Distillation: Epoch : 44, Loss : 1.329872, Accuracy: 0.953000, Test accuracy: 0.955300
Distillation: Epoch : 45, Loss : 1.357429, Accuracy: 0.959000, Test accuracy: 0.955700
Distillation: Epoch : 46, Loss : 1.362415, Accuracy: 0.951000, Test accuracy: 0.956900
Distillation: Epoch : 47, Loss : 1.380966, Accuracy: 0.944000, Test accuracy: 0.956600
Distillation: Epoch : 48, Loss : 1.361750, Accuracy: 0.947000, Test accuracy: 0.957100
Distillation: Epoch : 49, Loss : 1.353637, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 50, Loss : 1.352303, Accuracy: 0.952000, Test accuracy: 0.957400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9574
Generating confusion matrix for student4
[[ 963.    0.    7.    3.    0.    4.    7.    1.    7.    4.]
 [   1. 1118.    5.    0.    0.    1.    3.    4.    0.    6.]
 [   1.    2.  968.    4.    6.    1.    0.    8.    7.    0.]
 [   0.    1.    5.  950.    0.    4.    0.    9.    6.    3.]
 [   0.    1.    6.    2.  945.    5.    8.    4.    7.   11.]
 [   4.    0.    1.   21.    2.  855.   18.    1.   15.    7.]
 [   5.    4.    5.    0.    7.    6.  921.    0.    2.    1.]
 [   1.    1.    8.    9.    1.    1.    0.  982.    5.    5.]
 [   5.    8.   26.   16.    2.    8.    1.    3.  910.   10.]
 [   0.    0.    1.    5.   19.    7.    0.   16.   15.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.065606, Accuracy: 0.747000, Test accuracy: 0.751500
Distillation: Epoch : 2, Loss : 1.651173, Accuracy: 0.852000, Test accuracy: 0.857400
Distillation: Epoch : 3, Loss : 1.577274, Accuracy: 0.875000, Test accuracy: 0.885600
Distillation: Epoch : 4, Loss : 1.542262, Accuracy: 0.913000, Test accuracy: 0.905900
Distillation: Epoch : 5, Loss : 1.555282, Accuracy: 0.917000, Test accuracy: 0.915300
Distillation: Epoch : 6, Loss : 1.547590, Accuracy: 0.901000, Test accuracy: 0.925600
Distillation: Epoch : 7, Loss : 1.505534, Accuracy: 0.926000, Test accuracy: 0.930500
Distillation: Epoch : 8, Loss : 1.539772, Accuracy: 0.919000, Test accuracy: 0.935800
Distillation: Epoch : 9, Loss : 1.506280, Accuracy: 0.920000, Test accuracy: 0.939300
Distillation: Epoch : 10, Loss : 1.514399, Accuracy: 0.918000, Test accuracy: 0.943000
Distillation: Epoch : 11, Loss : 1.477137, Accuracy: 0.954000, Test accuracy: 0.944600
Distillation: Epoch : 12, Loss : 1.492713, Accuracy: 0.942000, Test accuracy: 0.947200
Distillation: Epoch : 13, Loss : 1.482568, Accuracy: 0.944000, Test accuracy: 0.948400
Distillation: Epoch : 14, Loss : 1.505940, Accuracy: 0.943000, Test accuracy: 0.950400
Distillation: Epoch : 15, Loss : 1.488862, Accuracy: 0.937000, Test accuracy: 0.952100
Distillation: Epoch : 16, Loss : 1.480297, Accuracy: 0.951000, Test accuracy: 0.954000
Distillation: Epoch : 17, Loss : 1.456657, Accuracy: 0.959000, Test accuracy: 0.955200
Distillation: Epoch : 18, Loss : 1.480933, Accuracy: 0.943000, Test accuracy: 0.956400
Distillation: Epoch : 19, Loss : 1.486386, Accuracy: 0.938000, Test accuracy: 0.956700
Distillation: Epoch : 20, Loss : 1.485549, Accuracy: 0.952000, Test accuracy: 0.957100
Distillation: Epoch : 21, Loss : 1.451633, Accuracy: 0.962000, Test accuracy: 0.959700
Distillation: Epoch : 22, Loss : 1.472488, Accuracy: 0.955000, Test accuracy: 0.959400
Distillation: Epoch : 23, Loss : 1.479979, Accuracy: 0.953000, Test accuracy: 0.960200
Distillation: Epoch : 24, Loss : 1.466537, Accuracy: 0.960000, Test accuracy: 0.960500
Distillation: Epoch : 25, Loss : 1.469379, Accuracy: 0.963000, Test accuracy: 0.961400
Distillation: Epoch : 26, Loss : 1.467722, Accuracy: 0.966000, Test accuracy: 0.962500
Distillation: Epoch : 27, Loss : 1.456971, Accuracy: 0.964000, Test accuracy: 0.962300
Distillation: Epoch : 28, Loss : 1.475654, Accuracy: 0.954000, Test accuracy: 0.963400
Distillation: Epoch : 29, Loss : 1.472903, Accuracy: 0.964000, Test accuracy: 0.963400
Distillation: Epoch : 30, Loss : 1.465448, Accuracy: 0.961000, Test accuracy: 0.964000
Distillation: Epoch : 31, Loss : 1.478586, Accuracy: 0.959000, Test accuracy: 0.964700
Distillation: Epoch : 32, Loss : 1.454948, Accuracy: 0.959000, Test accuracy: 0.964600
Distillation: Epoch : 33, Loss : 1.477123, Accuracy: 0.960000, Test accuracy: 0.966000
Distillation: Epoch : 34, Loss : 1.478494, Accuracy: 0.970000, Test accuracy: 0.966400
Distillation: Epoch : 35, Loss : 1.474802, Accuracy: 0.960000, Test accuracy: 0.965800
Distillation: Epoch : 36, Loss : 1.472619, Accuracy: 0.951000, Test accuracy: 0.966500
Distillation: Epoch : 37, Loss : 1.461266, Accuracy: 0.969000, Test accuracy: 0.966900
Distillation: Epoch : 38, Loss : 1.461401, Accuracy: 0.955000, Test accuracy: 0.966600
Distillation: Epoch : 39, Loss : 1.438918, Accuracy: 0.968000, Test accuracy: 0.967400
Distillation: Epoch : 40, Loss : 1.453735, Accuracy: 0.972000, Test accuracy: 0.967300
Distillation: Epoch : 41, Loss : 1.467271, Accuracy: 0.959000, Test accuracy: 0.967700
Distillation: Epoch : 42, Loss : 1.467579, Accuracy: 0.958000, Test accuracy: 0.967600
Distillation: Epoch : 43, Loss : 1.468287, Accuracy: 0.969000, Test accuracy: 0.967800
Distillation: Epoch : 44, Loss : 1.469694, Accuracy: 0.974000, Test accuracy: 0.967900
Distillation: Epoch : 45, Loss : 1.463271, Accuracy: 0.969000, Test accuracy: 0.968500
Distillation: Epoch : 46, Loss : 1.462828, Accuracy: 0.962000, Test accuracy: 0.969100
Distillation: Epoch : 47, Loss : 1.473678, Accuracy: 0.961000, Test accuracy: 0.968700
Distillation: Epoch : 48, Loss : 1.461721, Accuracy: 0.969000, Test accuracy: 0.969000
Distillation: Epoch : 49, Loss : 1.451862, Accuracy: 0.965000, Test accuracy: 0.968800
Distillation: Epoch : 50, Loss : 1.470851, Accuracy: 0.959000, Test accuracy: 0.969100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9691
Generating confusion matrix for student4
[[ 967.    0.    4.    0.    1.    2.    7.    2.    6.    5.]
 [   1. 1116.    6.    0.    0.    0.    3.    5.    1.    6.]
 [   2.    3.  982.    5.    1.    0.    1.   14.    5.    1.]
 [   0.    0.    5.  970.    0.    3.    0.    2.    0.    8.]
 [   2.    1.    5.    1.  965.    2.    3.    4.    3.    9.]
 [   0.    0.    0.   16.    0.  870.    7.    0.    3.    7.]
 [   3.    4.    1.    0.    2.    5.  935.    0.    3.    1.]
 [   2.    0.   11.    6.    1.    2.    0.  992.    7.    6.]
 [   3.   11.   18.   11.    4.    3.    2.    2.  937.    9.]
 [   0.    0.    0.    1.    8.    5.    0.    7.    9.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.128803, Accuracy: 0.739000, Test accuracy: 0.770200
Distillation: Epoch : 2, Loss : 1.880231, Accuracy: 0.843000, Test accuracy: 0.852700
Distillation: Epoch : 3, Loss : 1.859688, Accuracy: 0.864000, Test accuracy: 0.873500
Distillation: Epoch : 4, Loss : 1.839077, Accuracy: 0.879000, Test accuracy: 0.883500
Distillation: Epoch : 5, Loss : 1.829180, Accuracy: 0.882000, Test accuracy: 0.891200
Distillation: Epoch : 6, Loss : 1.817426, Accuracy: 0.909000, Test accuracy: 0.900000
Distillation: Epoch : 7, Loss : 1.809399, Accuracy: 0.897000, Test accuracy: 0.907100
Distillation: Epoch : 8, Loss : 1.814560, Accuracy: 0.896000, Test accuracy: 0.911600
Distillation: Epoch : 9, Loss : 1.796938, Accuracy: 0.901000, Test accuracy: 0.919200
Distillation: Epoch : 10, Loss : 1.789775, Accuracy: 0.924000, Test accuracy: 0.925100
Distillation: Epoch : 11, Loss : 1.787921, Accuracy: 0.922000, Test accuracy: 0.928600
Distillation: Epoch : 12, Loss : 1.785954, Accuracy: 0.915000, Test accuracy: 0.931400
Distillation: Epoch : 13, Loss : 1.783483, Accuracy: 0.942000, Test accuracy: 0.933100
Distillation: Epoch : 14, Loss : 1.775185, Accuracy: 0.933000, Test accuracy: 0.935700
Distillation: Epoch : 15, Loss : 1.772545, Accuracy: 0.933000, Test accuracy: 0.941200
Distillation: Epoch : 16, Loss : 1.765746, Accuracy: 0.934000, Test accuracy: 0.941100
Distillation: Epoch : 17, Loss : 1.784524, Accuracy: 0.929000, Test accuracy: 0.940500
Distillation: Epoch : 18, Loss : 1.785263, Accuracy: 0.935000, Test accuracy: 0.942600
Distillation: Epoch : 19, Loss : 1.784164, Accuracy: 0.931000, Test accuracy: 0.944300
Distillation: Epoch : 20, Loss : 1.778045, Accuracy: 0.940000, Test accuracy: 0.945400
Distillation: Epoch : 21, Loss : 1.773728, Accuracy: 0.939000, Test accuracy: 0.946100
Distillation: Epoch : 22, Loss : 1.776007, Accuracy: 0.934000, Test accuracy: 0.947000
Distillation: Epoch : 23, Loss : 1.773546, Accuracy: 0.940000, Test accuracy: 0.947800
Distillation: Epoch : 24, Loss : 1.746171, Accuracy: 0.950000, Test accuracy: 0.947600
Distillation: Epoch : 25, Loss : 1.774670, Accuracy: 0.943000, Test accuracy: 0.948700
Distillation: Epoch : 26, Loss : 1.768529, Accuracy: 0.930000, Test accuracy: 0.948800
Distillation: Epoch : 27, Loss : 1.758484, Accuracy: 0.942000, Test accuracy: 0.949300
Distillation: Epoch : 28, Loss : 1.761625, Accuracy: 0.941000, Test accuracy: 0.950900
Distillation: Epoch : 29, Loss : 1.761152, Accuracy: 0.956000, Test accuracy: 0.951500
Distillation: Epoch : 30, Loss : 1.756773, Accuracy: 0.952000, Test accuracy: 0.952400
Distillation: Epoch : 31, Loss : 1.769216, Accuracy: 0.942000, Test accuracy: 0.952000
Distillation: Epoch : 32, Loss : 1.756974, Accuracy: 0.949000, Test accuracy: 0.951600
Distillation: Epoch : 33, Loss : 1.760450, Accuracy: 0.941000, Test accuracy: 0.952200
Distillation: Epoch : 34, Loss : 1.779139, Accuracy: 0.949000, Test accuracy: 0.953700
Distillation: Epoch : 35, Loss : 1.760136, Accuracy: 0.944000, Test accuracy: 0.952800
Distillation: Epoch : 36, Loss : 1.749669, Accuracy: 0.952000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 1.757912, Accuracy: 0.946000, Test accuracy: 0.953300
Distillation: Epoch : 38, Loss : 1.767686, Accuracy: 0.949000, Test accuracy: 0.953800
Distillation: Epoch : 39, Loss : 1.773955, Accuracy: 0.952000, Test accuracy: 0.953400
Distillation: Epoch : 40, Loss : 1.762883, Accuracy: 0.945000, Test accuracy: 0.954400
Distillation: Epoch : 41, Loss : 1.762539, Accuracy: 0.948000, Test accuracy: 0.954900
Distillation: Epoch : 42, Loss : 1.751878, Accuracy: 0.946000, Test accuracy: 0.954500
Distillation: Epoch : 43, Loss : 1.764646, Accuracy: 0.941000, Test accuracy: 0.954400
Distillation: Epoch : 44, Loss : 1.764261, Accuracy: 0.961000, Test accuracy: 0.955800
Distillation: Epoch : 45, Loss : 1.757813, Accuracy: 0.949000, Test accuracy: 0.956500
Distillation: Epoch : 46, Loss : 1.777578, Accuracy: 0.945000, Test accuracy: 0.955300
Distillation: Epoch : 47, Loss : 1.761086, Accuracy: 0.951000, Test accuracy: 0.956000
Distillation: Epoch : 48, Loss : 1.749434, Accuracy: 0.943000, Test accuracy: 0.956200
Distillation: Epoch : 49, Loss : 1.762705, Accuracy: 0.954000, Test accuracy: 0.956600
Distillation: Epoch : 50, Loss : 1.772949, Accuracy: 0.951000, Test accuracy: 0.955400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9554
Generating confusion matrix for student4
[[ 963.    0.    2.    0.    0.    1.    7.    2.    7.    4.]
 [   2. 1107.   14.    2.    2.    1.    5.   10.   14.    9.]
 [   0.    4.  953.    5.    0.    0.    0.    9.    7.    1.]
 [   0.    0.    4.  961.    0.    4.    0.    4.    4.    4.]
 [   6.    0.   15.    2.  965.    0.   11.    8.   12.   29.]
 [   0.    0.    1.   15.    0.  870.    9.    0.    6.    7.]
 [   6.    4.    2.    0.    2.    5.  922.    0.    6.    0.]
 [   1.    1.   14.   11.    0.    1.    0.  975.    9.   13.]
 [   2.   19.   25.   11.    4.    3.    4.    5.  897.    1.]
 [   0.    0.    2.    3.    9.    7.    0.   15.   12.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.234172, Accuracy: 0.594000, Test accuracy: 0.570200
Distillation: Epoch : 2, Loss : 2.087506, Accuracy: 0.815000, Test accuracy: 0.825200
Distillation: Epoch : 3, Loss : 2.077892, Accuracy: 0.828000, Test accuracy: 0.849400
Distillation: Epoch : 4, Loss : 2.062797, Accuracy: 0.859000, Test accuracy: 0.863500
Distillation: Epoch : 5, Loss : 2.054351, Accuracy: 0.886000, Test accuracy: 0.873300
Distillation: Epoch : 6, Loss : 2.055866, Accuracy: 0.877000, Test accuracy: 0.879200
Distillation: Epoch : 7, Loss : 2.055452, Accuracy: 0.859000, Test accuracy: 0.884400
Distillation: Epoch : 8, Loss : 2.055464, Accuracy: 0.888000, Test accuracy: 0.889500
Distillation: Epoch : 9, Loss : 2.045583, Accuracy: 0.874000, Test accuracy: 0.893100
Distillation: Epoch : 10, Loss : 2.039614, Accuracy: 0.894000, Test accuracy: 0.893700
Distillation: Epoch : 11, Loss : 2.045260, Accuracy: 0.888000, Test accuracy: 0.897500
Distillation: Epoch : 12, Loss : 2.042484, Accuracy: 0.880000, Test accuracy: 0.902300
Distillation: Epoch : 13, Loss : 2.047285, Accuracy: 0.890000, Test accuracy: 0.906400
Distillation: Epoch : 14, Loss : 2.030378, Accuracy: 0.918000, Test accuracy: 0.907200
Distillation: Epoch : 15, Loss : 2.040858, Accuracy: 0.896000, Test accuracy: 0.910200
Distillation: Epoch : 16, Loss : 2.040602, Accuracy: 0.899000, Test accuracy: 0.912800
Distillation: Epoch : 17, Loss : 2.042149, Accuracy: 0.906000, Test accuracy: 0.916000
Distillation: Epoch : 18, Loss : 2.036035, Accuracy: 0.905000, Test accuracy: 0.917800
Distillation: Epoch : 19, Loss : 2.025317, Accuracy: 0.927000, Test accuracy: 0.922800
Distillation: Epoch : 20, Loss : 2.025393, Accuracy: 0.930000, Test accuracy: 0.924400
Distillation: Epoch : 21, Loss : 2.018944, Accuracy: 0.940000, Test accuracy: 0.928200
Distillation: Epoch : 22, Loss : 2.014777, Accuracy: 0.931000, Test accuracy: 0.930300
Distillation: Epoch : 23, Loss : 2.028534, Accuracy: 0.934000, Test accuracy: 0.934900
Distillation: Epoch : 24, Loss : 2.014637, Accuracy: 0.939000, Test accuracy: 0.938200
Distillation: Epoch : 25, Loss : 2.010111, Accuracy: 0.938000, Test accuracy: 0.941300
Distillation: Epoch : 26, Loss : 2.019043, Accuracy: 0.944000, Test accuracy: 0.943600
Distillation: Epoch : 27, Loss : 2.012703, Accuracy: 0.940000, Test accuracy: 0.945900
Distillation: Epoch : 28, Loss : 2.018030, Accuracy: 0.947000, Test accuracy: 0.947700
Distillation: Epoch : 29, Loss : 2.012629, Accuracy: 0.942000, Test accuracy: 0.950300
Distillation: Epoch : 30, Loss : 2.009139, Accuracy: 0.950000, Test accuracy: 0.951300
Distillation: Epoch : 31, Loss : 1.999263, Accuracy: 0.956000, Test accuracy: 0.953000
Distillation: Epoch : 32, Loss : 2.009440, Accuracy: 0.958000, Test accuracy: 0.952900
Distillation: Epoch : 33, Loss : 2.012666, Accuracy: 0.945000, Test accuracy: 0.954600
Distillation: Epoch : 34, Loss : 2.006764, Accuracy: 0.954000, Test accuracy: 0.955100
Distillation: Epoch : 35, Loss : 2.006104, Accuracy: 0.955000, Test accuracy: 0.956100
Distillation: Epoch : 36, Loss : 2.010629, Accuracy: 0.947000, Test accuracy: 0.958300
Distillation: Epoch : 37, Loss : 2.014802, Accuracy: 0.958000, Test accuracy: 0.957600
Distillation: Epoch : 38, Loss : 2.002883, Accuracy: 0.951000, Test accuracy: 0.958100
Distillation: Epoch : 39, Loss : 2.006014, Accuracy: 0.951000, Test accuracy: 0.957900
Distillation: Epoch : 40, Loss : 2.005130, Accuracy: 0.957000, Test accuracy: 0.960300
Distillation: Epoch : 41, Loss : 2.002545, Accuracy: 0.961000, Test accuracy: 0.960700
Distillation: Epoch : 42, Loss : 2.009409, Accuracy: 0.953000, Test accuracy: 0.960600
Distillation: Epoch : 43, Loss : 2.004986, Accuracy: 0.953000, Test accuracy: 0.961000
Distillation: Epoch : 44, Loss : 1.999645, Accuracy: 0.953000, Test accuracy: 0.962000
Distillation: Epoch : 45, Loss : 2.003600, Accuracy: 0.956000, Test accuracy: 0.961200
Distillation: Epoch : 46, Loss : 1.999387, Accuracy: 0.960000, Test accuracy: 0.963100
Distillation: Epoch : 47, Loss : 2.003743, Accuracy: 0.967000, Test accuracy: 0.964000
Distillation: Epoch : 48, Loss : 2.013194, Accuracy: 0.953000, Test accuracy: 0.963800
Distillation: Epoch : 49, Loss : 2.002012, Accuracy: 0.965000, Test accuracy: 0.962700
Distillation: Epoch : 50, Loss : 1.991337, Accuracy: 0.969000, Test accuracy: 0.963500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9635
Generating confusion matrix for student4
[[ 969.    0.    3.    0.    0.    2.    5.    0.    6.    2.]
 [   2. 1115.    7.    2.    0.    0.    4.   10.    4.    5.]
 [   0.    1.  979.    7.    0.    1.    1.    6.    4.    0.]
 [   0.    1.    8.  947.    0.    5.    0.    1.    2.    5.]
 [   1.    0.    7.    4.  960.    2.   10.    4.    9.   18.]
 [   0.    1.    0.   19.    0.  868.    5.    0.    5.    6.]
 [   3.    3.    2.    0.    6.    3.  931.    1.    4.    0.]
 [   1.    0.   14.   15.    0.    2.    0.  983.    6.    6.]
 [   3.   14.   11.    9.    4.    3.    2.    2.  921.    5.]
 [   1.    0.    1.    7.   12.    6.    0.   21.   13.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.968399, Accuracy: 0.774000, Test accuracy: 0.760900
Distillation: Epoch : 2, Loss : 0.469508, Accuracy: 0.869000, Test accuracy: 0.867100
Distillation: Epoch : 3, Loss : 0.410659, Accuracy: 0.881000, Test accuracy: 0.892300
Distillation: Epoch : 4, Loss : 0.373303, Accuracy: 0.884000, Test accuracy: 0.902000
Distillation: Epoch : 5, Loss : 0.404318, Accuracy: 0.878000, Test accuracy: 0.908300
Distillation: Epoch : 6, Loss : 0.321045, Accuracy: 0.904000, Test accuracy: 0.912500
Distillation: Epoch : 7, Loss : 0.353425, Accuracy: 0.895000, Test accuracy: 0.916300
Distillation: Epoch : 8, Loss : 0.252235, Accuracy: 0.929000, Test accuracy: 0.920400
Distillation: Epoch : 9, Loss : 0.239047, Accuracy: 0.929000, Test accuracy: 0.924300
Distillation: Epoch : 10, Loss : 0.273777, Accuracy: 0.924000, Test accuracy: 0.927400
Distillation: Epoch : 11, Loss : 0.222405, Accuracy: 0.940000, Test accuracy: 0.929000
Distillation: Epoch : 12, Loss : 0.251528, Accuracy: 0.929000, Test accuracy: 0.930500
Distillation: Epoch : 13, Loss : 0.261366, Accuracy: 0.925000, Test accuracy: 0.932900
Distillation: Epoch : 14, Loss : 0.244071, Accuracy: 0.934000, Test accuracy: 0.935100
Distillation: Epoch : 15, Loss : 0.227996, Accuracy: 0.935000, Test accuracy: 0.937200
Distillation: Epoch : 16, Loss : 0.171015, Accuracy: 0.955000, Test accuracy: 0.938500
Distillation: Epoch : 17, Loss : 0.193340, Accuracy: 0.954000, Test accuracy: 0.939700
Distillation: Epoch : 18, Loss : 0.200760, Accuracy: 0.943000, Test accuracy: 0.940300
Distillation: Epoch : 19, Loss : 0.224393, Accuracy: 0.935000, Test accuracy: 0.942600
Distillation: Epoch : 20, Loss : 0.198189, Accuracy: 0.944000, Test accuracy: 0.943700
Distillation: Epoch : 21, Loss : 0.163974, Accuracy: 0.950000, Test accuracy: 0.945200
Distillation: Epoch : 22, Loss : 0.170313, Accuracy: 0.944000, Test accuracy: 0.945700
Distillation: Epoch : 23, Loss : 0.168040, Accuracy: 0.957000, Test accuracy: 0.947200
Distillation: Epoch : 24, Loss : 0.192033, Accuracy: 0.945000, Test accuracy: 0.947200
Distillation: Epoch : 25, Loss : 0.178834, Accuracy: 0.941000, Test accuracy: 0.948400
Distillation: Epoch : 26, Loss : 0.184037, Accuracy: 0.945000, Test accuracy: 0.946600
Distillation: Epoch : 27, Loss : 0.167617, Accuracy: 0.954000, Test accuracy: 0.950000
Distillation: Epoch : 28, Loss : 0.129299, Accuracy: 0.961000, Test accuracy: 0.950200
Distillation: Epoch : 29, Loss : 0.147600, Accuracy: 0.949000, Test accuracy: 0.950400
Distillation: Epoch : 30, Loss : 0.197792, Accuracy: 0.955000, Test accuracy: 0.952200
Distillation: Epoch : 31, Loss : 0.133015, Accuracy: 0.961000, Test accuracy: 0.952700
Distillation: Epoch : 32, Loss : 0.172391, Accuracy: 0.948000, Test accuracy: 0.952800
Distillation: Epoch : 33, Loss : 0.180473, Accuracy: 0.943000, Test accuracy: 0.953400
Distillation: Epoch : 34, Loss : 0.181478, Accuracy: 0.947000, Test accuracy: 0.953500
Distillation: Epoch : 35, Loss : 0.141622, Accuracy: 0.959000, Test accuracy: 0.953300
Distillation: Epoch : 36, Loss : 0.167342, Accuracy: 0.955000, Test accuracy: 0.953800
Distillation: Epoch : 37, Loss : 0.176452, Accuracy: 0.950000, Test accuracy: 0.953300
Distillation: Epoch : 38, Loss : 0.148553, Accuracy: 0.955000, Test accuracy: 0.953300
Distillation: Epoch : 39, Loss : 0.168785, Accuracy: 0.950000, Test accuracy: 0.956200
Distillation: Epoch : 40, Loss : 0.128832, Accuracy: 0.960000, Test accuracy: 0.956000
Distillation: Epoch : 41, Loss : 0.158769, Accuracy: 0.953000, Test accuracy: 0.955900
Distillation: Epoch : 42, Loss : 0.143496, Accuracy: 0.958000, Test accuracy: 0.956000
Distillation: Epoch : 43, Loss : 0.153509, Accuracy: 0.955000, Test accuracy: 0.957500
Distillation: Epoch : 44, Loss : 0.139986, Accuracy: 0.959000, Test accuracy: 0.957400
Distillation: Epoch : 45, Loss : 0.142508, Accuracy: 0.956000, Test accuracy: 0.958200
Distillation: Epoch : 46, Loss : 0.149660, Accuracy: 0.956000, Test accuracy: 0.958300
Distillation: Epoch : 47, Loss : 0.135778, Accuracy: 0.968000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 0.127771, Accuracy: 0.965000, Test accuracy: 0.958300
Distillation: Epoch : 49, Loss : 0.140661, Accuracy: 0.961000, Test accuracy: 0.958200
Distillation: Epoch : 50, Loss : 0.126235, Accuracy: 0.961000, Test accuracy: 0.960300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9603
Generating confusion matrix for student5
[[ 967.    0.    5.    1.    0.    4.    6.    0.    7.    4.]
 [   0. 1126.    6.    0.    2.    2.    2.   10.    0.    5.]
 [   4.    2.  997.   11.    7.    2.    2.   17.    8.    2.]
 [   2.    2.    3.  960.    2.   13.    0.   12.    9.    6.]
 [   0.    0.    4.    1.  940.    3.    5.    3.    8.   11.]
 [   2.    1.    3.   16.    4.  841.   10.    0.   12.   16.]
 [   4.    0.    2.    2.    6.    7.  930.    0.    1.    1.]
 [   1.    0.    9.   10.    2.    4.    0.  973.    4.    6.]
 [   0.    4.    2.    7.    1.   12.    3.    2.  920.    9.]
 [   0.    0.    1.    2.   18.    4.    0.   11.    5.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.233169, Accuracy: 0.755000, Test accuracy: 0.785200
Distillation: Epoch : 2, Loss : 0.509688, Accuracy: 0.867000, Test accuracy: 0.866200
Distillation: Epoch : 3, Loss : 0.464973, Accuracy: 0.875000, Test accuracy: 0.887300
Distillation: Epoch : 4, Loss : 0.422156, Accuracy: 0.896000, Test accuracy: 0.896800
Distillation: Epoch : 5, Loss : 0.328392, Accuracy: 0.911000, Test accuracy: 0.902000
Distillation: Epoch : 6, Loss : 0.391126, Accuracy: 0.898000, Test accuracy: 0.904900
Distillation: Epoch : 7, Loss : 0.331108, Accuracy: 0.907000, Test accuracy: 0.908000
Distillation: Epoch : 8, Loss : 0.299965, Accuracy: 0.916000, Test accuracy: 0.909100
Distillation: Epoch : 9, Loss : 0.314866, Accuracy: 0.921000, Test accuracy: 0.912500
Distillation: Epoch : 10, Loss : 0.340776, Accuracy: 0.899000, Test accuracy: 0.913200
Distillation: Epoch : 11, Loss : 0.318657, Accuracy: 0.911000, Test accuracy: 0.917100
Distillation: Epoch : 12, Loss : 0.350294, Accuracy: 0.902000, Test accuracy: 0.918700
Distillation: Epoch : 13, Loss : 0.306051, Accuracy: 0.914000, Test accuracy: 0.918800
Distillation: Epoch : 14, Loss : 0.272645, Accuracy: 0.929000, Test accuracy: 0.921800
Distillation: Epoch : 15, Loss : 0.341783, Accuracy: 0.905000, Test accuracy: 0.924500
Distillation: Epoch : 16, Loss : 0.319035, Accuracy: 0.916000, Test accuracy: 0.928100
Distillation: Epoch : 17, Loss : 0.334437, Accuracy: 0.905000, Test accuracy: 0.929800
Distillation: Epoch : 18, Loss : 0.264389, Accuracy: 0.927000, Test accuracy: 0.930400
Distillation: Epoch : 19, Loss : 0.279688, Accuracy: 0.926000, Test accuracy: 0.933800
Distillation: Epoch : 20, Loss : 0.295611, Accuracy: 0.913000, Test accuracy: 0.934400
Distillation: Epoch : 21, Loss : 0.263057, Accuracy: 0.937000, Test accuracy: 0.936800
Distillation: Epoch : 22, Loss : 0.235492, Accuracy: 0.930000, Test accuracy: 0.937900
Distillation: Epoch : 23, Loss : 0.240945, Accuracy: 0.939000, Test accuracy: 0.939100
Distillation: Epoch : 24, Loss : 0.223913, Accuracy: 0.937000, Test accuracy: 0.941200
Distillation: Epoch : 25, Loss : 0.236028, Accuracy: 0.938000, Test accuracy: 0.941800
Distillation: Epoch : 26, Loss : 0.203204, Accuracy: 0.956000, Test accuracy: 0.943000
Distillation: Epoch : 27, Loss : 0.242637, Accuracy: 0.934000, Test accuracy: 0.944800
Distillation: Epoch : 28, Loss : 0.209835, Accuracy: 0.952000, Test accuracy: 0.944700
Distillation: Epoch : 29, Loss : 0.199947, Accuracy: 0.943000, Test accuracy: 0.947100
Distillation: Epoch : 30, Loss : 0.209632, Accuracy: 0.944000, Test accuracy: 0.948300
Distillation: Epoch : 31, Loss : 0.228235, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 32, Loss : 0.200864, Accuracy: 0.943000, Test accuracy: 0.950400
Distillation: Epoch : 33, Loss : 0.222602, Accuracy: 0.940000, Test accuracy: 0.951200
Distillation: Epoch : 34, Loss : 0.209495, Accuracy: 0.951000, Test accuracy: 0.953100
Distillation: Epoch : 35, Loss : 0.225959, Accuracy: 0.947000, Test accuracy: 0.953700
Distillation: Epoch : 36, Loss : 0.217511, Accuracy: 0.946000, Test accuracy: 0.953700
Distillation: Epoch : 37, Loss : 0.236876, Accuracy: 0.943000, Test accuracy: 0.954800
Distillation: Epoch : 38, Loss : 0.190693, Accuracy: 0.954000, Test accuracy: 0.955600
Distillation: Epoch : 39, Loss : 0.175583, Accuracy: 0.954000, Test accuracy: 0.956500
Distillation: Epoch : 40, Loss : 0.179578, Accuracy: 0.949000, Test accuracy: 0.957400
Distillation: Epoch : 41, Loss : 0.174921, Accuracy: 0.948000, Test accuracy: 0.957300
Distillation: Epoch : 42, Loss : 0.187961, Accuracy: 0.955000, Test accuracy: 0.958100
Distillation: Epoch : 43, Loss : 0.202124, Accuracy: 0.943000, Test accuracy: 0.958900
Distillation: Epoch : 44, Loss : 0.195213, Accuracy: 0.953000, Test accuracy: 0.959100
Distillation: Epoch : 45, Loss : 0.133248, Accuracy: 0.969000, Test accuracy: 0.961100
Distillation: Epoch : 46, Loss : 0.136432, Accuracy: 0.969000, Test accuracy: 0.960700
Distillation: Epoch : 47, Loss : 0.154554, Accuracy: 0.964000, Test accuracy: 0.961600
Distillation: Epoch : 48, Loss : 0.178915, Accuracy: 0.955000, Test accuracy: 0.960600
Distillation: Epoch : 49, Loss : 0.171005, Accuracy: 0.951000, Test accuracy: 0.961000
Distillation: Epoch : 50, Loss : 0.166095, Accuracy: 0.962000, Test accuracy: 0.962300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9623
Generating confusion matrix for student5
[[ 968.    0.    4.    1.    1.    2.    5.    2.    8.    3.]
 [   0. 1118.   12.    1.    2.    2.    3.   10.    6.    7.]
 [   1.    3.  982.    6.    2.    1.    2.   17.    3.    1.]
 [   0.    4.    9.  958.    0.    6.    1.    4.    7.    5.]
 [   1.    0.    8.    1.  944.    0.    6.    1.    6.   12.]
 [   0.    0.    0.   16.    0.  868.    8.    1.    5.    8.]
 [   3.    2.    2.    0.    6.    5.  930.    0.    8.    1.]
 [   3.    0.    9.    8.    3.    3.    0.  977.    9.    9.]
 [   4.    8.    3.    7.    4.    3.    3.    1.  915.    0.]
 [   0.    0.    3.   12.   20.    2.    0.   15.    7.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.686706, Accuracy: 0.707000, Test accuracy: 0.726600
Distillation: Epoch : 2, Loss : 0.907627, Accuracy: 0.818000, Test accuracy: 0.837100
Distillation: Epoch : 3, Loss : 0.782879, Accuracy: 0.854000, Test accuracy: 0.873100
Distillation: Epoch : 4, Loss : 0.735494, Accuracy: 0.873000, Test accuracy: 0.886400
Distillation: Epoch : 5, Loss : 0.692726, Accuracy: 0.901000, Test accuracy: 0.894000
Distillation: Epoch : 6, Loss : 0.706424, Accuracy: 0.874000, Test accuracy: 0.899500
Distillation: Epoch : 7, Loss : 0.696567, Accuracy: 0.889000, Test accuracy: 0.903000
Distillation: Epoch : 8, Loss : 0.651757, Accuracy: 0.914000, Test accuracy: 0.906000
Distillation: Epoch : 9, Loss : 0.635880, Accuracy: 0.911000, Test accuracy: 0.908800
Distillation: Epoch : 10, Loss : 0.641628, Accuracy: 0.917000, Test accuracy: 0.911600
Distillation: Epoch : 11, Loss : 0.651755, Accuracy: 0.909000, Test accuracy: 0.911900
Distillation: Epoch : 12, Loss : 0.628392, Accuracy: 0.908000, Test accuracy: 0.915700
Distillation: Epoch : 13, Loss : 0.612127, Accuracy: 0.926000, Test accuracy: 0.921500
Distillation: Epoch : 14, Loss : 0.640851, Accuracy: 0.911000, Test accuracy: 0.924100
Distillation: Epoch : 15, Loss : 0.609487, Accuracy: 0.917000, Test accuracy: 0.926800
Distillation: Epoch : 16, Loss : 0.604724, Accuracy: 0.921000, Test accuracy: 0.930200
Distillation: Epoch : 17, Loss : 0.546942, Accuracy: 0.944000, Test accuracy: 0.934100
Distillation: Epoch : 18, Loss : 0.558863, Accuracy: 0.940000, Test accuracy: 0.936300
Distillation: Epoch : 19, Loss : 0.537904, Accuracy: 0.937000, Test accuracy: 0.938300
Distillation: Epoch : 20, Loss : 0.542464, Accuracy: 0.943000, Test accuracy: 0.941700
Distillation: Epoch : 21, Loss : 0.580030, Accuracy: 0.933000, Test accuracy: 0.943400
Distillation: Epoch : 22, Loss : 0.539271, Accuracy: 0.941000, Test accuracy: 0.945300
Distillation: Epoch : 23, Loss : 0.561848, Accuracy: 0.940000, Test accuracy: 0.946800
Distillation: Epoch : 24, Loss : 0.550773, Accuracy: 0.949000, Test accuracy: 0.947600
Distillation: Epoch : 25, Loss : 0.562891, Accuracy: 0.942000, Test accuracy: 0.949100
Distillation: Epoch : 26, Loss : 0.529944, Accuracy: 0.937000, Test accuracy: 0.951200
Distillation: Epoch : 27, Loss : 0.515659, Accuracy: 0.945000, Test accuracy: 0.951200
Distillation: Epoch : 28, Loss : 0.527801, Accuracy: 0.944000, Test accuracy: 0.952400
Distillation: Epoch : 29, Loss : 0.498889, Accuracy: 0.956000, Test accuracy: 0.955400
Distillation: Epoch : 30, Loss : 0.523964, Accuracy: 0.945000, Test accuracy: 0.954900
Distillation: Epoch : 31, Loss : 0.504470, Accuracy: 0.952000, Test accuracy: 0.956100
Distillation: Epoch : 32, Loss : 0.505108, Accuracy: 0.953000, Test accuracy: 0.956200
Distillation: Epoch : 33, Loss : 0.491810, Accuracy: 0.967000, Test accuracy: 0.956800
Distillation: Epoch : 34, Loss : 0.487994, Accuracy: 0.957000, Test accuracy: 0.957100
Distillation: Epoch : 35, Loss : 0.485777, Accuracy: 0.958000, Test accuracy: 0.956100
Distillation: Epoch : 36, Loss : 0.498151, Accuracy: 0.959000, Test accuracy: 0.958400
Distillation: Epoch : 37, Loss : 0.496674, Accuracy: 0.949000, Test accuracy: 0.958400
Distillation: Epoch : 38, Loss : 0.490222, Accuracy: 0.958000, Test accuracy: 0.959500
Distillation: Epoch : 39, Loss : 0.527029, Accuracy: 0.948000, Test accuracy: 0.958900
Distillation: Epoch : 40, Loss : 0.497281, Accuracy: 0.961000, Test accuracy: 0.960200
Distillation: Epoch : 41, Loss : 0.491373, Accuracy: 0.958000, Test accuracy: 0.960400
Distillation: Epoch : 42, Loss : 0.488530, Accuracy: 0.965000, Test accuracy: 0.960000
Distillation: Epoch : 43, Loss : 0.498351, Accuracy: 0.957000, Test accuracy: 0.961000
Distillation: Epoch : 44, Loss : 0.520065, Accuracy: 0.945000, Test accuracy: 0.961100
Distillation: Epoch : 45, Loss : 0.473306, Accuracy: 0.966000, Test accuracy: 0.960800
Distillation: Epoch : 46, Loss : 0.483557, Accuracy: 0.969000, Test accuracy: 0.961100
Distillation: Epoch : 47, Loss : 0.485285, Accuracy: 0.958000, Test accuracy: 0.961200
Distillation: Epoch : 48, Loss : 0.496996, Accuracy: 0.953000, Test accuracy: 0.961300
Distillation: Epoch : 49, Loss : 0.515683, Accuracy: 0.950000, Test accuracy: 0.962600
Distillation: Epoch : 50, Loss : 0.469222, Accuracy: 0.962000, Test accuracy: 0.962000
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.962
Generating confusion matrix for student5
[[ 965.    0.    2.    3.    1.    4.    9.    1.    6.    6.]
 [   1. 1120.   10.    1.    1.    1.    3.    4.    3.    7.]
 [   0.    3.  978.    8.    1.    2.    0.   14.    7.    1.]
 [   0.    0.    3.  957.    0.    5.    0.    3.    6.    3.]
 [   1.    2.    6.    1.  960.    1.    5.    3.    8.   15.]
 [   3.    1.    1.   13.    0.  854.   16.    2.    9.    9.]
 [   6.    3.    2.    0.    4.    3.  923.    0.    2.    1.]
 [   3.    0.    9.    6.    0.    1.    0.  984.    5.    6.]
 [   1.    6.   20.   19.    3.   17.    2.    2.  920.    2.]
 [   0.    0.    1.    2.   12.    4.    0.   15.    8.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.044028, Accuracy: 0.652000, Test accuracy: 0.672300
Distillation: Epoch : 2, Loss : 1.163072, Accuracy: 0.795000, Test accuracy: 0.809300
Distillation: Epoch : 3, Loss : 0.938986, Accuracy: 0.860000, Test accuracy: 0.853700
Distillation: Epoch : 4, Loss : 0.929598, Accuracy: 0.858000, Test accuracy: 0.871700
Distillation: Epoch : 5, Loss : 0.893603, Accuracy: 0.877000, Test accuracy: 0.885200
Distillation: Epoch : 6, Loss : 0.896591, Accuracy: 0.876000, Test accuracy: 0.892300
Distillation: Epoch : 7, Loss : 0.871382, Accuracy: 0.890000, Test accuracy: 0.897700
Distillation: Epoch : 8, Loss : 0.839177, Accuracy: 0.899000, Test accuracy: 0.902300
Distillation: Epoch : 9, Loss : 0.811443, Accuracy: 0.908000, Test accuracy: 0.905500
Distillation: Epoch : 10, Loss : 0.827955, Accuracy: 0.902000, Test accuracy: 0.906800
Distillation: Epoch : 11, Loss : 0.810485, Accuracy: 0.902000, Test accuracy: 0.909900
Distillation: Epoch : 12, Loss : 0.847046, Accuracy: 0.886000, Test accuracy: 0.913300
Distillation: Epoch : 13, Loss : 0.816662, Accuracy: 0.914000, Test accuracy: 0.914700
Distillation: Epoch : 14, Loss : 0.819127, Accuracy: 0.902000, Test accuracy: 0.915800
Distillation: Epoch : 15, Loss : 0.807393, Accuracy: 0.920000, Test accuracy: 0.918200
Distillation: Epoch : 16, Loss : 0.784398, Accuracy: 0.923000, Test accuracy: 0.919700
Distillation: Epoch : 17, Loss : 0.789035, Accuracy: 0.912000, Test accuracy: 0.922600
Distillation: Epoch : 18, Loss : 0.821173, Accuracy: 0.915000, Test accuracy: 0.922700
Distillation: Epoch : 19, Loss : 0.803670, Accuracy: 0.909000, Test accuracy: 0.923600
Distillation: Epoch : 20, Loss : 0.787545, Accuracy: 0.910000, Test accuracy: 0.925400
Distillation: Epoch : 21, Loss : 0.789897, Accuracy: 0.914000, Test accuracy: 0.928200
Distillation: Epoch : 22, Loss : 0.771544, Accuracy: 0.929000, Test accuracy: 0.929800
Distillation: Epoch : 23, Loss : 0.785682, Accuracy: 0.932000, Test accuracy: 0.932400
Distillation: Epoch : 24, Loss : 0.748876, Accuracy: 0.931000, Test accuracy: 0.933400
Distillation: Epoch : 25, Loss : 0.743593, Accuracy: 0.938000, Test accuracy: 0.935100
Distillation: Epoch : 26, Loss : 0.750453, Accuracy: 0.927000, Test accuracy: 0.935900
Distillation: Epoch : 27, Loss : 0.775780, Accuracy: 0.928000, Test accuracy: 0.938400
Distillation: Epoch : 28, Loss : 0.743779, Accuracy: 0.931000, Test accuracy: 0.940400
Distillation: Epoch : 29, Loss : 0.739664, Accuracy: 0.945000, Test accuracy: 0.941400
Distillation: Epoch : 30, Loss : 0.741472, Accuracy: 0.938000, Test accuracy: 0.942800
Distillation: Epoch : 31, Loss : 0.704972, Accuracy: 0.947000, Test accuracy: 0.944800
Distillation: Epoch : 32, Loss : 0.709776, Accuracy: 0.941000, Test accuracy: 0.945200
Distillation: Epoch : 33, Loss : 0.716630, Accuracy: 0.936000, Test accuracy: 0.946600
Distillation: Epoch : 34, Loss : 0.713124, Accuracy: 0.952000, Test accuracy: 0.946900
Distillation: Epoch : 35, Loss : 0.693366, Accuracy: 0.945000, Test accuracy: 0.947400
Distillation: Epoch : 36, Loss : 0.686358, Accuracy: 0.952000, Test accuracy: 0.948900
Distillation: Epoch : 37, Loss : 0.715378, Accuracy: 0.947000, Test accuracy: 0.950100
Distillation: Epoch : 38, Loss : 0.722173, Accuracy: 0.942000, Test accuracy: 0.949900
Distillation: Epoch : 39, Loss : 0.691925, Accuracy: 0.951000, Test accuracy: 0.951700
Distillation: Epoch : 40, Loss : 0.686636, Accuracy: 0.953000, Test accuracy: 0.952700
Distillation: Epoch : 41, Loss : 0.688626, Accuracy: 0.954000, Test accuracy: 0.951500
Distillation: Epoch : 42, Loss : 0.725498, Accuracy: 0.952000, Test accuracy: 0.954000
Distillation: Epoch : 43, Loss : 0.709927, Accuracy: 0.944000, Test accuracy: 0.955400
Distillation: Epoch : 44, Loss : 0.710928, Accuracy: 0.956000, Test accuracy: 0.955100
Distillation: Epoch : 45, Loss : 0.694489, Accuracy: 0.953000, Test accuracy: 0.955600
Distillation: Epoch : 46, Loss : 0.725379, Accuracy: 0.944000, Test accuracy: 0.956100
Distillation: Epoch : 47, Loss : 0.704491, Accuracy: 0.952000, Test accuracy: 0.955700
Distillation: Epoch : 48, Loss : 0.695188, Accuracy: 0.959000, Test accuracy: 0.955500
Distillation: Epoch : 49, Loss : 0.688947, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 50, Loss : 0.703860, Accuracy: 0.949000, Test accuracy: 0.957300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9573
Generating confusion matrix for student5
[[ 964.    0.    5.    0.    0.    2.    8.    2.    7.    3.]
 [   1. 1113.    6.    0.    0.    1.    3.    6.    1.    5.]
 [   2.    2.  968.    8.    2.    2.    2.   22.   12.    0.]
 [   1.    1.    4.  971.    1.   14.    0.    2.    5.    8.]
 [   2.    1.    6.    2.  951.    0.    4.    8.    7.   17.]
 [   1.    1.    2.   15.    0.  845.   14.    1.   12.    8.]
 [   2.    4.    4.    0.    6.    5.  926.    0.    6.    0.]
 [   4.    0.   11.    7.    2.    2.    0.  970.    4.   12.]
 [   3.   13.   22.    6.    4.   17.    1.    2.  915.    6.]
 [   0.    0.    4.    1.   16.    4.    0.   15.    5.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.800187, Accuracy: 0.740000, Test accuracy: 0.755200
Distillation: Epoch : 2, Loss : 1.204951, Accuracy: 0.837000, Test accuracy: 0.848100
Distillation: Epoch : 3, Loss : 1.069411, Accuracy: 0.880000, Test accuracy: 0.877300
Distillation: Epoch : 4, Loss : 1.064594, Accuracy: 0.868000, Test accuracy: 0.890800
Distillation: Epoch : 5, Loss : 1.018752, Accuracy: 0.892000, Test accuracy: 0.900000
Distillation: Epoch : 6, Loss : 1.021441, Accuracy: 0.899000, Test accuracy: 0.903900
Distillation: Epoch : 7, Loss : 0.975805, Accuracy: 0.905000, Test accuracy: 0.908700
Distillation: Epoch : 8, Loss : 1.014065, Accuracy: 0.893000, Test accuracy: 0.913100
Distillation: Epoch : 9, Loss : 0.971645, Accuracy: 0.914000, Test accuracy: 0.917500
Distillation: Epoch : 10, Loss : 0.954722, Accuracy: 0.920000, Test accuracy: 0.921100
Distillation: Epoch : 11, Loss : 0.957548, Accuracy: 0.925000, Test accuracy: 0.924100
Distillation: Epoch : 12, Loss : 0.963730, Accuracy: 0.916000, Test accuracy: 0.926800
Distillation: Epoch : 13, Loss : 0.931991, Accuracy: 0.919000, Test accuracy: 0.929100
Distillation: Epoch : 14, Loss : 0.939479, Accuracy: 0.925000, Test accuracy: 0.932100
Distillation: Epoch : 15, Loss : 0.943322, Accuracy: 0.928000, Test accuracy: 0.935700
Distillation: Epoch : 16, Loss : 0.930945, Accuracy: 0.923000, Test accuracy: 0.939200
Distillation: Epoch : 17, Loss : 0.900479, Accuracy: 0.941000, Test accuracy: 0.940700
Distillation: Epoch : 18, Loss : 0.905353, Accuracy: 0.929000, Test accuracy: 0.943300
Distillation: Epoch : 19, Loss : 0.891287, Accuracy: 0.947000, Test accuracy: 0.943100
Distillation: Epoch : 20, Loss : 0.917346, Accuracy: 0.927000, Test accuracy: 0.945900
Distillation: Epoch : 21, Loss : 0.899620, Accuracy: 0.943000, Test accuracy: 0.946900
Distillation: Epoch : 22, Loss : 0.933252, Accuracy: 0.935000, Test accuracy: 0.949600
Distillation: Epoch : 23, Loss : 0.894473, Accuracy: 0.946000, Test accuracy: 0.950100
Distillation: Epoch : 24, Loss : 0.873883, Accuracy: 0.949000, Test accuracy: 0.949900
Distillation: Epoch : 25, Loss : 0.901110, Accuracy: 0.942000, Test accuracy: 0.951800
Distillation: Epoch : 26, Loss : 0.889209, Accuracy: 0.940000, Test accuracy: 0.951200
Distillation: Epoch : 27, Loss : 0.843616, Accuracy: 0.951000, Test accuracy: 0.953900
Distillation: Epoch : 28, Loss : 0.889067, Accuracy: 0.951000, Test accuracy: 0.954700
Distillation: Epoch : 29, Loss : 0.851945, Accuracy: 0.947000, Test accuracy: 0.956300
Distillation: Epoch : 30, Loss : 0.875447, Accuracy: 0.950000, Test accuracy: 0.956000
Distillation: Epoch : 31, Loss : 0.879189, Accuracy: 0.951000, Test accuracy: 0.957100
Distillation: Epoch : 32, Loss : 0.866883, Accuracy: 0.957000, Test accuracy: 0.957600
Distillation: Epoch : 33, Loss : 0.890977, Accuracy: 0.948000, Test accuracy: 0.958400
Distillation: Epoch : 34, Loss : 0.890689, Accuracy: 0.947000, Test accuracy: 0.958800
Distillation: Epoch : 35, Loss : 0.839204, Accuracy: 0.965000, Test accuracy: 0.958800
Distillation: Epoch : 36, Loss : 0.883231, Accuracy: 0.950000, Test accuracy: 0.960200
Distillation: Epoch : 37, Loss : 0.885073, Accuracy: 0.949000, Test accuracy: 0.960200
Distillation: Epoch : 38, Loss : 0.846106, Accuracy: 0.960000, Test accuracy: 0.960800
Distillation: Epoch : 39, Loss : 0.856426, Accuracy: 0.968000, Test accuracy: 0.961900
Distillation: Epoch : 40, Loss : 0.865968, Accuracy: 0.958000, Test accuracy: 0.961100
Distillation: Epoch : 41, Loss : 0.843879, Accuracy: 0.964000, Test accuracy: 0.961000
Distillation: Epoch : 42, Loss : 0.874256, Accuracy: 0.956000, Test accuracy: 0.962700
Distillation: Epoch : 43, Loss : 0.854026, Accuracy: 0.962000, Test accuracy: 0.961500
Distillation: Epoch : 44, Loss : 0.860328, Accuracy: 0.942000, Test accuracy: 0.962000
Distillation: Epoch : 45, Loss : 0.877144, Accuracy: 0.951000, Test accuracy: 0.962300
Distillation: Epoch : 46, Loss : 0.888632, Accuracy: 0.949000, Test accuracy: 0.962600
Distillation: Epoch : 47, Loss : 0.872194, Accuracy: 0.961000, Test accuracy: 0.963200
Distillation: Epoch : 48, Loss : 0.849446, Accuracy: 0.963000, Test accuracy: 0.963400
Distillation: Epoch : 49, Loss : 0.878817, Accuracy: 0.957000, Test accuracy: 0.963600
Distillation: Epoch : 50, Loss : 0.867510, Accuracy: 0.963000, Test accuracy: 0.963400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9634
Generating confusion matrix for student5
[[ 966.    0.    1.    0.    1.    1.    9.    2.    6.    5.]
 [   0. 1117.   16.    0.    3.    1.    5.    9.    8.    8.]
 [   1.    4.  975.    5.    1.    0.    1.   11.    6.    0.]
 [   0.    3.    6.  977.    1.    7.    0.    5.    5.    6.]
 [   3.    0.    8.    0.  956.    1.    8.    1.    7.   24.]
 [   0.    0.    0.   12.    0.  869.    7.    0.    5.    3.]
 [   6.    1.    0.    0.    2.    4.  925.    0.    3.    0.]
 [   1.    0.    8.    5.    0.    2.    0.  984.    8.   12.]
 [   3.   10.   16.    8.    3.    5.    3.    3.  918.    4.]
 [   0.    0.    2.    3.   15.    2.    0.   13.    8.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.577341, Accuracy: 0.767000, Test accuracy: 0.788800
Distillation: Epoch : 2, Loss : 1.294063, Accuracy: 0.843000, Test accuracy: 0.857800
Distillation: Epoch : 3, Loss : 1.285413, Accuracy: 0.849000, Test accuracy: 0.877300
Distillation: Epoch : 4, Loss : 1.245460, Accuracy: 0.875000, Test accuracy: 0.881900
Distillation: Epoch : 5, Loss : 1.235301, Accuracy: 0.859000, Test accuracy: 0.886300
Distillation: Epoch : 6, Loss : 1.190679, Accuracy: 0.877000, Test accuracy: 0.888400
Distillation: Epoch : 7, Loss : 1.223426, Accuracy: 0.878000, Test accuracy: 0.891400
Distillation: Epoch : 8, Loss : 1.185548, Accuracy: 0.915000, Test accuracy: 0.893400
Distillation: Epoch : 9, Loss : 1.156857, Accuracy: 0.901000, Test accuracy: 0.896800
Distillation: Epoch : 10, Loss : 1.167871, Accuracy: 0.895000, Test accuracy: 0.896900
Distillation: Epoch : 11, Loss : 1.189312, Accuracy: 0.883000, Test accuracy: 0.898000
Distillation: Epoch : 12, Loss : 1.200764, Accuracy: 0.890000, Test accuracy: 0.900000
Distillation: Epoch : 13, Loss : 1.226523, Accuracy: 0.869000, Test accuracy: 0.899300
Distillation: Epoch : 14, Loss : 1.159045, Accuracy: 0.888000, Test accuracy: 0.900400
Distillation: Epoch : 15, Loss : 1.187866, Accuracy: 0.901000, Test accuracy: 0.900800
Distillation: Epoch : 16, Loss : 1.171999, Accuracy: 0.908000, Test accuracy: 0.901000
Distillation: Epoch : 17, Loss : 1.198880, Accuracy: 0.873000, Test accuracy: 0.901400
Distillation: Epoch : 18, Loss : 1.175838, Accuracy: 0.902000, Test accuracy: 0.903600
Distillation: Epoch : 19, Loss : 1.179662, Accuracy: 0.888000, Test accuracy: 0.902500
Distillation: Epoch : 20, Loss : 1.175812, Accuracy: 0.897000, Test accuracy: 0.903000
Distillation: Epoch : 21, Loss : 1.163491, Accuracy: 0.893000, Test accuracy: 0.900700
Distillation: Epoch : 22, Loss : 1.175044, Accuracy: 0.894000, Test accuracy: 0.901800
Distillation: Epoch : 23, Loss : 1.149756, Accuracy: 0.897000, Test accuracy: 0.904000
Distillation: Epoch : 24, Loss : 1.185308, Accuracy: 0.901000, Test accuracy: 0.902400
Distillation: Epoch : 25, Loss : 1.189720, Accuracy: 0.902000, Test accuracy: 0.905800
Distillation: Epoch : 26, Loss : 1.173100, Accuracy: 0.884000, Test accuracy: 0.905200
Distillation: Epoch : 27, Loss : 1.166451, Accuracy: 0.908000, Test accuracy: 0.906100
Distillation: Epoch : 28, Loss : 1.187120, Accuracy: 0.902000, Test accuracy: 0.906000
Distillation: Epoch : 29, Loss : 1.191525, Accuracy: 0.900000, Test accuracy: 0.907200
Distillation: Epoch : 30, Loss : 1.159803, Accuracy: 0.911000, Test accuracy: 0.906600
Distillation: Epoch : 31, Loss : 1.145227, Accuracy: 0.901000, Test accuracy: 0.905900
Distillation: Epoch : 32, Loss : 1.161636, Accuracy: 0.908000, Test accuracy: 0.907100
Distillation: Epoch : 33, Loss : 1.173089, Accuracy: 0.902000, Test accuracy: 0.906100
Distillation: Epoch : 34, Loss : 1.149645, Accuracy: 0.898000, Test accuracy: 0.907100
Distillation: Epoch : 35, Loss : 1.142568, Accuracy: 0.905000, Test accuracy: 0.906200
Distillation: Epoch : 36, Loss : 1.146722, Accuracy: 0.894000, Test accuracy: 0.907600
Distillation: Epoch : 37, Loss : 1.151040, Accuracy: 0.906000, Test accuracy: 0.905800
Distillation: Epoch : 38, Loss : 1.189978, Accuracy: 0.897000, Test accuracy: 0.906400
Distillation: Epoch : 39, Loss : 1.135170, Accuracy: 0.898000, Test accuracy: 0.908000
Distillation: Epoch : 40, Loss : 1.106539, Accuracy: 0.923000, Test accuracy: 0.906600
Distillation: Epoch : 41, Loss : 1.161816, Accuracy: 0.892000, Test accuracy: 0.905800
Distillation: Epoch : 42, Loss : 1.147539, Accuracy: 0.905000, Test accuracy: 0.907400
Distillation: Epoch : 43, Loss : 1.143918, Accuracy: 0.902000, Test accuracy: 0.904900
Distillation: Epoch : 44, Loss : 1.146791, Accuracy: 0.906000, Test accuracy: 0.905600
Distillation: Epoch : 45, Loss : 1.144258, Accuracy: 0.892000, Test accuracy: 0.907400
Distillation: Epoch : 46, Loss : 1.153857, Accuracy: 0.913000, Test accuracy: 0.908200
Distillation: Epoch : 47, Loss : 1.168941, Accuracy: 0.911000, Test accuracy: 0.907700
Distillation: Epoch : 48, Loss : 1.138160, Accuracy: 0.893000, Test accuracy: 0.908100
Distillation: Epoch : 49, Loss : 1.143906, Accuracy: 0.910000, Test accuracy: 0.907800
Distillation: Epoch : 50, Loss : 1.158560, Accuracy: 0.899000, Test accuracy: 0.908600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9086
Generating confusion matrix for student5
[[ 944.    0.    8.    5.    0.    7.    7.    1.    7.    8.]
 [   1. 1106.   20.    3.    2.    4.    4.   22.   12.    7.]
 [   2.    3.  893.   23.    4.    2.    6.   17.    7.    0.]
 [   1.    2.   15.  879.    1.   16.    0.    3.   17.   11.]
 [   5.    1.   19.    4.  924.    9.   13.   19.   18.   50.]
 [   8.    4.    3.   50.    3.  792.   24.    2.   43.   10.]
 [  12.    4.   11.    4.    9.   15.  900.    0.   12.    1.]
 [   2.    0.   20.   14.    1.    9.    2.  924.    8.   27.]
 [   4.   15.   36.   19.   10.   28.    2.    0.  839.   10.]
 [   1.    0.    7.    9.   28.   10.    0.   40.   11.  885.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.160930, Accuracy: 0.581000, Test accuracy: 0.587600
Distillation: Epoch : 2, Loss : 1.506295, Accuracy: 0.814000, Test accuracy: 0.820700
Distillation: Epoch : 3, Loss : 1.402838, Accuracy: 0.863000, Test accuracy: 0.863100
Distillation: Epoch : 4, Loss : 1.373435, Accuracy: 0.864000, Test accuracy: 0.878400
Distillation: Epoch : 5, Loss : 1.345277, Accuracy: 0.879000, Test accuracy: 0.886300
Distillation: Epoch : 6, Loss : 1.333963, Accuracy: 0.889000, Test accuracy: 0.894100
Distillation: Epoch : 7, Loss : 1.313704, Accuracy: 0.885000, Test accuracy: 0.899100
Distillation: Epoch : 8, Loss : 1.338279, Accuracy: 0.874000, Test accuracy: 0.904900
Distillation: Epoch : 9, Loss : 1.296142, Accuracy: 0.894000, Test accuracy: 0.909800
Distillation: Epoch : 10, Loss : 1.276478, Accuracy: 0.917000, Test accuracy: 0.915500
Distillation: Epoch : 11, Loss : 1.315893, Accuracy: 0.894000, Test accuracy: 0.918500
Distillation: Epoch : 12, Loss : 1.281674, Accuracy: 0.916000, Test accuracy: 0.921800
Distillation: Epoch : 13, Loss : 1.298966, Accuracy: 0.904000, Test accuracy: 0.925900
Distillation: Epoch : 14, Loss : 1.272742, Accuracy: 0.919000, Test accuracy: 0.928900
Distillation: Epoch : 15, Loss : 1.259913, Accuracy: 0.929000, Test accuracy: 0.931000
Distillation: Epoch : 16, Loss : 1.248610, Accuracy: 0.926000, Test accuracy: 0.933500
Distillation: Epoch : 17, Loss : 1.267032, Accuracy: 0.937000, Test accuracy: 0.935900
Distillation: Epoch : 18, Loss : 1.262611, Accuracy: 0.917000, Test accuracy: 0.938700
Distillation: Epoch : 19, Loss : 1.235252, Accuracy: 0.947000, Test accuracy: 0.940600
Distillation: Epoch : 20, Loss : 1.249934, Accuracy: 0.936000, Test accuracy: 0.941800
Distillation: Epoch : 21, Loss : 1.234859, Accuracy: 0.936000, Test accuracy: 0.944900
Distillation: Epoch : 22, Loss : 1.228787, Accuracy: 0.951000, Test accuracy: 0.944800
Distillation: Epoch : 23, Loss : 1.236277, Accuracy: 0.933000, Test accuracy: 0.947100
Distillation: Epoch : 24, Loss : 1.249440, Accuracy: 0.938000, Test accuracy: 0.948200
Distillation: Epoch : 25, Loss : 1.216595, Accuracy: 0.949000, Test accuracy: 0.950000
Distillation: Epoch : 26, Loss : 1.213556, Accuracy: 0.943000, Test accuracy: 0.951100
Distillation: Epoch : 27, Loss : 1.212076, Accuracy: 0.953000, Test accuracy: 0.953100
Distillation: Epoch : 28, Loss : 1.240574, Accuracy: 0.938000, Test accuracy: 0.953000
Distillation: Epoch : 29, Loss : 1.215717, Accuracy: 0.952000, Test accuracy: 0.953900
Distillation: Epoch : 30, Loss : 1.183665, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 31, Loss : 1.229259, Accuracy: 0.951000, Test accuracy: 0.954800
Distillation: Epoch : 32, Loss : 1.216300, Accuracy: 0.951000, Test accuracy: 0.955100
Distillation: Epoch : 33, Loss : 1.201375, Accuracy: 0.955000, Test accuracy: 0.956900
Distillation: Epoch : 34, Loss : 1.204113, Accuracy: 0.958000, Test accuracy: 0.957200
Distillation: Epoch : 35, Loss : 1.217054, Accuracy: 0.951000, Test accuracy: 0.957600
Distillation: Epoch : 36, Loss : 1.204543, Accuracy: 0.953000, Test accuracy: 0.957800
Distillation: Epoch : 37, Loss : 1.189691, Accuracy: 0.958000, Test accuracy: 0.958400
Distillation: Epoch : 38, Loss : 1.199956, Accuracy: 0.958000, Test accuracy: 0.958100
Distillation: Epoch : 39, Loss : 1.193310, Accuracy: 0.943000, Test accuracy: 0.959000
Distillation: Epoch : 40, Loss : 1.198156, Accuracy: 0.950000, Test accuracy: 0.959300
Distillation: Epoch : 41, Loss : 1.187819, Accuracy: 0.960000, Test accuracy: 0.960000
Distillation: Epoch : 42, Loss : 1.201732, Accuracy: 0.950000, Test accuracy: 0.959600
Distillation: Epoch : 43, Loss : 1.206901, Accuracy: 0.957000, Test accuracy: 0.960500
Distillation: Epoch : 44, Loss : 1.218277, Accuracy: 0.952000, Test accuracy: 0.960500
Distillation: Epoch : 45, Loss : 1.179027, Accuracy: 0.958000, Test accuracy: 0.959800
Distillation: Epoch : 46, Loss : 1.227660, Accuracy: 0.954000, Test accuracy: 0.960300
Distillation: Epoch : 47, Loss : 1.216900, Accuracy: 0.956000, Test accuracy: 0.960500
Distillation: Epoch : 48, Loss : 1.192017, Accuracy: 0.958000, Test accuracy: 0.960300
Distillation: Epoch : 49, Loss : 1.197515, Accuracy: 0.945000, Test accuracy: 0.960900
Distillation: Epoch : 50, Loss : 1.192452, Accuracy: 0.962000, Test accuracy: 0.960400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9604
Generating confusion matrix for student5
[[ 966.    0.    5.    0.    1.    1.    7.    2.    6.    7.]
 [   1. 1113.    7.    1.    1.    0.    3.    2.    1.    5.]
 [   1.    3.  964.    9.    3.    0.    1.   16.    8.    1.]
 [   0.    1.    3.  960.    0.    6.    0.    3.    1.   11.]
 [   1.    1.    6.    1.  957.    0.    3.    4.    5.   11.]
 [   0.    0.    1.   16.    0.  865.   14.    1.   10.    7.]
 [   4.    3.    4.    0.    3.    3.  927.    0.    3.    0.]
 [   3.    0.   12.    7.    1.    1.    0.  978.    5.   15.]
 [   3.   14.   29.   13.    5.   11.    3.    5.  927.    5.]
 [   1.    0.    1.    3.   11.    5.    0.   17.    8.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.788102, Accuracy: 0.758000, Test accuracy: 0.756100
Distillation: Epoch : 2, Loss : 1.539589, Accuracy: 0.839000, Test accuracy: 0.848600
Distillation: Epoch : 3, Loss : 1.528517, Accuracy: 0.860000, Test accuracy: 0.866400
Distillation: Epoch : 4, Loss : 1.519979, Accuracy: 0.858000, Test accuracy: 0.875500
Distillation: Epoch : 5, Loss : 1.514411, Accuracy: 0.861000, Test accuracy: 0.880200
Distillation: Epoch : 6, Loss : 1.494574, Accuracy: 0.873000, Test accuracy: 0.883900
Distillation: Epoch : 7, Loss : 1.463801, Accuracy: 0.903000, Test accuracy: 0.887500
Distillation: Epoch : 8, Loss : 1.496781, Accuracy: 0.884000, Test accuracy: 0.889500
Distillation: Epoch : 9, Loss : 1.450570, Accuracy: 0.899000, Test accuracy: 0.889300
Distillation: Epoch : 10, Loss : 1.462734, Accuracy: 0.879000, Test accuracy: 0.891300
Distillation: Epoch : 11, Loss : 1.468906, Accuracy: 0.900000, Test accuracy: 0.891600
Distillation: Epoch : 12, Loss : 1.503680, Accuracy: 0.885000, Test accuracy: 0.892800
Distillation: Epoch : 13, Loss : 1.473426, Accuracy: 0.879000, Test accuracy: 0.896300
Distillation: Epoch : 14, Loss : 1.462558, Accuracy: 0.884000, Test accuracy: 0.894400
Distillation: Epoch : 15, Loss : 1.447626, Accuracy: 0.886000, Test accuracy: 0.894600
Distillation: Epoch : 16, Loss : 1.497492, Accuracy: 0.890000, Test accuracy: 0.894700
Distillation: Epoch : 17, Loss : 1.471185, Accuracy: 0.888000, Test accuracy: 0.896200
Distillation: Epoch : 18, Loss : 1.476317, Accuracy: 0.878000, Test accuracy: 0.896300
Distillation: Epoch : 19, Loss : 1.457477, Accuracy: 0.898000, Test accuracy: 0.897500
Distillation: Epoch : 20, Loss : 1.469185, Accuracy: 0.884000, Test accuracy: 0.896500
Distillation: Epoch : 21, Loss : 1.472249, Accuracy: 0.888000, Test accuracy: 0.897600
Distillation: Epoch : 22, Loss : 1.456706, Accuracy: 0.885000, Test accuracy: 0.898800
Distillation: Epoch : 23, Loss : 1.437124, Accuracy: 0.912000, Test accuracy: 0.899100
Distillation: Epoch : 24, Loss : 1.437034, Accuracy: 0.906000, Test accuracy: 0.899500
Distillation: Epoch : 25, Loss : 1.453242, Accuracy: 0.883000, Test accuracy: 0.900200
Distillation: Epoch : 26, Loss : 1.476484, Accuracy: 0.888000, Test accuracy: 0.900200
Distillation: Epoch : 27, Loss : 1.476324, Accuracy: 0.894000, Test accuracy: 0.898300
Distillation: Epoch : 28, Loss : 1.430947, Accuracy: 0.906000, Test accuracy: 0.899300
Distillation: Epoch : 29, Loss : 1.465968, Accuracy: 0.898000, Test accuracy: 0.896900
Distillation: Epoch : 30, Loss : 1.445030, Accuracy: 0.884000, Test accuracy: 0.899600
Distillation: Epoch : 31, Loss : 1.462712, Accuracy: 0.888000, Test accuracy: 0.899400
Distillation: Epoch : 32, Loss : 1.455767, Accuracy: 0.889000, Test accuracy: 0.900300
Distillation: Epoch : 33, Loss : 1.462597, Accuracy: 0.895000, Test accuracy: 0.899800
Distillation: Epoch : 34, Loss : 1.448105, Accuracy: 0.899000, Test accuracy: 0.900200
Distillation: Epoch : 35, Loss : 1.448506, Accuracy: 0.901000, Test accuracy: 0.901100
Distillation: Epoch : 36, Loss : 1.442828, Accuracy: 0.901000, Test accuracy: 0.900000
Distillation: Epoch : 37, Loss : 1.455725, Accuracy: 0.870000, Test accuracy: 0.899800
Distillation: Epoch : 38, Loss : 1.458605, Accuracy: 0.897000, Test accuracy: 0.899800
Distillation: Epoch : 39, Loss : 1.460677, Accuracy: 0.903000, Test accuracy: 0.901200
Distillation: Epoch : 40, Loss : 1.444304, Accuracy: 0.904000, Test accuracy: 0.900400
Distillation: Epoch : 41, Loss : 1.464615, Accuracy: 0.892000, Test accuracy: 0.898400
Distillation: Epoch : 42, Loss : 1.449257, Accuracy: 0.903000, Test accuracy: 0.900100
Distillation: Epoch : 43, Loss : 1.459154, Accuracy: 0.888000, Test accuracy: 0.901400
Distillation: Epoch : 44, Loss : 1.466229, Accuracy: 0.885000, Test accuracy: 0.901200
Distillation: Epoch : 45, Loss : 1.459675, Accuracy: 0.892000, Test accuracy: 0.901300
Distillation: Epoch : 46, Loss : 1.423289, Accuracy: 0.897000, Test accuracy: 0.901300
Distillation: Epoch : 47, Loss : 1.434778, Accuracy: 0.904000, Test accuracy: 0.904300
Distillation: Epoch : 48, Loss : 1.449764, Accuracy: 0.894000, Test accuracy: 0.902100
Distillation: Epoch : 49, Loss : 1.436587, Accuracy: 0.889000, Test accuracy: 0.901600
Distillation: Epoch : 50, Loss : 1.463993, Accuracy: 0.890000, Test accuracy: 0.899600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.8996
Generating confusion matrix for student5
[[ 932.    0.    8.    5.    0.    6.    6.    1.    6.    9.]
 [   1. 1106.   34.    6.    2.    7.    4.   28.   16.    8.]
 [   2.    2.  863.   19.    3.    2.    3.    9.    5.    0.]
 [   2.    3.   18.  872.    1.   16.    0.    4.   14.   11.]
 [   5.    1.   26.    5.  935.   18.   18.   23.   27.   76.]
 [  13.    5.    4.   58.    3.  785.   25.    2.   42.   10.]
 [  15.    4.   12.    4.    7.   12.  899.    1.   13.    1.]
 [   2.    0.   22.   15.    1.    8.    1.  918.    8.   26.]
 [   6.   14.   41.   19.    7.   29.    2.    1.  831.   13.]
 [   2.    0.    4.    7.   23.    9.    0.   41.   12.  855.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.247962, Accuracy: 0.344000, Test accuracy: 0.325000
Distillation: Epoch : 2, Loss : 1.827360, Accuracy: 0.807000, Test accuracy: 0.800400
Distillation: Epoch : 3, Loss : 1.648600, Accuracy: 0.832000, Test accuracy: 0.848300
Distillation: Epoch : 4, Loss : 1.591400, Accuracy: 0.871000, Test accuracy: 0.868100
Distillation: Epoch : 5, Loss : 1.601286, Accuracy: 0.871000, Test accuracy: 0.880900
Distillation: Epoch : 6, Loss : 1.583716, Accuracy: 0.895000, Test accuracy: 0.893800
Distillation: Epoch : 7, Loss : 1.561439, Accuracy: 0.896000, Test accuracy: 0.899800
Distillation: Epoch : 8, Loss : 1.551181, Accuracy: 0.875000, Test accuracy: 0.907400
Distillation: Epoch : 9, Loss : 1.563158, Accuracy: 0.900000, Test accuracy: 0.912300
Distillation: Epoch : 10, Loss : 1.547107, Accuracy: 0.896000, Test accuracy: 0.914000
Distillation: Epoch : 11, Loss : 1.550956, Accuracy: 0.906000, Test accuracy: 0.916700
Distillation: Epoch : 12, Loss : 1.527452, Accuracy: 0.912000, Test accuracy: 0.920500
Distillation: Epoch : 13, Loss : 1.542143, Accuracy: 0.910000, Test accuracy: 0.921800
Distillation: Epoch : 14, Loss : 1.509542, Accuracy: 0.935000, Test accuracy: 0.922500
Distillation: Epoch : 15, Loss : 1.529652, Accuracy: 0.921000, Test accuracy: 0.924900
Distillation: Epoch : 16, Loss : 1.539711, Accuracy: 0.918000, Test accuracy: 0.926100
Distillation: Epoch : 17, Loss : 1.502093, Accuracy: 0.926000, Test accuracy: 0.928500
Distillation: Epoch : 18, Loss : 1.542401, Accuracy: 0.913000, Test accuracy: 0.931200
Distillation: Epoch : 19, Loss : 1.516512, Accuracy: 0.921000, Test accuracy: 0.932800
Distillation: Epoch : 20, Loss : 1.502516, Accuracy: 0.918000, Test accuracy: 0.935800
Distillation: Epoch : 21, Loss : 1.506397, Accuracy: 0.933000, Test accuracy: 0.937800
Distillation: Epoch : 22, Loss : 1.508699, Accuracy: 0.917000, Test accuracy: 0.938900
Distillation: Epoch : 23, Loss : 1.504132, Accuracy: 0.930000, Test accuracy: 0.940200
Distillation: Epoch : 24, Loss : 1.501179, Accuracy: 0.932000, Test accuracy: 0.942500
Distillation: Epoch : 25, Loss : 1.504336, Accuracy: 0.947000, Test accuracy: 0.943100
Distillation: Epoch : 26, Loss : 1.472124, Accuracy: 0.932000, Test accuracy: 0.943900
Distillation: Epoch : 27, Loss : 1.499864, Accuracy: 0.935000, Test accuracy: 0.945700
Distillation: Epoch : 28, Loss : 1.487894, Accuracy: 0.940000, Test accuracy: 0.946600
Distillation: Epoch : 29, Loss : 1.503450, Accuracy: 0.938000, Test accuracy: 0.948100
Distillation: Epoch : 30, Loss : 1.484581, Accuracy: 0.948000, Test accuracy: 0.947900
Distillation: Epoch : 31, Loss : 1.489951, Accuracy: 0.935000, Test accuracy: 0.949900
Distillation: Epoch : 32, Loss : 1.503987, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 33, Loss : 1.481506, Accuracy: 0.946000, Test accuracy: 0.949500
Distillation: Epoch : 34, Loss : 1.489661, Accuracy: 0.942000, Test accuracy: 0.951100
Distillation: Epoch : 35, Loss : 1.477218, Accuracy: 0.932000, Test accuracy: 0.951300
Distillation: Epoch : 36, Loss : 1.491973, Accuracy: 0.950000, Test accuracy: 0.951700
Distillation: Epoch : 37, Loss : 1.490763, Accuracy: 0.955000, Test accuracy: 0.951900
Distillation: Epoch : 38, Loss : 1.480472, Accuracy: 0.945000, Test accuracy: 0.951200
Distillation: Epoch : 39, Loss : 1.499241, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 40, Loss : 1.491589, Accuracy: 0.953000, Test accuracy: 0.952900
Distillation: Epoch : 41, Loss : 1.503816, Accuracy: 0.948000, Test accuracy: 0.953400
Distillation: Epoch : 42, Loss : 1.478736, Accuracy: 0.947000, Test accuracy: 0.953500
Distillation: Epoch : 43, Loss : 1.512335, Accuracy: 0.943000, Test accuracy: 0.953800
Distillation: Epoch : 44, Loss : 1.487495, Accuracy: 0.947000, Test accuracy: 0.952800
Distillation: Epoch : 45, Loss : 1.479312, Accuracy: 0.945000, Test accuracy: 0.953500
Distillation: Epoch : 46, Loss : 1.490250, Accuracy: 0.950000, Test accuracy: 0.953500
Distillation: Epoch : 47, Loss : 1.493522, Accuracy: 0.937000, Test accuracy: 0.953700
Distillation: Epoch : 48, Loss : 1.480924, Accuracy: 0.960000, Test accuracy: 0.953900
Distillation: Epoch : 49, Loss : 1.497987, Accuracy: 0.940000, Test accuracy: 0.954000
Distillation: Epoch : 50, Loss : 1.485097, Accuracy: 0.936000, Test accuracy: 0.954500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9545
Generating confusion matrix for student5
[[ 966.    0.    6.    0.    0.    0.    7.    1.    7.    5.]
 [   1. 1126.   17.    0.    2.    2.    4.   17.    9.    9.]
 [   1.    3.  949.   13.    4.    0.    1.   18.    9.    0.]
 [   0.    0.    6.  956.    0.    5.    0.    5.    2.    8.]
 [   2.    0.    8.    4.  954.    1.    9.    6.   11.   33.]
 [   0.    0.    1.   19.    0.  865.    6.    1.    1.    7.]
 [   6.    5.    3.    0.    3.    6.  929.    0.    5.    1.]
 [   1.    0.   14.   10.    0.    2.    0.  959.    8.   13.]
 [   2.    1.   27.    6.    3.    1.    2.    4.  910.    2.]
 [   1.    0.    1.    2.   16.   10.    0.   17.   12.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.149676, Accuracy: 0.707000, Test accuracy: 0.686800
Distillation: Epoch : 2, Loss : 1.890558, Accuracy: 0.815000, Test accuracy: 0.829600
Distillation: Epoch : 3, Loss : 1.860487, Accuracy: 0.851000, Test accuracy: 0.858200
Distillation: Epoch : 4, Loss : 1.865046, Accuracy: 0.865000, Test accuracy: 0.869600
Distillation: Epoch : 5, Loss : 1.847031, Accuracy: 0.861000, Test accuracy: 0.875800
Distillation: Epoch : 6, Loss : 1.843024, Accuracy: 0.869000, Test accuracy: 0.882700
Distillation: Epoch : 7, Loss : 1.829676, Accuracy: 0.892000, Test accuracy: 0.888700
Distillation: Epoch : 8, Loss : 1.826062, Accuracy: 0.895000, Test accuracy: 0.895500
Distillation: Epoch : 9, Loss : 1.810935, Accuracy: 0.895000, Test accuracy: 0.900200
Distillation: Epoch : 10, Loss : 1.806218, Accuracy: 0.906000, Test accuracy: 0.906600
Distillation: Epoch : 11, Loss : 1.811857, Accuracy: 0.898000, Test accuracy: 0.912800
Distillation: Epoch : 12, Loss : 1.800223, Accuracy: 0.901000, Test accuracy: 0.918400
Distillation: Epoch : 13, Loss : 1.799403, Accuracy: 0.901000, Test accuracy: 0.920900
Distillation: Epoch : 14, Loss : 1.793002, Accuracy: 0.909000, Test accuracy: 0.926300
Distillation: Epoch : 15, Loss : 1.794060, Accuracy: 0.908000, Test accuracy: 0.930100
Distillation: Epoch : 16, Loss : 1.796903, Accuracy: 0.909000, Test accuracy: 0.932600
Distillation: Epoch : 17, Loss : 1.781820, Accuracy: 0.940000, Test accuracy: 0.935800
Distillation: Epoch : 18, Loss : 1.783910, Accuracy: 0.935000, Test accuracy: 0.937000
Distillation: Epoch : 19, Loss : 1.772202, Accuracy: 0.932000, Test accuracy: 0.940300
Distillation: Epoch : 20, Loss : 1.771670, Accuracy: 0.931000, Test accuracy: 0.940600
Distillation: Epoch : 21, Loss : 1.760666, Accuracy: 0.932000, Test accuracy: 0.942300
Distillation: Epoch : 22, Loss : 1.758433, Accuracy: 0.946000, Test accuracy: 0.944700
Distillation: Epoch : 23, Loss : 1.776535, Accuracy: 0.948000, Test accuracy: 0.945700
Distillation: Epoch : 24, Loss : 1.774363, Accuracy: 0.931000, Test accuracy: 0.947600
Distillation: Epoch : 25, Loss : 1.765899, Accuracy: 0.931000, Test accuracy: 0.948400
Distillation: Epoch : 26, Loss : 1.766346, Accuracy: 0.942000, Test accuracy: 0.948900
Distillation: Epoch : 27, Loss : 1.758836, Accuracy: 0.951000, Test accuracy: 0.949100
Distillation: Epoch : 28, Loss : 1.769711, Accuracy: 0.940000, Test accuracy: 0.948000
Distillation: Epoch : 29, Loss : 1.768848, Accuracy: 0.946000, Test accuracy: 0.949200
Distillation: Epoch : 30, Loss : 1.776541, Accuracy: 0.943000, Test accuracy: 0.949000
Distillation: Epoch : 31, Loss : 1.761701, Accuracy: 0.941000, Test accuracy: 0.950600
Distillation: Epoch : 32, Loss : 1.756748, Accuracy: 0.943000, Test accuracy: 0.950100
Distillation: Epoch : 33, Loss : 1.763284, Accuracy: 0.934000, Test accuracy: 0.950700
Distillation: Epoch : 34, Loss : 1.754250, Accuracy: 0.951000, Test accuracy: 0.949900
Distillation: Epoch : 35, Loss : 1.767552, Accuracy: 0.955000, Test accuracy: 0.951900
Distillation: Epoch : 36, Loss : 1.755859, Accuracy: 0.952000, Test accuracy: 0.951500
Distillation: Epoch : 37, Loss : 1.778209, Accuracy: 0.946000, Test accuracy: 0.951700
Distillation: Epoch : 38, Loss : 1.774518, Accuracy: 0.946000, Test accuracy: 0.951600
Distillation: Epoch : 39, Loss : 1.770630, Accuracy: 0.948000, Test accuracy: 0.952100
Distillation: Epoch : 40, Loss : 1.750487, Accuracy: 0.955000, Test accuracy: 0.952700
Distillation: Epoch : 41, Loss : 1.748899, Accuracy: 0.956000, Test accuracy: 0.952700
Distillation: Epoch : 42, Loss : 1.747154, Accuracy: 0.945000, Test accuracy: 0.952900
Distillation: Epoch : 43, Loss : 1.761243, Accuracy: 0.947000, Test accuracy: 0.952300
Distillation: Epoch : 44, Loss : 1.767827, Accuracy: 0.949000, Test accuracy: 0.953400
Distillation: Epoch : 45, Loss : 1.751910, Accuracy: 0.947000, Test accuracy: 0.953000
Distillation: Epoch : 46, Loss : 1.761826, Accuracy: 0.947000, Test accuracy: 0.953400
Distillation: Epoch : 47, Loss : 1.757402, Accuracy: 0.946000, Test accuracy: 0.953400
Distillation: Epoch : 48, Loss : 1.755463, Accuracy: 0.937000, Test accuracy: 0.953400
Distillation: Epoch : 49, Loss : 1.765205, Accuracy: 0.953000, Test accuracy: 0.952900
Distillation: Epoch : 50, Loss : 1.769359, Accuracy: 0.958000, Test accuracy: 0.953400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9534
Generating confusion matrix for student5
[[ 959.    0.    2.    1.    1.    1.    7.    2.    5.    7.]
 [   1. 1109.    6.    1.    0.    0.    3.    4.    0.    6.]
 [   2.    3.  962.    5.    2.    1.    2.   10.   10.    0.]
 [   0.    0.    4.  954.    0.    5.    0.    8.    4.    3.]
 [   2.    2.    9.    2.  956.    1.   10.    3.    6.   15.]
 [   5.    0.    1.   22.    0.  857.   23.    2.   20.   15.]
 [   6.    4.    4.    0.    3.    3.  910.    0.    4.    1.]
 [   3.    0.   11.    8.    0.    0.    0.  975.    4.   10.]
 [   1.   17.   31.   13.    4.   16.    3.    7.  909.    9.]
 [   1.    0.    2.    4.   16.    8.    0.   17.   12.  943.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.269862, Accuracy: 0.298000, Test accuracy: 0.288200
Distillation: Epoch : 2, Loss : 2.090555, Accuracy: 0.828000, Test accuracy: 0.824100
Distillation: Epoch : 3, Loss : 2.080163, Accuracy: 0.838000, Test accuracy: 0.852800
Distillation: Epoch : 4, Loss : 2.059373, Accuracy: 0.866000, Test accuracy: 0.862800
Distillation: Epoch : 5, Loss : 2.068526, Accuracy: 0.867000, Test accuracy: 0.872400
Distillation: Epoch : 6, Loss : 2.058001, Accuracy: 0.864000, Test accuracy: 0.875800
Distillation: Epoch : 7, Loss : 2.049244, Accuracy: 0.858000, Test accuracy: 0.882000
Distillation: Epoch : 8, Loss : 2.061782, Accuracy: 0.868000, Test accuracy: 0.882000
Distillation: Epoch : 9, Loss : 2.062418, Accuracy: 0.870000, Test accuracy: 0.885900
Distillation: Epoch : 10, Loss : 2.062300, Accuracy: 0.883000, Test accuracy: 0.887700
Distillation: Epoch : 11, Loss : 2.045919, Accuracy: 0.872000, Test accuracy: 0.888200
Distillation: Epoch : 12, Loss : 2.053690, Accuracy: 0.879000, Test accuracy: 0.887400
Distillation: Epoch : 13, Loss : 2.054851, Accuracy: 0.879000, Test accuracy: 0.889500
Distillation: Epoch : 14, Loss : 2.062644, Accuracy: 0.853000, Test accuracy: 0.890100
Distillation: Epoch : 15, Loss : 2.046265, Accuracy: 0.882000, Test accuracy: 0.890300
Distillation: Epoch : 16, Loss : 2.045509, Accuracy: 0.874000, Test accuracy: 0.891400
Distillation: Epoch : 17, Loss : 2.039553, Accuracy: 0.891000, Test accuracy: 0.893200
Distillation: Epoch : 18, Loss : 2.036559, Accuracy: 0.903000, Test accuracy: 0.892300
Distillation: Epoch : 19, Loss : 2.050774, Accuracy: 0.890000, Test accuracy: 0.892500
Distillation: Epoch : 20, Loss : 2.043437, Accuracy: 0.888000, Test accuracy: 0.894400
Distillation: Epoch : 21, Loss : 2.054981, Accuracy: 0.875000, Test accuracy: 0.894200
Distillation: Epoch : 22, Loss : 2.045800, Accuracy: 0.877000, Test accuracy: 0.894400
Distillation: Epoch : 23, Loss : 2.045187, Accuracy: 0.894000, Test accuracy: 0.895200
Distillation: Epoch : 24, Loss : 2.048477, Accuracy: 0.888000, Test accuracy: 0.894800
Distillation: Epoch : 25, Loss : 2.044788, Accuracy: 0.892000, Test accuracy: 0.895600
Distillation: Epoch : 26, Loss : 2.043187, Accuracy: 0.883000, Test accuracy: 0.896900
Distillation: Epoch : 27, Loss : 2.060107, Accuracy: 0.894000, Test accuracy: 0.898100
Distillation: Epoch : 28, Loss : 2.047334, Accuracy: 0.907000, Test accuracy: 0.899000
Distillation: Epoch : 29, Loss : 2.046080, Accuracy: 0.891000, Test accuracy: 0.899100
Distillation: Epoch : 30, Loss : 2.049395, Accuracy: 0.891000, Test accuracy: 0.900700
Distillation: Epoch : 31, Loss : 2.045304, Accuracy: 0.898000, Test accuracy: 0.898400
Distillation: Epoch : 32, Loss : 2.040745, Accuracy: 0.903000, Test accuracy: 0.901400
Distillation: Epoch : 33, Loss : 2.043442, Accuracy: 0.883000, Test accuracy: 0.900800
Distillation: Epoch : 34, Loss : 2.040112, Accuracy: 0.901000, Test accuracy: 0.900600
Distillation: Epoch : 35, Loss : 2.044524, Accuracy: 0.880000, Test accuracy: 0.900700
Distillation: Epoch : 36, Loss : 2.038336, Accuracy: 0.902000, Test accuracy: 0.901000
Distillation: Epoch : 37, Loss : 2.042470, Accuracy: 0.880000, Test accuracy: 0.902700
Distillation: Epoch : 38, Loss : 2.035030, Accuracy: 0.893000, Test accuracy: 0.902500
Distillation: Epoch : 39, Loss : 2.047037, Accuracy: 0.896000, Test accuracy: 0.904300
Distillation: Epoch : 40, Loss : 2.034200, Accuracy: 0.892000, Test accuracy: 0.904900
Distillation: Epoch : 41, Loss : 2.036021, Accuracy: 0.902000, Test accuracy: 0.905400
Distillation: Epoch : 42, Loss : 2.035780, Accuracy: 0.901000, Test accuracy: 0.905300
Distillation: Epoch : 43, Loss : 2.041451, Accuracy: 0.879000, Test accuracy: 0.905300
Distillation: Epoch : 44, Loss : 2.039488, Accuracy: 0.891000, Test accuracy: 0.908000
Distillation: Epoch : 45, Loss : 2.038330, Accuracy: 0.896000, Test accuracy: 0.908200
Distillation: Epoch : 46, Loss : 2.043211, Accuracy: 0.887000, Test accuracy: 0.908100
Distillation: Epoch : 47, Loss : 2.040505, Accuracy: 0.889000, Test accuracy: 0.910700
Distillation: Epoch : 48, Loss : 2.033266, Accuracy: 0.898000, Test accuracy: 0.909900
Distillation: Epoch : 49, Loss : 2.032592, Accuracy: 0.897000, Test accuracy: 0.911900
Distillation: Epoch : 50, Loss : 2.039944, Accuracy: 0.904000, Test accuracy: 0.912500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9125
Generating confusion matrix for student5
[[ 932.    0.   11.    4.    0.    6.   10.    1.   11.    5.]
 [   0. 1096.   18.    4.    0.    2.    4.   16.   16.    7.]
 [   2.    4.  878.   16.    2.    1.    1.   12.    6.    3.]
 [   2.    1.   18.  912.    0.    8.    0.    8.    8.   10.]
 [   7.    1.   29.    3.  923.    9.   13.   27.   14.   73.]
 [   5.    5.    1.   31.    0.  833.   24.    1.   27.    4.]
 [  10.    4.   13.    3.    7.   10.  903.    1.    9.    0.]
 [   2.    0.   21.   15.    1.    3.    0.  903.    6.   13.]
 [  18.   24.   40.   18.    8.   13.    3.    2.  860.    9.]
 [   2.    0.    3.    4.   41.    7.    0.   57.   17.  885.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.616870, Accuracy: 0.817000, Test accuracy: 0.835600
Distillation: Epoch : 2, Loss : 0.401685, Accuracy: 0.877000, Test accuracy: 0.890700
Distillation: Epoch : 3, Loss : 0.295616, Accuracy: 0.905000, Test accuracy: 0.911600
Distillation: Epoch : 4, Loss : 0.276656, Accuracy: 0.910000, Test accuracy: 0.920600
Distillation: Epoch : 5, Loss : 0.194746, Accuracy: 0.943000, Test accuracy: 0.930500
Distillation: Epoch : 6, Loss : 0.217731, Accuracy: 0.935000, Test accuracy: 0.937100
Distillation: Epoch : 7, Loss : 0.195484, Accuracy: 0.946000, Test accuracy: 0.942100
Distillation: Epoch : 8, Loss : 0.191530, Accuracy: 0.943000, Test accuracy: 0.947400
Distillation: Epoch : 9, Loss : 0.180654, Accuracy: 0.947000, Test accuracy: 0.951200
Distillation: Epoch : 10, Loss : 0.172369, Accuracy: 0.951000, Test accuracy: 0.953800
Distillation: Epoch : 11, Loss : 0.187091, Accuracy: 0.945000, Test accuracy: 0.956600
Distillation: Epoch : 12, Loss : 0.148418, Accuracy: 0.959000, Test accuracy: 0.958900
Distillation: Epoch : 13, Loss : 0.118224, Accuracy: 0.969000, Test accuracy: 0.960900
Distillation: Epoch : 14, Loss : 0.092075, Accuracy: 0.967000, Test accuracy: 0.961600
Distillation: Epoch : 15, Loss : 0.126672, Accuracy: 0.961000, Test accuracy: 0.963500
Distillation: Epoch : 16, Loss : 0.108690, Accuracy: 0.967000, Test accuracy: 0.964600
Distillation: Epoch : 17, Loss : 0.103974, Accuracy: 0.969000, Test accuracy: 0.967200
Distillation: Epoch : 18, Loss : 0.117438, Accuracy: 0.959000, Test accuracy: 0.968400
Distillation: Epoch : 19, Loss : 0.108132, Accuracy: 0.975000, Test accuracy: 0.968600
Distillation: Epoch : 20, Loss : 0.109228, Accuracy: 0.969000, Test accuracy: 0.970700
Distillation: Epoch : 21, Loss : 0.095100, Accuracy: 0.969000, Test accuracy: 0.969700
Distillation: Epoch : 22, Loss : 0.076377, Accuracy: 0.971000, Test accuracy: 0.971800
Distillation: Epoch : 23, Loss : 0.081069, Accuracy: 0.974000, Test accuracy: 0.973500
Distillation: Epoch : 24, Loss : 0.073933, Accuracy: 0.981000, Test accuracy: 0.974100
Distillation: Epoch : 25, Loss : 0.062914, Accuracy: 0.980000, Test accuracy: 0.973900
Distillation: Epoch : 26, Loss : 0.090090, Accuracy: 0.972000, Test accuracy: 0.975200
Distillation: Epoch : 27, Loss : 0.098613, Accuracy: 0.971000, Test accuracy: 0.974500
Distillation: Epoch : 28, Loss : 0.082076, Accuracy: 0.974000, Test accuracy: 0.976100
Distillation: Epoch : 29, Loss : 0.081810, Accuracy: 0.972000, Test accuracy: 0.975500
Distillation: Epoch : 30, Loss : 0.078670, Accuracy: 0.976000, Test accuracy: 0.977500
Distillation: Epoch : 31, Loss : 0.112036, Accuracy: 0.969000, Test accuracy: 0.976200
Distillation: Epoch : 32, Loss : 0.093003, Accuracy: 0.969000, Test accuracy: 0.977500
Distillation: Epoch : 33, Loss : 0.067989, Accuracy: 0.979000, Test accuracy: 0.976800
Distillation: Epoch : 34, Loss : 0.081080, Accuracy: 0.974000, Test accuracy: 0.977900
Distillation: Epoch : 35, Loss : 0.060710, Accuracy: 0.980000, Test accuracy: 0.977400
Distillation: Epoch : 36, Loss : 0.054737, Accuracy: 0.982000, Test accuracy: 0.978700
Distillation: Epoch : 37, Loss : 0.052021, Accuracy: 0.980000, Test accuracy: 0.977800
Distillation: Epoch : 38, Loss : 0.060917, Accuracy: 0.987000, Test accuracy: 0.978500
Distillation: Epoch : 39, Loss : 0.080110, Accuracy: 0.976000, Test accuracy: 0.978200
Distillation: Epoch : 40, Loss : 0.057598, Accuracy: 0.983000, Test accuracy: 0.978500
Distillation: Epoch : 41, Loss : 0.088864, Accuracy: 0.971000, Test accuracy: 0.978300
Distillation: Epoch : 42, Loss : 0.054356, Accuracy: 0.984000, Test accuracy: 0.978100
Distillation: Epoch : 43, Loss : 0.060814, Accuracy: 0.983000, Test accuracy: 0.978300
Distillation: Epoch : 44, Loss : 0.071703, Accuracy: 0.975000, Test accuracy: 0.979400
Distillation: Epoch : 45, Loss : 0.055577, Accuracy: 0.982000, Test accuracy: 0.977000
Distillation: Epoch : 46, Loss : 0.051034, Accuracy: 0.988000, Test accuracy: 0.979300
Distillation: Epoch : 47, Loss : 0.057219, Accuracy: 0.981000, Test accuracy: 0.979700
Distillation: Epoch : 48, Loss : 0.056747, Accuracy: 0.982000, Test accuracy: 0.980000
Distillation: Epoch : 49, Loss : 0.051074, Accuracy: 0.985000, Test accuracy: 0.980500
Distillation: Epoch : 50, Loss : 0.039501, Accuracy: 0.986000, Test accuracy: 0.980500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9805
Generating confusion matrix for student
[[ 972.    0.    3.    1.    0.    2.   10.    0.    4.    3.]
 [   0. 1127.    5.    0.    2.    0.    3.    4.    1.    5.]
 [   0.    1. 1013.    1.    2.    0.    0.    9.    5.    2.]
 [   0.    1.    2.  993.    0.    3.    0.    4.    4.    4.]
 [   0.    1.    1.    0.  964.    0.    4.    1.    1.   12.]
 [   1.    0.    0.    6.    0.  881.    5.    0.    2.    2.]
 [   1.    0.    0.    0.    1.    1.  934.    0.    0.    0.]
 [   2.    1.    1.    3.    1.    1.    0. 1000.    1.    6.]
 [   4.    4.    7.    6.    3.    4.    2.    2.  952.    6.]
 [   0.    0.    0.    0.    9.    0.    0.    8.    4.  969.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.751776, Accuracy: 0.805000, Test accuracy: 0.827100
Distillation: Epoch : 2, Loss : 0.419526, Accuracy: 0.889000, Test accuracy: 0.896900
Distillation: Epoch : 3, Loss : 0.304549, Accuracy: 0.914000, Test accuracy: 0.914100
Distillation: Epoch : 4, Loss : 0.318657, Accuracy: 0.922000, Test accuracy: 0.925100
Distillation: Epoch : 5, Loss : 0.273144, Accuracy: 0.925000, Test accuracy: 0.932400
Distillation: Epoch : 6, Loss : 0.258258, Accuracy: 0.924000, Test accuracy: 0.937600
Distillation: Epoch : 7, Loss : 0.211672, Accuracy: 0.941000, Test accuracy: 0.941400
Distillation: Epoch : 8, Loss : 0.266851, Accuracy: 0.930000, Test accuracy: 0.943600
Distillation: Epoch : 9, Loss : 0.235984, Accuracy: 0.944000, Test accuracy: 0.948100
Distillation: Epoch : 10, Loss : 0.203480, Accuracy: 0.951000, Test accuracy: 0.949400
Distillation: Epoch : 11, Loss : 0.202029, Accuracy: 0.943000, Test accuracy: 0.951700
Distillation: Epoch : 12, Loss : 0.189938, Accuracy: 0.956000, Test accuracy: 0.953400
Distillation: Epoch : 13, Loss : 0.174988, Accuracy: 0.954000, Test accuracy: 0.955200
Distillation: Epoch : 14, Loss : 0.179999, Accuracy: 0.947000, Test accuracy: 0.956300
Distillation: Epoch : 15, Loss : 0.152494, Accuracy: 0.972000, Test accuracy: 0.958500
Distillation: Epoch : 16, Loss : 0.191809, Accuracy: 0.955000, Test accuracy: 0.960100
Distillation: Epoch : 17, Loss : 0.124132, Accuracy: 0.977000, Test accuracy: 0.961400
Distillation: Epoch : 18, Loss : 0.191261, Accuracy: 0.953000, Test accuracy: 0.961500
Distillation: Epoch : 19, Loss : 0.169516, Accuracy: 0.953000, Test accuracy: 0.963400
Distillation: Epoch : 20, Loss : 0.145936, Accuracy: 0.969000, Test accuracy: 0.964000
Distillation: Epoch : 21, Loss : 0.145174, Accuracy: 0.963000, Test accuracy: 0.965100
Distillation: Epoch : 22, Loss : 0.142761, Accuracy: 0.967000, Test accuracy: 0.966000
Distillation: Epoch : 23, Loss : 0.124724, Accuracy: 0.968000, Test accuracy: 0.967500
Distillation: Epoch : 24, Loss : 0.125858, Accuracy: 0.973000, Test accuracy: 0.968000
Distillation: Epoch : 25, Loss : 0.162140, Accuracy: 0.953000, Test accuracy: 0.969100
Distillation: Epoch : 26, Loss : 0.133715, Accuracy: 0.968000, Test accuracy: 0.967600
Distillation: Epoch : 27, Loss : 0.144764, Accuracy: 0.959000, Test accuracy: 0.970400
Distillation: Epoch : 28, Loss : 0.144579, Accuracy: 0.960000, Test accuracy: 0.970700
Distillation: Epoch : 29, Loss : 0.118594, Accuracy: 0.973000, Test accuracy: 0.971300
Distillation: Epoch : 30, Loss : 0.127732, Accuracy: 0.970000, Test accuracy: 0.971600
Distillation: Epoch : 31, Loss : 0.140651, Accuracy: 0.965000, Test accuracy: 0.970600
Distillation: Epoch : 32, Loss : 0.178335, Accuracy: 0.952000, Test accuracy: 0.972100
Distillation: Epoch : 33, Loss : 0.118242, Accuracy: 0.972000, Test accuracy: 0.972300
Distillation: Epoch : 34, Loss : 0.124821, Accuracy: 0.976000, Test accuracy: 0.971700
Distillation: Epoch : 35, Loss : 0.117020, Accuracy: 0.966000, Test accuracy: 0.973600
Distillation: Epoch : 36, Loss : 0.134828, Accuracy: 0.970000, Test accuracy: 0.972400
Distillation: Epoch : 37, Loss : 0.140652, Accuracy: 0.961000, Test accuracy: 0.973000
Distillation: Epoch : 38, Loss : 0.130860, Accuracy: 0.965000, Test accuracy: 0.972900
Distillation: Epoch : 39, Loss : 0.126330, Accuracy: 0.969000, Test accuracy: 0.974600
Distillation: Epoch : 40, Loss : 0.116743, Accuracy: 0.975000, Test accuracy: 0.973100
Distillation: Epoch : 41, Loss : 0.106057, Accuracy: 0.972000, Test accuracy: 0.975000
Distillation: Epoch : 42, Loss : 0.134176, Accuracy: 0.971000, Test accuracy: 0.976500
Distillation: Epoch : 43, Loss : 0.093966, Accuracy: 0.980000, Test accuracy: 0.975700
Distillation: Epoch : 44, Loss : 0.133517, Accuracy: 0.964000, Test accuracy: 0.976300
Distillation: Epoch : 45, Loss : 0.122977, Accuracy: 0.967000, Test accuracy: 0.975700
Distillation: Epoch : 46, Loss : 0.105730, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 47, Loss : 0.121168, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 48, Loss : 0.093289, Accuracy: 0.985000, Test accuracy: 0.976600
Distillation: Epoch : 49, Loss : 0.114453, Accuracy: 0.979000, Test accuracy: 0.977000
Distillation: Epoch : 50, Loss : 0.121633, Accuracy: 0.974000, Test accuracy: 0.977300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9773
Generating confusion matrix for student
[[ 968.    0.    1.    1.    1.    1.    6.    1.    8.    4.]
 [   0. 1125.    2.    0.    0.    0.    1.    6.    0.    6.]
 [   1.    3. 1012.    5.    1.    0.    0.   11.    6.    0.]
 [   0.    1.    3.  981.    0.    3.    1.    2.    5.    3.]
 [   0.    2.    1.    0.  967.    0.    2.    1.    3.   13.]
 [   0.    0.    0.    9.    0.  880.    2.    0.    3.    4.]
 [   5.    2.    0.    0.    1.    3.  945.    0.    5.    0.]
 [   1.    1.    4.    4.    1.    1.    0.  991.    4.    7.]
 [   4.    1.    9.    7.    3.    4.    1.    3.  935.    3.]
 [   1.    0.    0.    3.    8.    0.    0.   13.    5.  969.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.056807, Accuracy: 0.785000, Test accuracy: 0.789800
Distillation: Epoch : 2, Loss : 0.786576, Accuracy: 0.863000, Test accuracy: 0.867100
Distillation: Epoch : 3, Loss : 0.722207, Accuracy: 0.878000, Test accuracy: 0.891300
Distillation: Epoch : 4, Loss : 0.690560, Accuracy: 0.894000, Test accuracy: 0.902200
Distillation: Epoch : 5, Loss : 0.661543, Accuracy: 0.898000, Test accuracy: 0.912500
Distillation: Epoch : 6, Loss : 0.581552, Accuracy: 0.937000, Test accuracy: 0.920600
Distillation: Epoch : 7, Loss : 0.606971, Accuracy: 0.921000, Test accuracy: 0.926200
Distillation: Epoch : 8, Loss : 0.614581, Accuracy: 0.914000, Test accuracy: 0.931600
Distillation: Epoch : 9, Loss : 0.553025, Accuracy: 0.931000, Test accuracy: 0.939400
Distillation: Epoch : 10, Loss : 0.567402, Accuracy: 0.932000, Test accuracy: 0.944200
Distillation: Epoch : 11, Loss : 0.550242, Accuracy: 0.941000, Test accuracy: 0.947000
Distillation: Epoch : 12, Loss : 0.493694, Accuracy: 0.954000, Test accuracy: 0.950600
Distillation: Epoch : 13, Loss : 0.549993, Accuracy: 0.936000, Test accuracy: 0.951600
Distillation: Epoch : 14, Loss : 0.512687, Accuracy: 0.952000, Test accuracy: 0.954900
Distillation: Epoch : 15, Loss : 0.512683, Accuracy: 0.957000, Test accuracy: 0.956000
Distillation: Epoch : 16, Loss : 0.522432, Accuracy: 0.939000, Test accuracy: 0.958300
Distillation: Epoch : 17, Loss : 0.490290, Accuracy: 0.968000, Test accuracy: 0.959300
Distillation: Epoch : 18, Loss : 0.506908, Accuracy: 0.966000, Test accuracy: 0.958900
Distillation: Epoch : 19, Loss : 0.490922, Accuracy: 0.956000, Test accuracy: 0.960100
Distillation: Epoch : 20, Loss : 0.545688, Accuracy: 0.952000, Test accuracy: 0.961900
Distillation: Epoch : 21, Loss : 0.473540, Accuracy: 0.966000, Test accuracy: 0.962800
Distillation: Epoch : 22, Loss : 0.481349, Accuracy: 0.961000, Test accuracy: 0.963600
Distillation: Epoch : 23, Loss : 0.481304, Accuracy: 0.964000, Test accuracy: 0.965100
Distillation: Epoch : 24, Loss : 0.501960, Accuracy: 0.964000, Test accuracy: 0.965500
Distillation: Epoch : 25, Loss : 0.472579, Accuracy: 0.967000, Test accuracy: 0.966800
Distillation: Epoch : 26, Loss : 0.464710, Accuracy: 0.970000, Test accuracy: 0.966800
Distillation: Epoch : 27, Loss : 0.458097, Accuracy: 0.976000, Test accuracy: 0.967600
Distillation: Epoch : 28, Loss : 0.474847, Accuracy: 0.966000, Test accuracy: 0.968100
Distillation: Epoch : 29, Loss : 0.488804, Accuracy: 0.959000, Test accuracy: 0.969300
Distillation: Epoch : 30, Loss : 0.483900, Accuracy: 0.963000, Test accuracy: 0.970400
Distillation: Epoch : 31, Loss : 0.487371, Accuracy: 0.966000, Test accuracy: 0.970500
Distillation: Epoch : 32, Loss : 0.468223, Accuracy: 0.967000, Test accuracy: 0.969500
Distillation: Epoch : 33, Loss : 0.482820, Accuracy: 0.979000, Test accuracy: 0.971200
Distillation: Epoch : 34, Loss : 0.467730, Accuracy: 0.966000, Test accuracy: 0.971500
Distillation: Epoch : 35, Loss : 0.472374, Accuracy: 0.973000, Test accuracy: 0.970500
Distillation: Epoch : 36, Loss : 0.463897, Accuracy: 0.971000, Test accuracy: 0.972500
Distillation: Epoch : 37, Loss : 0.484133, Accuracy: 0.971000, Test accuracy: 0.972500
Distillation: Epoch : 38, Loss : 0.471125, Accuracy: 0.965000, Test accuracy: 0.972300
Distillation: Epoch : 39, Loss : 0.458468, Accuracy: 0.970000, Test accuracy: 0.973200
Distillation: Epoch : 40, Loss : 0.475789, Accuracy: 0.966000, Test accuracy: 0.972900
Distillation: Epoch : 41, Loss : 0.451209, Accuracy: 0.981000, Test accuracy: 0.972800
Distillation: Epoch : 42, Loss : 0.478534, Accuracy: 0.959000, Test accuracy: 0.973100
Distillation: Epoch : 43, Loss : 0.463419, Accuracy: 0.975000, Test accuracy: 0.973500
Distillation: Epoch : 44, Loss : 0.469890, Accuracy: 0.966000, Test accuracy: 0.973900
Distillation: Epoch : 45, Loss : 0.460243, Accuracy: 0.964000, Test accuracy: 0.974300
Distillation: Epoch : 46, Loss : 0.450826, Accuracy: 0.977000, Test accuracy: 0.973800
Distillation: Epoch : 47, Loss : 0.478383, Accuracy: 0.963000, Test accuracy: 0.975400
Distillation: Epoch : 48, Loss : 0.454017, Accuracy: 0.974000, Test accuracy: 0.975200
Distillation: Epoch : 49, Loss : 0.427950, Accuracy: 0.981000, Test accuracy: 0.974000
Distillation: Epoch : 50, Loss : 0.462506, Accuracy: 0.972000, Test accuracy: 0.976000
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.976
Generating confusion matrix for student
[[ 969.    0.    5.    1.    0.    2.    5.    0.    6.    3.]
 [   0. 1120.    0.    0.    0.    0.    3.    5.    0.    8.]
 [   0.    2.  994.    3.    6.    0.    0.    8.    4.    0.]
 [   0.    2.    5.  984.    0.    1.    0.    2.    2.    6.]
 [   0.    0.    3.    0.  960.    0.    4.    5.    4.    5.]
 [   2.    0.    0.   10.    0.  883.    5.    0.    2.    5.]
 [   4.    2.    1.    0.    1.    3.  938.    0.    2.    0.]
 [   2.    1.    7.    7.    2.    1.    0.  994.    5.    7.]
 [   3.    8.   17.    4.    2.    2.    3.    3.  943.    0.]
 [   0.    0.    0.    1.   11.    0.    0.   11.    6.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.261789, Accuracy: 0.780000, Test accuracy: 0.796400
Distillation: Epoch : 2, Loss : 0.964046, Accuracy: 0.855000, Test accuracy: 0.859900
Distillation: Epoch : 3, Loss : 0.892000, Accuracy: 0.885000, Test accuracy: 0.884800
Distillation: Epoch : 4, Loss : 0.845264, Accuracy: 0.896000, Test accuracy: 0.899800
Distillation: Epoch : 5, Loss : 0.823458, Accuracy: 0.901000, Test accuracy: 0.913500
Distillation: Epoch : 6, Loss : 0.767602, Accuracy: 0.924000, Test accuracy: 0.923400
Distillation: Epoch : 7, Loss : 0.764098, Accuracy: 0.936000, Test accuracy: 0.931600
Distillation: Epoch : 8, Loss : 0.729938, Accuracy: 0.938000, Test accuracy: 0.936200
Distillation: Epoch : 9, Loss : 0.715536, Accuracy: 0.949000, Test accuracy: 0.945800
Distillation: Epoch : 10, Loss : 0.716736, Accuracy: 0.935000, Test accuracy: 0.949900
Distillation: Epoch : 11, Loss : 0.672739, Accuracy: 0.948000, Test accuracy: 0.956300
Distillation: Epoch : 12, Loss : 0.694939, Accuracy: 0.944000, Test accuracy: 0.959400
Distillation: Epoch : 13, Loss : 0.685036, Accuracy: 0.954000, Test accuracy: 0.961700
Distillation: Epoch : 14, Loss : 0.702573, Accuracy: 0.954000, Test accuracy: 0.964600
Distillation: Epoch : 15, Loss : 0.680330, Accuracy: 0.957000, Test accuracy: 0.966900
Distillation: Epoch : 16, Loss : 0.682052, Accuracy: 0.975000, Test accuracy: 0.967200
Distillation: Epoch : 17, Loss : 0.670276, Accuracy: 0.968000, Test accuracy: 0.969300
Distillation: Epoch : 18, Loss : 0.638930, Accuracy: 0.977000, Test accuracy: 0.969400
Distillation: Epoch : 19, Loss : 0.657875, Accuracy: 0.963000, Test accuracy: 0.970300
Distillation: Epoch : 20, Loss : 0.667732, Accuracy: 0.963000, Test accuracy: 0.972000
Distillation: Epoch : 21, Loss : 0.644155, Accuracy: 0.966000, Test accuracy: 0.971900
Distillation: Epoch : 22, Loss : 0.629657, Accuracy: 0.980000, Test accuracy: 0.973500
Distillation: Epoch : 23, Loss : 0.627577, Accuracy: 0.966000, Test accuracy: 0.973400
Distillation: Epoch : 24, Loss : 0.631531, Accuracy: 0.977000, Test accuracy: 0.974100
Distillation: Epoch : 25, Loss : 0.648529, Accuracy: 0.968000, Test accuracy: 0.974500
Distillation: Epoch : 26, Loss : 0.653671, Accuracy: 0.973000, Test accuracy: 0.975100
Distillation: Epoch : 27, Loss : 0.633078, Accuracy: 0.979000, Test accuracy: 0.975200
Distillation: Epoch : 28, Loss : 0.646143, Accuracy: 0.972000, Test accuracy: 0.976600
Distillation: Epoch : 29, Loss : 0.652771, Accuracy: 0.976000, Test accuracy: 0.976900
Distillation: Epoch : 30, Loss : 0.606936, Accuracy: 0.970000, Test accuracy: 0.976900
Distillation: Epoch : 31, Loss : 0.634627, Accuracy: 0.978000, Test accuracy: 0.977500
Distillation: Epoch : 32, Loss : 0.645118, Accuracy: 0.984000, Test accuracy: 0.977300
Distillation: Epoch : 33, Loss : 0.635637, Accuracy: 0.978000, Test accuracy: 0.978400
Distillation: Epoch : 34, Loss : 0.624766, Accuracy: 0.979000, Test accuracy: 0.978100
Distillation: Epoch : 35, Loss : 0.618698, Accuracy: 0.982000, Test accuracy: 0.978100
Distillation: Epoch : 36, Loss : 0.635189, Accuracy: 0.967000, Test accuracy: 0.978500
Distillation: Epoch : 37, Loss : 0.626871, Accuracy: 0.978000, Test accuracy: 0.979300
Distillation: Epoch : 38, Loss : 0.619922, Accuracy: 0.977000, Test accuracy: 0.979200
Distillation: Epoch : 39, Loss : 0.621895, Accuracy: 0.984000, Test accuracy: 0.979600
Distillation: Epoch : 40, Loss : 0.642215, Accuracy: 0.976000, Test accuracy: 0.979600
Distillation: Epoch : 41, Loss : 0.621752, Accuracy: 0.983000, Test accuracy: 0.980200
Distillation: Epoch : 42, Loss : 0.628483, Accuracy: 0.980000, Test accuracy: 0.980600
Distillation: Epoch : 43, Loss : 0.622322, Accuracy: 0.980000, Test accuracy: 0.980000
Distillation: Epoch : 44, Loss : 0.631859, Accuracy: 0.984000, Test accuracy: 0.980800
Distillation: Epoch : 45, Loss : 0.620734, Accuracy: 0.983000, Test accuracy: 0.980600
Distillation: Epoch : 46, Loss : 0.625081, Accuracy: 0.982000, Test accuracy: 0.981100
Distillation: Epoch : 47, Loss : 0.638627, Accuracy: 0.982000, Test accuracy: 0.980600
Distillation: Epoch : 48, Loss : 0.616909, Accuracy: 0.980000, Test accuracy: 0.981100
Distillation: Epoch : 49, Loss : 0.624623, Accuracy: 0.979000, Test accuracy: 0.980800
Distillation: Epoch : 50, Loss : 0.609006, Accuracy: 0.981000, Test accuracy: 0.982200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9822
Generating confusion matrix for student
[[ 975.    0.    1.    1.    0.    2.    3.    1.    4.    3.]
 [   1. 1129.    2.    0.    0.    0.    2.    5.    1.    6.]
 [   0.    4. 1014.    1.    0.    1.    0.   10.    1.    0.]
 [   0.    1.    1.  983.    0.    3.    0.    2.    1.    0.]
 [   0.    0.    3.    0.  969.    1.    5.    1.    2.    4.]
 [   1.    0.    0.   14.    0.  878.    4.    1.    3.    4.]
 [   1.    0.    0.    0.    2.    1.  940.    0.    2.    0.]
 [   1.    0.    4.    3.    1.    0.    0. 1001.    4.    6.]
 [   1.    1.    6.    6.    2.    3.    4.    2.  952.    5.]
 [   0.    0.    1.    2.    8.    3.    0.    5.    4.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.330431, Accuracy: 0.764000, Test accuracy: 0.781500
Distillation: Epoch : 2, Loss : 1.141051, Accuracy: 0.861000, Test accuracy: 0.865400
Distillation: Epoch : 3, Loss : 1.069743, Accuracy: 0.881000, Test accuracy: 0.884100
Distillation: Epoch : 4, Loss : 1.049914, Accuracy: 0.882000, Test accuracy: 0.899600
Distillation: Epoch : 5, Loss : 1.007410, Accuracy: 0.899000, Test accuracy: 0.906500
Distillation: Epoch : 6, Loss : 0.998728, Accuracy: 0.899000, Test accuracy: 0.915200
Distillation: Epoch : 7, Loss : 0.974500, Accuracy: 0.916000, Test accuracy: 0.923300
Distillation: Epoch : 8, Loss : 0.959423, Accuracy: 0.913000, Test accuracy: 0.927900
Distillation: Epoch : 9, Loss : 0.927358, Accuracy: 0.934000, Test accuracy: 0.933900
Distillation: Epoch : 10, Loss : 0.918539, Accuracy: 0.937000, Test accuracy: 0.938900
Distillation: Epoch : 11, Loss : 0.909207, Accuracy: 0.948000, Test accuracy: 0.944000
Distillation: Epoch : 12, Loss : 0.890955, Accuracy: 0.950000, Test accuracy: 0.945600
Distillation: Epoch : 13, Loss : 0.909178, Accuracy: 0.955000, Test accuracy: 0.948900
Distillation: Epoch : 14, Loss : 0.885127, Accuracy: 0.950000, Test accuracy: 0.951800
Distillation: Epoch : 15, Loss : 0.885583, Accuracy: 0.949000, Test accuracy: 0.954600
Distillation: Epoch : 16, Loss : 0.871083, Accuracy: 0.951000, Test accuracy: 0.956600
Distillation: Epoch : 17, Loss : 0.873755, Accuracy: 0.961000, Test accuracy: 0.958500
Distillation: Epoch : 18, Loss : 0.864213, Accuracy: 0.954000, Test accuracy: 0.959400
Distillation: Epoch : 19, Loss : 0.870692, Accuracy: 0.961000, Test accuracy: 0.960600
Distillation: Epoch : 20, Loss : 0.844601, Accuracy: 0.962000, Test accuracy: 0.961500
Distillation: Epoch : 21, Loss : 0.885524, Accuracy: 0.961000, Test accuracy: 0.962000
Distillation: Epoch : 22, Loss : 0.843069, Accuracy: 0.967000, Test accuracy: 0.964100
Distillation: Epoch : 23, Loss : 0.852897, Accuracy: 0.962000, Test accuracy: 0.964400
Distillation: Epoch : 24, Loss : 0.835647, Accuracy: 0.965000, Test accuracy: 0.966800
Distillation: Epoch : 25, Loss : 0.855898, Accuracy: 0.968000, Test accuracy: 0.964100
Distillation: Epoch : 26, Loss : 0.832284, Accuracy: 0.966000, Test accuracy: 0.968100
Distillation: Epoch : 27, Loss : 0.840713, Accuracy: 0.970000, Test accuracy: 0.970000
Distillation: Epoch : 28, Loss : 0.858806, Accuracy: 0.972000, Test accuracy: 0.968500
Distillation: Epoch : 29, Loss : 0.856940, Accuracy: 0.963000, Test accuracy: 0.970100
Distillation: Epoch : 30, Loss : 0.837510, Accuracy: 0.970000, Test accuracy: 0.970500
Distillation: Epoch : 31, Loss : 0.846483, Accuracy: 0.972000, Test accuracy: 0.970100
Distillation: Epoch : 32, Loss : 0.853774, Accuracy: 0.951000, Test accuracy: 0.971100
Distillation: Epoch : 33, Loss : 0.850447, Accuracy: 0.957000, Test accuracy: 0.969800
Distillation: Epoch : 34, Loss : 0.824929, Accuracy: 0.969000, Test accuracy: 0.971700
Distillation: Epoch : 35, Loss : 0.827487, Accuracy: 0.964000, Test accuracy: 0.972500
Distillation: Epoch : 36, Loss : 0.834816, Accuracy: 0.975000, Test accuracy: 0.972600
Distillation: Epoch : 37, Loss : 0.838467, Accuracy: 0.964000, Test accuracy: 0.973500
Distillation: Epoch : 38, Loss : 0.840911, Accuracy: 0.975000, Test accuracy: 0.972500
Distillation: Epoch : 39, Loss : 0.829977, Accuracy: 0.975000, Test accuracy: 0.973100
Distillation: Epoch : 40, Loss : 0.838337, Accuracy: 0.971000, Test accuracy: 0.973000
Distillation: Epoch : 41, Loss : 0.806068, Accuracy: 0.972000, Test accuracy: 0.971900
Distillation: Epoch : 42, Loss : 0.830929, Accuracy: 0.972000, Test accuracy: 0.973300
Distillation: Epoch : 43, Loss : 0.829306, Accuracy: 0.961000, Test accuracy: 0.974000
Distillation: Epoch : 44, Loss : 0.844921, Accuracy: 0.966000, Test accuracy: 0.972700
Distillation: Epoch : 45, Loss : 0.853035, Accuracy: 0.968000, Test accuracy: 0.974600
Distillation: Epoch : 46, Loss : 0.844505, Accuracy: 0.968000, Test accuracy: 0.974700
Distillation: Epoch : 47, Loss : 0.813754, Accuracy: 0.975000, Test accuracy: 0.974800
Distillation: Epoch : 48, Loss : 0.855919, Accuracy: 0.969000, Test accuracy: 0.974900
Distillation: Epoch : 49, Loss : 0.815432, Accuracy: 0.975000, Test accuracy: 0.975400
Distillation: Epoch : 50, Loss : 0.822973, Accuracy: 0.978000, Test accuracy: 0.976200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9762
Generating confusion matrix for student
[[ 970.    0.    2.    0.    0.    1.    1.    0.    4.    4.]
 [   0. 1126.    3.    0.    1.    0.    3.    7.    1.    6.]
 [   1.    5.  999.    4.    2.    1.    0.   12.    5.    0.]
 [   0.    0.    4.  976.    0.    2.    0.    2.    3.    3.]
 [   1.    1.    5.    1.  962.    1.    8.    3.    3.    5.]
 [   1.    1.    0.   12.    0.  878.   10.    0.    4.    3.]
 [   4.    0.    0.    0.    2.    2.  931.    0.    2.    0.]
 [   1.    1.    5.    7.    0.    0.    0.  995.    3.    1.]
 [   2.    1.   13.    8.    2.    5.    5.    1.  942.    4.]
 [   0.    0.    1.    2.   13.    2.    0.    8.    7.  983.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.503008, Accuracy: 0.752000, Test accuracy: 0.770100
Distillation: Epoch : 2, Loss : 1.231462, Accuracy: 0.857000, Test accuracy: 0.866600
Distillation: Epoch : 3, Loss : 1.234045, Accuracy: 0.865000, Test accuracy: 0.890500
Distillation: Epoch : 4, Loss : 1.143292, Accuracy: 0.899000, Test accuracy: 0.903100
Distillation: Epoch : 5, Loss : 1.168806, Accuracy: 0.910000, Test accuracy: 0.912500
Distillation: Epoch : 6, Loss : 1.156786, Accuracy: 0.920000, Test accuracy: 0.919600
Distillation: Epoch : 7, Loss : 1.149016, Accuracy: 0.913000, Test accuracy: 0.927700
Distillation: Epoch : 8, Loss : 1.102746, Accuracy: 0.911000, Test accuracy: 0.931700
Distillation: Epoch : 9, Loss : 1.091241, Accuracy: 0.928000, Test accuracy: 0.938200
Distillation: Epoch : 10, Loss : 1.070774, Accuracy: 0.946000, Test accuracy: 0.942400
Distillation: Epoch : 11, Loss : 1.087577, Accuracy: 0.938000, Test accuracy: 0.946100
Distillation: Epoch : 12, Loss : 1.086468, Accuracy: 0.933000, Test accuracy: 0.949400
Distillation: Epoch : 13, Loss : 1.042570, Accuracy: 0.964000, Test accuracy: 0.951700
Distillation: Epoch : 14, Loss : 1.064947, Accuracy: 0.940000, Test accuracy: 0.954600
Distillation: Epoch : 15, Loss : 1.045716, Accuracy: 0.963000, Test accuracy: 0.959900
Distillation: Epoch : 16, Loss : 1.041153, Accuracy: 0.947000, Test accuracy: 0.961100
Distillation: Epoch : 17, Loss : 1.047094, Accuracy: 0.958000, Test accuracy: 0.962600
Distillation: Epoch : 18, Loss : 1.041055, Accuracy: 0.962000, Test accuracy: 0.964300
Distillation: Epoch : 19, Loss : 1.048298, Accuracy: 0.963000, Test accuracy: 0.963500
Distillation: Epoch : 20, Loss : 1.054913, Accuracy: 0.950000, Test accuracy: 0.965400
Distillation: Epoch : 21, Loss : 1.048647, Accuracy: 0.957000, Test accuracy: 0.966300
Distillation: Epoch : 22, Loss : 1.030198, Accuracy: 0.963000, Test accuracy: 0.967500
Distillation: Epoch : 23, Loss : 1.067325, Accuracy: 0.956000, Test accuracy: 0.966700
Distillation: Epoch : 24, Loss : 1.033489, Accuracy: 0.964000, Test accuracy: 0.968500
Distillation: Epoch : 25, Loss : 1.027254, Accuracy: 0.951000, Test accuracy: 0.968200
Distillation: Epoch : 26, Loss : 1.029289, Accuracy: 0.964000, Test accuracy: 0.969300
Distillation: Epoch : 27, Loss : 1.050299, Accuracy: 0.956000, Test accuracy: 0.970800
Distillation: Epoch : 28, Loss : 1.020489, Accuracy: 0.969000, Test accuracy: 0.971300
Distillation: Epoch : 29, Loss : 1.012256, Accuracy: 0.973000, Test accuracy: 0.971600
Distillation: Epoch : 30, Loss : 1.027379, Accuracy: 0.971000, Test accuracy: 0.971400
Distillation: Epoch : 31, Loss : 1.012500, Accuracy: 0.966000, Test accuracy: 0.972500
Distillation: Epoch : 32, Loss : 0.996966, Accuracy: 0.977000, Test accuracy: 0.972500
Distillation: Epoch : 33, Loss : 1.015621, Accuracy: 0.969000, Test accuracy: 0.973800
Distillation: Epoch : 34, Loss : 1.024876, Accuracy: 0.970000, Test accuracy: 0.973800
Distillation: Epoch : 35, Loss : 1.007527, Accuracy: 0.968000, Test accuracy: 0.974400
Distillation: Epoch : 36, Loss : 1.031763, Accuracy: 0.963000, Test accuracy: 0.974400
Distillation: Epoch : 37, Loss : 1.017346, Accuracy: 0.969000, Test accuracy: 0.975100
Distillation: Epoch : 38, Loss : 1.034845, Accuracy: 0.962000, Test accuracy: 0.975600
Distillation: Epoch : 39, Loss : 1.015960, Accuracy: 0.966000, Test accuracy: 0.976000
Distillation: Epoch : 40, Loss : 1.003386, Accuracy: 0.973000, Test accuracy: 0.975900
Distillation: Epoch : 41, Loss : 0.998443, Accuracy: 0.969000, Test accuracy: 0.976900
Distillation: Epoch : 42, Loss : 1.010011, Accuracy: 0.970000, Test accuracy: 0.977400
Distillation: Epoch : 43, Loss : 1.027974, Accuracy: 0.969000, Test accuracy: 0.977200
Distillation: Epoch : 44, Loss : 1.002120, Accuracy: 0.966000, Test accuracy: 0.977800
Distillation: Epoch : 45, Loss : 0.991857, Accuracy: 0.976000, Test accuracy: 0.978400
Distillation: Epoch : 46, Loss : 1.007609, Accuracy: 0.969000, Test accuracy: 0.978500
Distillation: Epoch : 47, Loss : 1.000118, Accuracy: 0.973000, Test accuracy: 0.978300
Distillation: Epoch : 48, Loss : 0.991262, Accuracy: 0.982000, Test accuracy: 0.977400
Distillation: Epoch : 49, Loss : 1.006159, Accuracy: 0.969000, Test accuracy: 0.978800
Distillation: Epoch : 50, Loss : 0.998865, Accuracy: 0.979000, Test accuracy: 0.978600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9786
Generating confusion matrix for student
[[ 972.    0.    3.    1.    0.    0.    7.    0.    4.    4.]
 [   0. 1128.    3.    0.    0.    0.    3.    6.    0.    6.]
 [   1.    2.  998.    0.    1.    1.    0.    7.    3.    0.]
 [   0.    1.    4.  983.    0.    0.    0.    1.    2.    2.]
 [   1.    0.    3.    1.  971.    0.    9.    1.    4.   11.]
 [   0.    1.    0.   13.    0.  885.    7.    0.    6.    2.]
 [   3.    1.    1.    0.    2.    2.  928.    0.    1.    0.]
 [   1.    1.    8.    6.    1.    1.    0. 1005.    4.    6.]
 [   2.    1.   11.    5.    2.    3.    4.    2.  943.    5.]
 [   0.    0.    1.    1.    5.    0.    0.    6.    7.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.834479, Accuracy: 0.634000, Test accuracy: 0.674300
Distillation: Epoch : 2, Loss : 1.485335, Accuracy: 0.814000, Test accuracy: 0.830100
Distillation: Epoch : 3, Loss : 1.346036, Accuracy: 0.881000, Test accuracy: 0.876000
Distillation: Epoch : 4, Loss : 1.361729, Accuracy: 0.877000, Test accuracy: 0.896400
Distillation: Epoch : 5, Loss : 1.326801, Accuracy: 0.887000, Test accuracy: 0.909100
Distillation: Epoch : 6, Loss : 1.285874, Accuracy: 0.898000, Test accuracy: 0.920400
Distillation: Epoch : 7, Loss : 1.261852, Accuracy: 0.911000, Test accuracy: 0.927700
Distillation: Epoch : 8, Loss : 1.254450, Accuracy: 0.916000, Test accuracy: 0.933600
Distillation: Epoch : 9, Loss : 1.231226, Accuracy: 0.938000, Test accuracy: 0.938700
Distillation: Epoch : 10, Loss : 1.234449, Accuracy: 0.935000, Test accuracy: 0.945400
Distillation: Epoch : 11, Loss : 1.232946, Accuracy: 0.950000, Test accuracy: 0.949700
Distillation: Epoch : 12, Loss : 1.224870, Accuracy: 0.938000, Test accuracy: 0.952900
Distillation: Epoch : 13, Loss : 1.236785, Accuracy: 0.944000, Test accuracy: 0.955800
Distillation: Epoch : 14, Loss : 1.229867, Accuracy: 0.953000, Test accuracy: 0.957800
Distillation: Epoch : 15, Loss : 1.206122, Accuracy: 0.955000, Test accuracy: 0.960000
Distillation: Epoch : 16, Loss : 1.199279, Accuracy: 0.950000, Test accuracy: 0.961700
Distillation: Epoch : 17, Loss : 1.174528, Accuracy: 0.962000, Test accuracy: 0.963900
Distillation: Epoch : 18, Loss : 1.207586, Accuracy: 0.957000, Test accuracy: 0.966500
Distillation: Epoch : 19, Loss : 1.195653, Accuracy: 0.963000, Test accuracy: 0.968700
Distillation: Epoch : 20, Loss : 1.175155, Accuracy: 0.969000, Test accuracy: 0.968200
Distillation: Epoch : 21, Loss : 1.193251, Accuracy: 0.953000, Test accuracy: 0.970000
Distillation: Epoch : 22, Loss : 1.205993, Accuracy: 0.955000, Test accuracy: 0.970600
Distillation: Epoch : 23, Loss : 1.201488, Accuracy: 0.965000, Test accuracy: 0.971300
Distillation: Epoch : 24, Loss : 1.172574, Accuracy: 0.964000, Test accuracy: 0.972100
Distillation: Epoch : 25, Loss : 1.187370, Accuracy: 0.969000, Test accuracy: 0.972000
Distillation: Epoch : 26, Loss : 1.196326, Accuracy: 0.965000, Test accuracy: 0.973200
Distillation: Epoch : 27, Loss : 1.181823, Accuracy: 0.963000, Test accuracy: 0.973200
Distillation: Epoch : 28, Loss : 1.186618, Accuracy: 0.957000, Test accuracy: 0.974200
Distillation: Epoch : 29, Loss : 1.161336, Accuracy: 0.978000, Test accuracy: 0.974900
Distillation: Epoch : 30, Loss : 1.165304, Accuracy: 0.975000, Test accuracy: 0.974900
Distillation: Epoch : 31, Loss : 1.162706, Accuracy: 0.979000, Test accuracy: 0.974800
Distillation: Epoch : 32, Loss : 1.169740, Accuracy: 0.975000, Test accuracy: 0.975500
Distillation: Epoch : 33, Loss : 1.175735, Accuracy: 0.973000, Test accuracy: 0.975700
Distillation: Epoch : 34, Loss : 1.214060, Accuracy: 0.957000, Test accuracy: 0.975300
Distillation: Epoch : 35, Loss : 1.169417, Accuracy: 0.976000, Test accuracy: 0.976400
Distillation: Epoch : 36, Loss : 1.170925, Accuracy: 0.968000, Test accuracy: 0.976900
Distillation: Epoch : 37, Loss : 1.157467, Accuracy: 0.972000, Test accuracy: 0.976500
Distillation: Epoch : 38, Loss : 1.189362, Accuracy: 0.968000, Test accuracy: 0.977600
Distillation: Epoch : 39, Loss : 1.157755, Accuracy: 0.977000, Test accuracy: 0.977700
Distillation: Epoch : 40, Loss : 1.174782, Accuracy: 0.966000, Test accuracy: 0.977700
Distillation: Epoch : 41, Loss : 1.152023, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 42, Loss : 1.182485, Accuracy: 0.978000, Test accuracy: 0.977900
Distillation: Epoch : 43, Loss : 1.173043, Accuracy: 0.966000, Test accuracy: 0.977900
Distillation: Epoch : 44, Loss : 1.170790, Accuracy: 0.968000, Test accuracy: 0.978000
Distillation: Epoch : 45, Loss : 1.177404, Accuracy: 0.976000, Test accuracy: 0.977900
Distillation: Epoch : 46, Loss : 1.147079, Accuracy: 0.974000, Test accuracy: 0.978800
Distillation: Epoch : 47, Loss : 1.164554, Accuracy: 0.980000, Test accuracy: 0.979000
Distillation: Epoch : 48, Loss : 1.188331, Accuracy: 0.972000, Test accuracy: 0.978900
Distillation: Epoch : 49, Loss : 1.160401, Accuracy: 0.982000, Test accuracy: 0.979700
Distillation: Epoch : 50, Loss : 1.184817, Accuracy: 0.976000, Test accuracy: 0.979800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9798
Generating confusion matrix for student
[[ 973.    0.    2.    0.    0.    2.    4.    0.    5.    2.]
 [   0. 1123.    2.    0.    1.    0.    2.    6.    0.    9.]
 [   0.    2. 1017.    2.    1.    0.    1.   10.    3.    0.]
 [   0.    2.    0.  982.    0.    0.    0.    1.    1.    3.]
 [   0.    0.    0.    1.  968.    0.    3.    2.    5.    9.]
 [   1.    1.    0.   10.    0.  882.    7.    1.    4.    1.]
 [   2.    1.    0.    0.    2.    5.  938.    0.    2.    0.]
 [   1.    0.    5.    7.    0.    2.    0.  998.    2.    6.]
 [   3.    6.    6.    5.    2.    1.    3.    2.  944.    6.]
 [   0.    0.    0.    3.    8.    0.    0.    8.    8.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.897116, Accuracy: 0.818000, Test accuracy: 0.830300
Distillation: Epoch : 2, Loss : 1.492050, Accuracy: 0.878000, Test accuracy: 0.888900
Distillation: Epoch : 3, Loss : 1.448861, Accuracy: 0.898000, Test accuracy: 0.916400
Distillation: Epoch : 4, Loss : 1.419133, Accuracy: 0.923000, Test accuracy: 0.927600
Distillation: Epoch : 5, Loss : 1.398143, Accuracy: 0.941000, Test accuracy: 0.939300
Distillation: Epoch : 6, Loss : 1.397701, Accuracy: 0.941000, Test accuracy: 0.945500
Distillation: Epoch : 7, Loss : 1.376597, Accuracy: 0.940000, Test accuracy: 0.948900
Distillation: Epoch : 8, Loss : 1.375943, Accuracy: 0.944000, Test accuracy: 0.952200
Distillation: Epoch : 9, Loss : 1.369314, Accuracy: 0.942000, Test accuracy: 0.956100
Distillation: Epoch : 10, Loss : 1.354538, Accuracy: 0.965000, Test accuracy: 0.958700
Distillation: Epoch : 11, Loss : 1.364140, Accuracy: 0.944000, Test accuracy: 0.961900
Distillation: Epoch : 12, Loss : 1.359185, Accuracy: 0.956000, Test accuracy: 0.964500
Distillation: Epoch : 13, Loss : 1.367895, Accuracy: 0.961000, Test accuracy: 0.964800
Distillation: Epoch : 14, Loss : 1.354526, Accuracy: 0.961000, Test accuracy: 0.965700
Distillation: Epoch : 15, Loss : 1.342462, Accuracy: 0.962000, Test accuracy: 0.966800
Distillation: Epoch : 16, Loss : 1.365012, Accuracy: 0.959000, Test accuracy: 0.967700
Distillation: Epoch : 17, Loss : 1.326745, Accuracy: 0.969000, Test accuracy: 0.968500
Distillation: Epoch : 18, Loss : 1.336314, Accuracy: 0.959000, Test accuracy: 0.969300
Distillation: Epoch : 19, Loss : 1.346863, Accuracy: 0.977000, Test accuracy: 0.970000
Distillation: Epoch : 20, Loss : 1.320785, Accuracy: 0.970000, Test accuracy: 0.971200
Distillation: Epoch : 21, Loss : 1.349870, Accuracy: 0.964000, Test accuracy: 0.971900
Distillation: Epoch : 22, Loss : 1.315734, Accuracy: 0.976000, Test accuracy: 0.971800
Distillation: Epoch : 23, Loss : 1.307395, Accuracy: 0.981000, Test accuracy: 0.972800
Distillation: Epoch : 24, Loss : 1.328743, Accuracy: 0.962000, Test accuracy: 0.972200
Distillation: Epoch : 25, Loss : 1.330571, Accuracy: 0.962000, Test accuracy: 0.973200
Distillation: Epoch : 26, Loss : 1.350800, Accuracy: 0.969000, Test accuracy: 0.974600
Distillation: Epoch : 27, Loss : 1.304304, Accuracy: 0.968000, Test accuracy: 0.975200
Distillation: Epoch : 28, Loss : 1.341949, Accuracy: 0.979000, Test accuracy: 0.974400
Distillation: Epoch : 29, Loss : 1.344982, Accuracy: 0.974000, Test accuracy: 0.973500
Distillation: Epoch : 30, Loss : 1.342525, Accuracy: 0.974000, Test accuracy: 0.975900
Distillation: Epoch : 31, Loss : 1.342976, Accuracy: 0.970000, Test accuracy: 0.976300
Distillation: Epoch : 32, Loss : 1.330796, Accuracy: 0.964000, Test accuracy: 0.975900
Distillation: Epoch : 33, Loss : 1.337231, Accuracy: 0.970000, Test accuracy: 0.975900
Distillation: Epoch : 34, Loss : 1.318307, Accuracy: 0.972000, Test accuracy: 0.976500
Distillation: Epoch : 35, Loss : 1.321082, Accuracy: 0.968000, Test accuracy: 0.976600
Distillation: Epoch : 36, Loss : 1.335624, Accuracy: 0.976000, Test accuracy: 0.976200
Distillation: Epoch : 37, Loss : 1.337317, Accuracy: 0.981000, Test accuracy: 0.975400
Distillation: Epoch : 38, Loss : 1.328044, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 39, Loss : 1.334072, Accuracy: 0.966000, Test accuracy: 0.977000
Distillation: Epoch : 40, Loss : 1.314854, Accuracy: 0.967000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 1.340766, Accuracy: 0.978000, Test accuracy: 0.976900
Distillation: Epoch : 42, Loss : 1.350076, Accuracy: 0.971000, Test accuracy: 0.977200
Distillation: Epoch : 43, Loss : 1.335455, Accuracy: 0.977000, Test accuracy: 0.977600
Distillation: Epoch : 44, Loss : 1.312328, Accuracy: 0.973000, Test accuracy: 0.977600
Distillation: Epoch : 45, Loss : 1.316176, Accuracy: 0.979000, Test accuracy: 0.977400
Distillation: Epoch : 46, Loss : 1.325438, Accuracy: 0.980000, Test accuracy: 0.978200
Distillation: Epoch : 47, Loss : 1.331797, Accuracy: 0.977000, Test accuracy: 0.978100
Distillation: Epoch : 48, Loss : 1.312829, Accuracy: 0.973000, Test accuracy: 0.977500
Distillation: Epoch : 49, Loss : 1.318898, Accuracy: 0.978000, Test accuracy: 0.977700
Distillation: Epoch : 50, Loss : 1.303077, Accuracy: 0.983000, Test accuracy: 0.977600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9776
Generating confusion matrix for student
[[ 973.    0.    2.    1.    0.    1.    8.    0.    5.    3.]
 [   1. 1130.    3.    0.    0.    0.    3.    4.    2.    5.]
 [   0.    3.  992.    3.    1.    0.    0.    9.    6.    0.]
 [   0.    0.    2.  979.    0.    3.    0.    3.    1.    3.]
 [   0.    0.    3.    0.  971.    0.    7.    0.    3.    9.]
 [   1.    1.    0.   15.    0.  882.    9.    0.    4.    5.]
 [   2.    1.    0.    0.    1.    3.  928.    0.    2.    0.]
 [   1.    0.    7.    3.    1.    0.    0. 1005.    3.    7.]
 [   2.    0.   22.    8.    2.    3.    3.    1.  944.    5.]
 [   0.    0.    1.    1.    6.    0.    0.    6.    4.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.781268, Accuracy: 0.803000, Test accuracy: 0.795300
Distillation: Epoch : 2, Loss : 1.637768, Accuracy: 0.857000, Test accuracy: 0.864000
Distillation: Epoch : 3, Loss : 1.588713, Accuracy: 0.886000, Test accuracy: 0.891800
Distillation: Epoch : 4, Loss : 1.587616, Accuracy: 0.895000, Test accuracy: 0.908800
Distillation: Epoch : 5, Loss : 1.540330, Accuracy: 0.920000, Test accuracy: 0.921000
Distillation: Epoch : 6, Loss : 1.561239, Accuracy: 0.917000, Test accuracy: 0.930600
Distillation: Epoch : 7, Loss : 1.501561, Accuracy: 0.941000, Test accuracy: 0.938300
Distillation: Epoch : 8, Loss : 1.524529, Accuracy: 0.942000, Test accuracy: 0.943400
Distillation: Epoch : 9, Loss : 1.488468, Accuracy: 0.945000, Test accuracy: 0.948900
Distillation: Epoch : 10, Loss : 1.505270, Accuracy: 0.950000, Test accuracy: 0.954100
Distillation: Epoch : 11, Loss : 1.491034, Accuracy: 0.961000, Test accuracy: 0.956300
Distillation: Epoch : 12, Loss : 1.492459, Accuracy: 0.953000, Test accuracy: 0.958200
Distillation: Epoch : 13, Loss : 1.467495, Accuracy: 0.954000, Test accuracy: 0.960000
Distillation: Epoch : 14, Loss : 1.459215, Accuracy: 0.958000, Test accuracy: 0.962400
Distillation: Epoch : 15, Loss : 1.463286, Accuracy: 0.970000, Test accuracy: 0.964400
Distillation: Epoch : 16, Loss : 1.476722, Accuracy: 0.964000, Test accuracy: 0.965100
Distillation: Epoch : 17, Loss : 1.457914, Accuracy: 0.972000, Test accuracy: 0.967100
Distillation: Epoch : 18, Loss : 1.443604, Accuracy: 0.971000, Test accuracy: 0.967200
Distillation: Epoch : 19, Loss : 1.451039, Accuracy: 0.967000, Test accuracy: 0.967700
Distillation: Epoch : 20, Loss : 1.448548, Accuracy: 0.968000, Test accuracy: 0.968700
Distillation: Epoch : 21, Loss : 1.464345, Accuracy: 0.973000, Test accuracy: 0.970000
Distillation: Epoch : 22, Loss : 1.452780, Accuracy: 0.967000, Test accuracy: 0.970400
Distillation: Epoch : 23, Loss : 1.436337, Accuracy: 0.976000, Test accuracy: 0.971200
Distillation: Epoch : 24, Loss : 1.458263, Accuracy: 0.968000, Test accuracy: 0.971200
Distillation: Epoch : 25, Loss : 1.466283, Accuracy: 0.964000, Test accuracy: 0.971900
Distillation: Epoch : 26, Loss : 1.455291, Accuracy: 0.968000, Test accuracy: 0.972600
Distillation: Epoch : 27, Loss : 1.454231, Accuracy: 0.977000, Test accuracy: 0.972600
Distillation: Epoch : 28, Loss : 1.447981, Accuracy: 0.972000, Test accuracy: 0.974000
Distillation: Epoch : 29, Loss : 1.435984, Accuracy: 0.972000, Test accuracy: 0.973500
Distillation: Epoch : 30, Loss : 1.438833, Accuracy: 0.973000, Test accuracy: 0.973400
Distillation: Epoch : 31, Loss : 1.466432, Accuracy: 0.970000, Test accuracy: 0.974900
Distillation: Epoch : 32, Loss : 1.465168, Accuracy: 0.971000, Test accuracy: 0.974400
Distillation: Epoch : 33, Loss : 1.433578, Accuracy: 0.973000, Test accuracy: 0.975200
Distillation: Epoch : 34, Loss : 1.439785, Accuracy: 0.975000, Test accuracy: 0.974300
Distillation: Epoch : 35, Loss : 1.464802, Accuracy: 0.969000, Test accuracy: 0.975000
Distillation: Epoch : 36, Loss : 1.429495, Accuracy: 0.974000, Test accuracy: 0.975200
Distillation: Epoch : 37, Loss : 1.449520, Accuracy: 0.968000, Test accuracy: 0.975600
Distillation: Epoch : 38, Loss : 1.447311, Accuracy: 0.979000, Test accuracy: 0.975400
Distillation: Epoch : 39, Loss : 1.449030, Accuracy: 0.974000, Test accuracy: 0.976200
Distillation: Epoch : 40, Loss : 1.451290, Accuracy: 0.974000, Test accuracy: 0.976200
Distillation: Epoch : 41, Loss : 1.424505, Accuracy: 0.976000, Test accuracy: 0.976000
Distillation: Epoch : 42, Loss : 1.442130, Accuracy: 0.986000, Test accuracy: 0.976900
Distillation: Epoch : 43, Loss : 1.437767, Accuracy: 0.978000, Test accuracy: 0.977300
Distillation: Epoch : 44, Loss : 1.435450, Accuracy: 0.978000, Test accuracy: 0.976200
Distillation: Epoch : 45, Loss : 1.432581, Accuracy: 0.983000, Test accuracy: 0.977600
Distillation: Epoch : 46, Loss : 1.450118, Accuracy: 0.975000, Test accuracy: 0.977500
Distillation: Epoch : 47, Loss : 1.473426, Accuracy: 0.967000, Test accuracy: 0.977200
Distillation: Epoch : 48, Loss : 1.445101, Accuracy: 0.968000, Test accuracy: 0.977100
Distillation: Epoch : 49, Loss : 1.450971, Accuracy: 0.973000, Test accuracy: 0.977100
Distillation: Epoch : 50, Loss : 1.446544, Accuracy: 0.973000, Test accuracy: 0.977700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9777
Generating confusion matrix for student
[[ 973.    0.    2.    0.    0.    1.    5.    0.    4.    1.]
 [   0. 1126.    4.    0.    0.    0.    4.    5.    0.    6.]
 [   0.    4.  997.    4.    2.    0.    0.    8.    3.    0.]
 [   0.    0.    4.  981.    1.    2.    0.    2.    1.    3.]
 [   1.    1.    3.    0.  962.    1.    3.    2.    2.   13.]
 [   0.    1.    0.    9.    0.  882.   10.    0.    4.    3.]
 [   2.    0.    1.    0.    1.    3.  932.    0.    1.    0.]
 [   1.    0.    7.    7.    0.    1.    0.  999.    2.    5.]
 [   3.    3.   13.    7.    2.    1.    4.    3.  951.    4.]
 [   0.    0.    1.    2.   14.    1.    0.    9.    6.  974.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.975492, Accuracy: 0.770000, Test accuracy: 0.791800
Distillation: Epoch : 2, Loss : 1.894239, Accuracy: 0.867000, Test accuracy: 0.859300
Distillation: Epoch : 3, Loss : 1.822356, Accuracy: 0.892000, Test accuracy: 0.883700
Distillation: Epoch : 4, Loss : 1.834507, Accuracy: 0.894000, Test accuracy: 0.903100
Distillation: Epoch : 5, Loss : 1.800415, Accuracy: 0.910000, Test accuracy: 0.915800
Distillation: Epoch : 6, Loss : 1.803767, Accuracy: 0.914000, Test accuracy: 0.928100
Distillation: Epoch : 7, Loss : 1.777711, Accuracy: 0.931000, Test accuracy: 0.940000
Distillation: Epoch : 8, Loss : 1.782739, Accuracy: 0.944000, Test accuracy: 0.945000
Distillation: Epoch : 9, Loss : 1.780149, Accuracy: 0.946000, Test accuracy: 0.950300
Distillation: Epoch : 10, Loss : 1.769400, Accuracy: 0.947000, Test accuracy: 0.953400
Distillation: Epoch : 11, Loss : 1.762589, Accuracy: 0.946000, Test accuracy: 0.955400
Distillation: Epoch : 12, Loss : 1.776217, Accuracy: 0.950000, Test accuracy: 0.959800
Distillation: Epoch : 13, Loss : 1.758173, Accuracy: 0.950000, Test accuracy: 0.960700
Distillation: Epoch : 14, Loss : 1.751413, Accuracy: 0.963000, Test accuracy: 0.962100
Distillation: Epoch : 15, Loss : 1.748113, Accuracy: 0.957000, Test accuracy: 0.963200
Distillation: Epoch : 16, Loss : 1.755483, Accuracy: 0.970000, Test accuracy: 0.962900
Distillation: Epoch : 17, Loss : 1.747909, Accuracy: 0.959000, Test accuracy: 0.964700
Distillation: Epoch : 18, Loss : 1.735763, Accuracy: 0.957000, Test accuracy: 0.966500
Distillation: Epoch : 19, Loss : 1.762206, Accuracy: 0.953000, Test accuracy: 0.967700
Distillation: Epoch : 20, Loss : 1.720443, Accuracy: 0.968000, Test accuracy: 0.968800
Distillation: Epoch : 21, Loss : 1.736270, Accuracy: 0.967000, Test accuracy: 0.969000
Distillation: Epoch : 22, Loss : 1.749607, Accuracy: 0.962000, Test accuracy: 0.968600
Distillation: Epoch : 23, Loss : 1.745383, Accuracy: 0.973000, Test accuracy: 0.971000
Distillation: Epoch : 24, Loss : 1.757795, Accuracy: 0.973000, Test accuracy: 0.971200
Distillation: Epoch : 25, Loss : 1.764077, Accuracy: 0.967000, Test accuracy: 0.970800
Distillation: Epoch : 26, Loss : 1.739787, Accuracy: 0.965000, Test accuracy: 0.972900
Distillation: Epoch : 27, Loss : 1.750790, Accuracy: 0.965000, Test accuracy: 0.974400
Distillation: Epoch : 28, Loss : 1.746034, Accuracy: 0.978000, Test accuracy: 0.974500
Distillation: Epoch : 29, Loss : 1.737292, Accuracy: 0.972000, Test accuracy: 0.975500
Distillation: Epoch : 30, Loss : 1.748930, Accuracy: 0.968000, Test accuracy: 0.973800
Distillation: Epoch : 31, Loss : 1.745937, Accuracy: 0.967000, Test accuracy: 0.975000
Distillation: Epoch : 32, Loss : 1.731263, Accuracy: 0.965000, Test accuracy: 0.976300
Distillation: Epoch : 33, Loss : 1.742515, Accuracy: 0.970000, Test accuracy: 0.975500
Distillation: Epoch : 34, Loss : 1.740519, Accuracy: 0.972000, Test accuracy: 0.975800
Distillation: Epoch : 35, Loss : 1.742513, Accuracy: 0.969000, Test accuracy: 0.976100
Distillation: Epoch : 36, Loss : 1.750252, Accuracy: 0.977000, Test accuracy: 0.976200
Distillation: Epoch : 37, Loss : 1.741001, Accuracy: 0.975000, Test accuracy: 0.977200
Distillation: Epoch : 38, Loss : 1.736438, Accuracy: 0.976000, Test accuracy: 0.978400
Distillation: Epoch : 39, Loss : 1.743289, Accuracy: 0.977000, Test accuracy: 0.977200
Distillation: Epoch : 40, Loss : 1.734116, Accuracy: 0.981000, Test accuracy: 0.978200
Distillation: Epoch : 41, Loss : 1.738622, Accuracy: 0.975000, Test accuracy: 0.978500
Distillation: Epoch : 42, Loss : 1.732932, Accuracy: 0.977000, Test accuracy: 0.979100
Distillation: Epoch : 43, Loss : 1.723805, Accuracy: 0.979000, Test accuracy: 0.978600
Distillation: Epoch : 44, Loss : 1.737014, Accuracy: 0.974000, Test accuracy: 0.978500
Distillation: Epoch : 45, Loss : 1.754915, Accuracy: 0.970000, Test accuracy: 0.978200
Distillation: Epoch : 46, Loss : 1.748160, Accuracy: 0.972000, Test accuracy: 0.978800
Distillation: Epoch : 47, Loss : 1.735876, Accuracy: 0.967000, Test accuracy: 0.979500
Distillation: Epoch : 48, Loss : 1.744721, Accuracy: 0.969000, Test accuracy: 0.979900
Distillation: Epoch : 49, Loss : 1.744701, Accuracy: 0.967000, Test accuracy: 0.979900
Distillation: Epoch : 50, Loss : 1.747621, Accuracy: 0.973000, Test accuracy: 0.979500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9795
Generating confusion matrix for student
[[ 972.    0.    2.    0.    0.    2.    3.    0.    4.    1.]
 [   0. 1124.    2.    0.    0.    0.    3.    8.    1.    6.]
 [   0.    5. 1006.    2.    0.    0.    0.    6.    2.    0.]
 [   0.    0.    2.  974.    0.    2.    0.    2.    2.    5.]
 [   0.    0.    1.    0.  964.    0.    2.    2.    4.    8.]
 [   2.    0.    0.   17.    0.  882.    7.    0.    4.    4.]
 [   3.    3.    0.    0.    1.    4.  942.    0.    2.    1.]
 [   2.    0.    5.    3.    0.    0.    0. 1003.    2.    3.]
 [   1.    3.   14.   10.    2.    2.    1.    4.  948.    1.]
 [   0.    0.    0.    4.   15.    0.    0.    3.    5.  980.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.133296, Accuracy: 0.765000, Test accuracy: 0.776000
Distillation: Epoch : 2, Loss : 2.068837, Accuracy: 0.826000, Test accuracy: 0.842200
Distillation: Epoch : 3, Loss : 2.069625, Accuracy: 0.876000, Test accuracy: 0.876400
Distillation: Epoch : 4, Loss : 2.048912, Accuracy: 0.897000, Test accuracy: 0.893500
Distillation: Epoch : 5, Loss : 2.042739, Accuracy: 0.889000, Test accuracy: 0.903900
Distillation: Epoch : 6, Loss : 2.040151, Accuracy: 0.897000, Test accuracy: 0.913900
Distillation: Epoch : 7, Loss : 2.022125, Accuracy: 0.938000, Test accuracy: 0.924900
Distillation: Epoch : 8, Loss : 2.035195, Accuracy: 0.908000, Test accuracy: 0.929000
Distillation: Epoch : 9, Loss : 2.035171, Accuracy: 0.922000, Test accuracy: 0.937900
Distillation: Epoch : 10, Loss : 2.023775, Accuracy: 0.933000, Test accuracy: 0.943700
Distillation: Epoch : 11, Loss : 2.020021, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 12, Loss : 2.014539, Accuracy: 0.950000, Test accuracy: 0.952800
Distillation: Epoch : 13, Loss : 2.010296, Accuracy: 0.954000, Test accuracy: 0.954500
Distillation: Epoch : 14, Loss : 2.004639, Accuracy: 0.951000, Test accuracy: 0.957300
Distillation: Epoch : 15, Loss : 2.009648, Accuracy: 0.959000, Test accuracy: 0.959600
Distillation: Epoch : 16, Loss : 2.010369, Accuracy: 0.951000, Test accuracy: 0.962100
Distillation: Epoch : 17, Loss : 1.999775, Accuracy: 0.968000, Test accuracy: 0.963100
Distillation: Epoch : 18, Loss : 2.008405, Accuracy: 0.960000, Test accuracy: 0.964100
Distillation: Epoch : 19, Loss : 2.001065, Accuracy: 0.960000, Test accuracy: 0.966500
Distillation: Epoch : 20, Loss : 2.006921, Accuracy: 0.963000, Test accuracy: 0.967900
Distillation: Epoch : 21, Loss : 2.002983, Accuracy: 0.960000, Test accuracy: 0.967900
Distillation: Epoch : 22, Loss : 2.004981, Accuracy: 0.962000, Test accuracy: 0.969000
Distillation: Epoch : 23, Loss : 1.998773, Accuracy: 0.962000, Test accuracy: 0.970000
Distillation: Epoch : 24, Loss : 2.002570, Accuracy: 0.951000, Test accuracy: 0.970400
Distillation: Epoch : 25, Loss : 2.005268, Accuracy: 0.961000, Test accuracy: 0.971300
Distillation: Epoch : 26, Loss : 2.007263, Accuracy: 0.967000, Test accuracy: 0.971600
Distillation: Epoch : 27, Loss : 1.994997, Accuracy: 0.962000, Test accuracy: 0.972400
Distillation: Epoch : 28, Loss : 2.002280, Accuracy: 0.958000, Test accuracy: 0.972200
Distillation: Epoch : 29, Loss : 1.999695, Accuracy: 0.971000, Test accuracy: 0.973100
Distillation: Epoch : 30, Loss : 2.005913, Accuracy: 0.972000, Test accuracy: 0.973400
Distillation: Epoch : 31, Loss : 2.002970, Accuracy: 0.953000, Test accuracy: 0.972700
Distillation: Epoch : 32, Loss : 1.992546, Accuracy: 0.967000, Test accuracy: 0.973500
Distillation: Epoch : 33, Loss : 2.004038, Accuracy: 0.965000, Test accuracy: 0.973900
Distillation: Epoch : 34, Loss : 2.001643, Accuracy: 0.964000, Test accuracy: 0.974200
Distillation: Epoch : 35, Loss : 2.006068, Accuracy: 0.975000, Test accuracy: 0.975100
Distillation: Epoch : 36, Loss : 2.002901, Accuracy: 0.972000, Test accuracy: 0.975600
Distillation: Epoch : 37, Loss : 1.996989, Accuracy: 0.969000, Test accuracy: 0.974400
Distillation: Epoch : 38, Loss : 2.002808, Accuracy: 0.979000, Test accuracy: 0.975200
Distillation: Epoch : 39, Loss : 2.010794, Accuracy: 0.976000, Test accuracy: 0.976000
Distillation: Epoch : 40, Loss : 1.998535, Accuracy: 0.969000, Test accuracy: 0.975800
Distillation: Epoch : 41, Loss : 1.995352, Accuracy: 0.970000, Test accuracy: 0.975100
Distillation: Epoch : 42, Loss : 1.998041, Accuracy: 0.974000, Test accuracy: 0.976700
Distillation: Epoch : 43, Loss : 1.995644, Accuracy: 0.971000, Test accuracy: 0.976100
Distillation: Epoch : 44, Loss : 2.002016, Accuracy: 0.969000, Test accuracy: 0.977400
Distillation: Epoch : 45, Loss : 2.004643, Accuracy: 0.972000, Test accuracy: 0.976900
Distillation: Epoch : 46, Loss : 1.996440, Accuracy: 0.972000, Test accuracy: 0.977200
Distillation: Epoch : 47, Loss : 1.981869, Accuracy: 0.969000, Test accuracy: 0.976800
Distillation: Epoch : 48, Loss : 2.001089, Accuracy: 0.974000, Test accuracy: 0.977600
Distillation: Epoch : 49, Loss : 1.994873, Accuracy: 0.976000, Test accuracy: 0.977200
Distillation: Epoch : 50, Loss : 1.998151, Accuracy: 0.973000, Test accuracy: 0.977300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9773
Generating confusion matrix for student
[[ 972.    0.    2.    1.    0.    0.    3.    0.    2.    3.]
 [   0. 1123.    4.    0.    0.    0.    3.    6.    2.    5.]
 [   0.    4.  998.    2.    2.    0.    0.    6.    4.    0.]
 [   0.    1.    0.  974.    0.    1.    0.    2.    3.    2.]
 [   1.    0.    5.    0.  970.    0.    3.    5.    3.    6.]
 [   1.    0.    0.   21.    0.  886.   11.    1.    6.    3.]
 [   3.    3.    0.    0.    1.    2.  935.    0.    0.    0.]
 [   0.    0.    6.    3.    0.    0.    0.  996.    3.    5.]
 [   2.    4.   17.    7.    2.    1.    3.    2.  941.    7.]
 [   1.    0.    0.    2.    7.    2.    0.   10.   10.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.659879, Accuracy: 0.837000, Test accuracy: 0.854300
Distillation: Epoch : 2, Loss : 0.421484, Accuracy: 0.890000, Test accuracy: 0.898300
Distillation: Epoch : 3, Loss : 0.332217, Accuracy: 0.906000, Test accuracy: 0.913200
Distillation: Epoch : 4, Loss : 0.329668, Accuracy: 0.913000, Test accuracy: 0.921800
Distillation: Epoch : 5, Loss : 0.284716, Accuracy: 0.913000, Test accuracy: 0.928100
Distillation: Epoch : 6, Loss : 0.261615, Accuracy: 0.929000, Test accuracy: 0.934800
Distillation: Epoch : 7, Loss : 0.229645, Accuracy: 0.934000, Test accuracy: 0.936700
Distillation: Epoch : 8, Loss : 0.233820, Accuracy: 0.933000, Test accuracy: 0.940000
Distillation: Epoch : 9, Loss : 0.216594, Accuracy: 0.929000, Test accuracy: 0.944800
Distillation: Epoch : 10, Loss : 0.202945, Accuracy: 0.940000, Test accuracy: 0.945300
Distillation: Epoch : 11, Loss : 0.199762, Accuracy: 0.942000, Test accuracy: 0.946200
Distillation: Epoch : 12, Loss : 0.190600, Accuracy: 0.944000, Test accuracy: 0.948500
Distillation: Epoch : 13, Loss : 0.199994, Accuracy: 0.942000, Test accuracy: 0.951900
Distillation: Epoch : 14, Loss : 0.145723, Accuracy: 0.963000, Test accuracy: 0.953600
Distillation: Epoch : 15, Loss : 0.177041, Accuracy: 0.948000, Test accuracy: 0.954700
Distillation: Epoch : 16, Loss : 0.133427, Accuracy: 0.953000, Test accuracy: 0.955900
Distillation: Epoch : 17, Loss : 0.138575, Accuracy: 0.963000, Test accuracy: 0.956800
Distillation: Epoch : 18, Loss : 0.167415, Accuracy: 0.947000, Test accuracy: 0.957400
Distillation: Epoch : 19, Loss : 0.148179, Accuracy: 0.959000, Test accuracy: 0.958600
Distillation: Epoch : 20, Loss : 0.137286, Accuracy: 0.958000, Test accuracy: 0.959500
Distillation: Epoch : 21, Loss : 0.160944, Accuracy: 0.951000, Test accuracy: 0.959600
Distillation: Epoch : 22, Loss : 0.114029, Accuracy: 0.961000, Test accuracy: 0.960700
Distillation: Epoch : 23, Loss : 0.142999, Accuracy: 0.958000, Test accuracy: 0.961100
Distillation: Epoch : 24, Loss : 0.114191, Accuracy: 0.976000, Test accuracy: 0.962500
Distillation: Epoch : 25, Loss : 0.124981, Accuracy: 0.969000, Test accuracy: 0.963800
Distillation: Epoch : 26, Loss : 0.159311, Accuracy: 0.957000, Test accuracy: 0.963100
Distillation: Epoch : 27, Loss : 0.133321, Accuracy: 0.970000, Test accuracy: 0.963900
Distillation: Epoch : 28, Loss : 0.099723, Accuracy: 0.978000, Test accuracy: 0.965100
Distillation: Epoch : 29, Loss : 0.105429, Accuracy: 0.975000, Test accuracy: 0.966100
Distillation: Epoch : 30, Loss : 0.106156, Accuracy: 0.973000, Test accuracy: 0.966200
Distillation: Epoch : 31, Loss : 0.107988, Accuracy: 0.966000, Test accuracy: 0.965800
Distillation: Epoch : 32, Loss : 0.132897, Accuracy: 0.964000, Test accuracy: 0.966800
Distillation: Epoch : 33, Loss : 0.108175, Accuracy: 0.965000, Test accuracy: 0.967200
Distillation: Epoch : 34, Loss : 0.102442, Accuracy: 0.977000, Test accuracy: 0.967500
Distillation: Epoch : 35, Loss : 0.092842, Accuracy: 0.971000, Test accuracy: 0.968800
Distillation: Epoch : 36, Loss : 0.089011, Accuracy: 0.980000, Test accuracy: 0.968700
Distillation: Epoch : 37, Loss : 0.097733, Accuracy: 0.973000, Test accuracy: 0.968900
Distillation: Epoch : 38, Loss : 0.103243, Accuracy: 0.968000, Test accuracy: 0.969400
Distillation: Epoch : 39, Loss : 0.108475, Accuracy: 0.970000, Test accuracy: 0.969700
Distillation: Epoch : 40, Loss : 0.103000, Accuracy: 0.972000, Test accuracy: 0.970100
Distillation: Epoch : 41, Loss : 0.104683, Accuracy: 0.971000, Test accuracy: 0.970700
Distillation: Epoch : 42, Loss : 0.103026, Accuracy: 0.970000, Test accuracy: 0.971600
Distillation: Epoch : 43, Loss : 0.091244, Accuracy: 0.970000, Test accuracy: 0.970900
Distillation: Epoch : 44, Loss : 0.113591, Accuracy: 0.967000, Test accuracy: 0.972100
Distillation: Epoch : 45, Loss : 0.101973, Accuracy: 0.968000, Test accuracy: 0.972500
Distillation: Epoch : 46, Loss : 0.112307, Accuracy: 0.967000, Test accuracy: 0.972300
Distillation: Epoch : 47, Loss : 0.097379, Accuracy: 0.971000, Test accuracy: 0.972900
Distillation: Epoch : 48, Loss : 0.106994, Accuracy: 0.966000, Test accuracy: 0.972600
Distillation: Epoch : 49, Loss : 0.093001, Accuracy: 0.976000, Test accuracy: 0.973900
Distillation: Epoch : 50, Loss : 0.094336, Accuracy: 0.973000, Test accuracy: 0.972700
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9727
Generating confusion matrix for student2
[[ 974.    0.    3.    0.    1.    2.   11.    2.    6.    9.]
 [   0. 1127.    8.    0.    1.    1.    3.    5.    3.    6.]
 [   1.    2.  993.    3.    1.    0.    1.    9.    6.    1.]
 [   0.    0.    9.  992.    0.    6.    1.    8.   13.    4.]
 [   1.    1.    3.    0.  959.    0.    5.    1.    3.   12.]
 [   1.    1.    0.    5.    0.  874.    3.    0.    3.    3.]
 [   0.    2.    1.    0.    1.    2.  932.    0.    1.    0.]
 [   1.    0.    9.    4.    2.    1.    0.  993.   11.   13.]
 [   2.    2.    4.    4.    2.    5.    2.    3.  924.    2.]
 [   0.    0.    2.    2.   15.    1.    0.    7.    4.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.144256, Accuracy: 0.782000, Test accuracy: 0.794500
Distillation: Epoch : 2, Loss : 0.616116, Accuracy: 0.841000, Test accuracy: 0.872400
Distillation: Epoch : 3, Loss : 0.397101, Accuracy: 0.898000, Test accuracy: 0.897000
Distillation: Epoch : 4, Loss : 0.345482, Accuracy: 0.915000, Test accuracy: 0.911400
Distillation: Epoch : 5, Loss : 0.345538, Accuracy: 0.907000, Test accuracy: 0.918500
Distillation: Epoch : 6, Loss : 0.251566, Accuracy: 0.940000, Test accuracy: 0.925500
Distillation: Epoch : 7, Loss : 0.279540, Accuracy: 0.919000, Test accuracy: 0.930500
Distillation: Epoch : 8, Loss : 0.273720, Accuracy: 0.919000, Test accuracy: 0.933400
Distillation: Epoch : 9, Loss : 0.251793, Accuracy: 0.932000, Test accuracy: 0.936000
Distillation: Epoch : 10, Loss : 0.260422, Accuracy: 0.939000, Test accuracy: 0.940700
Distillation: Epoch : 11, Loss : 0.252035, Accuracy: 0.931000, Test accuracy: 0.942800
Distillation: Epoch : 12, Loss : 0.203079, Accuracy: 0.939000, Test accuracy: 0.945900
Distillation: Epoch : 13, Loss : 0.216899, Accuracy: 0.938000, Test accuracy: 0.947500
Distillation: Epoch : 14, Loss : 0.218574, Accuracy: 0.945000, Test accuracy: 0.949800
Distillation: Epoch : 15, Loss : 0.173293, Accuracy: 0.955000, Test accuracy: 0.951200
Distillation: Epoch : 16, Loss : 0.208493, Accuracy: 0.934000, Test accuracy: 0.952600
Distillation: Epoch : 17, Loss : 0.201191, Accuracy: 0.952000, Test accuracy: 0.953600
Distillation: Epoch : 18, Loss : 0.164540, Accuracy: 0.959000, Test accuracy: 0.954500
Distillation: Epoch : 19, Loss : 0.153893, Accuracy: 0.956000, Test accuracy: 0.955500
Distillation: Epoch : 20, Loss : 0.193535, Accuracy: 0.950000, Test accuracy: 0.957000
Distillation: Epoch : 21, Loss : 0.195188, Accuracy: 0.945000, Test accuracy: 0.957500
Distillation: Epoch : 22, Loss : 0.161273, Accuracy: 0.965000, Test accuracy: 0.957600
Distillation: Epoch : 23, Loss : 0.157145, Accuracy: 0.964000, Test accuracy: 0.959000
Distillation: Epoch : 24, Loss : 0.162693, Accuracy: 0.964000, Test accuracy: 0.959900
Distillation: Epoch : 25, Loss : 0.167739, Accuracy: 0.961000, Test accuracy: 0.960700
Distillation: Epoch : 26, Loss : 0.168971, Accuracy: 0.960000, Test accuracy: 0.961600
Distillation: Epoch : 27, Loss : 0.171237, Accuracy: 0.953000, Test accuracy: 0.961700
Distillation: Epoch : 28, Loss : 0.161348, Accuracy: 0.958000, Test accuracy: 0.962500
Distillation: Epoch : 29, Loss : 0.140111, Accuracy: 0.965000, Test accuracy: 0.962700
Distillation: Epoch : 30, Loss : 0.172929, Accuracy: 0.958000, Test accuracy: 0.963600
Distillation: Epoch : 31, Loss : 0.175802, Accuracy: 0.964000, Test accuracy: 0.964000
Distillation: Epoch : 32, Loss : 0.164220, Accuracy: 0.963000, Test accuracy: 0.964900
Distillation: Epoch : 33, Loss : 0.153964, Accuracy: 0.965000, Test accuracy: 0.964300
Distillation: Epoch : 34, Loss : 0.141137, Accuracy: 0.967000, Test accuracy: 0.965800
Distillation: Epoch : 35, Loss : 0.163183, Accuracy: 0.960000, Test accuracy: 0.965600
Distillation: Epoch : 36, Loss : 0.131052, Accuracy: 0.970000, Test accuracy: 0.966000
Distillation: Epoch : 37, Loss : 0.153801, Accuracy: 0.970000, Test accuracy: 0.966500
Distillation: Epoch : 38, Loss : 0.138760, Accuracy: 0.967000, Test accuracy: 0.966900
Distillation: Epoch : 39, Loss : 0.180290, Accuracy: 0.952000, Test accuracy: 0.967900
Distillation: Epoch : 40, Loss : 0.134219, Accuracy: 0.965000, Test accuracy: 0.967700
Distillation: Epoch : 41, Loss : 0.158356, Accuracy: 0.959000, Test accuracy: 0.968400
Distillation: Epoch : 42, Loss : 0.119878, Accuracy: 0.972000, Test accuracy: 0.968100
Distillation: Epoch : 43, Loss : 0.143317, Accuracy: 0.966000, Test accuracy: 0.968500
Distillation: Epoch : 44, Loss : 0.148525, Accuracy: 0.965000, Test accuracy: 0.969000
Distillation: Epoch : 45, Loss : 0.141571, Accuracy: 0.965000, Test accuracy: 0.969000
Distillation: Epoch : 46, Loss : 0.129409, Accuracy: 0.971000, Test accuracy: 0.969600
Distillation: Epoch : 47, Loss : 0.110290, Accuracy: 0.982000, Test accuracy: 0.970500
Distillation: Epoch : 48, Loss : 0.110640, Accuracy: 0.974000, Test accuracy: 0.970100
Distillation: Epoch : 49, Loss : 0.129216, Accuracy: 0.966000, Test accuracy: 0.970500
Distillation: Epoch : 50, Loss : 0.134450, Accuracy: 0.963000, Test accuracy: 0.970700
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9707
Generating confusion matrix for student2
[[ 974.    0.    4.    0.    1.    2.    9.    2.    8.    8.]
 [   0. 1123.    4.    0.    1.    1.    3.    4.    1.    5.]
 [   1.    3.  994.    7.    1.    0.    1.   19.   13.    1.]
 [   0.    0.    6.  982.    0.    4.    1.    1.    7.    4.]
 [   0.    0.    3.    1.  962.    0.    3.    2.    4.    6.]
 [   0.    1.    0.    5.    0.  872.    5.    0.    3.    5.]
 [   1.    1.    3.    0.    2.    3.  934.    0.    1.    0.]
 [   2.    0.    5.    6.    2.    3.    0.  984.    8.   19.]
 [   2.    7.   12.    8.    2.    5.    2.    3.  926.    5.]
 [   0.    0.    1.    1.   11.    2.    0.   13.    3.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.695212, Accuracy: 0.769000, Test accuracy: 0.798400
Distillation: Epoch : 2, Loss : 0.951063, Accuracy: 0.854000, Test accuracy: 0.860600
Distillation: Epoch : 3, Loss : 0.780048, Accuracy: 0.894000, Test accuracy: 0.890700
Distillation: Epoch : 4, Loss : 0.665377, Accuracy: 0.899000, Test accuracy: 0.902900
Distillation: Epoch : 5, Loss : 0.658506, Accuracy: 0.904000, Test accuracy: 0.912700
Distillation: Epoch : 6, Loss : 0.625900, Accuracy: 0.920000, Test accuracy: 0.921100
Distillation: Epoch : 7, Loss : 0.603591, Accuracy: 0.921000, Test accuracy: 0.927400
Distillation: Epoch : 8, Loss : 0.577932, Accuracy: 0.931000, Test accuracy: 0.930800
Distillation: Epoch : 9, Loss : 0.590928, Accuracy: 0.928000, Test accuracy: 0.936600
Distillation: Epoch : 10, Loss : 0.607975, Accuracy: 0.917000, Test accuracy: 0.939200
Distillation: Epoch : 11, Loss : 0.573076, Accuracy: 0.935000, Test accuracy: 0.942600
Distillation: Epoch : 12, Loss : 0.565297, Accuracy: 0.934000, Test accuracy: 0.944500
Distillation: Epoch : 13, Loss : 0.559599, Accuracy: 0.937000, Test accuracy: 0.946500
Distillation: Epoch : 14, Loss : 0.529471, Accuracy: 0.952000, Test accuracy: 0.948600
Distillation: Epoch : 15, Loss : 0.529988, Accuracy: 0.959000, Test accuracy: 0.952600
Distillation: Epoch : 16, Loss : 0.523236, Accuracy: 0.952000, Test accuracy: 0.952900
Distillation: Epoch : 17, Loss : 0.531835, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 18, Loss : 0.513887, Accuracy: 0.959000, Test accuracy: 0.955700
Distillation: Epoch : 19, Loss : 0.508756, Accuracy: 0.963000, Test accuracy: 0.957400
Distillation: Epoch : 20, Loss : 0.515851, Accuracy: 0.954000, Test accuracy: 0.957400
Distillation: Epoch : 21, Loss : 0.513809, Accuracy: 0.955000, Test accuracy: 0.958500
Distillation: Epoch : 22, Loss : 0.517023, Accuracy: 0.952000, Test accuracy: 0.959900
Distillation: Epoch : 23, Loss : 0.496232, Accuracy: 0.956000, Test accuracy: 0.960800
Distillation: Epoch : 24, Loss : 0.528581, Accuracy: 0.949000, Test accuracy: 0.961400
Distillation: Epoch : 25, Loss : 0.501384, Accuracy: 0.959000, Test accuracy: 0.962400
Distillation: Epoch : 26, Loss : 0.496494, Accuracy: 0.958000, Test accuracy: 0.963300
Distillation: Epoch : 27, Loss : 0.492667, Accuracy: 0.956000, Test accuracy: 0.963900
Distillation: Epoch : 28, Loss : 0.498763, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 29, Loss : 0.481332, Accuracy: 0.963000, Test accuracy: 0.964900
Distillation: Epoch : 30, Loss : 0.490531, Accuracy: 0.955000, Test accuracy: 0.964200
Distillation: Epoch : 31, Loss : 0.469765, Accuracy: 0.962000, Test accuracy: 0.965600
Distillation: Epoch : 32, Loss : 0.470117, Accuracy: 0.960000, Test accuracy: 0.966400
Distillation: Epoch : 33, Loss : 0.472259, Accuracy: 0.962000, Test accuracy: 0.966100
Distillation: Epoch : 34, Loss : 0.456827, Accuracy: 0.967000, Test accuracy: 0.965700
Distillation: Epoch : 35, Loss : 0.471660, Accuracy: 0.972000, Test accuracy: 0.965900
Distillation: Epoch : 36, Loss : 0.475994, Accuracy: 0.969000, Test accuracy: 0.966100
Distillation: Epoch : 37, Loss : 0.478591, Accuracy: 0.972000, Test accuracy: 0.967700
Distillation: Epoch : 38, Loss : 0.493536, Accuracy: 0.963000, Test accuracy: 0.966900
Distillation: Epoch : 39, Loss : 0.489105, Accuracy: 0.966000, Test accuracy: 0.967300
Distillation: Epoch : 40, Loss : 0.485913, Accuracy: 0.964000, Test accuracy: 0.967300
Distillation: Epoch : 41, Loss : 0.482216, Accuracy: 0.969000, Test accuracy: 0.967700
Distillation: Epoch : 42, Loss : 0.461515, Accuracy: 0.966000, Test accuracy: 0.968100
Distillation: Epoch : 43, Loss : 0.455931, Accuracy: 0.977000, Test accuracy: 0.967600
Distillation: Epoch : 44, Loss : 0.462846, Accuracy: 0.971000, Test accuracy: 0.968700
Distillation: Epoch : 45, Loss : 0.486256, Accuracy: 0.969000, Test accuracy: 0.968900
Distillation: Epoch : 46, Loss : 0.464482, Accuracy: 0.968000, Test accuracy: 0.968000
Distillation: Epoch : 47, Loss : 0.469989, Accuracy: 0.969000, Test accuracy: 0.969100
Distillation: Epoch : 48, Loss : 0.456387, Accuracy: 0.976000, Test accuracy: 0.968700
Distillation: Epoch : 49, Loss : 0.488121, Accuracy: 0.961000, Test accuracy: 0.968500
Distillation: Epoch : 50, Loss : 0.465296, Accuracy: 0.977000, Test accuracy: 0.969500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9695
Generating confusion matrix for student2
[[ 974.    0.    3.    0.    0.    2.    6.    2.    6.    1.]
 [   1. 1124.    5.    1.    3.    0.    3.    6.    2.    6.]
 [   0.    2.  987.    4.    1.    0.    0.   15.    6.    0.]
 [   0.    2.    5.  967.    0.    5.    1.    1.    5.    1.]
 [   1.    0.    4.    2.  960.    0.    8.    6.    4.   14.]
 [   1.    2.    1.   17.    0.  873.    3.    0.    7.    9.]
 [   0.    2.    1.    0.    1.    3.  932.    0.    2.    3.]
 [   1.    0.   13.    8.    3.    2.    0.  985.    6.    6.]
 [   2.    3.   11.    7.    2.    3.    5.    5.  928.    4.]
 [   0.    0.    2.    4.   12.    4.    0.    8.    8.  965.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.712371, Accuracy: 0.724000, Test accuracy: 0.743400
Distillation: Epoch : 2, Loss : 1.101460, Accuracy: 0.844000, Test accuracy: 0.846800
Distillation: Epoch : 3, Loss : 0.925937, Accuracy: 0.872000, Test accuracy: 0.888000
Distillation: Epoch : 4, Loss : 0.843526, Accuracy: 0.894000, Test accuracy: 0.909000
Distillation: Epoch : 5, Loss : 0.797701, Accuracy: 0.920000, Test accuracy: 0.919100
Distillation: Epoch : 6, Loss : 0.785688, Accuracy: 0.919000, Test accuracy: 0.925100
Distillation: Epoch : 7, Loss : 0.787114, Accuracy: 0.914000, Test accuracy: 0.929600
Distillation: Epoch : 8, Loss : 0.747736, Accuracy: 0.923000, Test accuracy: 0.934200
Distillation: Epoch : 9, Loss : 0.750026, Accuracy: 0.932000, Test accuracy: 0.937600
Distillation: Epoch : 10, Loss : 0.729004, Accuracy: 0.939000, Test accuracy: 0.940500
Distillation: Epoch : 11, Loss : 0.730553, Accuracy: 0.931000, Test accuracy: 0.943500
Distillation: Epoch : 12, Loss : 0.692212, Accuracy: 0.940000, Test accuracy: 0.947100
Distillation: Epoch : 13, Loss : 0.701818, Accuracy: 0.951000, Test accuracy: 0.949800
Distillation: Epoch : 14, Loss : 0.688815, Accuracy: 0.947000, Test accuracy: 0.951400
Distillation: Epoch : 15, Loss : 0.696917, Accuracy: 0.949000, Test accuracy: 0.954200
Distillation: Epoch : 16, Loss : 0.695589, Accuracy: 0.948000, Test accuracy: 0.955100
Distillation: Epoch : 17, Loss : 0.705366, Accuracy: 0.964000, Test accuracy: 0.956400
Distillation: Epoch : 18, Loss : 0.710003, Accuracy: 0.947000, Test accuracy: 0.957100
Distillation: Epoch : 19, Loss : 0.675892, Accuracy: 0.963000, Test accuracy: 0.958400
Distillation: Epoch : 20, Loss : 0.656007, Accuracy: 0.960000, Test accuracy: 0.959900
Distillation: Epoch : 21, Loss : 0.684308, Accuracy: 0.958000, Test accuracy: 0.961000
Distillation: Epoch : 22, Loss : 0.689432, Accuracy: 0.953000, Test accuracy: 0.960400
Distillation: Epoch : 23, Loss : 0.702725, Accuracy: 0.966000, Test accuracy: 0.961200
Distillation: Epoch : 24, Loss : 0.662723, Accuracy: 0.961000, Test accuracy: 0.961800
Distillation: Epoch : 25, Loss : 0.652859, Accuracy: 0.969000, Test accuracy: 0.962500
Distillation: Epoch : 26, Loss : 0.707587, Accuracy: 0.941000, Test accuracy: 0.963400
Distillation: Epoch : 27, Loss : 0.655615, Accuracy: 0.954000, Test accuracy: 0.963400
Distillation: Epoch : 28, Loss : 0.654485, Accuracy: 0.955000, Test accuracy: 0.964600
Distillation: Epoch : 29, Loss : 0.682792, Accuracy: 0.958000, Test accuracy: 0.965300
Distillation: Epoch : 30, Loss : 0.679433, Accuracy: 0.951000, Test accuracy: 0.965100
Distillation: Epoch : 31, Loss : 0.651893, Accuracy: 0.965000, Test accuracy: 0.965600
Distillation: Epoch : 32, Loss : 0.682252, Accuracy: 0.970000, Test accuracy: 0.966000
Distillation: Epoch : 33, Loss : 0.664415, Accuracy: 0.961000, Test accuracy: 0.966900
Distillation: Epoch : 34, Loss : 0.668940, Accuracy: 0.963000, Test accuracy: 0.966900
Distillation: Epoch : 35, Loss : 0.660804, Accuracy: 0.962000, Test accuracy: 0.967400
Distillation: Epoch : 36, Loss : 0.670230, Accuracy: 0.958000, Test accuracy: 0.968200
Distillation: Epoch : 37, Loss : 0.647938, Accuracy: 0.970000, Test accuracy: 0.967900
Distillation: Epoch : 38, Loss : 0.685096, Accuracy: 0.956000, Test accuracy: 0.969000
Distillation: Epoch : 39, Loss : 0.660059, Accuracy: 0.964000, Test accuracy: 0.968400
Distillation: Epoch : 40, Loss : 0.667663, Accuracy: 0.964000, Test accuracy: 0.968400
Distillation: Epoch : 41, Loss : 0.658619, Accuracy: 0.960000, Test accuracy: 0.968700
Distillation: Epoch : 42, Loss : 0.639364, Accuracy: 0.973000, Test accuracy: 0.969600
Distillation: Epoch : 43, Loss : 0.642890, Accuracy: 0.963000, Test accuracy: 0.969600
Distillation: Epoch : 44, Loss : 0.674741, Accuracy: 0.959000, Test accuracy: 0.970000
Distillation: Epoch : 45, Loss : 0.682216, Accuracy: 0.964000, Test accuracy: 0.970400
Distillation: Epoch : 46, Loss : 0.649375, Accuracy: 0.971000, Test accuracy: 0.969800
Distillation: Epoch : 47, Loss : 0.670488, Accuracy: 0.963000, Test accuracy: 0.969900
Distillation: Epoch : 48, Loss : 0.647554, Accuracy: 0.971000, Test accuracy: 0.970400
Distillation: Epoch : 49, Loss : 0.672580, Accuracy: 0.974000, Test accuracy: 0.970500
Distillation: Epoch : 50, Loss : 0.668629, Accuracy: 0.966000, Test accuracy: 0.970300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9703
Generating confusion matrix for student2
[[ 971.    0.    4.    0.    1.    1.    6.    1.    7.    3.]
 [   1. 1121.    9.    0.    1.    1.    3.    5.    2.    9.]
 [   1.    3.  978.    3.    0.    0.    0.    9.    7.    2.]
 [   0.    1.    5.  975.    0.    4.    0.    2.    3.    4.]
 [   1.    0.    5.    0.  969.    0.    8.    2.    5.   13.]
 [   0.    0.    0.   12.    0.  880.    7.    0.    4.    8.]
 [   1.    2.    1.    0.    2.    2.  930.    0.    3.    0.]
 [   2.    0.   12.    5.    1.    0.    0.  994.    7.   11.]
 [   3.    8.   16.   14.    3.    3.    4.    3.  929.    3.]
 [   0.    0.    2.    1.    5.    1.    0.   12.    7.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.863961, Accuracy: 0.735000, Test accuracy: 0.746300
Distillation: Epoch : 2, Loss : 1.254774, Accuracy: 0.825000, Test accuracy: 0.837600
Distillation: Epoch : 3, Loss : 1.122665, Accuracy: 0.855000, Test accuracy: 0.874700
Distillation: Epoch : 4, Loss : 1.039660, Accuracy: 0.894000, Test accuracy: 0.890200
Distillation: Epoch : 5, Loss : 1.009863, Accuracy: 0.895000, Test accuracy: 0.902700
Distillation: Epoch : 6, Loss : 0.972916, Accuracy: 0.908000, Test accuracy: 0.911500
Distillation: Epoch : 7, Loss : 0.971412, Accuracy: 0.904000, Test accuracy: 0.914700
Distillation: Epoch : 8, Loss : 0.977231, Accuracy: 0.898000, Test accuracy: 0.920100
Distillation: Epoch : 9, Loss : 0.951032, Accuracy: 0.923000, Test accuracy: 0.922900
Distillation: Epoch : 10, Loss : 0.954910, Accuracy: 0.919000, Test accuracy: 0.925800
Distillation: Epoch : 11, Loss : 0.942447, Accuracy: 0.913000, Test accuracy: 0.928200
Distillation: Epoch : 12, Loss : 0.945652, Accuracy: 0.935000, Test accuracy: 0.931700
Distillation: Epoch : 13, Loss : 0.914863, Accuracy: 0.939000, Test accuracy: 0.934100
Distillation: Epoch : 14, Loss : 0.953946, Accuracy: 0.905000, Test accuracy: 0.936000
Distillation: Epoch : 15, Loss : 0.920451, Accuracy: 0.932000, Test accuracy: 0.938400
Distillation: Epoch : 16, Loss : 0.891466, Accuracy: 0.932000, Test accuracy: 0.940400
Distillation: Epoch : 17, Loss : 0.902271, Accuracy: 0.945000, Test accuracy: 0.942900
Distillation: Epoch : 18, Loss : 0.892438, Accuracy: 0.937000, Test accuracy: 0.944700
Distillation: Epoch : 19, Loss : 0.911318, Accuracy: 0.935000, Test accuracy: 0.946300
Distillation: Epoch : 20, Loss : 0.886631, Accuracy: 0.948000, Test accuracy: 0.947900
Distillation: Epoch : 21, Loss : 0.878613, Accuracy: 0.940000, Test accuracy: 0.950400
Distillation: Epoch : 22, Loss : 0.876977, Accuracy: 0.938000, Test accuracy: 0.950800
Distillation: Epoch : 23, Loss : 0.858776, Accuracy: 0.955000, Test accuracy: 0.952500
Distillation: Epoch : 24, Loss : 0.882727, Accuracy: 0.938000, Test accuracy: 0.954100
Distillation: Epoch : 25, Loss : 0.881419, Accuracy: 0.947000, Test accuracy: 0.955000
Distillation: Epoch : 26, Loss : 0.859602, Accuracy: 0.956000, Test accuracy: 0.957200
Distillation: Epoch : 27, Loss : 0.903637, Accuracy: 0.944000, Test accuracy: 0.957800
Distillation: Epoch : 28, Loss : 0.873367, Accuracy: 0.955000, Test accuracy: 0.958800
Distillation: Epoch : 29, Loss : 0.883062, Accuracy: 0.947000, Test accuracy: 0.959500
Distillation: Epoch : 30, Loss : 0.867653, Accuracy: 0.962000, Test accuracy: 0.960300
Distillation: Epoch : 31, Loss : 0.910755, Accuracy: 0.939000, Test accuracy: 0.961400
Distillation: Epoch : 32, Loss : 0.878035, Accuracy: 0.961000, Test accuracy: 0.961500
Distillation: Epoch : 33, Loss : 0.869690, Accuracy: 0.952000, Test accuracy: 0.962000
Distillation: Epoch : 34, Loss : 0.848912, Accuracy: 0.958000, Test accuracy: 0.962300
Distillation: Epoch : 35, Loss : 0.873114, Accuracy: 0.952000, Test accuracy: 0.962300
Distillation: Epoch : 36, Loss : 0.864485, Accuracy: 0.948000, Test accuracy: 0.962900
Distillation: Epoch : 37, Loss : 0.880436, Accuracy: 0.957000, Test accuracy: 0.963000
Distillation: Epoch : 38, Loss : 0.870696, Accuracy: 0.955000, Test accuracy: 0.963700
Distillation: Epoch : 39, Loss : 0.876092, Accuracy: 0.954000, Test accuracy: 0.964300
Distillation: Epoch : 40, Loss : 0.868155, Accuracy: 0.955000, Test accuracy: 0.964900
Distillation: Epoch : 41, Loss : 0.842810, Accuracy: 0.958000, Test accuracy: 0.964900
Distillation: Epoch : 42, Loss : 0.847282, Accuracy: 0.958000, Test accuracy: 0.964800
Distillation: Epoch : 43, Loss : 0.858322, Accuracy: 0.970000, Test accuracy: 0.965700
Distillation: Epoch : 44, Loss : 0.841555, Accuracy: 0.970000, Test accuracy: 0.965700
Distillation: Epoch : 45, Loss : 0.852813, Accuracy: 0.962000, Test accuracy: 0.966700
Distillation: Epoch : 46, Loss : 0.867839, Accuracy: 0.963000, Test accuracy: 0.966700
Distillation: Epoch : 47, Loss : 0.835162, Accuracy: 0.966000, Test accuracy: 0.967100
Distillation: Epoch : 48, Loss : 0.843368, Accuracy: 0.960000, Test accuracy: 0.967100
Distillation: Epoch : 49, Loss : 0.846896, Accuracy: 0.961000, Test accuracy: 0.967200
Distillation: Epoch : 50, Loss : 0.873674, Accuracy: 0.951000, Test accuracy: 0.967900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9679
Generating confusion matrix for student2
[[ 970.    0.    1.    0.    1.    1.    4.    1.    8.    4.]
 [   0. 1123.    6.    0.    0.    0.    3.    6.    2.    5.]
 [   1.    2.  976.    4.    2.    0.    2.   11.    8.    1.]
 [   0.    1.    3.  975.    1.    5.    0.    2.    5.    7.]
 [   2.    0.    5.    0.  960.    0.    4.    4.    5.    8.]
 [   1.    1.    0.    8.    0.  869.   10.    1.    7.    4.]
 [   3.    4.    2.    0.    1.    3.  932.    0.    1.    0.]
 [   2.    0.    5.    6.    1.    2.    0.  983.    7.   10.]
 [   1.    4.   34.   15.    3.    9.    3.    4.  926.    5.]
 [   0.    0.    0.    2.   13.    3.    0.   16.    5.  965.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.759995, Accuracy: 0.757000, Test accuracy: 0.754500
Distillation: Epoch : 2, Loss : 1.376984, Accuracy: 0.822000, Test accuracy: 0.830400
Distillation: Epoch : 3, Loss : 1.272658, Accuracy: 0.855000, Test accuracy: 0.863100
Distillation: Epoch : 4, Loss : 1.244961, Accuracy: 0.867000, Test accuracy: 0.877000
Distillation: Epoch : 5, Loss : 1.228383, Accuracy: 0.877000, Test accuracy: 0.884400
Distillation: Epoch : 6, Loss : 1.218517, Accuracy: 0.881000, Test accuracy: 0.892900
Distillation: Epoch : 7, Loss : 1.191889, Accuracy: 0.890000, Test accuracy: 0.898500
Distillation: Epoch : 8, Loss : 1.172714, Accuracy: 0.901000, Test accuracy: 0.904900
Distillation: Epoch : 9, Loss : 1.166850, Accuracy: 0.894000, Test accuracy: 0.909100
Distillation: Epoch : 10, Loss : 1.133896, Accuracy: 0.912000, Test accuracy: 0.911500
Distillation: Epoch : 11, Loss : 1.130126, Accuracy: 0.919000, Test accuracy: 0.916300
Distillation: Epoch : 12, Loss : 1.119234, Accuracy: 0.920000, Test accuracy: 0.918900
Distillation: Epoch : 13, Loss : 1.129573, Accuracy: 0.923000, Test accuracy: 0.922800
Distillation: Epoch : 14, Loss : 1.099332, Accuracy: 0.922000, Test accuracy: 0.926700
Distillation: Epoch : 15, Loss : 1.105587, Accuracy: 0.925000, Test accuracy: 0.928200
Distillation: Epoch : 16, Loss : 1.111629, Accuracy: 0.932000, Test accuracy: 0.931500
Distillation: Epoch : 17, Loss : 1.124731, Accuracy: 0.916000, Test accuracy: 0.934400
Distillation: Epoch : 18, Loss : 1.129377, Accuracy: 0.930000, Test accuracy: 0.937900
Distillation: Epoch : 19, Loss : 1.079151, Accuracy: 0.932000, Test accuracy: 0.941300
Distillation: Epoch : 20, Loss : 1.095169, Accuracy: 0.944000, Test accuracy: 0.941200
Distillation: Epoch : 21, Loss : 1.083519, Accuracy: 0.937000, Test accuracy: 0.944900
Distillation: Epoch : 22, Loss : 1.059294, Accuracy: 0.943000, Test accuracy: 0.946600
Distillation: Epoch : 23, Loss : 1.062446, Accuracy: 0.943000, Test accuracy: 0.948200
Distillation: Epoch : 24, Loss : 1.044776, Accuracy: 0.953000, Test accuracy: 0.949800
Distillation: Epoch : 25, Loss : 1.051364, Accuracy: 0.942000, Test accuracy: 0.952100
Distillation: Epoch : 26, Loss : 1.085998, Accuracy: 0.951000, Test accuracy: 0.953900
Distillation: Epoch : 27, Loss : 1.042255, Accuracy: 0.949000, Test accuracy: 0.954100
Distillation: Epoch : 28, Loss : 1.073575, Accuracy: 0.940000, Test accuracy: 0.955700
Distillation: Epoch : 29, Loss : 1.064926, Accuracy: 0.951000, Test accuracy: 0.957300
Distillation: Epoch : 30, Loss : 1.051519, Accuracy: 0.958000, Test accuracy: 0.958000
Distillation: Epoch : 31, Loss : 1.022140, Accuracy: 0.947000, Test accuracy: 0.958000
Distillation: Epoch : 32, Loss : 1.058456, Accuracy: 0.943000, Test accuracy: 0.959700
Distillation: Epoch : 33, Loss : 1.045199, Accuracy: 0.946000, Test accuracy: 0.960000
Distillation: Epoch : 34, Loss : 1.048304, Accuracy: 0.959000, Test accuracy: 0.961300
Distillation: Epoch : 35, Loss : 1.048264, Accuracy: 0.951000, Test accuracy: 0.961400
Distillation: Epoch : 36, Loss : 1.069208, Accuracy: 0.960000, Test accuracy: 0.962900
Distillation: Epoch : 37, Loss : 1.013110, Accuracy: 0.962000, Test accuracy: 0.961700
Distillation: Epoch : 38, Loss : 1.036645, Accuracy: 0.964000, Test accuracy: 0.962100
Distillation: Epoch : 39, Loss : 1.047976, Accuracy: 0.957000, Test accuracy: 0.963200
Distillation: Epoch : 40, Loss : 1.033464, Accuracy: 0.961000, Test accuracy: 0.962400
Distillation: Epoch : 41, Loss : 1.031763, Accuracy: 0.963000, Test accuracy: 0.964500
Distillation: Epoch : 42, Loss : 1.058823, Accuracy: 0.956000, Test accuracy: 0.963300
Distillation: Epoch : 43, Loss : 1.042987, Accuracy: 0.961000, Test accuracy: 0.963500
Distillation: Epoch : 44, Loss : 1.007954, Accuracy: 0.955000, Test accuracy: 0.964300
Distillation: Epoch : 45, Loss : 1.034844, Accuracy: 0.959000, Test accuracy: 0.964400
Distillation: Epoch : 46, Loss : 1.016720, Accuracy: 0.956000, Test accuracy: 0.964600
Distillation: Epoch : 47, Loss : 1.019175, Accuracy: 0.959000, Test accuracy: 0.964900
Distillation: Epoch : 48, Loss : 1.014301, Accuracy: 0.959000, Test accuracy: 0.965900
Distillation: Epoch : 49, Loss : 1.048004, Accuracy: 0.951000, Test accuracy: 0.966200
Distillation: Epoch : 50, Loss : 1.038649, Accuracy: 0.966000, Test accuracy: 0.966700
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9667
Generating confusion matrix for student2
[[ 967.    0.    3.    0.    0.    1.    4.    1.    6.    6.]
 [   1. 1122.    8.    1.    0.    1.    3.    6.    1.    6.]
 [   1.    2.  982.    6.    6.    0.    0.   15.   10.    0.]
 [   0.    1.    3.  975.    0.   10.    0.    2.    1.    6.]
 [   3.    0.    4.    1.  959.    2.    5.    3.    7.   14.]
 [   1.    0.    0.    6.    0.  863.    8.    0.    8.    3.]
 [   3.    3.    2.    0.    2.    3.  935.    0.    2.    0.]
 [   2.    0.    7.    6.    1.    2.    0.  981.    5.   12.]
 [   2.    7.   23.   13.    2.    8.    3.    4.  926.    5.]
 [   0.    0.    0.    2.   12.    2.    0.   16.    8.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.818854, Accuracy: 0.784000, Test accuracy: 0.800300
Distillation: Epoch : 2, Loss : 1.487286, Accuracy: 0.809000, Test accuracy: 0.848200
Distillation: Epoch : 3, Loss : 1.393610, Accuracy: 0.868000, Test accuracy: 0.871500
Distillation: Epoch : 4, Loss : 1.389656, Accuracy: 0.866000, Test accuracy: 0.881600
Distillation: Epoch : 5, Loss : 1.345741, Accuracy: 0.884000, Test accuracy: 0.886300
Distillation: Epoch : 6, Loss : 1.345089, Accuracy: 0.895000, Test accuracy: 0.892800
Distillation: Epoch : 7, Loss : 1.361102, Accuracy: 0.882000, Test accuracy: 0.896800
Distillation: Epoch : 8, Loss : 1.312667, Accuracy: 0.910000, Test accuracy: 0.897900
Distillation: Epoch : 9, Loss : 1.342410, Accuracy: 0.885000, Test accuracy: 0.901500
Distillation: Epoch : 10, Loss : 1.305457, Accuracy: 0.905000, Test accuracy: 0.905100
Distillation: Epoch : 11, Loss : 1.326848, Accuracy: 0.905000, Test accuracy: 0.907100
Distillation: Epoch : 12, Loss : 1.307120, Accuracy: 0.894000, Test accuracy: 0.909800
Distillation: Epoch : 13, Loss : 1.289813, Accuracy: 0.917000, Test accuracy: 0.914200
Distillation: Epoch : 14, Loss : 1.281759, Accuracy: 0.908000, Test accuracy: 0.916700
Distillation: Epoch : 15, Loss : 1.274532, Accuracy: 0.902000, Test accuracy: 0.919400
Distillation: Epoch : 16, Loss : 1.284046, Accuracy: 0.914000, Test accuracy: 0.923000
Distillation: Epoch : 17, Loss : 1.271984, Accuracy: 0.917000, Test accuracy: 0.926700
Distillation: Epoch : 18, Loss : 1.291604, Accuracy: 0.902000, Test accuracy: 0.928700
Distillation: Epoch : 19, Loss : 1.281936, Accuracy: 0.923000, Test accuracy: 0.931300
Distillation: Epoch : 20, Loss : 1.246717, Accuracy: 0.924000, Test accuracy: 0.935400
Distillation: Epoch : 21, Loss : 1.241070, Accuracy: 0.935000, Test accuracy: 0.937400
Distillation: Epoch : 22, Loss : 1.255537, Accuracy: 0.922000, Test accuracy: 0.938700
Distillation: Epoch : 23, Loss : 1.247745, Accuracy: 0.940000, Test accuracy: 0.941100
Distillation: Epoch : 24, Loss : 1.232151, Accuracy: 0.945000, Test accuracy: 0.943800
Distillation: Epoch : 25, Loss : 1.251861, Accuracy: 0.938000, Test accuracy: 0.945800
Distillation: Epoch : 26, Loss : 1.219426, Accuracy: 0.939000, Test accuracy: 0.948500
Distillation: Epoch : 27, Loss : 1.215724, Accuracy: 0.939000, Test accuracy: 0.949500
Distillation: Epoch : 28, Loss : 1.221272, Accuracy: 0.944000, Test accuracy: 0.952000
Distillation: Epoch : 29, Loss : 1.228683, Accuracy: 0.940000, Test accuracy: 0.952900
Distillation: Epoch : 30, Loss : 1.214121, Accuracy: 0.948000, Test accuracy: 0.953300
Distillation: Epoch : 31, Loss : 1.221370, Accuracy: 0.951000, Test accuracy: 0.953800
Distillation: Epoch : 32, Loss : 1.212733, Accuracy: 0.945000, Test accuracy: 0.955500
Distillation: Epoch : 33, Loss : 1.190373, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 34, Loss : 1.238011, Accuracy: 0.938000, Test accuracy: 0.957000
Distillation: Epoch : 35, Loss : 1.207108, Accuracy: 0.957000, Test accuracy: 0.958700
Distillation: Epoch : 36, Loss : 1.205316, Accuracy: 0.951000, Test accuracy: 0.959900
Distillation: Epoch : 37, Loss : 1.198467, Accuracy: 0.956000, Test accuracy: 0.960800
Distillation: Epoch : 38, Loss : 1.203032, Accuracy: 0.966000, Test accuracy: 0.962400
Distillation: Epoch : 39, Loss : 1.211147, Accuracy: 0.960000, Test accuracy: 0.963000
Distillation: Epoch : 40, Loss : 1.201526, Accuracy: 0.968000, Test accuracy: 0.963300
Distillation: Epoch : 41, Loss : 1.190887, Accuracy: 0.964000, Test accuracy: 0.964500
Distillation: Epoch : 42, Loss : 1.196362, Accuracy: 0.965000, Test accuracy: 0.965100
Distillation: Epoch : 43, Loss : 1.203244, Accuracy: 0.964000, Test accuracy: 0.965500
Distillation: Epoch : 44, Loss : 1.187962, Accuracy: 0.961000, Test accuracy: 0.965700
Distillation: Epoch : 45, Loss : 1.212679, Accuracy: 0.961000, Test accuracy: 0.966600
Distillation: Epoch : 46, Loss : 1.198136, Accuracy: 0.964000, Test accuracy: 0.967800
Distillation: Epoch : 47, Loss : 1.193363, Accuracy: 0.958000, Test accuracy: 0.967400
Distillation: Epoch : 48, Loss : 1.196549, Accuracy: 0.964000, Test accuracy: 0.967900
Distillation: Epoch : 49, Loss : 1.172743, Accuracy: 0.977000, Test accuracy: 0.968700
Distillation: Epoch : 50, Loss : 1.188393, Accuracy: 0.957000, Test accuracy: 0.968600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9686
Generating confusion matrix for student2
[[ 969.    0.    4.    0.    0.    0.    5.    1.    6.    6.]
 [   1. 1126.    7.    0.    1.    1.    3.   10.    2.    5.]
 [   1.    2.  986.    6.    5.    0.    0.   14.    6.    0.]
 [   0.    2.    3.  974.    0.    1.    0.    3.    3.    3.]
 [   1.    0.    6.    1.  963.    1.    8.    4.    6.   23.]
 [   0.    0.    1.   12.    0.  879.    8.    0.    3.    6.]
 [   4.    3.    1.    0.    1.    3.  930.    0.    1.    0.]
 [   1.    0.    9.    8.    1.    1.    0.  981.   10.   11.]
 [   3.    2.   13.    7.    2.    3.    4.    3.  927.    4.]
 [   0.    0.    2.    2.    9.    3.    0.   12.   10.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.883930, Accuracy: 0.795000, Test accuracy: 0.803200
Distillation: Epoch : 2, Loss : 1.579204, Accuracy: 0.849000, Test accuracy: 0.845700
Distillation: Epoch : 3, Loss : 1.552710, Accuracy: 0.859000, Test accuracy: 0.872200
Distillation: Epoch : 4, Loss : 1.486402, Accuracy: 0.873000, Test accuracy: 0.884000
Distillation: Epoch : 5, Loss : 1.472539, Accuracy: 0.887000, Test accuracy: 0.890700
Distillation: Epoch : 6, Loss : 1.467258, Accuracy: 0.885000, Test accuracy: 0.897600
Distillation: Epoch : 7, Loss : 1.475908, Accuracy: 0.875000, Test accuracy: 0.902000
Distillation: Epoch : 8, Loss : 1.456511, Accuracy: 0.903000, Test accuracy: 0.907300
Distillation: Epoch : 9, Loss : 1.452733, Accuracy: 0.899000, Test accuracy: 0.911800
Distillation: Epoch : 10, Loss : 1.428961, Accuracy: 0.914000, Test accuracy: 0.915300
Distillation: Epoch : 11, Loss : 1.411050, Accuracy: 0.917000, Test accuracy: 0.918700
Distillation: Epoch : 12, Loss : 1.424888, Accuracy: 0.917000, Test accuracy: 0.922400
Distillation: Epoch : 13, Loss : 1.407305, Accuracy: 0.916000, Test accuracy: 0.926500
Distillation: Epoch : 14, Loss : 1.426663, Accuracy: 0.918000, Test accuracy: 0.929500
Distillation: Epoch : 15, Loss : 1.379179, Accuracy: 0.919000, Test accuracy: 0.931600
Distillation: Epoch : 16, Loss : 1.393421, Accuracy: 0.933000, Test accuracy: 0.934600
Distillation: Epoch : 17, Loss : 1.398735, Accuracy: 0.931000, Test accuracy: 0.936900
Distillation: Epoch : 18, Loss : 1.376257, Accuracy: 0.941000, Test accuracy: 0.939500
Distillation: Epoch : 19, Loss : 1.369615, Accuracy: 0.935000, Test accuracy: 0.939700
Distillation: Epoch : 20, Loss : 1.364260, Accuracy: 0.943000, Test accuracy: 0.940700
Distillation: Epoch : 21, Loss : 1.388283, Accuracy: 0.918000, Test accuracy: 0.942500
Distillation: Epoch : 22, Loss : 1.388408, Accuracy: 0.926000, Test accuracy: 0.944200
Distillation: Epoch : 23, Loss : 1.379320, Accuracy: 0.936000, Test accuracy: 0.946400
Distillation: Epoch : 24, Loss : 1.347260, Accuracy: 0.948000, Test accuracy: 0.946900
Distillation: Epoch : 25, Loss : 1.343903, Accuracy: 0.950000, Test accuracy: 0.948900
Distillation: Epoch : 26, Loss : 1.350330, Accuracy: 0.942000, Test accuracy: 0.949700
Distillation: Epoch : 27, Loss : 1.351113, Accuracy: 0.948000, Test accuracy: 0.950500
Distillation: Epoch : 28, Loss : 1.368696, Accuracy: 0.945000, Test accuracy: 0.950800
Distillation: Epoch : 29, Loss : 1.361711, Accuracy: 0.952000, Test accuracy: 0.952000
Distillation: Epoch : 30, Loss : 1.377297, Accuracy: 0.947000, Test accuracy: 0.951600
Distillation: Epoch : 31, Loss : 1.363779, Accuracy: 0.946000, Test accuracy: 0.952600
Distillation: Epoch : 32, Loss : 1.375351, Accuracy: 0.936000, Test accuracy: 0.952600
Distillation: Epoch : 33, Loss : 1.376384, Accuracy: 0.953000, Test accuracy: 0.954500
Distillation: Epoch : 34, Loss : 1.328174, Accuracy: 0.950000, Test accuracy: 0.954400
Distillation: Epoch : 35, Loss : 1.367543, Accuracy: 0.953000, Test accuracy: 0.954700
Distillation: Epoch : 36, Loss : 1.346167, Accuracy: 0.950000, Test accuracy: 0.955400
Distillation: Epoch : 37, Loss : 1.362369, Accuracy: 0.957000, Test accuracy: 0.955300
Distillation: Epoch : 38, Loss : 1.356954, Accuracy: 0.949000, Test accuracy: 0.956000
Distillation: Epoch : 39, Loss : 1.348679, Accuracy: 0.937000, Test accuracy: 0.956600
Distillation: Epoch : 40, Loss : 1.372172, Accuracy: 0.942000, Test accuracy: 0.956400
Distillation: Epoch : 41, Loss : 1.349971, Accuracy: 0.958000, Test accuracy: 0.956700
Distillation: Epoch : 42, Loss : 1.342689, Accuracy: 0.959000, Test accuracy: 0.958000
Distillation: Epoch : 43, Loss : 1.354268, Accuracy: 0.950000, Test accuracy: 0.957900
Distillation: Epoch : 44, Loss : 1.347356, Accuracy: 0.950000, Test accuracy: 0.958000
Distillation: Epoch : 45, Loss : 1.339998, Accuracy: 0.953000, Test accuracy: 0.958500
Distillation: Epoch : 46, Loss : 1.353508, Accuracy: 0.952000, Test accuracy: 0.959200
Distillation: Epoch : 47, Loss : 1.347547, Accuracy: 0.961000, Test accuracy: 0.959400
Distillation: Epoch : 48, Loss : 1.346461, Accuracy: 0.959000, Test accuracy: 0.959400
Distillation: Epoch : 49, Loss : 1.353753, Accuracy: 0.948000, Test accuracy: 0.960000
Distillation: Epoch : 50, Loss : 1.330965, Accuracy: 0.960000, Test accuracy: 0.960400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9604
Generating confusion matrix for student2
[[ 968.    0.    3.    0.    0.    2.    7.    1.    8.    5.]
 [   1. 1119.    6.    3.    1.    1.    5.   12.    4.    5.]
 [   0.    4.  977.    7.    1.    0.    1.   10.    8.    1.]
 [   0.    0.    5.  960.    0.    1.    0.    2.    6.    3.]
 [   1.    0.    5.    3.  962.    0.   10.    5.    8.   20.]
 [   1.    0.    1.   16.    0.  869.    9.    0.    8.    4.]
 [   4.    3.    1.    0.    3.    4.  923.    0.    8.    0.]
 [   2.    0.   13.    7.    1.    3.    0.  975.    9.   18.]
 [   3.    9.   19.   11.    4.    6.    3.    3.  901.    3.]
 [   0.    0.    2.    3.   10.    6.    0.   20.   14.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.074066, Accuracy: 0.792000, Test accuracy: 0.787700
Distillation: Epoch : 2, Loss : 1.711032, Accuracy: 0.834000, Test accuracy: 0.837600
Distillation: Epoch : 3, Loss : 1.610933, Accuracy: 0.870000, Test accuracy: 0.868800
Distillation: Epoch : 4, Loss : 1.590643, Accuracy: 0.888000, Test accuracy: 0.889300
Distillation: Epoch : 5, Loss : 1.596670, Accuracy: 0.902000, Test accuracy: 0.899000
Distillation: Epoch : 6, Loss : 1.570796, Accuracy: 0.886000, Test accuracy: 0.907900
Distillation: Epoch : 7, Loss : 1.555540, Accuracy: 0.906000, Test accuracy: 0.913700
Distillation: Epoch : 8, Loss : 1.526285, Accuracy: 0.921000, Test accuracy: 0.919800
Distillation: Epoch : 9, Loss : 1.528668, Accuracy: 0.914000, Test accuracy: 0.925800
Distillation: Epoch : 10, Loss : 1.518681, Accuracy: 0.926000, Test accuracy: 0.929600
Distillation: Epoch : 11, Loss : 1.525737, Accuracy: 0.934000, Test accuracy: 0.933400
Distillation: Epoch : 12, Loss : 1.528953, Accuracy: 0.920000, Test accuracy: 0.937300
Distillation: Epoch : 13, Loss : 1.503094, Accuracy: 0.941000, Test accuracy: 0.941500
Distillation: Epoch : 14, Loss : 1.493294, Accuracy: 0.946000, Test accuracy: 0.944000
Distillation: Epoch : 15, Loss : 1.505874, Accuracy: 0.934000, Test accuracy: 0.947300
Distillation: Epoch : 16, Loss : 1.489264, Accuracy: 0.943000, Test accuracy: 0.948800
Distillation: Epoch : 17, Loss : 1.495966, Accuracy: 0.942000, Test accuracy: 0.950900
Distillation: Epoch : 18, Loss : 1.498222, Accuracy: 0.945000, Test accuracy: 0.952400
Distillation: Epoch : 19, Loss : 1.476614, Accuracy: 0.950000, Test accuracy: 0.954100
Distillation: Epoch : 20, Loss : 1.477407, Accuracy: 0.954000, Test accuracy: 0.955300
Distillation: Epoch : 21, Loss : 1.490373, Accuracy: 0.948000, Test accuracy: 0.956700
Distillation: Epoch : 22, Loss : 1.482641, Accuracy: 0.941000, Test accuracy: 0.957300
Distillation: Epoch : 23, Loss : 1.472821, Accuracy: 0.962000, Test accuracy: 0.958400
Distillation: Epoch : 24, Loss : 1.496642, Accuracy: 0.950000, Test accuracy: 0.959400
Distillation: Epoch : 25, Loss : 1.507924, Accuracy: 0.944000, Test accuracy: 0.959600
Distillation: Epoch : 26, Loss : 1.478944, Accuracy: 0.945000, Test accuracy: 0.960400
Distillation: Epoch : 27, Loss : 1.472893, Accuracy: 0.957000, Test accuracy: 0.960500
Distillation: Epoch : 28, Loss : 1.475562, Accuracy: 0.960000, Test accuracy: 0.961900
Distillation: Epoch : 29, Loss : 1.470743, Accuracy: 0.959000, Test accuracy: 0.961400
Distillation: Epoch : 30, Loss : 1.470843, Accuracy: 0.964000, Test accuracy: 0.961700
Distillation: Epoch : 31, Loss : 1.481630, Accuracy: 0.955000, Test accuracy: 0.962600
Distillation: Epoch : 32, Loss : 1.462956, Accuracy: 0.959000, Test accuracy: 0.962900
Distillation: Epoch : 33, Loss : 1.472166, Accuracy: 0.963000, Test accuracy: 0.963900
Distillation: Epoch : 34, Loss : 1.455217, Accuracy: 0.960000, Test accuracy: 0.964300
Distillation: Epoch : 35, Loss : 1.486442, Accuracy: 0.966000, Test accuracy: 0.964400
Distillation: Epoch : 36, Loss : 1.464892, Accuracy: 0.964000, Test accuracy: 0.965300
Distillation: Epoch : 37, Loss : 1.469721, Accuracy: 0.960000, Test accuracy: 0.965600
Distillation: Epoch : 38, Loss : 1.474667, Accuracy: 0.963000, Test accuracy: 0.965400
Distillation: Epoch : 39, Loss : 1.462613, Accuracy: 0.963000, Test accuracy: 0.966600
Distillation: Epoch : 40, Loss : 1.453966, Accuracy: 0.965000, Test accuracy: 0.966100
Distillation: Epoch : 41, Loss : 1.463070, Accuracy: 0.970000, Test accuracy: 0.966700
Distillation: Epoch : 42, Loss : 1.465523, Accuracy: 0.961000, Test accuracy: 0.967800
Distillation: Epoch : 43, Loss : 1.459264, Accuracy: 0.967000, Test accuracy: 0.967200
Distillation: Epoch : 44, Loss : 1.469337, Accuracy: 0.964000, Test accuracy: 0.968200
Distillation: Epoch : 45, Loss : 1.453717, Accuracy: 0.971000, Test accuracy: 0.968100
Distillation: Epoch : 46, Loss : 1.437322, Accuracy: 0.969000, Test accuracy: 0.968600
Distillation: Epoch : 47, Loss : 1.451786, Accuracy: 0.969000, Test accuracy: 0.968100
Distillation: Epoch : 48, Loss : 1.441269, Accuracy: 0.972000, Test accuracy: 0.969100
Distillation: Epoch : 49, Loss : 1.459041, Accuracy: 0.969000, Test accuracy: 0.969300
Distillation: Epoch : 50, Loss : 1.449170, Accuracy: 0.969000, Test accuracy: 0.969400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9694
Generating confusion matrix for student2
[[ 966.    0.    6.    0.    0.    1.    8.    2.    6.    4.]
 [   1. 1121.    5.    0.    0.    0.    4.    5.    1.    6.]
 [   1.    2.  982.    6.    3.    0.    0.   16.    7.    0.]
 [   0.    2.    5.  969.    0.    2.    0.    3.    2.    3.]
 [   0.    0.    4.    0.  962.    1.    5.    1.    4.   13.]
 [   2.    1.    0.   16.    0.  880.    8.    0.    5.    5.]
 [   7.    2.    1.    0.    1.    2.  931.    0.    2.    0.]
 [   2.    0.   11.   10.    1.    1.    0.  990.    5.    9.]
 [   1.    7.   16.    8.    2.    2.    2.    5.  930.    6.]
 [   0.    0.    2.    1.   13.    3.    0.    6.   12.  963.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.066267, Accuracy: 0.787000, Test accuracy: 0.785400
Distillation: Epoch : 2, Loss : 1.896997, Accuracy: 0.833000, Test accuracy: 0.833400
Distillation: Epoch : 3, Loss : 1.881047, Accuracy: 0.840000, Test accuracy: 0.859300
Distillation: Epoch : 4, Loss : 1.866389, Accuracy: 0.858000, Test accuracy: 0.867700
Distillation: Epoch : 5, Loss : 1.861810, Accuracy: 0.848000, Test accuracy: 0.874800
Distillation: Epoch : 6, Loss : 1.847108, Accuracy: 0.872000, Test accuracy: 0.879900
Distillation: Epoch : 7, Loss : 1.837334, Accuracy: 0.888000, Test accuracy: 0.882300
Distillation: Epoch : 8, Loss : 1.834412, Accuracy: 0.880000, Test accuracy: 0.883100
Distillation: Epoch : 9, Loss : 1.852578, Accuracy: 0.881000, Test accuracy: 0.886700
Distillation: Epoch : 10, Loss : 1.814052, Accuracy: 0.904000, Test accuracy: 0.887900
Distillation: Epoch : 11, Loss : 1.833896, Accuracy: 0.873000, Test accuracy: 0.892100
Distillation: Epoch : 12, Loss : 1.826508, Accuracy: 0.887000, Test accuracy: 0.891700
Distillation: Epoch : 13, Loss : 1.826400, Accuracy: 0.870000, Test accuracy: 0.894000
Distillation: Epoch : 14, Loss : 1.821693, Accuracy: 0.875000, Test accuracy: 0.895400
Distillation: Epoch : 15, Loss : 1.830913, Accuracy: 0.874000, Test accuracy: 0.897100
Distillation: Epoch : 16, Loss : 1.818210, Accuracy: 0.904000, Test accuracy: 0.900800
Distillation: Epoch : 17, Loss : 1.831508, Accuracy: 0.879000, Test accuracy: 0.899700
Distillation: Epoch : 18, Loss : 1.826503, Accuracy: 0.884000, Test accuracy: 0.902800
Distillation: Epoch : 19, Loss : 1.809389, Accuracy: 0.896000, Test accuracy: 0.905700
Distillation: Epoch : 20, Loss : 1.821912, Accuracy: 0.898000, Test accuracy: 0.907500
Distillation: Epoch : 21, Loss : 1.804434, Accuracy: 0.886000, Test accuracy: 0.910100
Distillation: Epoch : 22, Loss : 1.800618, Accuracy: 0.908000, Test accuracy: 0.913200
Distillation: Epoch : 23, Loss : 1.799594, Accuracy: 0.909000, Test accuracy: 0.916200
Distillation: Epoch : 24, Loss : 1.792769, Accuracy: 0.923000, Test accuracy: 0.919800
Distillation: Epoch : 25, Loss : 1.778869, Accuracy: 0.930000, Test accuracy: 0.921200
Distillation: Epoch : 26, Loss : 1.779637, Accuracy: 0.914000, Test accuracy: 0.923200
Distillation: Epoch : 27, Loss : 1.783842, Accuracy: 0.927000, Test accuracy: 0.926700
Distillation: Epoch : 28, Loss : 1.793535, Accuracy: 0.910000, Test accuracy: 0.930600
Distillation: Epoch : 29, Loss : 1.777951, Accuracy: 0.924000, Test accuracy: 0.932900
Distillation: Epoch : 30, Loss : 1.793197, Accuracy: 0.928000, Test accuracy: 0.936000
Distillation: Epoch : 31, Loss : 1.767600, Accuracy: 0.953000, Test accuracy: 0.938900
Distillation: Epoch : 32, Loss : 1.773551, Accuracy: 0.938000, Test accuracy: 0.941400
Distillation: Epoch : 33, Loss : 1.768108, Accuracy: 0.935000, Test accuracy: 0.944100
Distillation: Epoch : 34, Loss : 1.764395, Accuracy: 0.932000, Test accuracy: 0.945300
Distillation: Epoch : 35, Loss : 1.770909, Accuracy: 0.933000, Test accuracy: 0.949100
Distillation: Epoch : 36, Loss : 1.763010, Accuracy: 0.938000, Test accuracy: 0.950000
Distillation: Epoch : 37, Loss : 1.766819, Accuracy: 0.953000, Test accuracy: 0.952800
Distillation: Epoch : 38, Loss : 1.755245, Accuracy: 0.951000, Test accuracy: 0.954200
Distillation: Epoch : 39, Loss : 1.752285, Accuracy: 0.955000, Test accuracy: 0.954800
Distillation: Epoch : 40, Loss : 1.757648, Accuracy: 0.952000, Test accuracy: 0.957300
Distillation: Epoch : 41, Loss : 1.753964, Accuracy: 0.955000, Test accuracy: 0.958000
Distillation: Epoch : 42, Loss : 1.743852, Accuracy: 0.958000, Test accuracy: 0.957900
Distillation: Epoch : 43, Loss : 1.740048, Accuracy: 0.968000, Test accuracy: 0.959900
Distillation: Epoch : 44, Loss : 1.750698, Accuracy: 0.967000, Test accuracy: 0.960300
Distillation: Epoch : 45, Loss : 1.753406, Accuracy: 0.956000, Test accuracy: 0.961000
Distillation: Epoch : 46, Loss : 1.740737, Accuracy: 0.955000, Test accuracy: 0.961900
Distillation: Epoch : 47, Loss : 1.771738, Accuracy: 0.964000, Test accuracy: 0.962500
Distillation: Epoch : 48, Loss : 1.741658, Accuracy: 0.958000, Test accuracy: 0.963900
Distillation: Epoch : 49, Loss : 1.748121, Accuracy: 0.970000, Test accuracy: 0.964200
Distillation: Epoch : 50, Loss : 1.759808, Accuracy: 0.950000, Test accuracy: 0.964000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.964
Generating confusion matrix for student2
[[ 966.    0.    3.    0.    0.    2.    4.    0.    6.    6.]
 [   1. 1123.   10.    1.    2.    1.    5.    7.    1.    5.]
 [   0.    2.  981.    2.    2.    1.    0.   11.    8.    0.]
 [   0.    1.    4.  959.    0.    3.    0.    3.    5.    1.]
 [   4.    0.    8.    0.  961.    0.   11.    5.    6.   14.]
 [   2.    1.    0.   33.    0.  870.   15.    2.   13.    5.]
 [   3.    4.    2.    0.    2.    4.  919.    0.    3.    0.]
 [   1.    0.    7.    8.    1.    3.    0.  987.    7.   14.]
 [   2.    4.   17.    6.    2.    3.    4.    1.  915.    5.]
 [   1.    0.    0.    1.   12.    5.    0.   12.   10.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.181729, Accuracy: 0.783000, Test accuracy: 0.778600
Distillation: Epoch : 2, Loss : 2.097592, Accuracy: 0.802000, Test accuracy: 0.831200
Distillation: Epoch : 3, Loss : 2.078484, Accuracy: 0.840000, Test accuracy: 0.855300
Distillation: Epoch : 4, Loss : 2.062550, Accuracy: 0.857000, Test accuracy: 0.864800
Distillation: Epoch : 5, Loss : 2.057733, Accuracy: 0.878000, Test accuracy: 0.871100
Distillation: Epoch : 6, Loss : 2.051919, Accuracy: 0.876000, Test accuracy: 0.876800
Distillation: Epoch : 7, Loss : 2.061924, Accuracy: 0.865000, Test accuracy: 0.882600
Distillation: Epoch : 8, Loss : 2.055320, Accuracy: 0.894000, Test accuracy: 0.887900
Distillation: Epoch : 9, Loss : 2.049334, Accuracy: 0.891000, Test accuracy: 0.891600
Distillation: Epoch : 10, Loss : 2.039140, Accuracy: 0.895000, Test accuracy: 0.895500
Distillation: Epoch : 11, Loss : 2.051944, Accuracy: 0.896000, Test accuracy: 0.899800
Distillation: Epoch : 12, Loss : 2.039039, Accuracy: 0.901000, Test accuracy: 0.902900
Distillation: Epoch : 13, Loss : 2.041842, Accuracy: 0.902000, Test accuracy: 0.908500
Distillation: Epoch : 14, Loss : 2.037362, Accuracy: 0.920000, Test accuracy: 0.914300
Distillation: Epoch : 15, Loss : 2.033841, Accuracy: 0.897000, Test accuracy: 0.917400
Distillation: Epoch : 16, Loss : 2.029985, Accuracy: 0.904000, Test accuracy: 0.919900
Distillation: Epoch : 17, Loss : 2.036827, Accuracy: 0.911000, Test accuracy: 0.923300
Distillation: Epoch : 18, Loss : 2.027123, Accuracy: 0.915000, Test accuracy: 0.927300
Distillation: Epoch : 19, Loss : 2.028725, Accuracy: 0.919000, Test accuracy: 0.929700
Distillation: Epoch : 20, Loss : 2.020800, Accuracy: 0.926000, Test accuracy: 0.932100
Distillation: Epoch : 21, Loss : 2.023776, Accuracy: 0.940000, Test accuracy: 0.934700
Distillation: Epoch : 22, Loss : 2.028120, Accuracy: 0.933000, Test accuracy: 0.937500
Distillation: Epoch : 23, Loss : 2.017440, Accuracy: 0.922000, Test accuracy: 0.940700
Distillation: Epoch : 24, Loss : 2.015625, Accuracy: 0.921000, Test accuracy: 0.941600
Distillation: Epoch : 25, Loss : 2.015779, Accuracy: 0.935000, Test accuracy: 0.943300
Distillation: Epoch : 26, Loss : 2.015931, Accuracy: 0.946000, Test accuracy: 0.945300
Distillation: Epoch : 27, Loss : 2.017171, Accuracy: 0.923000, Test accuracy: 0.945700
Distillation: Epoch : 28, Loss : 2.020099, Accuracy: 0.940000, Test accuracy: 0.946400
Distillation: Epoch : 29, Loss : 2.009331, Accuracy: 0.939000, Test accuracy: 0.947000
Distillation: Epoch : 30, Loss : 2.012794, Accuracy: 0.947000, Test accuracy: 0.947200
Distillation: Epoch : 31, Loss : 2.023430, Accuracy: 0.940000, Test accuracy: 0.949800
Distillation: Epoch : 32, Loss : 2.003255, Accuracy: 0.951000, Test accuracy: 0.951300
Distillation: Epoch : 33, Loss : 2.017803, Accuracy: 0.947000, Test accuracy: 0.952900
Distillation: Epoch : 34, Loss : 2.013479, Accuracy: 0.945000, Test accuracy: 0.953000
Distillation: Epoch : 35, Loss : 2.012396, Accuracy: 0.942000, Test accuracy: 0.951500
Distillation: Epoch : 36, Loss : 2.002147, Accuracy: 0.956000, Test accuracy: 0.954100
Distillation: Epoch : 37, Loss : 2.003086, Accuracy: 0.959000, Test accuracy: 0.954600
Distillation: Epoch : 38, Loss : 2.018204, Accuracy: 0.951000, Test accuracy: 0.954400
Distillation: Epoch : 39, Loss : 1.997046, Accuracy: 0.957000, Test accuracy: 0.956900
Distillation: Epoch : 40, Loss : 2.004921, Accuracy: 0.958000, Test accuracy: 0.957100
Distillation: Epoch : 41, Loss : 1.996958, Accuracy: 0.967000, Test accuracy: 0.958300
Distillation: Epoch : 42, Loss : 2.003579, Accuracy: 0.956000, Test accuracy: 0.958100
Distillation: Epoch : 43, Loss : 2.000407, Accuracy: 0.955000, Test accuracy: 0.958800
Distillation: Epoch : 44, Loss : 2.004414, Accuracy: 0.952000, Test accuracy: 0.959700
Distillation: Epoch : 45, Loss : 2.011961, Accuracy: 0.960000, Test accuracy: 0.960600
Distillation: Epoch : 46, Loss : 1.999686, Accuracy: 0.950000, Test accuracy: 0.961000
Distillation: Epoch : 47, Loss : 2.003880, Accuracy: 0.960000, Test accuracy: 0.960900
Distillation: Epoch : 48, Loss : 2.000742, Accuracy: 0.957000, Test accuracy: 0.962000
Distillation: Epoch : 49, Loss : 2.011048, Accuracy: 0.956000, Test accuracy: 0.961600
Distillation: Epoch : 50, Loss : 2.000463, Accuracy: 0.957000, Test accuracy: 0.962400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9624
Generating confusion matrix for student2
[[ 965.    0.    5.    1.    0.    2.    7.    0.    6.    5.]
 [   2. 1122.   10.    0.    2.    0.    4.    7.    2.    6.]
 [   1.    1.  971.    4.    1.    1.    0.   12.   10.    1.]
 [   0.    1.    6.  952.    0.    3.    0.    2.    4.    3.]
 [   5.    1.    7.    1.  963.    0.    5.    5.    5.   14.]
 [   2.    0.    0.   38.    0.  867.   15.    1.   18.    4.]
 [   3.    5.    2.    0.    3.    3.  924.    0.    3.    0.]
 [   1.    0.    7.    8.    1.    3.    0.  989.    6.   11.]
 [   1.    5.   22.    5.    2.    8.    3.    3.  913.    7.]
 [   0.    0.    2.    1.   10.    5.    0.    9.    7.  958.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.797351, Accuracy: 0.813000, Test accuracy: 0.819800
Distillation: Epoch : 2, Loss : 0.429711, Accuracy: 0.892000, Test accuracy: 0.881100
Distillation: Epoch : 3, Loss : 0.377904, Accuracy: 0.882000, Test accuracy: 0.900100
Distillation: Epoch : 4, Loss : 0.327161, Accuracy: 0.894000, Test accuracy: 0.910700
Distillation: Epoch : 5, Loss : 0.268387, Accuracy: 0.913000, Test accuracy: 0.918100
Distillation: Epoch : 6, Loss : 0.285175, Accuracy: 0.920000, Test accuracy: 0.924000
Distillation: Epoch : 7, Loss : 0.225201, Accuracy: 0.938000, Test accuracy: 0.927700
Distillation: Epoch : 8, Loss : 0.226653, Accuracy: 0.933000, Test accuracy: 0.929300
Distillation: Epoch : 9, Loss : 0.214469, Accuracy: 0.926000, Test accuracy: 0.933700
Distillation: Epoch : 10, Loss : 0.213151, Accuracy: 0.934000, Test accuracy: 0.934400
Distillation: Epoch : 11, Loss : 0.202245, Accuracy: 0.936000, Test accuracy: 0.937800
Distillation: Epoch : 12, Loss : 0.174810, Accuracy: 0.954000, Test accuracy: 0.939600
Distillation: Epoch : 13, Loss : 0.194046, Accuracy: 0.941000, Test accuracy: 0.941500
Distillation: Epoch : 14, Loss : 0.204728, Accuracy: 0.932000, Test accuracy: 0.943400
Distillation: Epoch : 15, Loss : 0.190954, Accuracy: 0.945000, Test accuracy: 0.943300
Distillation: Epoch : 16, Loss : 0.212981, Accuracy: 0.941000, Test accuracy: 0.945000
Distillation: Epoch : 17, Loss : 0.217517, Accuracy: 0.937000, Test accuracy: 0.946800
Distillation: Epoch : 18, Loss : 0.170407, Accuracy: 0.955000, Test accuracy: 0.947900
Distillation: Epoch : 19, Loss : 0.234612, Accuracy: 0.937000, Test accuracy: 0.947700
Distillation: Epoch : 20, Loss : 0.169483, Accuracy: 0.950000, Test accuracy: 0.947900
Distillation: Epoch : 21, Loss : 0.188959, Accuracy: 0.948000, Test accuracy: 0.949500
Distillation: Epoch : 22, Loss : 0.164553, Accuracy: 0.953000, Test accuracy: 0.949800
Distillation: Epoch : 23, Loss : 0.148442, Accuracy: 0.961000, Test accuracy: 0.951500
Distillation: Epoch : 24, Loss : 0.189488, Accuracy: 0.943000, Test accuracy: 0.952400
Distillation: Epoch : 25, Loss : 0.170199, Accuracy: 0.950000, Test accuracy: 0.952100
Distillation: Epoch : 26, Loss : 0.145323, Accuracy: 0.955000, Test accuracy: 0.952200
Distillation: Epoch : 27, Loss : 0.159717, Accuracy: 0.952000, Test accuracy: 0.953000
Distillation: Epoch : 28, Loss : 0.160040, Accuracy: 0.956000, Test accuracy: 0.953500
Distillation: Epoch : 29, Loss : 0.157916, Accuracy: 0.945000, Test accuracy: 0.954400
Distillation: Epoch : 30, Loss : 0.129584, Accuracy: 0.958000, Test accuracy: 0.954400
Distillation: Epoch : 31, Loss : 0.153628, Accuracy: 0.955000, Test accuracy: 0.955500
Distillation: Epoch : 32, Loss : 0.159557, Accuracy: 0.954000, Test accuracy: 0.956000
Distillation: Epoch : 33, Loss : 0.196227, Accuracy: 0.943000, Test accuracy: 0.956200
Distillation: Epoch : 34, Loss : 0.126472, Accuracy: 0.966000, Test accuracy: 0.957400
Distillation: Epoch : 35, Loss : 0.141791, Accuracy: 0.958000, Test accuracy: 0.956200
Distillation: Epoch : 36, Loss : 0.112103, Accuracy: 0.968000, Test accuracy: 0.957300
Distillation: Epoch : 37, Loss : 0.153757, Accuracy: 0.948000, Test accuracy: 0.957900
Distillation: Epoch : 38, Loss : 0.160563, Accuracy: 0.953000, Test accuracy: 0.957400
Distillation: Epoch : 39, Loss : 0.133093, Accuracy: 0.963000, Test accuracy: 0.957900
Distillation: Epoch : 40, Loss : 0.147965, Accuracy: 0.951000, Test accuracy: 0.957800
Distillation: Epoch : 41, Loss : 0.125405, Accuracy: 0.958000, Test accuracy: 0.959000
Distillation: Epoch : 42, Loss : 0.117690, Accuracy: 0.962000, Test accuracy: 0.959700
Distillation: Epoch : 43, Loss : 0.146133, Accuracy: 0.955000, Test accuracy: 0.959100
Distillation: Epoch : 44, Loss : 0.157027, Accuracy: 0.952000, Test accuracy: 0.959200
Distillation: Epoch : 45, Loss : 0.131192, Accuracy: 0.960000, Test accuracy: 0.959200
Distillation: Epoch : 46, Loss : 0.164551, Accuracy: 0.948000, Test accuracy: 0.959300
Distillation: Epoch : 47, Loss : 0.126458, Accuracy: 0.966000, Test accuracy: 0.959100
Distillation: Epoch : 48, Loss : 0.136096, Accuracy: 0.964000, Test accuracy: 0.959600
Distillation: Epoch : 49, Loss : 0.138810, Accuracy: 0.959000, Test accuracy: 0.960000
Distillation: Epoch : 50, Loss : 0.175995, Accuracy: 0.943000, Test accuracy: 0.959900
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9599
Generating confusion matrix for student3
[[ 971.    0.    4.    3.    1.    3.   13.    1.    7.    8.]
 [   0. 1114.    4.    0.    3.    2.    4.    6.    2.    7.]
 [   1.    4.  988.    9.    5.    1.    4.   22.   11.    2.]
 [   0.    1.    6.  975.    0.   20.    0.    7.   16.   11.]
 [   1.    0.    3.    0.  955.    0.    3.    2.    7.    8.]
 [   1.    0.    1.    3.    0.  837.    8.    0.    6.    5.]
 [   1.    3.    2.    0.    0.    7.  922.    0.    2.    0.]
 [   3.    1.    6.    6.    1.    2.    1.  969.    4.   11.]
 [   2.   12.   16.   11.    4.   17.    3.    2.  914.    3.]
 [   0.    0.    2.    3.   13.    3.    0.   19.    5.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.161517, Accuracy: 0.779000, Test accuracy: 0.785200
Distillation: Epoch : 2, Loss : 0.644328, Accuracy: 0.838000, Test accuracy: 0.853600
Distillation: Epoch : 3, Loss : 0.444634, Accuracy: 0.890000, Test accuracy: 0.877600
Distillation: Epoch : 4, Loss : 0.462001, Accuracy: 0.873000, Test accuracy: 0.889400
Distillation: Epoch : 5, Loss : 0.359290, Accuracy: 0.907000, Test accuracy: 0.895700
Distillation: Epoch : 6, Loss : 0.355332, Accuracy: 0.908000, Test accuracy: 0.900700
Distillation: Epoch : 7, Loss : 0.316162, Accuracy: 0.911000, Test accuracy: 0.907200
Distillation: Epoch : 8, Loss : 0.345765, Accuracy: 0.902000, Test accuracy: 0.908700
Distillation: Epoch : 9, Loss : 0.340768, Accuracy: 0.907000, Test accuracy: 0.909900
Distillation: Epoch : 10, Loss : 0.309715, Accuracy: 0.911000, Test accuracy: 0.912300
Distillation: Epoch : 11, Loss : 0.307751, Accuracy: 0.910000, Test accuracy: 0.913200
Distillation: Epoch : 12, Loss : 0.347069, Accuracy: 0.909000, Test accuracy: 0.914300
Distillation: Epoch : 13, Loss : 0.345234, Accuracy: 0.903000, Test accuracy: 0.915100
Distillation: Epoch : 14, Loss : 0.321398, Accuracy: 0.909000, Test accuracy: 0.916900
Distillation: Epoch : 15, Loss : 0.300026, Accuracy: 0.921000, Test accuracy: 0.917800
Distillation: Epoch : 16, Loss : 0.247669, Accuracy: 0.929000, Test accuracy: 0.918200
Distillation: Epoch : 17, Loss : 0.269262, Accuracy: 0.926000, Test accuracy: 0.920600
Distillation: Epoch : 18, Loss : 0.266502, Accuracy: 0.929000, Test accuracy: 0.920900
Distillation: Epoch : 19, Loss : 0.276218, Accuracy: 0.928000, Test accuracy: 0.921300
Distillation: Epoch : 20, Loss : 0.314946, Accuracy: 0.918000, Test accuracy: 0.923400
Distillation: Epoch : 21, Loss : 0.291243, Accuracy: 0.915000, Test accuracy: 0.924500
Distillation: Epoch : 22, Loss : 0.292621, Accuracy: 0.926000, Test accuracy: 0.924700
Distillation: Epoch : 23, Loss : 0.282091, Accuracy: 0.918000, Test accuracy: 0.925500
Distillation: Epoch : 24, Loss : 0.292907, Accuracy: 0.921000, Test accuracy: 0.926600
Distillation: Epoch : 25, Loss : 0.299724, Accuracy: 0.912000, Test accuracy: 0.929100
Distillation: Epoch : 26, Loss : 0.279317, Accuracy: 0.929000, Test accuracy: 0.929900
Distillation: Epoch : 27, Loss : 0.269237, Accuracy: 0.922000, Test accuracy: 0.930900
Distillation: Epoch : 28, Loss : 0.289737, Accuracy: 0.928000, Test accuracy: 0.932600
Distillation: Epoch : 29, Loss : 0.259323, Accuracy: 0.936000, Test accuracy: 0.932300
Distillation: Epoch : 30, Loss : 0.242470, Accuracy: 0.938000, Test accuracy: 0.933700
Distillation: Epoch : 31, Loss : 0.242178, Accuracy: 0.943000, Test accuracy: 0.935000
Distillation: Epoch : 32, Loss : 0.251729, Accuracy: 0.932000, Test accuracy: 0.937100
Distillation: Epoch : 33, Loss : 0.271859, Accuracy: 0.937000, Test accuracy: 0.936600
Distillation: Epoch : 34, Loss : 0.246911, Accuracy: 0.938000, Test accuracy: 0.939000
Distillation: Epoch : 35, Loss : 0.268252, Accuracy: 0.928000, Test accuracy: 0.940300
Distillation: Epoch : 36, Loss : 0.224942, Accuracy: 0.946000, Test accuracy: 0.941800
Distillation: Epoch : 37, Loss : 0.252624, Accuracy: 0.931000, Test accuracy: 0.943100
Distillation: Epoch : 38, Loss : 0.210458, Accuracy: 0.945000, Test accuracy: 0.943500
Distillation: Epoch : 39, Loss : 0.229640, Accuracy: 0.942000, Test accuracy: 0.944900
Distillation: Epoch : 40, Loss : 0.231227, Accuracy: 0.936000, Test accuracy: 0.946000
Distillation: Epoch : 41, Loss : 0.225366, Accuracy: 0.938000, Test accuracy: 0.946900
Distillation: Epoch : 42, Loss : 0.183293, Accuracy: 0.956000, Test accuracy: 0.947300
Distillation: Epoch : 43, Loss : 0.198682, Accuracy: 0.957000, Test accuracy: 0.948500
Distillation: Epoch : 44, Loss : 0.218503, Accuracy: 0.941000, Test accuracy: 0.949700
Distillation: Epoch : 45, Loss : 0.233074, Accuracy: 0.944000, Test accuracy: 0.949400
Distillation: Epoch : 46, Loss : 0.208092, Accuracy: 0.949000, Test accuracy: 0.950500
Distillation: Epoch : 47, Loss : 0.207174, Accuracy: 0.944000, Test accuracy: 0.951700
Distillation: Epoch : 48, Loss : 0.188618, Accuracy: 0.959000, Test accuracy: 0.952100
Distillation: Epoch : 49, Loss : 0.195065, Accuracy: 0.945000, Test accuracy: 0.953800
Distillation: Epoch : 50, Loss : 0.207837, Accuracy: 0.945000, Test accuracy: 0.953000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.953
Generating confusion matrix for student3
[[ 967.    0.    8.    0.    1.    5.   11.    1.    7.   11.]
 [   0. 1123.    8.    0.    2.    2.    3.    3.    3.    5.]
 [   2.    3.  962.    7.    3.    0.    1.   22.    7.    1.]
 [   1.    0.   10.  968.    0.   13.    1.    7.   15.    8.]
 [   1.    0.    4.    0.  944.    1.    6.    1.    5.   10.]
 [   4.    2.    0.    6.    0.  836.    7.    1.   15.    8.]
 [   2.    3.    5.    0.    5.    7.  925.    0.    4.    0.]
 [   2.    0.   10.    6.    3.    2.    0.  963.   12.   14.]
 [   1.    4.   20.   20.    4.   19.    4.    1.  898.    8.]
 [   0.    0.    5.    3.   20.    7.    0.   29.    8.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.917041, Accuracy: 0.742000, Test accuracy: 0.752200
Distillation: Epoch : 2, Loss : 1.137649, Accuracy: 0.823000, Test accuracy: 0.828900
Distillation: Epoch : 3, Loss : 0.840344, Accuracy: 0.857000, Test accuracy: 0.858300
Distillation: Epoch : 4, Loss : 0.785021, Accuracy: 0.862000, Test accuracy: 0.877700
Distillation: Epoch : 5, Loss : 0.721220, Accuracy: 0.893000, Test accuracy: 0.890300
Distillation: Epoch : 6, Loss : 0.748795, Accuracy: 0.864000, Test accuracy: 0.898400
Distillation: Epoch : 7, Loss : 0.720932, Accuracy: 0.869000, Test accuracy: 0.902200
Distillation: Epoch : 8, Loss : 0.692964, Accuracy: 0.887000, Test accuracy: 0.905300
Distillation: Epoch : 9, Loss : 0.656864, Accuracy: 0.909000, Test accuracy: 0.908500
Distillation: Epoch : 10, Loss : 0.682056, Accuracy: 0.886000, Test accuracy: 0.912000
Distillation: Epoch : 11, Loss : 0.640995, Accuracy: 0.897000, Test accuracy: 0.913600
Distillation: Epoch : 12, Loss : 0.661740, Accuracy: 0.911000, Test accuracy: 0.914900
Distillation: Epoch : 13, Loss : 0.645752, Accuracy: 0.911000, Test accuracy: 0.917800
Distillation: Epoch : 14, Loss : 0.612861, Accuracy: 0.917000, Test accuracy: 0.918700
Distillation: Epoch : 15, Loss : 0.632865, Accuracy: 0.916000, Test accuracy: 0.921300
Distillation: Epoch : 16, Loss : 0.640328, Accuracy: 0.906000, Test accuracy: 0.922200
Distillation: Epoch : 17, Loss : 0.684871, Accuracy: 0.902000, Test accuracy: 0.922800
Distillation: Epoch : 18, Loss : 0.608995, Accuracy: 0.926000, Test accuracy: 0.924400
Distillation: Epoch : 19, Loss : 0.596276, Accuracy: 0.918000, Test accuracy: 0.925000
Distillation: Epoch : 20, Loss : 0.614386, Accuracy: 0.910000, Test accuracy: 0.925900
Distillation: Epoch : 21, Loss : 0.593322, Accuracy: 0.924000, Test accuracy: 0.926900
Distillation: Epoch : 22, Loss : 0.582099, Accuracy: 0.930000, Test accuracy: 0.929300
Distillation: Epoch : 23, Loss : 0.584086, Accuracy: 0.920000, Test accuracy: 0.929500
Distillation: Epoch : 24, Loss : 0.609466, Accuracy: 0.924000, Test accuracy: 0.931900
Distillation: Epoch : 25, Loss : 0.602289, Accuracy: 0.934000, Test accuracy: 0.932400
Distillation: Epoch : 26, Loss : 0.574190, Accuracy: 0.934000, Test accuracy: 0.933800
Distillation: Epoch : 27, Loss : 0.576519, Accuracy: 0.923000, Test accuracy: 0.935300
Distillation: Epoch : 28, Loss : 0.582723, Accuracy: 0.932000, Test accuracy: 0.935700
Distillation: Epoch : 29, Loss : 0.595752, Accuracy: 0.918000, Test accuracy: 0.936400
Distillation: Epoch : 30, Loss : 0.551655, Accuracy: 0.938000, Test accuracy: 0.938700
Distillation: Epoch : 31, Loss : 0.552705, Accuracy: 0.939000, Test accuracy: 0.939900
Distillation: Epoch : 32, Loss : 0.586306, Accuracy: 0.925000, Test accuracy: 0.939700
Distillation: Epoch : 33, Loss : 0.563774, Accuracy: 0.938000, Test accuracy: 0.942600
Distillation: Epoch : 34, Loss : 0.545661, Accuracy: 0.938000, Test accuracy: 0.942800
Distillation: Epoch : 35, Loss : 0.539200, Accuracy: 0.946000, Test accuracy: 0.945100
Distillation: Epoch : 36, Loss : 0.535001, Accuracy: 0.945000, Test accuracy: 0.946900
Distillation: Epoch : 37, Loss : 0.564211, Accuracy: 0.936000, Test accuracy: 0.948000
Distillation: Epoch : 38, Loss : 0.533035, Accuracy: 0.943000, Test accuracy: 0.948300
Distillation: Epoch : 39, Loss : 0.536075, Accuracy: 0.945000, Test accuracy: 0.948700
Distillation: Epoch : 40, Loss : 0.520252, Accuracy: 0.949000, Test accuracy: 0.950300
Distillation: Epoch : 41, Loss : 0.545813, Accuracy: 0.945000, Test accuracy: 0.952200
Distillation: Epoch : 42, Loss : 0.533584, Accuracy: 0.943000, Test accuracy: 0.952300
Distillation: Epoch : 43, Loss : 0.511354, Accuracy: 0.952000, Test accuracy: 0.952700
Distillation: Epoch : 44, Loss : 0.531534, Accuracy: 0.953000, Test accuracy: 0.953700
Distillation: Epoch : 45, Loss : 0.507963, Accuracy: 0.955000, Test accuracy: 0.954500
Distillation: Epoch : 46, Loss : 0.514665, Accuracy: 0.959000, Test accuracy: 0.955400
Distillation: Epoch : 47, Loss : 0.529895, Accuracy: 0.941000, Test accuracy: 0.955800
Distillation: Epoch : 48, Loss : 0.550141, Accuracy: 0.944000, Test accuracy: 0.956800
Distillation: Epoch : 49, Loss : 0.501936, Accuracy: 0.957000, Test accuracy: 0.957100
Distillation: Epoch : 50, Loss : 0.541251, Accuracy: 0.948000, Test accuracy: 0.957400
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9574
Generating confusion matrix for student3
[[ 970.    0.    6.    2.    1.    5.    7.    0.    6.    6.]
 [   1. 1119.    6.    0.    1.    2.    5.    6.    4.    6.]
 [   1.    3.  971.    8.    2.    1.    0.   19.    6.    2.]
 [   0.    1.    8.  956.    0.    7.    1.    2.    8.    2.]
 [   0.    0.    6.    0.  955.    0.    7.    3.    7.   20.]
 [   2.    0.    0.   25.    0.  853.    7.    0.   13.    3.]
 [   2.    4.    6.    0.    5.    8.  925.    0.    7.    0.]
 [   2.    1.    9.    5.    2.    4.    0.  978.    9.   23.]
 [   2.    7.   17.   11.    5.    6.    6.    2.  906.    6.]
 [   0.    0.    3.    3.   11.    6.    0.   18.    8.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.873468, Accuracy: 0.755000, Test accuracy: 0.744400
Distillation: Epoch : 2, Loss : 1.276619, Accuracy: 0.794000, Test accuracy: 0.812200
Distillation: Epoch : 3, Loss : 1.055019, Accuracy: 0.835000, Test accuracy: 0.849200
Distillation: Epoch : 4, Loss : 0.974770, Accuracy: 0.840000, Test accuracy: 0.870800
Distillation: Epoch : 5, Loss : 0.921708, Accuracy: 0.877000, Test accuracy: 0.884600
Distillation: Epoch : 6, Loss : 0.862922, Accuracy: 0.888000, Test accuracy: 0.893100
Distillation: Epoch : 7, Loss : 0.835704, Accuracy: 0.913000, Test accuracy: 0.901000
Distillation: Epoch : 8, Loss : 0.833709, Accuracy: 0.901000, Test accuracy: 0.906200
Distillation: Epoch : 9, Loss : 0.838701, Accuracy: 0.891000, Test accuracy: 0.910000
Distillation: Epoch : 10, Loss : 0.799133, Accuracy: 0.909000, Test accuracy: 0.912900
Distillation: Epoch : 11, Loss : 0.803284, Accuracy: 0.905000, Test accuracy: 0.916500
Distillation: Epoch : 12, Loss : 0.766895, Accuracy: 0.924000, Test accuracy: 0.921000
Distillation: Epoch : 13, Loss : 0.780954, Accuracy: 0.908000, Test accuracy: 0.922400
Distillation: Epoch : 14, Loss : 0.779393, Accuracy: 0.916000, Test accuracy: 0.924700
Distillation: Epoch : 15, Loss : 0.744966, Accuracy: 0.924000, Test accuracy: 0.926800
Distillation: Epoch : 16, Loss : 0.763524, Accuracy: 0.927000, Test accuracy: 0.929600
Distillation: Epoch : 17, Loss : 0.761418, Accuracy: 0.927000, Test accuracy: 0.932800
Distillation: Epoch : 18, Loss : 0.743536, Accuracy: 0.931000, Test accuracy: 0.935200
Distillation: Epoch : 19, Loss : 0.736309, Accuracy: 0.928000, Test accuracy: 0.937100
Distillation: Epoch : 20, Loss : 0.732447, Accuracy: 0.933000, Test accuracy: 0.938600
Distillation: Epoch : 21, Loss : 0.704042, Accuracy: 0.950000, Test accuracy: 0.938800
Distillation: Epoch : 22, Loss : 0.721233, Accuracy: 0.930000, Test accuracy: 0.941100
Distillation: Epoch : 23, Loss : 0.769751, Accuracy: 0.927000, Test accuracy: 0.942300
Distillation: Epoch : 24, Loss : 0.710151, Accuracy: 0.943000, Test accuracy: 0.942600
Distillation: Epoch : 25, Loss : 0.714715, Accuracy: 0.940000, Test accuracy: 0.943900
Distillation: Epoch : 26, Loss : 0.729884, Accuracy: 0.928000, Test accuracy: 0.945000
Distillation: Epoch : 27, Loss : 0.719089, Accuracy: 0.934000, Test accuracy: 0.946100
Distillation: Epoch : 28, Loss : 0.706351, Accuracy: 0.940000, Test accuracy: 0.947000
Distillation: Epoch : 29, Loss : 0.705627, Accuracy: 0.948000, Test accuracy: 0.947200
Distillation: Epoch : 30, Loss : 0.754206, Accuracy: 0.918000, Test accuracy: 0.948300
Distillation: Epoch : 31, Loss : 0.742773, Accuracy: 0.933000, Test accuracy: 0.948900
Distillation: Epoch : 32, Loss : 0.698907, Accuracy: 0.965000, Test accuracy: 0.949800
Distillation: Epoch : 33, Loss : 0.674608, Accuracy: 0.954000, Test accuracy: 0.950600
Distillation: Epoch : 34, Loss : 0.703617, Accuracy: 0.955000, Test accuracy: 0.951900
Distillation: Epoch : 35, Loss : 0.722311, Accuracy: 0.940000, Test accuracy: 0.952200
Distillation: Epoch : 36, Loss : 0.695783, Accuracy: 0.942000, Test accuracy: 0.953100
Distillation: Epoch : 37, Loss : 0.703014, Accuracy: 0.947000, Test accuracy: 0.953700
Distillation: Epoch : 38, Loss : 0.706074, Accuracy: 0.940000, Test accuracy: 0.953700
Distillation: Epoch : 39, Loss : 0.721648, Accuracy: 0.946000, Test accuracy: 0.953600
Distillation: Epoch : 40, Loss : 0.681086, Accuracy: 0.957000, Test accuracy: 0.954100
Distillation: Epoch : 41, Loss : 0.694213, Accuracy: 0.949000, Test accuracy: 0.954300
Distillation: Epoch : 42, Loss : 0.708770, Accuracy: 0.946000, Test accuracy: 0.956200
Distillation: Epoch : 43, Loss : 0.680885, Accuracy: 0.953000, Test accuracy: 0.955600
Distillation: Epoch : 44, Loss : 0.681996, Accuracy: 0.955000, Test accuracy: 0.956200
Distillation: Epoch : 45, Loss : 0.702378, Accuracy: 0.946000, Test accuracy: 0.955900
Distillation: Epoch : 46, Loss : 0.694579, Accuracy: 0.954000, Test accuracy: 0.956100
Distillation: Epoch : 47, Loss : 0.684084, Accuracy: 0.954000, Test accuracy: 0.956700
Distillation: Epoch : 48, Loss : 0.703205, Accuracy: 0.945000, Test accuracy: 0.956700
Distillation: Epoch : 49, Loss : 0.696909, Accuracy: 0.956000, Test accuracy: 0.956900
Distillation: Epoch : 50, Loss : 0.641074, Accuracy: 0.962000, Test accuracy: 0.957400
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9574
Generating confusion matrix for student3
[[ 965.    0.    5.    2.    0.    3.    9.    0.    7.    6.]
 [   1. 1113.    9.    0.    2.    1.    3.    8.    3.    7.]
 [   1.    3.  961.    5.    2.    0.    3.   15.   11.    1.]
 [   0.    0.    8.  960.    1.    9.    0.    2.    4.    4.]
 [   3.    0.    7.    1.  955.    0.    6.    4.    7.    9.]
 [   1.    2.    0.   20.    0.  853.   10.    0.   10.    8.]
 [   6.    5.    5.    0.    1.    7.  921.    0.    3.    0.]
 [   2.    0.    9.    7.    1.    2.    0.  981.    8.   17.]
 [   1.   12.   26.   11.    3.   12.    6.    3.  916.    8.]
 [   0.    0.    2.    4.   17.    5.    0.   15.    5.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.790356, Accuracy: 0.780000, Test accuracy: 0.774700
Distillation: Epoch : 2, Loss : 1.300522, Accuracy: 0.804000, Test accuracy: 0.823200
Distillation: Epoch : 3, Loss : 1.139519, Accuracy: 0.845000, Test accuracy: 0.856000
Distillation: Epoch : 4, Loss : 1.096198, Accuracy: 0.860000, Test accuracy: 0.874000
Distillation: Epoch : 5, Loss : 1.097910, Accuracy: 0.855000, Test accuracy: 0.882800
Distillation: Epoch : 6, Loss : 1.041905, Accuracy: 0.883000, Test accuracy: 0.890000
Distillation: Epoch : 7, Loss : 1.062815, Accuracy: 0.883000, Test accuracy: 0.893400
Distillation: Epoch : 8, Loss : 1.061849, Accuracy: 0.883000, Test accuracy: 0.895800
Distillation: Epoch : 9, Loss : 1.018761, Accuracy: 0.901000, Test accuracy: 0.898800
Distillation: Epoch : 10, Loss : 1.022177, Accuracy: 0.879000, Test accuracy: 0.899700
Distillation: Epoch : 11, Loss : 1.024879, Accuracy: 0.891000, Test accuracy: 0.901600
Distillation: Epoch : 12, Loss : 0.990244, Accuracy: 0.909000, Test accuracy: 0.904100
Distillation: Epoch : 13, Loss : 1.003350, Accuracy: 0.903000, Test accuracy: 0.906100
Distillation: Epoch : 14, Loss : 0.975931, Accuracy: 0.907000, Test accuracy: 0.907700
Distillation: Epoch : 15, Loss : 0.968636, Accuracy: 0.925000, Test accuracy: 0.909800
Distillation: Epoch : 16, Loss : 0.981425, Accuracy: 0.913000, Test accuracy: 0.911300
Distillation: Epoch : 17, Loss : 0.993253, Accuracy: 0.899000, Test accuracy: 0.913200
Distillation: Epoch : 18, Loss : 0.989565, Accuracy: 0.903000, Test accuracy: 0.914500
Distillation: Epoch : 19, Loss : 0.958175, Accuracy: 0.913000, Test accuracy: 0.915700
Distillation: Epoch : 20, Loss : 0.985578, Accuracy: 0.906000, Test accuracy: 0.917400
Distillation: Epoch : 21, Loss : 0.972558, Accuracy: 0.907000, Test accuracy: 0.917700
Distillation: Epoch : 22, Loss : 0.971113, Accuracy: 0.917000, Test accuracy: 0.920600
Distillation: Epoch : 23, Loss : 0.928413, Accuracy: 0.930000, Test accuracy: 0.922100
Distillation: Epoch : 24, Loss : 0.921908, Accuracy: 0.936000, Test accuracy: 0.923000
Distillation: Epoch : 25, Loss : 0.946038, Accuracy: 0.923000, Test accuracy: 0.925300
Distillation: Epoch : 26, Loss : 0.942524, Accuracy: 0.928000, Test accuracy: 0.927300
Distillation: Epoch : 27, Loss : 0.918431, Accuracy: 0.933000, Test accuracy: 0.928400
Distillation: Epoch : 28, Loss : 0.930976, Accuracy: 0.932000, Test accuracy: 0.930700
Distillation: Epoch : 29, Loss : 0.947654, Accuracy: 0.923000, Test accuracy: 0.933600
Distillation: Epoch : 30, Loss : 0.941103, Accuracy: 0.933000, Test accuracy: 0.934800
Distillation: Epoch : 31, Loss : 0.913440, Accuracy: 0.934000, Test accuracy: 0.936100
Distillation: Epoch : 32, Loss : 0.944794, Accuracy: 0.935000, Test accuracy: 0.937500
Distillation: Epoch : 33, Loss : 0.903647, Accuracy: 0.940000, Test accuracy: 0.939100
Distillation: Epoch : 34, Loss : 0.913595, Accuracy: 0.932000, Test accuracy: 0.940200
Distillation: Epoch : 35, Loss : 0.904108, Accuracy: 0.938000, Test accuracy: 0.941600
Distillation: Epoch : 36, Loss : 0.893375, Accuracy: 0.939000, Test accuracy: 0.942300
Distillation: Epoch : 37, Loss : 0.870635, Accuracy: 0.935000, Test accuracy: 0.943900
Distillation: Epoch : 38, Loss : 0.909751, Accuracy: 0.931000, Test accuracy: 0.944100
Distillation: Epoch : 39, Loss : 0.890091, Accuracy: 0.937000, Test accuracy: 0.944600
Distillation: Epoch : 40, Loss : 0.900540, Accuracy: 0.940000, Test accuracy: 0.946800
Distillation: Epoch : 41, Loss : 0.888481, Accuracy: 0.943000, Test accuracy: 0.947600
Distillation: Epoch : 42, Loss : 0.886418, Accuracy: 0.942000, Test accuracy: 0.947900
Distillation: Epoch : 43, Loss : 0.881176, Accuracy: 0.941000, Test accuracy: 0.948300
Distillation: Epoch : 44, Loss : 0.911992, Accuracy: 0.931000, Test accuracy: 0.948600
Distillation: Epoch : 45, Loss : 0.869704, Accuracy: 0.951000, Test accuracy: 0.949100
Distillation: Epoch : 46, Loss : 0.905137, Accuracy: 0.942000, Test accuracy: 0.949900
Distillation: Epoch : 47, Loss : 0.909918, Accuracy: 0.933000, Test accuracy: 0.950600
Distillation: Epoch : 48, Loss : 0.879741, Accuracy: 0.946000, Test accuracy: 0.950700
Distillation: Epoch : 49, Loss : 0.881004, Accuracy: 0.949000, Test accuracy: 0.951200
Distillation: Epoch : 50, Loss : 0.898721, Accuracy: 0.940000, Test accuracy: 0.951800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9518
Generating confusion matrix for student3
[[ 960.    0.    3.    0.    1.    0.    6.    1.    6.    7.]
 [   2. 1124.    8.    4.    2.    1.    3.   10.    7.    7.]
 [   0.    2.  954.    9.    4.    0.    1.   19.    9.    1.]
 [   0.    1.    4.  948.    0.    6.    0.    3.   10.    6.]
 [   3.    2.   12.    4.  953.    0.    9.    7.    9.   23.]
 [   3.    0.    3.   15.    0.  861.   19.    2.   11.   10.]
 [   7.    2.    3.    0.    5.    3.  919.    0.    2.    0.]
 [   2.    0.   10.    6.    1.    2.    0.  958.    9.    9.]
 [   3.    4.   34.   18.    2.   13.    1.    4.  899.    4.]
 [   0.    0.    1.    6.   14.    6.    0.   24.   12.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.851522, Accuracy: 0.718000, Test accuracy: 0.757800
Distillation: Epoch : 2, Loss : 1.410851, Accuracy: 0.813000, Test accuracy: 0.816500
Distillation: Epoch : 3, Loss : 1.342336, Accuracy: 0.829000, Test accuracy: 0.856100
Distillation: Epoch : 4, Loss : 1.283880, Accuracy: 0.864000, Test accuracy: 0.869900
Distillation: Epoch : 5, Loss : 1.270573, Accuracy: 0.852000, Test accuracy: 0.876800
Distillation: Epoch : 6, Loss : 1.235524, Accuracy: 0.856000, Test accuracy: 0.883400
Distillation: Epoch : 7, Loss : 1.192491, Accuracy: 0.884000, Test accuracy: 0.888100
Distillation: Epoch : 8, Loss : 1.233992, Accuracy: 0.891000, Test accuracy: 0.888500
Distillation: Epoch : 9, Loss : 1.205097, Accuracy: 0.876000, Test accuracy: 0.892100
Distillation: Epoch : 10, Loss : 1.182305, Accuracy: 0.910000, Test accuracy: 0.893700
Distillation: Epoch : 11, Loss : 1.206135, Accuracy: 0.887000, Test accuracy: 0.894500
Distillation: Epoch : 12, Loss : 1.185516, Accuracy: 0.892000, Test accuracy: 0.894800
Distillation: Epoch : 13, Loss : 1.198764, Accuracy: 0.888000, Test accuracy: 0.895800
Distillation: Epoch : 14, Loss : 1.168534, Accuracy: 0.888000, Test accuracy: 0.898300
Distillation: Epoch : 15, Loss : 1.181714, Accuracy: 0.886000, Test accuracy: 0.900400
Distillation: Epoch : 16, Loss : 1.178659, Accuracy: 0.892000, Test accuracy: 0.901000
Distillation: Epoch : 17, Loss : 1.168342, Accuracy: 0.884000, Test accuracy: 0.902100
Distillation: Epoch : 18, Loss : 1.131955, Accuracy: 0.905000, Test accuracy: 0.902000
Distillation: Epoch : 19, Loss : 1.142704, Accuracy: 0.916000, Test accuracy: 0.903300
Distillation: Epoch : 20, Loss : 1.174285, Accuracy: 0.896000, Test accuracy: 0.902900
Distillation: Epoch : 21, Loss : 1.156095, Accuracy: 0.898000, Test accuracy: 0.905200
Distillation: Epoch : 22, Loss : 1.158885, Accuracy: 0.903000, Test accuracy: 0.906300
Distillation: Epoch : 23, Loss : 1.161444, Accuracy: 0.893000, Test accuracy: 0.905300
Distillation: Epoch : 24, Loss : 1.161617, Accuracy: 0.910000, Test accuracy: 0.906000
Distillation: Epoch : 25, Loss : 1.152661, Accuracy: 0.905000, Test accuracy: 0.908700
Distillation: Epoch : 26, Loss : 1.145712, Accuracy: 0.899000, Test accuracy: 0.908600
Distillation: Epoch : 27, Loss : 1.154054, Accuracy: 0.882000, Test accuracy: 0.909100
Distillation: Epoch : 28, Loss : 1.160157, Accuracy: 0.904000, Test accuracy: 0.909000
Distillation: Epoch : 29, Loss : 1.132799, Accuracy: 0.915000, Test accuracy: 0.909600
Distillation: Epoch : 30, Loss : 1.142772, Accuracy: 0.896000, Test accuracy: 0.912100
Distillation: Epoch : 31, Loss : 1.152256, Accuracy: 0.900000, Test accuracy: 0.911500
Distillation: Epoch : 32, Loss : 1.149265, Accuracy: 0.898000, Test accuracy: 0.910900
Distillation: Epoch : 33, Loss : 1.113755, Accuracy: 0.912000, Test accuracy: 0.912600
Distillation: Epoch : 34, Loss : 1.128393, Accuracy: 0.906000, Test accuracy: 0.917000
Distillation: Epoch : 35, Loss : 1.145501, Accuracy: 0.918000, Test accuracy: 0.917100
Distillation: Epoch : 36, Loss : 1.127891, Accuracy: 0.918000, Test accuracy: 0.916700
Distillation: Epoch : 37, Loss : 1.124549, Accuracy: 0.933000, Test accuracy: 0.919700
Distillation: Epoch : 38, Loss : 1.108903, Accuracy: 0.912000, Test accuracy: 0.919700
Distillation: Epoch : 39, Loss : 1.122925, Accuracy: 0.920000, Test accuracy: 0.920500
Distillation: Epoch : 40, Loss : 1.115219, Accuracy: 0.921000, Test accuracy: 0.921000
Distillation: Epoch : 41, Loss : 1.094607, Accuracy: 0.929000, Test accuracy: 0.922800
Distillation: Epoch : 42, Loss : 1.147905, Accuracy: 0.920000, Test accuracy: 0.923500
Distillation: Epoch : 43, Loss : 1.122668, Accuracy: 0.915000, Test accuracy: 0.925600
Distillation: Epoch : 44, Loss : 1.107948, Accuracy: 0.922000, Test accuracy: 0.925900
Distillation: Epoch : 45, Loss : 1.124035, Accuracy: 0.913000, Test accuracy: 0.927900
Distillation: Epoch : 46, Loss : 1.095477, Accuracy: 0.923000, Test accuracy: 0.928700
Distillation: Epoch : 47, Loss : 1.118249, Accuracy: 0.922000, Test accuracy: 0.930900
Distillation: Epoch : 48, Loss : 1.110135, Accuracy: 0.916000, Test accuracy: 0.930100
Distillation: Epoch : 49, Loss : 1.077737, Accuracy: 0.927000, Test accuracy: 0.932000
Distillation: Epoch : 50, Loss : 1.093491, Accuracy: 0.922000, Test accuracy: 0.931900
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9319
Generating confusion matrix for student3
[[ 948.    0.    8.    6.    0.    5.    4.    0.    5.    7.]
 [   1. 1110.   15.    2.    1.    3.    3.   19.    7.    5.]
 [   1.    2.  921.   16.    7.    0.    2.   17.    7.    2.]
 [   4.    2.   10.  924.    0.    8.    2.    2.    9.   10.]
 [   4.    1.   19.    3.  934.    5.   13.   15.   15.   43.]
 [   5.    3.    1.   32.    0.  838.   19.    1.   25.    8.]
 [  10.    4.    5.    3.    6.   10.  913.    0.    7.    0.]
 [   1.    1.   18.   10.    1.    3.    0.  939.    5.   21.]
 [   4.   12.   30.   12.    8.   17.    2.    0.  884.    5.]
 [   2.    0.    5.    2.   25.    3.    0.   35.   10.  908.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.914875, Accuracy: 0.732000, Test accuracy: 0.743400
Distillation: Epoch : 2, Loss : 1.539950, Accuracy: 0.806000, Test accuracy: 0.815900
Distillation: Epoch : 3, Loss : 1.463745, Accuracy: 0.830000, Test accuracy: 0.850600
Distillation: Epoch : 4, Loss : 1.380943, Accuracy: 0.882000, Test accuracy: 0.867400
Distillation: Epoch : 5, Loss : 1.378213, Accuracy: 0.857000, Test accuracy: 0.877100
Distillation: Epoch : 6, Loss : 1.386058, Accuracy: 0.865000, Test accuracy: 0.881800
Distillation: Epoch : 7, Loss : 1.347448, Accuracy: 0.889000, Test accuracy: 0.886300
Distillation: Epoch : 8, Loss : 1.349672, Accuracy: 0.884000, Test accuracy: 0.890500
Distillation: Epoch : 9, Loss : 1.328227, Accuracy: 0.886000, Test accuracy: 0.893500
Distillation: Epoch : 10, Loss : 1.332117, Accuracy: 0.903000, Test accuracy: 0.895000
Distillation: Epoch : 11, Loss : 1.336219, Accuracy: 0.878000, Test accuracy: 0.896300
Distillation: Epoch : 12, Loss : 1.360052, Accuracy: 0.889000, Test accuracy: 0.897300
Distillation: Epoch : 13, Loss : 1.338866, Accuracy: 0.876000, Test accuracy: 0.899400
Distillation: Epoch : 14, Loss : 1.334051, Accuracy: 0.888000, Test accuracy: 0.902200
Distillation: Epoch : 15, Loss : 1.305000, Accuracy: 0.896000, Test accuracy: 0.902700
Distillation: Epoch : 16, Loss : 1.331840, Accuracy: 0.891000, Test accuracy: 0.904400
Distillation: Epoch : 17, Loss : 1.355778, Accuracy: 0.877000, Test accuracy: 0.905700
Distillation: Epoch : 18, Loss : 1.295005, Accuracy: 0.898000, Test accuracy: 0.906500
Distillation: Epoch : 19, Loss : 1.304865, Accuracy: 0.904000, Test accuracy: 0.907700
Distillation: Epoch : 20, Loss : 1.302498, Accuracy: 0.890000, Test accuracy: 0.907900
Distillation: Epoch : 21, Loss : 1.313950, Accuracy: 0.889000, Test accuracy: 0.908200
Distillation: Epoch : 22, Loss : 1.307994, Accuracy: 0.907000, Test accuracy: 0.909200
Distillation: Epoch : 23, Loss : 1.295575, Accuracy: 0.900000, Test accuracy: 0.911000
Distillation: Epoch : 24, Loss : 1.299832, Accuracy: 0.909000, Test accuracy: 0.912800
Distillation: Epoch : 25, Loss : 1.310939, Accuracy: 0.897000, Test accuracy: 0.913000
Distillation: Epoch : 26, Loss : 1.296358, Accuracy: 0.908000, Test accuracy: 0.914300
Distillation: Epoch : 27, Loss : 1.310956, Accuracy: 0.899000, Test accuracy: 0.914700
Distillation: Epoch : 28, Loss : 1.295861, Accuracy: 0.900000, Test accuracy: 0.915400
Distillation: Epoch : 29, Loss : 1.290740, Accuracy: 0.907000, Test accuracy: 0.916200
Distillation: Epoch : 30, Loss : 1.289271, Accuracy: 0.911000, Test accuracy: 0.916500
Distillation: Epoch : 31, Loss : 1.297855, Accuracy: 0.919000, Test accuracy: 0.917800
Distillation: Epoch : 32, Loss : 1.280043, Accuracy: 0.914000, Test accuracy: 0.916900
Distillation: Epoch : 33, Loss : 1.264325, Accuracy: 0.923000, Test accuracy: 0.920300
Distillation: Epoch : 34, Loss : 1.271543, Accuracy: 0.913000, Test accuracy: 0.920900
Distillation: Epoch : 35, Loss : 1.260315, Accuracy: 0.919000, Test accuracy: 0.920500
Distillation: Epoch : 36, Loss : 1.274708, Accuracy: 0.912000, Test accuracy: 0.923400
Distillation: Epoch : 37, Loss : 1.284675, Accuracy: 0.918000, Test accuracy: 0.924200
Distillation: Epoch : 38, Loss : 1.262519, Accuracy: 0.920000, Test accuracy: 0.924300
Distillation: Epoch : 39, Loss : 1.280376, Accuracy: 0.924000, Test accuracy: 0.926100
Distillation: Epoch : 40, Loss : 1.258411, Accuracy: 0.911000, Test accuracy: 0.926200
Distillation: Epoch : 41, Loss : 1.274389, Accuracy: 0.922000, Test accuracy: 0.927600
Distillation: Epoch : 42, Loss : 1.277787, Accuracy: 0.910000, Test accuracy: 0.928500
Distillation: Epoch : 43, Loss : 1.252578, Accuracy: 0.915000, Test accuracy: 0.928600
Distillation: Epoch : 44, Loss : 1.252868, Accuracy: 0.929000, Test accuracy: 0.928700
Distillation: Epoch : 45, Loss : 1.273305, Accuracy: 0.922000, Test accuracy: 0.930800
Distillation: Epoch : 46, Loss : 1.246763, Accuracy: 0.939000, Test accuracy: 0.929500
Distillation: Epoch : 47, Loss : 1.268957, Accuracy: 0.914000, Test accuracy: 0.931200
Distillation: Epoch : 48, Loss : 1.238553, Accuracy: 0.934000, Test accuracy: 0.932000
Distillation: Epoch : 49, Loss : 1.242264, Accuracy: 0.942000, Test accuracy: 0.934300
Distillation: Epoch : 50, Loss : 1.254311, Accuracy: 0.928000, Test accuracy: 0.934000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.934
Generating confusion matrix for student3
[[ 947.    0.    9.    2.    0.    8.    4.    0.    4.    7.]
 [   1. 1114.    8.    2.    2.    4.    4.   13.   10.    6.]
 [   3.    2.  930.   16.    4.    2.    1.   17.    5.    2.]
 [   1.    2.   16.  928.    0.    8.    0.    4.   11.    7.]
 [   2.    1.   19.    3.  934.    5.    9.   16.   14.   29.]
 [   7.    3.    0.   31.    1.  818.   21.    1.   28.   11.]
 [  11.    4.    2.    2.    6.   10.  917.    0.    4.    1.]
 [   2.    0.   15.   11.    1.    5.    0.  941.    5.   14.]
 [   3.    9.   27.   12.    7.   24.    2.    1.  883.    4.]
 [   3.    0.    6.    3.   27.    8.    0.   35.   10.  928.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.084071, Accuracy: 0.700000, Test accuracy: 0.702700
Distillation: Epoch : 2, Loss : 1.686637, Accuracy: 0.816000, Test accuracy: 0.819000
Distillation: Epoch : 3, Loss : 1.582732, Accuracy: 0.819000, Test accuracy: 0.853400
Distillation: Epoch : 4, Loss : 1.512599, Accuracy: 0.854000, Test accuracy: 0.876100
Distillation: Epoch : 5, Loss : 1.488565, Accuracy: 0.882000, Test accuracy: 0.885400
Distillation: Epoch : 6, Loss : 1.485486, Accuracy: 0.875000, Test accuracy: 0.894700
Distillation: Epoch : 7, Loss : 1.457242, Accuracy: 0.901000, Test accuracy: 0.900400
Distillation: Epoch : 8, Loss : 1.462095, Accuracy: 0.887000, Test accuracy: 0.904300
Distillation: Epoch : 9, Loss : 1.442982, Accuracy: 0.900000, Test accuracy: 0.908300
Distillation: Epoch : 10, Loss : 1.432288, Accuracy: 0.902000, Test accuracy: 0.912500
Distillation: Epoch : 11, Loss : 1.418918, Accuracy: 0.913000, Test accuracy: 0.915200
Distillation: Epoch : 12, Loss : 1.415484, Accuracy: 0.899000, Test accuracy: 0.916900
Distillation: Epoch : 13, Loss : 1.413030, Accuracy: 0.919000, Test accuracy: 0.919400
Distillation: Epoch : 14, Loss : 1.425788, Accuracy: 0.903000, Test accuracy: 0.922600
Distillation: Epoch : 15, Loss : 1.411526, Accuracy: 0.914000, Test accuracy: 0.925900
Distillation: Epoch : 16, Loss : 1.367587, Accuracy: 0.945000, Test accuracy: 0.928100
Distillation: Epoch : 17, Loss : 1.391373, Accuracy: 0.936000, Test accuracy: 0.929700
Distillation: Epoch : 18, Loss : 1.407019, Accuracy: 0.920000, Test accuracy: 0.931800
Distillation: Epoch : 19, Loss : 1.385667, Accuracy: 0.918000, Test accuracy: 0.932900
Distillation: Epoch : 20, Loss : 1.395531, Accuracy: 0.931000, Test accuracy: 0.934000
Distillation: Epoch : 21, Loss : 1.378911, Accuracy: 0.927000, Test accuracy: 0.934900
Distillation: Epoch : 22, Loss : 1.389777, Accuracy: 0.948000, Test accuracy: 0.935300
Distillation: Epoch : 23, Loss : 1.424499, Accuracy: 0.927000, Test accuracy: 0.936300
Distillation: Epoch : 24, Loss : 1.374673, Accuracy: 0.939000, Test accuracy: 0.938100
Distillation: Epoch : 25, Loss : 1.402315, Accuracy: 0.920000, Test accuracy: 0.938100
Distillation: Epoch : 26, Loss : 1.378016, Accuracy: 0.942000, Test accuracy: 0.939900
Distillation: Epoch : 27, Loss : 1.377715, Accuracy: 0.926000, Test accuracy: 0.940900
Distillation: Epoch : 28, Loss : 1.395535, Accuracy: 0.928000, Test accuracy: 0.942200
Distillation: Epoch : 29, Loss : 1.371588, Accuracy: 0.950000, Test accuracy: 0.941200
Distillation: Epoch : 30, Loss : 1.375478, Accuracy: 0.945000, Test accuracy: 0.943000
Distillation: Epoch : 31, Loss : 1.362949, Accuracy: 0.936000, Test accuracy: 0.943200
Distillation: Epoch : 32, Loss : 1.365538, Accuracy: 0.937000, Test accuracy: 0.943200
Distillation: Epoch : 33, Loss : 1.375980, Accuracy: 0.945000, Test accuracy: 0.943800
Distillation: Epoch : 34, Loss : 1.375591, Accuracy: 0.942000, Test accuracy: 0.944000
Distillation: Epoch : 35, Loss : 1.379975, Accuracy: 0.935000, Test accuracy: 0.945600
Distillation: Epoch : 36, Loss : 1.376446, Accuracy: 0.937000, Test accuracy: 0.945500
Distillation: Epoch : 37, Loss : 1.352968, Accuracy: 0.952000, Test accuracy: 0.945600
Distillation: Epoch : 38, Loss : 1.397764, Accuracy: 0.934000, Test accuracy: 0.946600
Distillation: Epoch : 39, Loss : 1.331355, Accuracy: 0.957000, Test accuracy: 0.947200
Distillation: Epoch : 40, Loss : 1.369233, Accuracy: 0.955000, Test accuracy: 0.948500
Distillation: Epoch : 41, Loss : 1.370288, Accuracy: 0.941000, Test accuracy: 0.947800
Distillation: Epoch : 42, Loss : 1.366395, Accuracy: 0.952000, Test accuracy: 0.948000
Distillation: Epoch : 43, Loss : 1.366053, Accuracy: 0.938000, Test accuracy: 0.948600
Distillation: Epoch : 44, Loss : 1.348432, Accuracy: 0.950000, Test accuracy: 0.948800
Distillation: Epoch : 45, Loss : 1.371804, Accuracy: 0.952000, Test accuracy: 0.948900
Distillation: Epoch : 46, Loss : 1.357368, Accuracy: 0.951000, Test accuracy: 0.949600
Distillation: Epoch : 47, Loss : 1.391428, Accuracy: 0.931000, Test accuracy: 0.949600
Distillation: Epoch : 48, Loss : 1.346858, Accuracy: 0.966000, Test accuracy: 0.949500
Distillation: Epoch : 49, Loss : 1.337988, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 50, Loss : 1.348817, Accuracy: 0.937000, Test accuracy: 0.949800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9498
Generating confusion matrix for student3
[[ 966.    0.    8.    3.    0.    2.    6.    1.    6.    5.]
 [   1. 1108.    9.    1.    0.    1.    4.    8.    4.    5.]
 [   1.    2.  943.   10.    3.    2.    3.   13.   12.    1.]
 [   0.    1.    8.  949.    0.    8.    0.    4.    3.    8.]
 [   1.    0.   10.    1.  945.    0.    6.    8.   10.   18.]
 [   2.    2.    1.   23.    1.  855.   15.    1.   17.   10.]
 [   5.    4.    3.    1.    3.    5.  920.    0.    4.    0.]
 [   1.    0.   15.    8.    2.    1.    0.  974.    6.   18.]
 [   3.   18.   33.   11.    6.   12.    4.    5.  902.    8.]
 [   0.    0.    2.    3.   22.    6.    0.   14.   10.  936.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.989431, Accuracy: 0.755000, Test accuracy: 0.757600
Distillation: Epoch : 2, Loss : 1.723634, Accuracy: 0.808000, Test accuracy: 0.818300
Distillation: Epoch : 3, Loss : 1.661927, Accuracy: 0.845000, Test accuracy: 0.853000
Distillation: Epoch : 4, Loss : 1.651113, Accuracy: 0.857000, Test accuracy: 0.864500
Distillation: Epoch : 5, Loss : 1.634957, Accuracy: 0.853000, Test accuracy: 0.868700
Distillation: Epoch : 6, Loss : 1.610504, Accuracy: 0.873000, Test accuracy: 0.872900
Distillation: Epoch : 7, Loss : 1.608814, Accuracy: 0.860000, Test accuracy: 0.880700
Distillation: Epoch : 8, Loss : 1.584839, Accuracy: 0.866000, Test accuracy: 0.883000
Distillation: Epoch : 9, Loss : 1.614129, Accuracy: 0.869000, Test accuracy: 0.885200
Distillation: Epoch : 10, Loss : 1.625838, Accuracy: 0.868000, Test accuracy: 0.887100
Distillation: Epoch : 11, Loss : 1.597045, Accuracy: 0.884000, Test accuracy: 0.888600
Distillation: Epoch : 12, Loss : 1.582083, Accuracy: 0.891000, Test accuracy: 0.890200
Distillation: Epoch : 13, Loss : 1.585235, Accuracy: 0.872000, Test accuracy: 0.890700
Distillation: Epoch : 14, Loss : 1.599907, Accuracy: 0.880000, Test accuracy: 0.892800
Distillation: Epoch : 15, Loss : 1.590277, Accuracy: 0.891000, Test accuracy: 0.893400
Distillation: Epoch : 16, Loss : 1.596791, Accuracy: 0.893000, Test accuracy: 0.894700
Distillation: Epoch : 17, Loss : 1.583732, Accuracy: 0.879000, Test accuracy: 0.894200
Distillation: Epoch : 18, Loss : 1.562845, Accuracy: 0.901000, Test accuracy: 0.897200
Distillation: Epoch : 19, Loss : 1.585076, Accuracy: 0.880000, Test accuracy: 0.898400
Distillation: Epoch : 20, Loss : 1.580243, Accuracy: 0.872000, Test accuracy: 0.898100
Distillation: Epoch : 21, Loss : 1.586179, Accuracy: 0.887000, Test accuracy: 0.898000
Distillation: Epoch : 22, Loss : 1.565862, Accuracy: 0.877000, Test accuracy: 0.899900
Distillation: Epoch : 23, Loss : 1.564267, Accuracy: 0.882000, Test accuracy: 0.899500
Distillation: Epoch : 24, Loss : 1.574316, Accuracy: 0.879000, Test accuracy: 0.901100
Distillation: Epoch : 25, Loss : 1.569986, Accuracy: 0.881000, Test accuracy: 0.900800
Distillation: Epoch : 26, Loss : 1.567959, Accuracy: 0.902000, Test accuracy: 0.901700
Distillation: Epoch : 27, Loss : 1.563851, Accuracy: 0.894000, Test accuracy: 0.902100
Distillation: Epoch : 28, Loss : 1.583143, Accuracy: 0.894000, Test accuracy: 0.903000
Distillation: Epoch : 29, Loss : 1.564882, Accuracy: 0.894000, Test accuracy: 0.902600
Distillation: Epoch : 30, Loss : 1.574105, Accuracy: 0.895000, Test accuracy: 0.904400
Distillation: Epoch : 31, Loss : 1.564015, Accuracy: 0.889000, Test accuracy: 0.903500
Distillation: Epoch : 32, Loss : 1.552701, Accuracy: 0.895000, Test accuracy: 0.904400
Distillation: Epoch : 33, Loss : 1.579010, Accuracy: 0.894000, Test accuracy: 0.904200
Distillation: Epoch : 34, Loss : 1.551783, Accuracy: 0.904000, Test accuracy: 0.904700
Distillation: Epoch : 35, Loss : 1.565461, Accuracy: 0.900000, Test accuracy: 0.905200
Distillation: Epoch : 36, Loss : 1.583443, Accuracy: 0.879000, Test accuracy: 0.905800
Distillation: Epoch : 37, Loss : 1.570911, Accuracy: 0.881000, Test accuracy: 0.907200
Distillation: Epoch : 38, Loss : 1.551122, Accuracy: 0.904000, Test accuracy: 0.907000
Distillation: Epoch : 39, Loss : 1.549970, Accuracy: 0.903000, Test accuracy: 0.908900
Distillation: Epoch : 40, Loss : 1.557201, Accuracy: 0.892000, Test accuracy: 0.911900
Distillation: Epoch : 41, Loss : 1.534051, Accuracy: 0.905000, Test accuracy: 0.911900
Distillation: Epoch : 42, Loss : 1.531717, Accuracy: 0.916000, Test accuracy: 0.912800
Distillation: Epoch : 43, Loss : 1.548548, Accuracy: 0.893000, Test accuracy: 0.914800
Distillation: Epoch : 44, Loss : 1.532726, Accuracy: 0.905000, Test accuracy: 0.916800
Distillation: Epoch : 45, Loss : 1.525755, Accuracy: 0.918000, Test accuracy: 0.916500
Distillation: Epoch : 46, Loss : 1.542898, Accuracy: 0.903000, Test accuracy: 0.918300
Distillation: Epoch : 47, Loss : 1.529048, Accuracy: 0.909000, Test accuracy: 0.918800
Distillation: Epoch : 48, Loss : 1.526690, Accuracy: 0.918000, Test accuracy: 0.921000
Distillation: Epoch : 49, Loss : 1.552515, Accuracy: 0.898000, Test accuracy: 0.921800
Distillation: Epoch : 50, Loss : 1.531607, Accuracy: 0.917000, Test accuracy: 0.922100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9221
Generating confusion matrix for student3
[[ 956.    0.   10.    5.    0.    5.    9.    0.    8.    8.]
 [   1. 1101.   22.    4.    1.    4.    6.   20.   10.    6.]
 [   0.    4.  899.   18.    4.    1.    1.   11.    6.    1.]
 [   0.    0.   11.  899.    0.   13.    0.    4.   11.   12.]
 [   7.    1.   20.    3.  943.    3.   16.   15.   13.   51.]
 [   4.    5.    2.   47.    0.  823.   28.    2.   30.    4.]
 [   6.    4.    7.    2.    3.   12.  897.    0.    9.    0.]
 [   1.    0.   20.    8.    1.    2.    0.  940.    5.   26.]
 [   3.   20.   37.   18.    6.   22.    1.    3.  872.   10.]
 [   2.    0.    4.    6.   24.    7.    0.   33.   10.  891.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.148216, Accuracy: 0.698000, Test accuracy: 0.723600
Distillation: Epoch : 2, Loss : 1.942459, Accuracy: 0.811000, Test accuracy: 0.810400
Distillation: Epoch : 3, Loss : 1.885980, Accuracy: 0.851000, Test accuracy: 0.846300
Distillation: Epoch : 4, Loss : 1.875650, Accuracy: 0.849000, Test accuracy: 0.859000
Distillation: Epoch : 5, Loss : 1.875533, Accuracy: 0.849000, Test accuracy: 0.866500
Distillation: Epoch : 6, Loss : 1.853441, Accuracy: 0.844000, Test accuracy: 0.873000
Distillation: Epoch : 7, Loss : 1.852772, Accuracy: 0.866000, Test accuracy: 0.876300
Distillation: Epoch : 8, Loss : 1.841412, Accuracy: 0.867000, Test accuracy: 0.882000
Distillation: Epoch : 9, Loss : 1.837547, Accuracy: 0.874000, Test accuracy: 0.885500
Distillation: Epoch : 10, Loss : 1.838542, Accuracy: 0.869000, Test accuracy: 0.887300
Distillation: Epoch : 11, Loss : 1.834890, Accuracy: 0.873000, Test accuracy: 0.890500
Distillation: Epoch : 12, Loss : 1.815278, Accuracy: 0.899000, Test accuracy: 0.893000
Distillation: Epoch : 13, Loss : 1.810636, Accuracy: 0.895000, Test accuracy: 0.895600
Distillation: Epoch : 14, Loss : 1.819154, Accuracy: 0.887000, Test accuracy: 0.898000
Distillation: Epoch : 15, Loss : 1.804525, Accuracy: 0.877000, Test accuracy: 0.899800
Distillation: Epoch : 16, Loss : 1.830248, Accuracy: 0.897000, Test accuracy: 0.901900
Distillation: Epoch : 17, Loss : 1.827713, Accuracy: 0.895000, Test accuracy: 0.904700
Distillation: Epoch : 18, Loss : 1.802569, Accuracy: 0.898000, Test accuracy: 0.906500
Distillation: Epoch : 19, Loss : 1.794314, Accuracy: 0.910000, Test accuracy: 0.906800
Distillation: Epoch : 20, Loss : 1.795909, Accuracy: 0.913000, Test accuracy: 0.907700
Distillation: Epoch : 21, Loss : 1.806148, Accuracy: 0.895000, Test accuracy: 0.910000
Distillation: Epoch : 22, Loss : 1.805971, Accuracy: 0.913000, Test accuracy: 0.911400
Distillation: Epoch : 23, Loss : 1.799024, Accuracy: 0.914000, Test accuracy: 0.914600
Distillation: Epoch : 24, Loss : 1.808086, Accuracy: 0.911000, Test accuracy: 0.914100
Distillation: Epoch : 25, Loss : 1.798684, Accuracy: 0.904000, Test accuracy: 0.915200
Distillation: Epoch : 26, Loss : 1.801685, Accuracy: 0.915000, Test accuracy: 0.916100
Distillation: Epoch : 27, Loss : 1.817035, Accuracy: 0.875000, Test accuracy: 0.918000
Distillation: Epoch : 28, Loss : 1.792541, Accuracy: 0.913000, Test accuracy: 0.919200
Distillation: Epoch : 29, Loss : 1.818295, Accuracy: 0.894000, Test accuracy: 0.920200
Distillation: Epoch : 30, Loss : 1.771185, Accuracy: 0.921000, Test accuracy: 0.920900
Distillation: Epoch : 31, Loss : 1.805223, Accuracy: 0.897000, Test accuracy: 0.921700
Distillation: Epoch : 32, Loss : 1.802889, Accuracy: 0.910000, Test accuracy: 0.921300
Distillation: Epoch : 33, Loss : 1.773544, Accuracy: 0.931000, Test accuracy: 0.923500
Distillation: Epoch : 34, Loss : 1.791206, Accuracy: 0.925000, Test accuracy: 0.925100
Distillation: Epoch : 35, Loss : 1.806753, Accuracy: 0.901000, Test accuracy: 0.924700
Distillation: Epoch : 36, Loss : 1.790050, Accuracy: 0.911000, Test accuracy: 0.925500
Distillation: Epoch : 37, Loss : 1.782393, Accuracy: 0.926000, Test accuracy: 0.925800
Distillation: Epoch : 38, Loss : 1.792047, Accuracy: 0.905000, Test accuracy: 0.927500
Distillation: Epoch : 39, Loss : 1.779679, Accuracy: 0.919000, Test accuracy: 0.927200
Distillation: Epoch : 40, Loss : 1.782995, Accuracy: 0.935000, Test accuracy: 0.928000
Distillation: Epoch : 41, Loss : 1.785587, Accuracy: 0.909000, Test accuracy: 0.930600
Distillation: Epoch : 42, Loss : 1.776743, Accuracy: 0.920000, Test accuracy: 0.929100
Distillation: Epoch : 43, Loss : 1.785792, Accuracy: 0.918000, Test accuracy: 0.931300
Distillation: Epoch : 44, Loss : 1.795343, Accuracy: 0.924000, Test accuracy: 0.929800
Distillation: Epoch : 45, Loss : 1.801132, Accuracy: 0.921000, Test accuracy: 0.931300
Distillation: Epoch : 46, Loss : 1.782243, Accuracy: 0.923000, Test accuracy: 0.931600
Distillation: Epoch : 47, Loss : 1.783836, Accuracy: 0.925000, Test accuracy: 0.932900
Distillation: Epoch : 48, Loss : 1.787483, Accuracy: 0.916000, Test accuracy: 0.933300
Distillation: Epoch : 49, Loss : 1.771740, Accuracy: 0.939000, Test accuracy: 0.932200
Distillation: Epoch : 50, Loss : 1.788003, Accuracy: 0.917000, Test accuracy: 0.933600
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9336
Generating confusion matrix for student3
[[ 954.    0.    7.    7.    0.    6.    4.    0.    5.    6.]
 [   1. 1112.   19.    4.    1.    2.    4.   16.    6.    9.]
 [   1.    2.  930.    8.    5.    0.    0.   14.    8.    1.]
 [   1.    1.    8.  903.    0.    7.    0.    4.   16.    4.]
 [   5.    1.   23.    6.  941.    7.    5.   19.   14.   41.]
 [   9.    2.    1.   40.    0.  846.   29.    1.   30.    4.]
 [   4.    5.    5.    2.    8.    5.  914.    0.    2.    0.]
 [   1.    1.   21.   17.    1.    2.    0.  933.    3.    9.]
 [   4.   11.   17.   20.    5.   13.    2.    2.  877.    9.]
 [   0.    0.    1.    3.   21.    4.    0.   39.   13.  926.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.221172, Accuracy: 0.665000, Test accuracy: 0.660800
Distillation: Epoch : 2, Loss : 2.114479, Accuracy: 0.806000, Test accuracy: 0.809500
Distillation: Epoch : 3, Loss : 2.087038, Accuracy: 0.827000, Test accuracy: 0.836300
Distillation: Epoch : 4, Loss : 2.078644, Accuracy: 0.852000, Test accuracy: 0.849700
Distillation: Epoch : 5, Loss : 2.071112, Accuracy: 0.855000, Test accuracy: 0.856200
Distillation: Epoch : 6, Loss : 2.073181, Accuracy: 0.858000, Test accuracy: 0.862300
Distillation: Epoch : 7, Loss : 2.064085, Accuracy: 0.870000, Test accuracy: 0.869800
Distillation: Epoch : 8, Loss : 2.061921, Accuracy: 0.869000, Test accuracy: 0.871800
Distillation: Epoch : 9, Loss : 2.056425, Accuracy: 0.880000, Test accuracy: 0.876000
Distillation: Epoch : 10, Loss : 2.052712, Accuracy: 0.879000, Test accuracy: 0.879000
Distillation: Epoch : 11, Loss : 2.053787, Accuracy: 0.879000, Test accuracy: 0.882400
Distillation: Epoch : 12, Loss : 2.052065, Accuracy: 0.880000, Test accuracy: 0.885900
Distillation: Epoch : 13, Loss : 2.055868, Accuracy: 0.884000, Test accuracy: 0.886800
Distillation: Epoch : 14, Loss : 2.050127, Accuracy: 0.867000, Test accuracy: 0.887600
Distillation: Epoch : 15, Loss : 2.045177, Accuracy: 0.882000, Test accuracy: 0.889700
Distillation: Epoch : 16, Loss : 2.049664, Accuracy: 0.889000, Test accuracy: 0.893300
Distillation: Epoch : 17, Loss : 2.041385, Accuracy: 0.882000, Test accuracy: 0.893200
Distillation: Epoch : 18, Loss : 2.045005, Accuracy: 0.897000, Test accuracy: 0.895100
Distillation: Epoch : 19, Loss : 2.047407, Accuracy: 0.884000, Test accuracy: 0.898700
Distillation: Epoch : 20, Loss : 2.045598, Accuracy: 0.892000, Test accuracy: 0.898000
Distillation: Epoch : 21, Loss : 2.045782, Accuracy: 0.888000, Test accuracy: 0.901400
Distillation: Epoch : 22, Loss : 2.029001, Accuracy: 0.902000, Test accuracy: 0.904100
Distillation: Epoch : 23, Loss : 2.036999, Accuracy: 0.916000, Test accuracy: 0.906700
Distillation: Epoch : 24, Loss : 2.042232, Accuracy: 0.896000, Test accuracy: 0.907600
Distillation: Epoch : 25, Loss : 2.028821, Accuracy: 0.905000, Test accuracy: 0.911300
Distillation: Epoch : 26, Loss : 2.033068, Accuracy: 0.920000, Test accuracy: 0.911800
Distillation: Epoch : 27, Loss : 2.032751, Accuracy: 0.909000, Test accuracy: 0.916100
Distillation: Epoch : 28, Loss : 2.026452, Accuracy: 0.910000, Test accuracy: 0.916200
Distillation: Epoch : 29, Loss : 2.029797, Accuracy: 0.930000, Test accuracy: 0.918800
Distillation: Epoch : 30, Loss : 2.039108, Accuracy: 0.910000, Test accuracy: 0.921800
Distillation: Epoch : 31, Loss : 2.017123, Accuracy: 0.915000, Test accuracy: 0.924000
Distillation: Epoch : 32, Loss : 2.021558, Accuracy: 0.924000, Test accuracy: 0.925100
Distillation: Epoch : 33, Loss : 2.023702, Accuracy: 0.923000, Test accuracy: 0.925900
Distillation: Epoch : 34, Loss : 2.023651, Accuracy: 0.926000, Test accuracy: 0.927800
Distillation: Epoch : 35, Loss : 2.019893, Accuracy: 0.925000, Test accuracy: 0.929500
Distillation: Epoch : 36, Loss : 2.010523, Accuracy: 0.925000, Test accuracy: 0.930600
Distillation: Epoch : 37, Loss : 2.018284, Accuracy: 0.916000, Test accuracy: 0.931700
Distillation: Epoch : 38, Loss : 2.018681, Accuracy: 0.944000, Test accuracy: 0.933600
Distillation: Epoch : 39, Loss : 2.013267, Accuracy: 0.937000, Test accuracy: 0.935000
Distillation: Epoch : 40, Loss : 2.021697, Accuracy: 0.936000, Test accuracy: 0.935500
Distillation: Epoch : 41, Loss : 2.018836, Accuracy: 0.929000, Test accuracy: 0.936800
Distillation: Epoch : 42, Loss : 2.022560, Accuracy: 0.932000, Test accuracy: 0.938300
Distillation: Epoch : 43, Loss : 2.029748, Accuracy: 0.930000, Test accuracy: 0.939900
Distillation: Epoch : 44, Loss : 2.016067, Accuracy: 0.932000, Test accuracy: 0.940700
Distillation: Epoch : 45, Loss : 2.014996, Accuracy: 0.928000, Test accuracy: 0.940600
Distillation: Epoch : 46, Loss : 2.014659, Accuracy: 0.940000, Test accuracy: 0.942300
Distillation: Epoch : 47, Loss : 2.020956, Accuracy: 0.944000, Test accuracy: 0.943200
Distillation: Epoch : 48, Loss : 2.009685, Accuracy: 0.940000, Test accuracy: 0.944400
Distillation: Epoch : 49, Loss : 2.008091, Accuracy: 0.935000, Test accuracy: 0.945000
Distillation: Epoch : 50, Loss : 2.015954, Accuracy: 0.951000, Test accuracy: 0.946300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9463
Generating confusion matrix for student3
[[ 964.    0.    4.    2.    0.    1.    6.    1.    7.    6.]
 [   0. 1113.    9.    1.    2.    3.    3.    8.    8.    8.]
 [   0.    2.  937.    9.    4.    0.    0.   14.    9.    0.]
 [   0.    2.   12.  945.    0.    7.    0.    7.    6.    9.]
 [   5.    1.    7.    1.  958.    0.    8.   11.    9.   23.]
 [   2.    2.    2.   25.    0.  854.   19.    1.   21.    8.]
 [   6.    6.    4.    1.    2.    5.  918.    0.    2.    0.]
 [   1.    0.   17.    9.    0.    3.    0.  950.    7.   17.]
 [   2.    9.   39.   13.    3.   14.    4.    4.  893.    7.]
 [   0.    0.    1.    4.   13.    5.    0.   32.   12.  931.]]
</confusion_matrix>
