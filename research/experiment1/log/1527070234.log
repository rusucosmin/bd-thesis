Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.137323, Accuracy: 0.968000, Test accuracy: 0.966800
Starting training epoch 1
Epoch : 2, Loss : 0.084430, Accuracy: 0.976000, Test accuracy: 0.977600
Starting training epoch 2
Epoch : 3, Loss : 0.038511, Accuracy: 0.992000, Test accuracy: 0.982700
Starting training epoch 3
Epoch : 4, Loss : 0.030440, Accuracy: 0.992000, Test accuracy: 0.987100
Starting training epoch 4
Epoch : 5, Loss : 0.018639, Accuracy: 0.988000, Test accuracy: 0.985700
Starting training epoch 5
Epoch : 6, Loss : 0.096487, Accuracy: 0.984000, Test accuracy: 0.988400
Starting training epoch 6
Epoch : 7, Loss : 0.008483, Accuracy: 1.000000, Test accuracy: 0.989800
Starting training epoch 7
Epoch : 8, Loss : 0.013325, Accuracy: 0.996000, Test accuracy: 0.990100
Starting training epoch 8
Epoch : 9, Loss : 0.007612, Accuracy: 1.000000, Test accuracy: 0.990300
Starting training epoch 9
Epoch : 10, Loss : 0.006700, Accuracy: 1.000000, Test accuracy: 0.991200
Starting training epoch 10
Epoch : 11, Loss : 0.008246, Accuracy: 0.996000, Test accuracy: 0.991700
Starting training epoch 11
Epoch : 12, Loss : 0.001756, Accuracy: 1.000000, Test accuracy: 0.990900
Starting training epoch 12
Epoch : 13, Loss : 0.002205, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 13
Epoch : 14, Loss : 0.001235, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 14
Epoch : 15, Loss : 0.021425, Accuracy: 0.996000, Test accuracy: 0.991400
Starting training epoch 15
Epoch : 16, Loss : 0.002673, Accuracy: 1.000000, Test accuracy: 0.992300
Starting training epoch 16
Epoch : 17, Loss : 0.016791, Accuracy: 0.992000, Test accuracy: 0.991600
Starting training epoch 17
Epoch : 18, Loss : 0.001780, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 18
Epoch : 19, Loss : 0.000993, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 19
Epoch : 20, Loss : 0.003072, Accuracy: 1.000000, Test accuracy: 0.991900
Starting training epoch 20
Epoch : 21, Loss : 0.000185, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 21
Epoch : 22, Loss : 0.000184, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 22
Epoch : 23, Loss : 0.000469, Accuracy: 1.000000, Test accuracy: 0.991100
Starting training epoch 23
Epoch : 24, Loss : 0.000566, Accuracy: 1.000000, Test accuracy: 0.992100
Starting training epoch 24
Epoch : 25, Loss : 0.001961, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 25
Epoch : 26, Loss : 0.000522, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 26
Epoch : 27, Loss : 0.000073, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 27
Epoch : 28, Loss : 0.000156, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 28
Epoch : 29, Loss : 0.000236, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 29
Epoch : 30, Loss : 0.000951, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 30
Epoch : 31, Loss : 0.000269, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 31
Epoch : 32, Loss : 0.000303, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 32
Epoch : 33, Loss : 0.000084, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 33
Epoch : 34, Loss : 0.000146, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 34
Epoch : 35, Loss : 0.000325, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 35
Epoch : 36, Loss : 0.000355, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 36
Epoch : 37, Loss : 0.000164, Accuracy: 1.000000, Test accuracy: 0.992700
Starting training epoch 37
Epoch : 38, Loss : 0.000095, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 38
Epoch : 39, Loss : 0.000615, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 39
Epoch : 40, Loss : 0.000066, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 40
Epoch : 41, Loss : 0.000014, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 41
Epoch : 42, Loss : 0.000017, Accuracy: 1.000000, Test accuracy: 0.992500
Starting training epoch 42
Epoch : 43, Loss : 0.000026, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 43
Epoch : 44, Loss : 0.000034, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 44
Epoch : 45, Loss : 0.000012, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 45
Epoch : 46, Loss : 0.000035, Accuracy: 1.000000, Test accuracy: 0.994500
Starting training epoch 46
Epoch : 47, Loss : 0.000011, Accuracy: 1.000000, Test accuracy: 0.993500
Starting training epoch 47
Epoch : 48, Loss : 0.000042, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 48
Epoch : 49, Loss : 0.000505, Accuracy: 1.000000, Test accuracy: 0.991900
Starting training epoch 49
Epoch : 50, Loss : 0.000048, Accuracy: 1.000000, Test accuracy: 0.993100
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 1.003429, Accuracy: 0.776000, Test accuracy: 0.770400
Starting training epoch 1
Epoch : 2, Loss : 0.518612, Accuracy: 0.844000, Test accuracy: 0.854700
Starting training epoch 2
Epoch : 3, Loss : 0.519922, Accuracy: 0.864000, Test accuracy: 0.876800
Starting training epoch 3
Epoch : 4, Loss : 0.423427, Accuracy: 0.876000, Test accuracy: 0.892600
Starting training epoch 4
Epoch : 5, Loss : 0.315994, Accuracy: 0.912000, Test accuracy: 0.903500
Starting training epoch 5
Epoch : 6, Loss : 0.369911, Accuracy: 0.912000, Test accuracy: 0.911200
Starting training epoch 6
Epoch : 7, Loss : 0.293744, Accuracy: 0.912000, Test accuracy: 0.914500
Starting training epoch 7
Epoch : 8, Loss : 0.324667, Accuracy: 0.896000, Test accuracy: 0.919800
Starting training epoch 8
Epoch : 9, Loss : 0.289496, Accuracy: 0.908000, Test accuracy: 0.923300
Starting training epoch 9
Epoch : 10, Loss : 0.237033, Accuracy: 0.928000, Test accuracy: 0.925900
Starting training epoch 10
Epoch : 11, Loss : 0.266494, Accuracy: 0.948000, Test accuracy: 0.929300
Starting training epoch 11
Epoch : 12, Loss : 0.318529, Accuracy: 0.908000, Test accuracy: 0.930900
Starting training epoch 12
Epoch : 13, Loss : 0.217774, Accuracy: 0.928000, Test accuracy: 0.932200
Starting training epoch 13
Epoch : 14, Loss : 0.170600, Accuracy: 0.960000, Test accuracy: 0.934500
Starting training epoch 14
Epoch : 15, Loss : 0.224490, Accuracy: 0.940000, Test accuracy: 0.937300
Starting training epoch 15
Epoch : 16, Loss : 0.273448, Accuracy: 0.928000, Test accuracy: 0.938200
Starting training epoch 16
Epoch : 17, Loss : 0.240045, Accuracy: 0.928000, Test accuracy: 0.940800
Starting training epoch 17
Epoch : 18, Loss : 0.186329, Accuracy: 0.928000, Test accuracy: 0.941900
Starting training epoch 18
Epoch : 19, Loss : 0.246672, Accuracy: 0.948000, Test accuracy: 0.943400
Starting training epoch 19
Epoch : 20, Loss : 0.210701, Accuracy: 0.924000, Test accuracy: 0.944300
Starting training epoch 20
Epoch : 21, Loss : 0.220146, Accuracy: 0.932000, Test accuracy: 0.944800
Starting training epoch 21
Epoch : 22, Loss : 0.206841, Accuracy: 0.924000, Test accuracy: 0.946600
Starting training epoch 22
Epoch : 23, Loss : 0.199504, Accuracy: 0.936000, Test accuracy: 0.948300
Starting training epoch 23
Epoch : 24, Loss : 0.269364, Accuracy: 0.908000, Test accuracy: 0.947500
Starting training epoch 24
Epoch : 25, Loss : 0.236510, Accuracy: 0.956000, Test accuracy: 0.948100
Starting training epoch 25
Epoch : 26, Loss : 0.166357, Accuracy: 0.952000, Test accuracy: 0.950400
Starting training epoch 26
Epoch : 27, Loss : 0.196441, Accuracy: 0.948000, Test accuracy: 0.950700
Starting training epoch 27
Epoch : 28, Loss : 0.221180, Accuracy: 0.952000, Test accuracy: 0.952800
Starting training epoch 28
Epoch : 29, Loss : 0.241484, Accuracy: 0.944000, Test accuracy: 0.952900
Starting training epoch 29
Epoch : 30, Loss : 0.185199, Accuracy: 0.928000, Test accuracy: 0.953700
Starting training epoch 30
Epoch : 31, Loss : 0.112240, Accuracy: 0.976000, Test accuracy: 0.953500
Starting training epoch 31
Epoch : 32, Loss : 0.210267, Accuracy: 0.940000, Test accuracy: 0.954700
Starting training epoch 32
Epoch : 33, Loss : 0.135721, Accuracy: 0.956000, Test accuracy: 0.955900
Starting training epoch 33
Epoch : 34, Loss : 0.096912, Accuracy: 0.976000, Test accuracy: 0.956200
Starting training epoch 34
Epoch : 35, Loss : 0.111150, Accuracy: 0.956000, Test accuracy: 0.958100
Starting training epoch 35
Epoch : 36, Loss : 0.183300, Accuracy: 0.940000, Test accuracy: 0.956800
Starting training epoch 36
Epoch : 37, Loss : 0.192007, Accuracy: 0.948000, Test accuracy: 0.956500
Starting training epoch 37
Epoch : 38, Loss : 0.071508, Accuracy: 0.976000, Test accuracy: 0.957900
Starting training epoch 38
Epoch : 39, Loss : 0.129021, Accuracy: 0.960000, Test accuracy: 0.958800
Starting training epoch 39
Epoch : 40, Loss : 0.166154, Accuracy: 0.952000, Test accuracy: 0.959400
Starting training epoch 40
Epoch : 41, Loss : 0.068805, Accuracy: 0.976000, Test accuracy: 0.959000
Starting training epoch 41
Epoch : 42, Loss : 0.052635, Accuracy: 0.984000, Test accuracy: 0.960300
Starting training epoch 42
Epoch : 43, Loss : 0.102911, Accuracy: 0.956000, Test accuracy: 0.961200
Starting training epoch 43
Epoch : 44, Loss : 0.123519, Accuracy: 0.968000, Test accuracy: 0.961300
Starting training epoch 44
Epoch : 45, Loss : 0.095653, Accuracy: 0.960000, Test accuracy: 0.962700
Starting training epoch 45
Epoch : 46, Loss : 0.061132, Accuracy: 0.988000, Test accuracy: 0.962600
Starting training epoch 46
Epoch : 47, Loss : 0.089964, Accuracy: 0.972000, Test accuracy: 0.962400
Starting training epoch 47
Epoch : 48, Loss : 0.111238, Accuracy: 0.968000, Test accuracy: 0.962300
Starting training epoch 48
Epoch : 49, Loss : 0.068810, Accuracy: 0.980000, Test accuracy: 0.963800
Starting training epoch 49
Epoch : 50, Loss : 0.129696, Accuracy: 0.956000, Test accuracy: 0.963700
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 0.926726, Accuracy: 0.768000, Test accuracy: 0.764600
Starting training opoch 1
Epoch : 2, Loss : 0.554021, Accuracy: 0.812000, Test accuracy: 0.852100
Starting training opoch 2
Epoch : 3, Loss : 0.354272, Accuracy: 0.884000, Test accuracy: 0.877500
Starting training opoch 3
Epoch : 4, Loss : 0.474974, Accuracy: 0.864000, Test accuracy: 0.890900
Starting training opoch 4
Epoch : 5, Loss : 0.480272, Accuracy: 0.856000, Test accuracy: 0.897000
Starting training opoch 5
Epoch : 6, Loss : 0.291408, Accuracy: 0.916000, Test accuracy: 0.900100
Starting training opoch 6
Epoch : 7, Loss : 0.269890, Accuracy: 0.912000, Test accuracy: 0.904300
Starting training opoch 7
Epoch : 8, Loss : 0.412719, Accuracy: 0.892000, Test accuracy: 0.904300
Starting training opoch 8
Epoch : 9, Loss : 0.283110, Accuracy: 0.916000, Test accuracy: 0.907400
Starting training opoch 9
Epoch : 10, Loss : 0.274156, Accuracy: 0.928000, Test accuracy: 0.906300
Starting training opoch 10
Epoch : 11, Loss : 0.414206, Accuracy: 0.892000, Test accuracy: 0.909900
Starting training opoch 11
Epoch : 12, Loss : 0.274279, Accuracy: 0.924000, Test accuracy: 0.911900
Starting training opoch 12
Epoch : 13, Loss : 0.220047, Accuracy: 0.936000, Test accuracy: 0.910700
Starting training opoch 13
Epoch : 14, Loss : 0.411566, Accuracy: 0.892000, Test accuracy: 0.912400
Starting training opoch 14
Epoch : 15, Loss : 0.288071, Accuracy: 0.896000, Test accuracy: 0.912900
Starting training opoch 15
Epoch : 16, Loss : 0.409427, Accuracy: 0.888000, Test accuracy: 0.912400
Starting training opoch 16
Epoch : 17, Loss : 0.351034, Accuracy: 0.900000, Test accuracy: 0.914500
Starting training opoch 17
Epoch : 18, Loss : 0.346869, Accuracy: 0.920000, Test accuracy: 0.916300
Starting training opoch 18
Epoch : 19, Loss : 0.430518, Accuracy: 0.892000, Test accuracy: 0.914900
Starting training opoch 19
Epoch : 20, Loss : 0.261663, Accuracy: 0.924000, Test accuracy: 0.916100
Starting training opoch 20
Epoch : 21, Loss : 0.349923, Accuracy: 0.908000, Test accuracy: 0.915800
Starting training opoch 21
Epoch : 22, Loss : 0.267897, Accuracy: 0.924000, Test accuracy: 0.917100
Starting training opoch 22
Epoch : 23, Loss : 0.274965, Accuracy: 0.904000, Test accuracy: 0.918900
Starting training opoch 23
Epoch : 24, Loss : 0.204145, Accuracy: 0.944000, Test accuracy: 0.918700
Starting training opoch 24
Epoch : 25, Loss : 0.254546, Accuracy: 0.916000, Test accuracy: 0.918500
Starting training opoch 25
Epoch : 26, Loss : 0.288537, Accuracy: 0.912000, Test accuracy: 0.919600
Starting training opoch 26
Epoch : 27, Loss : 0.341112, Accuracy: 0.940000, Test accuracy: 0.919100
Starting training opoch 27
Epoch : 28, Loss : 0.284119, Accuracy: 0.920000, Test accuracy: 0.920100
Starting training opoch 28
Epoch : 29, Loss : 0.226822, Accuracy: 0.940000, Test accuracy: 0.919800
Starting training opoch 29
Epoch : 30, Loss : 0.321134, Accuracy: 0.920000, Test accuracy: 0.919900
Starting training opoch 30
Epoch : 31, Loss : 0.234351, Accuracy: 0.928000, Test accuracy: 0.919600
Starting training opoch 31
Epoch : 32, Loss : 0.382679, Accuracy: 0.900000, Test accuracy: 0.919400
Starting training opoch 32
Epoch : 33, Loss : 0.277064, Accuracy: 0.900000, Test accuracy: 0.920800
Starting training opoch 33
Epoch : 34, Loss : 0.298219, Accuracy: 0.916000, Test accuracy: 0.920300
Starting training opoch 34
Epoch : 35, Loss : 0.411534, Accuracy: 0.900000, Test accuracy: 0.922100
Starting training opoch 35
Epoch : 36, Loss : 0.180542, Accuracy: 0.960000, Test accuracy: 0.922000
Starting training opoch 36
Epoch : 37, Loss : 0.295778, Accuracy: 0.908000, Test accuracy: 0.920500
Starting training opoch 37
Epoch : 38, Loss : 0.264729, Accuracy: 0.928000, Test accuracy: 0.922400
Starting training opoch 38
Epoch : 39, Loss : 0.262013, Accuracy: 0.928000, Test accuracy: 0.922400
Starting training opoch 39
Epoch : 40, Loss : 0.155199, Accuracy: 0.952000, Test accuracy: 0.921500
Starting training opoch 40
Epoch : 41, Loss : 0.303015, Accuracy: 0.920000, Test accuracy: 0.922800
Starting training opoch 41
Epoch : 42, Loss : 0.266164, Accuracy: 0.916000, Test accuracy: 0.922100
Starting training opoch 42
Epoch : 43, Loss : 0.221662, Accuracy: 0.940000, Test accuracy: 0.922800
Starting training opoch 43
Epoch : 44, Loss : 0.312240, Accuracy: 0.912000, Test accuracy: 0.923400
Starting training opoch 44
Epoch : 45, Loss : 0.237053, Accuracy: 0.928000, Test accuracy: 0.922100
Starting training opoch 45
Epoch : 46, Loss : 0.286157, Accuracy: 0.912000, Test accuracy: 0.923400
Starting training opoch 46
Epoch : 47, Loss : 0.264978, Accuracy: 0.908000, Test accuracy: 0.924700
Starting training opoch 47
Epoch : 48, Loss : 0.322431, Accuracy: 0.916000, Test accuracy: 0.925900
Starting training opoch 48
Epoch : 49, Loss : 0.319560, Accuracy: 0.940000, Test accuracy: 0.925000
Starting training opoch 49
Epoch : 50, Loss : 0.234025, Accuracy: 0.928000, Test accuracy: 0.923300
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.645149, Accuracy: 0.824000, Test accuracy: 0.818000
Starting training epoch 1
Epoch : 2, Loss : 0.541103, Accuracy: 0.836000, Test accuracy: 0.879200
Starting training epoch 2
Epoch : 3, Loss : 0.454739, Accuracy: 0.840000, Test accuracy: 0.898800
Starting training epoch 3
Epoch : 4, Loss : 0.289137, Accuracy: 0.912000, Test accuracy: 0.912900
Starting training epoch 4
Epoch : 5, Loss : 0.186431, Accuracy: 0.948000, Test accuracy: 0.921800
Starting training epoch 5
Epoch : 6, Loss : 0.214844, Accuracy: 0.944000, Test accuracy: 0.929000
Starting training epoch 6
Epoch : 7, Loss : 0.169235, Accuracy: 0.956000, Test accuracy: 0.934800
Starting training epoch 7
Epoch : 8, Loss : 0.216320, Accuracy: 0.940000, Test accuracy: 0.939700
Starting training epoch 8
Epoch : 9, Loss : 0.200270, Accuracy: 0.948000, Test accuracy: 0.945800
Starting training epoch 9
Epoch : 10, Loss : 0.151281, Accuracy: 0.948000, Test accuracy: 0.949600
Starting training epoch 10
Epoch : 11, Loss : 0.158670, Accuracy: 0.940000, Test accuracy: 0.954400
Starting training epoch 11
Epoch : 12, Loss : 0.198219, Accuracy: 0.956000, Test accuracy: 0.955500
Starting training epoch 12
Epoch : 13, Loss : 0.135537, Accuracy: 0.960000, Test accuracy: 0.957500
Starting training epoch 13
Epoch : 14, Loss : 0.130397, Accuracy: 0.976000, Test accuracy: 0.960500
Starting training epoch 14
Epoch : 15, Loss : 0.108715, Accuracy: 0.972000, Test accuracy: 0.962000
Starting training epoch 15
Epoch : 16, Loss : 0.189917, Accuracy: 0.956000, Test accuracy: 0.963200
Starting training epoch 16
Epoch : 17, Loss : 0.094078, Accuracy: 0.972000, Test accuracy: 0.965900
Starting training epoch 17
Epoch : 18, Loss : 0.109171, Accuracy: 0.960000, Test accuracy: 0.965300
Starting training epoch 18
Epoch : 19, Loss : 0.084748, Accuracy: 0.964000, Test accuracy: 0.967600
Starting training epoch 19
Epoch : 20, Loss : 0.132860, Accuracy: 0.972000, Test accuracy: 0.969000
Starting training epoch 20
Epoch : 21, Loss : 0.076252, Accuracy: 0.972000, Test accuracy: 0.968800
Starting training epoch 21
Epoch : 22, Loss : 0.098822, Accuracy: 0.976000, Test accuracy: 0.970100
Starting training epoch 22
Epoch : 23, Loss : 0.095636, Accuracy: 0.976000, Test accuracy: 0.970700
Starting training epoch 23
Epoch : 24, Loss : 0.099363, Accuracy: 0.972000, Test accuracy: 0.970500
Starting training epoch 24
Epoch : 25, Loss : 0.081520, Accuracy: 0.972000, Test accuracy: 0.971500
Starting training epoch 25
Epoch : 26, Loss : 0.103706, Accuracy: 0.964000, Test accuracy: 0.970400
Starting training epoch 26
Epoch : 27, Loss : 0.082199, Accuracy: 0.972000, Test accuracy: 0.972700
Starting training epoch 27
Epoch : 28, Loss : 0.083196, Accuracy: 0.968000, Test accuracy: 0.972900
Starting training epoch 28
Epoch : 29, Loss : 0.075007, Accuracy: 0.972000, Test accuracy: 0.971700
Starting training epoch 29
Epoch : 30, Loss : 0.066920, Accuracy: 0.968000, Test accuracy: 0.974100
Starting training epoch 30
Epoch : 31, Loss : 0.078699, Accuracy: 0.980000, Test accuracy: 0.974800
Starting training epoch 31
Epoch : 32, Loss : 0.075207, Accuracy: 0.964000, Test accuracy: 0.973700
Starting training epoch 32
Epoch : 33, Loss : 0.073235, Accuracy: 0.980000, Test accuracy: 0.974700
Starting training epoch 33
Epoch : 34, Loss : 0.071409, Accuracy: 0.988000, Test accuracy: 0.975300
Starting training epoch 34
Epoch : 35, Loss : 0.067968, Accuracy: 0.988000, Test accuracy: 0.974500
Starting training epoch 35
Epoch : 36, Loss : 0.048676, Accuracy: 0.976000, Test accuracy: 0.976300
Starting training epoch 36
Epoch : 37, Loss : 0.108791, Accuracy: 0.972000, Test accuracy: 0.976100
Starting training epoch 37
Epoch : 38, Loss : 0.126025, Accuracy: 0.952000, Test accuracy: 0.976700
Starting training epoch 38
Epoch : 39, Loss : 0.104220, Accuracy: 0.956000, Test accuracy: 0.976200
Starting training epoch 39
Epoch : 40, Loss : 0.052954, Accuracy: 0.972000, Test accuracy: 0.976200
Starting training epoch 40
Epoch : 41, Loss : 0.062913, Accuracy: 0.984000, Test accuracy: 0.977800
Starting training epoch 41
Epoch : 42, Loss : 0.065882, Accuracy: 0.972000, Test accuracy: 0.977200
Starting training epoch 42
Epoch : 43, Loss : 0.044753, Accuracy: 0.988000, Test accuracy: 0.978000
Starting training epoch 43
Epoch : 44, Loss : 0.070534, Accuracy: 0.968000, Test accuracy: 0.977300
Starting training epoch 44
Epoch : 45, Loss : 0.046106, Accuracy: 0.988000, Test accuracy: 0.977200
Starting training epoch 45
Epoch : 46, Loss : 0.054796, Accuracy: 0.980000, Test accuracy: 0.977500
Starting training epoch 46
Epoch : 47, Loss : 0.114309, Accuracy: 0.956000, Test accuracy: 0.978200
Starting training epoch 47
Epoch : 48, Loss : 0.044542, Accuracy: 0.980000, Test accuracy: 0.977800
Starting training epoch 48
Epoch : 49, Loss : 0.062092, Accuracy: 0.972000, Test accuracy: 0.978400
Starting training epoch 49
Epoch : 50, Loss : 0.045593, Accuracy: 0.980000, Test accuracy: 0.978500
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.716913, Accuracy: 0.824000, Test accuracy: 0.827900
Starting training opoch 1
Epoch : 2, Loss : 0.443172, Accuracy: 0.860000, Test accuracy: 0.884700
Starting training opoch 2
Epoch : 3, Loss : 0.337771, Accuracy: 0.904000, Test accuracy: 0.901300
Starting training opoch 3
Epoch : 4, Loss : 0.320470, Accuracy: 0.932000, Test accuracy: 0.905000
Starting training opoch 4
Epoch : 5, Loss : 0.348160, Accuracy: 0.928000, Test accuracy: 0.912900
Starting training opoch 5
Epoch : 6, Loss : 0.276300, Accuracy: 0.912000, Test accuracy: 0.914400
Starting training opoch 6
Epoch : 7, Loss : 0.205864, Accuracy: 0.948000, Test accuracy: 0.916300
Starting training opoch 7
Epoch : 8, Loss : 0.283559, Accuracy: 0.900000, Test accuracy: 0.918000
Starting training opoch 8
Epoch : 9, Loss : 0.298205, Accuracy: 0.904000, Test accuracy: 0.920300
Starting training opoch 9
Epoch : 10, Loss : 0.181364, Accuracy: 0.948000, Test accuracy: 0.922800
Starting training opoch 10
Epoch : 11, Loss : 0.310940, Accuracy: 0.880000, Test accuracy: 0.923600
Starting training opoch 11
Epoch : 12, Loss : 0.341849, Accuracy: 0.904000, Test accuracy: 0.923200
Starting training opoch 12
Epoch : 13, Loss : 0.267428, Accuracy: 0.908000, Test accuracy: 0.926400
Starting training opoch 13
Epoch : 14, Loss : 0.222898, Accuracy: 0.924000, Test accuracy: 0.927600
Starting training opoch 14
Epoch : 15, Loss : 0.242702, Accuracy: 0.936000, Test accuracy: 0.930100
Starting training opoch 15
Epoch : 16, Loss : 0.207939, Accuracy: 0.940000, Test accuracy: 0.931400
Starting training opoch 16
Epoch : 17, Loss : 0.242143, Accuracy: 0.928000, Test accuracy: 0.934400
Starting training opoch 17
Epoch : 18, Loss : 0.195148, Accuracy: 0.936000, Test accuracy: 0.934800
Starting training opoch 18
Epoch : 19, Loss : 0.332862, Accuracy: 0.904000, Test accuracy: 0.937000
Starting training opoch 19
Epoch : 20, Loss : 0.258614, Accuracy: 0.908000, Test accuracy: 0.937400
Starting training opoch 20
Epoch : 21, Loss : 0.182273, Accuracy: 0.952000, Test accuracy: 0.939100
Starting training opoch 21
Epoch : 22, Loss : 0.137243, Accuracy: 0.960000, Test accuracy: 0.941300
Starting training opoch 22
Epoch : 23, Loss : 0.206403, Accuracy: 0.960000, Test accuracy: 0.942200
Starting training opoch 23
Epoch : 24, Loss : 0.156440, Accuracy: 0.952000, Test accuracy: 0.943600
Starting training opoch 24
Epoch : 25, Loss : 0.140107, Accuracy: 0.956000, Test accuracy: 0.945200
Starting training opoch 25
Epoch : 26, Loss : 0.138173, Accuracy: 0.968000, Test accuracy: 0.948000
Starting training opoch 26
Epoch : 27, Loss : 0.178566, Accuracy: 0.944000, Test accuracy: 0.947800
Starting training opoch 27
Epoch : 28, Loss : 0.123731, Accuracy: 0.956000, Test accuracy: 0.949800
Starting training opoch 28
Epoch : 29, Loss : 0.189879, Accuracy: 0.944000, Test accuracy: 0.951400
Starting training opoch 29
Epoch : 30, Loss : 0.204836, Accuracy: 0.928000, Test accuracy: 0.951200
Starting training opoch 30
Epoch : 31, Loss : 0.316793, Accuracy: 0.908000, Test accuracy: 0.954000
Starting training opoch 31
Epoch : 32, Loss : 0.147810, Accuracy: 0.944000, Test accuracy: 0.953900
Starting training opoch 32
Epoch : 33, Loss : 0.198733, Accuracy: 0.956000, Test accuracy: 0.954700
Starting training opoch 33
Epoch : 34, Loss : 0.169480, Accuracy: 0.964000, Test accuracy: 0.955300
Starting training opoch 34
Epoch : 35, Loss : 0.122618, Accuracy: 0.972000, Test accuracy: 0.956300
Starting training opoch 35
Epoch : 36, Loss : 0.136240, Accuracy: 0.960000, Test accuracy: 0.956300
Starting training opoch 36
Epoch : 37, Loss : 0.131112, Accuracy: 0.952000, Test accuracy: 0.957500
Starting training opoch 37
Epoch : 38, Loss : 0.168678, Accuracy: 0.952000, Test accuracy: 0.957900
Starting training opoch 38
Epoch : 39, Loss : 0.193722, Accuracy: 0.944000, Test accuracy: 0.958400
Starting training opoch 39
Epoch : 40, Loss : 0.222430, Accuracy: 0.932000, Test accuracy: 0.959700
Starting training opoch 40
Epoch : 41, Loss : 0.204842, Accuracy: 0.948000, Test accuracy: 0.959200
Starting training opoch 41
Epoch : 42, Loss : 0.159983, Accuracy: 0.960000, Test accuracy: 0.960700
Starting training opoch 42
Epoch : 43, Loss : 0.154647, Accuracy: 0.956000, Test accuracy: 0.960000
Starting training opoch 43
Epoch : 44, Loss : 0.120641, Accuracy: 0.968000, Test accuracy: 0.959600
Starting training opoch 44
Epoch : 45, Loss : 0.158860, Accuracy: 0.956000, Test accuracy: 0.960400
Starting training opoch 45
Epoch : 46, Loss : 0.073493, Accuracy: 0.972000, Test accuracy: 0.961600
Starting training opoch 46
Epoch : 47, Loss : 0.109386, Accuracy: 0.956000, Test accuracy: 0.960500
Starting training opoch 47
Epoch : 48, Loss : 0.132342, Accuracy: 0.960000, Test accuracy: 0.963200
Starting training opoch 48
Epoch : 49, Loss : 0.134654, Accuracy: 0.960000, Test accuracy: 0.961400
Starting training opoch 49
Epoch : 50, Loss : 0.117292, Accuracy: 0.964000, Test accuracy: 0.962300
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.688726, Accuracy: 0.820000, Test accuracy: 0.822500
Starting training opoch 1
Epoch : 2, Loss : 0.416997, Accuracy: 0.880000, Test accuracy: 0.869600
Starting training opoch 2
Epoch : 3, Loss : 0.425492, Accuracy: 0.896000, Test accuracy: 0.888700
Starting training opoch 3
Epoch : 4, Loss : 0.287103, Accuracy: 0.912000, Test accuracy: 0.897500
Starting training opoch 4
Epoch : 5, Loss : 0.453180, Accuracy: 0.892000, Test accuracy: 0.901900
Starting training opoch 5
Epoch : 6, Loss : 0.269955, Accuracy: 0.932000, Test accuracy: 0.904900
Starting training opoch 6
Epoch : 7, Loss : 0.388911, Accuracy: 0.880000, Test accuracy: 0.906500
Starting training opoch 7
Epoch : 8, Loss : 0.297458, Accuracy: 0.904000, Test accuracy: 0.909300
Starting training opoch 8
Epoch : 9, Loss : 0.479682, Accuracy: 0.880000, Test accuracy: 0.910400
Starting training opoch 9
Epoch : 10, Loss : 0.265644, Accuracy: 0.924000, Test accuracy: 0.911800
Starting training opoch 10
Epoch : 11, Loss : 0.249788, Accuracy: 0.924000, Test accuracy: 0.914200
Starting training opoch 11
Epoch : 12, Loss : 0.279444, Accuracy: 0.916000, Test accuracy: 0.914200
Starting training opoch 12
Epoch : 13, Loss : 0.317443, Accuracy: 0.900000, Test accuracy: 0.915400
Starting training opoch 13
Epoch : 14, Loss : 0.290879, Accuracy: 0.928000, Test accuracy: 0.916800
Starting training opoch 14
Epoch : 15, Loss : 0.393672, Accuracy: 0.892000, Test accuracy: 0.918600
Starting training opoch 15
Epoch : 16, Loss : 0.246945, Accuracy: 0.928000, Test accuracy: 0.919400
Starting training opoch 16
Epoch : 17, Loss : 0.289493, Accuracy: 0.908000, Test accuracy: 0.920100
Starting training opoch 17
Epoch : 18, Loss : 0.280833, Accuracy: 0.928000, Test accuracy: 0.921500
Starting training opoch 18
Epoch : 19, Loss : 0.348448, Accuracy: 0.924000, Test accuracy: 0.921800
Starting training opoch 19
Epoch : 20, Loss : 0.324820, Accuracy: 0.896000, Test accuracy: 0.923600
Starting training opoch 20
Epoch : 21, Loss : 0.237625, Accuracy: 0.936000, Test accuracy: 0.924100
Starting training opoch 21
Epoch : 22, Loss : 0.323669, Accuracy: 0.912000, Test accuracy: 0.925600
Starting training opoch 22
Epoch : 23, Loss : 0.158673, Accuracy: 0.956000, Test accuracy: 0.926200
Starting training opoch 23
Epoch : 24, Loss : 0.199110, Accuracy: 0.948000, Test accuracy: 0.926900
Starting training opoch 24
Epoch : 25, Loss : 0.281002, Accuracy: 0.916000, Test accuracy: 0.927700
Starting training opoch 25
Epoch : 26, Loss : 0.220114, Accuracy: 0.928000, Test accuracy: 0.927900
Starting training opoch 26
Epoch : 27, Loss : 0.225897, Accuracy: 0.940000, Test accuracy: 0.928900
Starting training opoch 27
Epoch : 28, Loss : 0.195851, Accuracy: 0.944000, Test accuracy: 0.929400
Starting training opoch 28
Epoch : 29, Loss : 0.170083, Accuracy: 0.952000, Test accuracy: 0.929600
Starting training opoch 29
Epoch : 30, Loss : 0.273251, Accuracy: 0.936000, Test accuracy: 0.930000
Starting training opoch 30
Epoch : 31, Loss : 0.203267, Accuracy: 0.924000, Test accuracy: 0.930800
Starting training opoch 31
Epoch : 32, Loss : 0.264511, Accuracy: 0.904000, Test accuracy: 0.931900
Starting training opoch 32
Epoch : 33, Loss : 0.221005, Accuracy: 0.944000, Test accuracy: 0.933800
Starting training opoch 33
Epoch : 34, Loss : 0.239445, Accuracy: 0.948000, Test accuracy: 0.933700
Starting training opoch 34
Epoch : 35, Loss : 0.168530, Accuracy: 0.940000, Test accuracy: 0.934700
Starting training opoch 35
Epoch : 36, Loss : 0.184053, Accuracy: 0.940000, Test accuracy: 0.935900
Starting training opoch 36
Epoch : 37, Loss : 0.223881, Accuracy: 0.928000, Test accuracy: 0.936600
Starting training opoch 37
Epoch : 38, Loss : 0.219461, Accuracy: 0.936000, Test accuracy: 0.938700
Starting training opoch 38
Epoch : 39, Loss : 0.177840, Accuracy: 0.956000, Test accuracy: 0.938800
Starting training opoch 39
Epoch : 40, Loss : 0.246872, Accuracy: 0.932000, Test accuracy: 0.939200
Starting training opoch 40
Epoch : 41, Loss : 0.200229, Accuracy: 0.928000, Test accuracy: 0.940700
Starting training opoch 41
Epoch : 42, Loss : 0.211573, Accuracy: 0.952000, Test accuracy: 0.941800
Starting training opoch 42
Epoch : 43, Loss : 0.173657, Accuracy: 0.944000, Test accuracy: 0.942600
Starting training opoch 43
Epoch : 44, Loss : 0.166744, Accuracy: 0.936000, Test accuracy: 0.942800
Starting training opoch 44
Epoch : 45, Loss : 0.204072, Accuracy: 0.944000, Test accuracy: 0.943000
Starting training opoch 45
Epoch : 46, Loss : 0.159804, Accuracy: 0.960000, Test accuracy: 0.944700
Starting training opoch 46
Epoch : 47, Loss : 0.171818, Accuracy: 0.928000, Test accuracy: 0.944900
Starting training opoch 47
Epoch : 48, Loss : 0.222131, Accuracy: 0.928000, Test accuracy: 0.945600
Starting training opoch 48
Epoch : 49, Loss : 0.143387, Accuracy: 0.952000, Test accuracy: 0.945500
Starting training opoch 49
Epoch : 50, Loss : 0.274733, Accuracy: 0.932000, Test accuracy: 0.945400
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9931
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.825738, Accuracy: 0.770000, Test accuracy: 0.789200
Distillation: Epoch : 2, Loss : 0.444965, Accuracy: 0.882000, Test accuracy: 0.881900
Distillation: Epoch : 3, Loss : 0.381691, Accuracy: 0.891000, Test accuracy: 0.897300
Distillation: Epoch : 4, Loss : 0.382274, Accuracy: 0.875000, Test accuracy: 0.904500
Distillation: Epoch : 5, Loss : 0.323775, Accuracy: 0.900000, Test accuracy: 0.908200
Distillation: Epoch : 6, Loss : 0.311737, Accuracy: 0.907000, Test accuracy: 0.911100
Distillation: Epoch : 7, Loss : 0.329900, Accuracy: 0.900000, Test accuracy: 0.913300
Distillation: Epoch : 8, Loss : 0.357303, Accuracy: 0.911000, Test accuracy: 0.914500
Distillation: Epoch : 9, Loss : 0.242232, Accuracy: 0.927000, Test accuracy: 0.917000
Distillation: Epoch : 10, Loss : 0.311033, Accuracy: 0.916000, Test accuracy: 0.917400
Distillation: Epoch : 11, Loss : 0.274626, Accuracy: 0.914000, Test accuracy: 0.919700
Distillation: Epoch : 12, Loss : 0.265505, Accuracy: 0.934000, Test accuracy: 0.919300
Distillation: Epoch : 13, Loss : 0.251609, Accuracy: 0.929000, Test accuracy: 0.920200
Distillation: Epoch : 14, Loss : 0.295588, Accuracy: 0.911000, Test accuracy: 0.922100
Distillation: Epoch : 15, Loss : 0.295103, Accuracy: 0.919000, Test accuracy: 0.922900
Distillation: Epoch : 16, Loss : 0.261094, Accuracy: 0.922000, Test accuracy: 0.922300
Distillation: Epoch : 17, Loss : 0.267090, Accuracy: 0.926000, Test accuracy: 0.924900
Distillation: Epoch : 18, Loss : 0.276588, Accuracy: 0.925000, Test accuracy: 0.924600
Distillation: Epoch : 19, Loss : 0.328310, Accuracy: 0.904000, Test accuracy: 0.925600
Distillation: Epoch : 20, Loss : 0.291416, Accuracy: 0.920000, Test accuracy: 0.925200
Distillation: Epoch : 21, Loss : 0.240824, Accuracy: 0.930000, Test accuracy: 0.926500
Distillation: Epoch : 22, Loss : 0.239580, Accuracy: 0.936000, Test accuracy: 0.926400
Distillation: Epoch : 23, Loss : 0.243883, Accuracy: 0.933000, Test accuracy: 0.928200
Distillation: Epoch : 24, Loss : 0.234831, Accuracy: 0.945000, Test accuracy: 0.928700
Distillation: Epoch : 25, Loss : 0.211144, Accuracy: 0.935000, Test accuracy: 0.928800
Distillation: Epoch : 26, Loss : 0.293942, Accuracy: 0.908000, Test accuracy: 0.930200
Distillation: Epoch : 27, Loss : 0.244680, Accuracy: 0.930000, Test accuracy: 0.931700
Distillation: Epoch : 28, Loss : 0.218112, Accuracy: 0.946000, Test accuracy: 0.932200
Distillation: Epoch : 29, Loss : 0.210240, Accuracy: 0.941000, Test accuracy: 0.934000
Distillation: Epoch : 30, Loss : 0.209358, Accuracy: 0.943000, Test accuracy: 0.936600
Distillation: Epoch : 31, Loss : 0.244839, Accuracy: 0.933000, Test accuracy: 0.937000
Distillation: Epoch : 32, Loss : 0.206634, Accuracy: 0.938000, Test accuracy: 0.937900
Distillation: Epoch : 33, Loss : 0.209348, Accuracy: 0.950000, Test accuracy: 0.938800
Distillation: Epoch : 34, Loss : 0.192133, Accuracy: 0.942000, Test accuracy: 0.942700
Distillation: Epoch : 35, Loss : 0.199360, Accuracy: 0.941000, Test accuracy: 0.942400
Distillation: Epoch : 36, Loss : 0.195350, Accuracy: 0.948000, Test accuracy: 0.945600
Distillation: Epoch : 37, Loss : 0.164576, Accuracy: 0.959000, Test accuracy: 0.947600
Distillation: Epoch : 38, Loss : 0.177534, Accuracy: 0.957000, Test accuracy: 0.948800
Distillation: Epoch : 39, Loss : 0.185703, Accuracy: 0.949000, Test accuracy: 0.952200
Distillation: Epoch : 40, Loss : 0.152661, Accuracy: 0.953000, Test accuracy: 0.952900
Distillation: Epoch : 41, Loss : 0.152317, Accuracy: 0.954000, Test accuracy: 0.953800
Distillation: Epoch : 42, Loss : 0.189602, Accuracy: 0.950000, Test accuracy: 0.956900
Distillation: Epoch : 43, Loss : 0.152156, Accuracy: 0.955000, Test accuracy: 0.957500
Distillation: Epoch : 44, Loss : 0.148865, Accuracy: 0.958000, Test accuracy: 0.958100
Distillation: Epoch : 45, Loss : 0.161684, Accuracy: 0.956000, Test accuracy: 0.958500
Distillation: Epoch : 46, Loss : 0.159889, Accuracy: 0.958000, Test accuracy: 0.959500
Distillation: Epoch : 47, Loss : 0.143565, Accuracy: 0.963000, Test accuracy: 0.961300
Distillation: Epoch : 48, Loss : 0.129333, Accuracy: 0.964000, Test accuracy: 0.961600
Distillation: Epoch : 49, Loss : 0.087441, Accuracy: 0.973000, Test accuracy: 0.963000
Distillation: Epoch : 50, Loss : 0.116300, Accuracy: 0.967000, Test accuracy: 0.963300
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9633
Generating confusion matrix for student4
[[ 963.    0.    3.    0.    1.    2.    8.    2.    5.    6.]
 [   0. 1118.    7.    0.    2.    1.    3.    5.    1.    6.]
 [   2.    4.  983.    9.    2.    0.    1.   17.    8.    0.]
 [   0.    2.    9.  979.    0.   11.    0.   14.   14.    9.]
 [   0.    0.    5.    0.  947.    1.    4.    1.    5.   12.]
 [   2.    0.    1.    5.    0.  863.    5.    0.    7.    6.]
 [   6.    3.    1.    0.    6.    4.  931.    0.    5.    0.]
 [   3.    1.   11.    9.    3.    1.    0.  976.    7.   10.]
 [   4.    7.   10.    4.    3.    6.    6.    1.  915.    2.]
 [   0.    0.    2.    4.   18.    3.    0.   12.    7.  958.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.921671, Accuracy: 0.795000, Test accuracy: 0.808800
Distillation: Epoch : 2, Loss : 0.489476, Accuracy: 0.864000, Test accuracy: 0.878800
Distillation: Epoch : 3, Loss : 0.376919, Accuracy: 0.897000, Test accuracy: 0.893900
Distillation: Epoch : 4, Loss : 0.407369, Accuracy: 0.886000, Test accuracy: 0.899200
Distillation: Epoch : 5, Loss : 0.327752, Accuracy: 0.914000, Test accuracy: 0.904800
Distillation: Epoch : 6, Loss : 0.287738, Accuracy: 0.920000, Test accuracy: 0.908100
Distillation: Epoch : 7, Loss : 0.313044, Accuracy: 0.916000, Test accuracy: 0.909300
Distillation: Epoch : 8, Loss : 0.290544, Accuracy: 0.914000, Test accuracy: 0.912200
Distillation: Epoch : 9, Loss : 0.326097, Accuracy: 0.907000, Test accuracy: 0.912900
Distillation: Epoch : 10, Loss : 0.275613, Accuracy: 0.931000, Test accuracy: 0.914500
Distillation: Epoch : 11, Loss : 0.283580, Accuracy: 0.917000, Test accuracy: 0.915700
Distillation: Epoch : 12, Loss : 0.319118, Accuracy: 0.914000, Test accuracy: 0.917600
Distillation: Epoch : 13, Loss : 0.302251, Accuracy: 0.927000, Test accuracy: 0.919700
Distillation: Epoch : 14, Loss : 0.270709, Accuracy: 0.928000, Test accuracy: 0.919900
Distillation: Epoch : 15, Loss : 0.299194, Accuracy: 0.921000, Test accuracy: 0.922600
Distillation: Epoch : 16, Loss : 0.268470, Accuracy: 0.935000, Test accuracy: 0.924100
Distillation: Epoch : 17, Loss : 0.241663, Accuracy: 0.934000, Test accuracy: 0.926100
Distillation: Epoch : 18, Loss : 0.282931, Accuracy: 0.920000, Test accuracy: 0.927800
Distillation: Epoch : 19, Loss : 0.246804, Accuracy: 0.925000, Test accuracy: 0.929800
Distillation: Epoch : 20, Loss : 0.257410, Accuracy: 0.932000, Test accuracy: 0.931100
Distillation: Epoch : 21, Loss : 0.198986, Accuracy: 0.944000, Test accuracy: 0.932800
Distillation: Epoch : 22, Loss : 0.245956, Accuracy: 0.935000, Test accuracy: 0.936200
Distillation: Epoch : 23, Loss : 0.205042, Accuracy: 0.946000, Test accuracy: 0.938700
Distillation: Epoch : 24, Loss : 0.247445, Accuracy: 0.937000, Test accuracy: 0.939600
Distillation: Epoch : 25, Loss : 0.232523, Accuracy: 0.944000, Test accuracy: 0.941600
Distillation: Epoch : 26, Loss : 0.245866, Accuracy: 0.937000, Test accuracy: 0.942500
Distillation: Epoch : 27, Loss : 0.208727, Accuracy: 0.949000, Test accuracy: 0.945700
Distillation: Epoch : 28, Loss : 0.179123, Accuracy: 0.956000, Test accuracy: 0.947100
Distillation: Epoch : 29, Loss : 0.226514, Accuracy: 0.938000, Test accuracy: 0.948700
Distillation: Epoch : 30, Loss : 0.188335, Accuracy: 0.945000, Test accuracy: 0.950700
Distillation: Epoch : 31, Loss : 0.206954, Accuracy: 0.949000, Test accuracy: 0.952000
Distillation: Epoch : 32, Loss : 0.197452, Accuracy: 0.947000, Test accuracy: 0.952100
Distillation: Epoch : 33, Loss : 0.174145, Accuracy: 0.956000, Test accuracy: 0.954500
Distillation: Epoch : 34, Loss : 0.213561, Accuracy: 0.934000, Test accuracy: 0.955800
Distillation: Epoch : 35, Loss : 0.179839, Accuracy: 0.957000, Test accuracy: 0.956600
Distillation: Epoch : 36, Loss : 0.168247, Accuracy: 0.957000, Test accuracy: 0.957700
Distillation: Epoch : 37, Loss : 0.198677, Accuracy: 0.957000, Test accuracy: 0.959200
Distillation: Epoch : 38, Loss : 0.168166, Accuracy: 0.956000, Test accuracy: 0.958700
Distillation: Epoch : 39, Loss : 0.162221, Accuracy: 0.955000, Test accuracy: 0.960700
Distillation: Epoch : 40, Loss : 0.162372, Accuracy: 0.966000, Test accuracy: 0.960800
Distillation: Epoch : 41, Loss : 0.177492, Accuracy: 0.957000, Test accuracy: 0.962200
Distillation: Epoch : 42, Loss : 0.151649, Accuracy: 0.963000, Test accuracy: 0.962600
Distillation: Epoch : 43, Loss : 0.188116, Accuracy: 0.962000, Test accuracy: 0.961900
Distillation: Epoch : 44, Loss : 0.174041, Accuracy: 0.960000, Test accuracy: 0.963900
Distillation: Epoch : 45, Loss : 0.116637, Accuracy: 0.969000, Test accuracy: 0.963900
Distillation: Epoch : 46, Loss : 0.134140, Accuracy: 0.967000, Test accuracy: 0.964600
Distillation: Epoch : 47, Loss : 0.165221, Accuracy: 0.969000, Test accuracy: 0.964300
Distillation: Epoch : 48, Loss : 0.162450, Accuracy: 0.958000, Test accuracy: 0.964800
Distillation: Epoch : 49, Loss : 0.134955, Accuracy: 0.966000, Test accuracy: 0.966100
Distillation: Epoch : 50, Loss : 0.161511, Accuracy: 0.956000, Test accuracy: 0.966100
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9661
Generating confusion matrix for student4
[[ 966.    0.    4.    0.    1.    1.    7.    1.    9.    7.]
 [   0. 1117.    7.    0.    1.    2.    3.    7.    3.    7.]
 [   1.    3.  994.    8.    3.    2.    1.   17.    7.    1.]
 [   0.    1.    4.  979.    0.   12.    0.    3.    9.    6.]
 [   0.    0.    6.    0.  957.    0.    5.    0.    8.   16.]
 [   2.    0.    1.    8.    0.  857.    3.    0.    4.    3.]
 [   5.    6.    2.    0.    3.    6.  933.    0.    5.    1.]
 [   2.    1.    5.    3.    3.    2.    0.  983.    7.    9.]
 [   4.    7.    8.    9.    1.    4.    6.    2.  916.    0.]
 [   0.    0.    1.    3.   13.    6.    0.   15.    6.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.437149, Accuracy: 0.775000, Test accuracy: 0.773500
Distillation: Epoch : 2, Loss : 0.752352, Accuracy: 0.861000, Test accuracy: 0.871000
Distillation: Epoch : 3, Loss : 0.674643, Accuracy: 0.888000, Test accuracy: 0.889500
Distillation: Epoch : 4, Loss : 0.651114, Accuracy: 0.887000, Test accuracy: 0.900400
Distillation: Epoch : 5, Loss : 0.626083, Accuracy: 0.911000, Test accuracy: 0.905200
Distillation: Epoch : 6, Loss : 0.633840, Accuracy: 0.898000, Test accuracy: 0.908100
Distillation: Epoch : 7, Loss : 0.604962, Accuracy: 0.900000, Test accuracy: 0.914400
Distillation: Epoch : 8, Loss : 0.614423, Accuracy: 0.897000, Test accuracy: 0.917300
Distillation: Epoch : 9, Loss : 0.612534, Accuracy: 0.903000, Test accuracy: 0.918900
Distillation: Epoch : 10, Loss : 0.567555, Accuracy: 0.936000, Test accuracy: 0.923100
Distillation: Epoch : 11, Loss : 0.577826, Accuracy: 0.918000, Test accuracy: 0.925900
Distillation: Epoch : 12, Loss : 0.553612, Accuracy: 0.932000, Test accuracy: 0.928700
Distillation: Epoch : 13, Loss : 0.561076, Accuracy: 0.919000, Test accuracy: 0.931300
Distillation: Epoch : 14, Loss : 0.520403, Accuracy: 0.933000, Test accuracy: 0.934800
Distillation: Epoch : 15, Loss : 0.549033, Accuracy: 0.923000, Test accuracy: 0.936200
Distillation: Epoch : 16, Loss : 0.503580, Accuracy: 0.938000, Test accuracy: 0.939900
Distillation: Epoch : 17, Loss : 0.562284, Accuracy: 0.926000, Test accuracy: 0.943500
Distillation: Epoch : 18, Loss : 0.517668, Accuracy: 0.932000, Test accuracy: 0.944800
Distillation: Epoch : 19, Loss : 0.499297, Accuracy: 0.941000, Test accuracy: 0.946600
Distillation: Epoch : 20, Loss : 0.469421, Accuracy: 0.951000, Test accuracy: 0.950000
Distillation: Epoch : 21, Loss : 0.512002, Accuracy: 0.935000, Test accuracy: 0.950900
Distillation: Epoch : 22, Loss : 0.493069, Accuracy: 0.947000, Test accuracy: 0.951200
Distillation: Epoch : 23, Loss : 0.504144, Accuracy: 0.943000, Test accuracy: 0.952800
Distillation: Epoch : 24, Loss : 0.445086, Accuracy: 0.950000, Test accuracy: 0.953500
Distillation: Epoch : 25, Loss : 0.450742, Accuracy: 0.957000, Test accuracy: 0.954900
Distillation: Epoch : 26, Loss : 0.453261, Accuracy: 0.947000, Test accuracy: 0.955200
Distillation: Epoch : 27, Loss : 0.473940, Accuracy: 0.947000, Test accuracy: 0.956800
Distillation: Epoch : 28, Loss : 0.466594, Accuracy: 0.943000, Test accuracy: 0.957300
Distillation: Epoch : 29, Loss : 0.472099, Accuracy: 0.953000, Test accuracy: 0.956600
Distillation: Epoch : 30, Loss : 0.465044, Accuracy: 0.953000, Test accuracy: 0.957700
Distillation: Epoch : 31, Loss : 0.447121, Accuracy: 0.948000, Test accuracy: 0.959800
Distillation: Epoch : 32, Loss : 0.448037, Accuracy: 0.973000, Test accuracy: 0.959300
Distillation: Epoch : 33, Loss : 0.444559, Accuracy: 0.958000, Test accuracy: 0.959900
Distillation: Epoch : 34, Loss : 0.448943, Accuracy: 0.958000, Test accuracy: 0.960000
Distillation: Epoch : 35, Loss : 0.432768, Accuracy: 0.971000, Test accuracy: 0.961600
Distillation: Epoch : 36, Loss : 0.440566, Accuracy: 0.958000, Test accuracy: 0.962100
Distillation: Epoch : 37, Loss : 0.424878, Accuracy: 0.959000, Test accuracy: 0.962000
Distillation: Epoch : 38, Loss : 0.446429, Accuracy: 0.960000, Test accuracy: 0.961800
Distillation: Epoch : 39, Loss : 0.428296, Accuracy: 0.952000, Test accuracy: 0.962000
Distillation: Epoch : 40, Loss : 0.436270, Accuracy: 0.973000, Test accuracy: 0.962700
Distillation: Epoch : 41, Loss : 0.448533, Accuracy: 0.952000, Test accuracy: 0.963000
Distillation: Epoch : 42, Loss : 0.444518, Accuracy: 0.964000, Test accuracy: 0.963700
Distillation: Epoch : 43, Loss : 0.444816, Accuracy: 0.962000, Test accuracy: 0.963000
Distillation: Epoch : 44, Loss : 0.435008, Accuracy: 0.960000, Test accuracy: 0.963600
Distillation: Epoch : 45, Loss : 0.440807, Accuracy: 0.959000, Test accuracy: 0.964800
Distillation: Epoch : 46, Loss : 0.437280, Accuracy: 0.968000, Test accuracy: 0.965200
Distillation: Epoch : 47, Loss : 0.427974, Accuracy: 0.966000, Test accuracy: 0.964800
Distillation: Epoch : 48, Loss : 0.451431, Accuracy: 0.960000, Test accuracy: 0.964600
Distillation: Epoch : 49, Loss : 0.446333, Accuracy: 0.958000, Test accuracy: 0.965200
Distillation: Epoch : 50, Loss : 0.439382, Accuracy: 0.957000, Test accuracy: 0.964700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9647
Generating confusion matrix for student4
[[ 967.    0.    6.    1.    0.    1.    7.    2.    7.    5.]
 [   1. 1118.    6.    0.    0.    1.    2.    2.    0.    6.]
 [   2.    2.  980.    4.    4.    1.    1.   21.    5.    1.]
 [   0.    1.    3.  979.    0.   14.    0.   10.    3.   12.]
 [   0.    2.    3.    1.  963.    1.    4.    2.    5.   10.]
 [   1.    0.    0.    4.    0.  846.    5.    1.    5.    8.]
 [   3.    3.    3.    0.    2.    4.  935.    0.    1.    0.]
 [   1.    1.    2.    4.    0.    1.    0.  962.    1.    8.]
 [   4.    7.   28.   14.    4.   22.    4.    5.  941.    3.]
 [   1.    1.    1.    3.    9.    1.    0.   23.    6.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.227631, Accuracy: 0.803000, Test accuracy: 0.802800
Distillation: Epoch : 2, Loss : 0.859553, Accuracy: 0.863000, Test accuracy: 0.877300
Distillation: Epoch : 3, Loss : 0.836587, Accuracy: 0.880000, Test accuracy: 0.890700
Distillation: Epoch : 4, Loss : 0.776454, Accuracy: 0.899000, Test accuracy: 0.899200
Distillation: Epoch : 5, Loss : 0.792561, Accuracy: 0.907000, Test accuracy: 0.903300
Distillation: Epoch : 6, Loss : 0.802097, Accuracy: 0.891000, Test accuracy: 0.907300
Distillation: Epoch : 7, Loss : 0.771254, Accuracy: 0.902000, Test accuracy: 0.908900
Distillation: Epoch : 8, Loss : 0.745121, Accuracy: 0.909000, Test accuracy: 0.912000
Distillation: Epoch : 9, Loss : 0.726982, Accuracy: 0.911000, Test accuracy: 0.912100
Distillation: Epoch : 10, Loss : 0.740743, Accuracy: 0.899000, Test accuracy: 0.913700
Distillation: Epoch : 11, Loss : 0.738121, Accuracy: 0.916000, Test accuracy: 0.915300
Distillation: Epoch : 12, Loss : 0.771042, Accuracy: 0.908000, Test accuracy: 0.916400
Distillation: Epoch : 13, Loss : 0.750355, Accuracy: 0.919000, Test accuracy: 0.916900
Distillation: Epoch : 14, Loss : 0.731192, Accuracy: 0.922000, Test accuracy: 0.917500
Distillation: Epoch : 15, Loss : 0.744717, Accuracy: 0.920000, Test accuracy: 0.918700
Distillation: Epoch : 16, Loss : 0.732255, Accuracy: 0.925000, Test accuracy: 0.919500
Distillation: Epoch : 17, Loss : 0.731778, Accuracy: 0.907000, Test accuracy: 0.922500
Distillation: Epoch : 18, Loss : 0.732035, Accuracy: 0.903000, Test accuracy: 0.922100
Distillation: Epoch : 19, Loss : 0.740802, Accuracy: 0.927000, Test accuracy: 0.923600
Distillation: Epoch : 20, Loss : 0.717015, Accuracy: 0.927000, Test accuracy: 0.925900
Distillation: Epoch : 21, Loss : 0.674688, Accuracy: 0.930000, Test accuracy: 0.926600
Distillation: Epoch : 22, Loss : 0.711322, Accuracy: 0.927000, Test accuracy: 0.930100
Distillation: Epoch : 23, Loss : 0.742302, Accuracy: 0.923000, Test accuracy: 0.932300
Distillation: Epoch : 24, Loss : 0.706262, Accuracy: 0.937000, Test accuracy: 0.933900
Distillation: Epoch : 25, Loss : 0.674745, Accuracy: 0.942000, Test accuracy: 0.935400
Distillation: Epoch : 26, Loss : 0.683269, Accuracy: 0.932000, Test accuracy: 0.937200
Distillation: Epoch : 27, Loss : 0.651153, Accuracy: 0.946000, Test accuracy: 0.939000
Distillation: Epoch : 28, Loss : 0.656299, Accuracy: 0.941000, Test accuracy: 0.940900
Distillation: Epoch : 29, Loss : 0.681975, Accuracy: 0.937000, Test accuracy: 0.943000
Distillation: Epoch : 30, Loss : 0.646242, Accuracy: 0.948000, Test accuracy: 0.944200
Distillation: Epoch : 31, Loss : 0.654731, Accuracy: 0.946000, Test accuracy: 0.946300
Distillation: Epoch : 32, Loss : 0.670505, Accuracy: 0.943000, Test accuracy: 0.948900
Distillation: Epoch : 33, Loss : 0.645034, Accuracy: 0.952000, Test accuracy: 0.950700
Distillation: Epoch : 34, Loss : 0.650019, Accuracy: 0.946000, Test accuracy: 0.951400
Distillation: Epoch : 35, Loss : 0.634491, Accuracy: 0.948000, Test accuracy: 0.952400
Distillation: Epoch : 36, Loss : 0.673943, Accuracy: 0.930000, Test accuracy: 0.954100
Distillation: Epoch : 37, Loss : 0.615707, Accuracy: 0.960000, Test accuracy: 0.955200
Distillation: Epoch : 38, Loss : 0.606130, Accuracy: 0.961000, Test accuracy: 0.955400
Distillation: Epoch : 39, Loss : 0.617411, Accuracy: 0.962000, Test accuracy: 0.956400
Distillation: Epoch : 40, Loss : 0.662654, Accuracy: 0.946000, Test accuracy: 0.957700
Distillation: Epoch : 41, Loss : 0.620339, Accuracy: 0.958000, Test accuracy: 0.957700
Distillation: Epoch : 42, Loss : 0.617947, Accuracy: 0.967000, Test accuracy: 0.958700
Distillation: Epoch : 43, Loss : 0.635547, Accuracy: 0.945000, Test accuracy: 0.958100
Distillation: Epoch : 44, Loss : 0.629897, Accuracy: 0.956000, Test accuracy: 0.959300
Distillation: Epoch : 45, Loss : 0.613564, Accuracy: 0.958000, Test accuracy: 0.959400
Distillation: Epoch : 46, Loss : 0.637003, Accuracy: 0.948000, Test accuracy: 0.960900
Distillation: Epoch : 47, Loss : 0.638612, Accuracy: 0.952000, Test accuracy: 0.960900
Distillation: Epoch : 48, Loss : 0.618466, Accuracy: 0.953000, Test accuracy: 0.962600
Distillation: Epoch : 49, Loss : 0.623630, Accuracy: 0.943000, Test accuracy: 0.961000
Distillation: Epoch : 50, Loss : 0.647136, Accuracy: 0.946000, Test accuracy: 0.962200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9622
Generating confusion matrix for student4
[[ 962.    1.    4.    0.    1.    2.    5.    2.    6.    5.]
 [   1. 1115.    3.    0.    3.    1.    3.    6.    5.    6.]
 [   1.    3.  982.    7.    1.    0.    0.   15.    4.    1.]
 [   0.    3.    2.  976.    0.    8.    1.    5.    5.    2.]
 [   0.    1.   11.    1.  957.    0.    6.    5.    8.   23.]
 [   1.    0.    1.    6.    0.  850.    3.    0.    3.    2.]
 [   9.    3.    3.    0.    5.    5.  933.    0.    7.    0.]
 [   1.    0.    9.    5.    1.    2.    0.  963.    6.    8.]
 [   3.    9.   14.   10.    5.   16.    7.    5.  925.    3.]
 [   2.    0.    3.    5.    9.    8.    0.   27.    5.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.423271, Accuracy: 0.751000, Test accuracy: 0.779800
Distillation: Epoch : 2, Loss : 1.027896, Accuracy: 0.882000, Test accuracy: 0.873500
Distillation: Epoch : 3, Loss : 1.004656, Accuracy: 0.890000, Test accuracy: 0.890700
Distillation: Epoch : 4, Loss : 0.939244, Accuracy: 0.884000, Test accuracy: 0.895900
Distillation: Epoch : 5, Loss : 0.972380, Accuracy: 0.881000, Test accuracy: 0.899800
Distillation: Epoch : 6, Loss : 0.923281, Accuracy: 0.909000, Test accuracy: 0.901900
Distillation: Epoch : 7, Loss : 0.958881, Accuracy: 0.893000, Test accuracy: 0.904400
Distillation: Epoch : 8, Loss : 0.963556, Accuracy: 0.877000, Test accuracy: 0.907000
Distillation: Epoch : 9, Loss : 0.917848, Accuracy: 0.884000, Test accuracy: 0.906900
Distillation: Epoch : 10, Loss : 0.923679, Accuracy: 0.904000, Test accuracy: 0.908200
Distillation: Epoch : 11, Loss : 0.931014, Accuracy: 0.904000, Test accuracy: 0.910300
Distillation: Epoch : 12, Loss : 0.931504, Accuracy: 0.898000, Test accuracy: 0.908700
Distillation: Epoch : 13, Loss : 0.953246, Accuracy: 0.882000, Test accuracy: 0.910400
Distillation: Epoch : 14, Loss : 0.897588, Accuracy: 0.911000, Test accuracy: 0.913000
Distillation: Epoch : 15, Loss : 0.925970, Accuracy: 0.903000, Test accuracy: 0.913100
Distillation: Epoch : 16, Loss : 0.923291, Accuracy: 0.908000, Test accuracy: 0.914900
Distillation: Epoch : 17, Loss : 0.895676, Accuracy: 0.932000, Test accuracy: 0.913600
Distillation: Epoch : 18, Loss : 0.918917, Accuracy: 0.886000, Test accuracy: 0.914800
Distillation: Epoch : 19, Loss : 0.911413, Accuracy: 0.909000, Test accuracy: 0.913400
Distillation: Epoch : 20, Loss : 0.923377, Accuracy: 0.894000, Test accuracy: 0.915300
Distillation: Epoch : 21, Loss : 0.900670, Accuracy: 0.919000, Test accuracy: 0.916600
Distillation: Epoch : 22, Loss : 0.926745, Accuracy: 0.900000, Test accuracy: 0.916600
Distillation: Epoch : 23, Loss : 0.899815, Accuracy: 0.914000, Test accuracy: 0.917800
Distillation: Epoch : 24, Loss : 0.925551, Accuracy: 0.905000, Test accuracy: 0.916000
Distillation: Epoch : 25, Loss : 0.902296, Accuracy: 0.898000, Test accuracy: 0.916100
Distillation: Epoch : 26, Loss : 0.875782, Accuracy: 0.917000, Test accuracy: 0.917700
Distillation: Epoch : 27, Loss : 0.876319, Accuracy: 0.906000, Test accuracy: 0.917100
Distillation: Epoch : 28, Loss : 0.904281, Accuracy: 0.909000, Test accuracy: 0.917500
Distillation: Epoch : 29, Loss : 0.889739, Accuracy: 0.916000, Test accuracy: 0.918200
Distillation: Epoch : 30, Loss : 0.891933, Accuracy: 0.911000, Test accuracy: 0.918100
Distillation: Epoch : 31, Loss : 0.873828, Accuracy: 0.918000, Test accuracy: 0.919100
Distillation: Epoch : 32, Loss : 0.876516, Accuracy: 0.914000, Test accuracy: 0.920000
Distillation: Epoch : 33, Loss : 0.904718, Accuracy: 0.906000, Test accuracy: 0.919500
Distillation: Epoch : 34, Loss : 0.891812, Accuracy: 0.928000, Test accuracy: 0.919100
Distillation: Epoch : 35, Loss : 0.903921, Accuracy: 0.914000, Test accuracy: 0.919900
Distillation: Epoch : 36, Loss : 0.872526, Accuracy: 0.925000, Test accuracy: 0.919600
Distillation: Epoch : 37, Loss : 0.897556, Accuracy: 0.917000, Test accuracy: 0.920300
Distillation: Epoch : 38, Loss : 0.907585, Accuracy: 0.913000, Test accuracy: 0.920700
Distillation: Epoch : 39, Loss : 0.879693, Accuracy: 0.924000, Test accuracy: 0.921200
Distillation: Epoch : 40, Loss : 0.896283, Accuracy: 0.917000, Test accuracy: 0.920600
Distillation: Epoch : 41, Loss : 0.881559, Accuracy: 0.914000, Test accuracy: 0.922400
Distillation: Epoch : 42, Loss : 0.879517, Accuracy: 0.913000, Test accuracy: 0.923400
Distillation: Epoch : 43, Loss : 0.892876, Accuracy: 0.914000, Test accuracy: 0.923800
Distillation: Epoch : 44, Loss : 0.869951, Accuracy: 0.919000, Test accuracy: 0.921800
Distillation: Epoch : 45, Loss : 0.843358, Accuracy: 0.913000, Test accuracy: 0.923300
Distillation: Epoch : 46, Loss : 0.871533, Accuracy: 0.917000, Test accuracy: 0.923700
Distillation: Epoch : 47, Loss : 0.902656, Accuracy: 0.911000, Test accuracy: 0.922900
Distillation: Epoch : 48, Loss : 0.897670, Accuracy: 0.917000, Test accuracy: 0.924300
Distillation: Epoch : 49, Loss : 0.878230, Accuracy: 0.918000, Test accuracy: 0.925000
Distillation: Epoch : 50, Loss : 0.883514, Accuracy: 0.915000, Test accuracy: 0.924200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9242
Generating confusion matrix for student4
[[ 956.    0.    9.    4.    1.    8.    8.    2.    7.    7.]
 [   0. 1102.    5.    2.    1.    2.    4.   11.    6.    7.]
 [   0.    3.  903.   16.    3.    1.    4.   20.    5.    0.]
 [   1.    3.   24.  929.    1.   27.    1.    8.   11.   11.]
 [   3.    1.   16.    4.  930.   12.    8.   15.    8.   46.]
 [   4.    3.    1.   15.    0.  781.   13.    1.   16.    7.]
 [   9.    4.   12.    3.    9.   12.  917.    1.    7.    1.]
 [   1.    0.   10.    7.    1.    6.    0.  911.    4.   10.]
 [   5.   19.   46.   25.   10.   35.    3.    2.  904.   11.]
 [   1.    0.    6.    5.   26.    8.    0.   57.    6.  909.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.019691, Accuracy: 0.578000, Test accuracy: 0.598500
Distillation: Epoch : 2, Loss : 1.213132, Accuracy: 0.844000, Test accuracy: 0.845700
Distillation: Epoch : 3, Loss : 1.143786, Accuracy: 0.879000, Test accuracy: 0.877500
Distillation: Epoch : 4, Loss : 1.118994, Accuracy: 0.874000, Test accuracy: 0.894400
Distillation: Epoch : 5, Loss : 1.112815, Accuracy: 0.896000, Test accuracy: 0.908000
Distillation: Epoch : 6, Loss : 1.055689, Accuracy: 0.905000, Test accuracy: 0.917200
Distillation: Epoch : 7, Loss : 1.028370, Accuracy: 0.924000, Test accuracy: 0.921300
Distillation: Epoch : 8, Loss : 1.043225, Accuracy: 0.917000, Test accuracy: 0.925400
Distillation: Epoch : 9, Loss : 1.007771, Accuracy: 0.923000, Test accuracy: 0.930300
Distillation: Epoch : 10, Loss : 1.055826, Accuracy: 0.909000, Test accuracy: 0.931400
Distillation: Epoch : 11, Loss : 1.065462, Accuracy: 0.916000, Test accuracy: 0.934700
Distillation: Epoch : 12, Loss : 1.010612, Accuracy: 0.930000, Test accuracy: 0.937800
Distillation: Epoch : 13, Loss : 1.004320, Accuracy: 0.941000, Test accuracy: 0.939800
Distillation: Epoch : 14, Loss : 0.979474, Accuracy: 0.938000, Test accuracy: 0.941300
Distillation: Epoch : 15, Loss : 0.978976, Accuracy: 0.949000, Test accuracy: 0.942300
Distillation: Epoch : 16, Loss : 1.003962, Accuracy: 0.943000, Test accuracy: 0.944100
Distillation: Epoch : 17, Loss : 0.974911, Accuracy: 0.958000, Test accuracy: 0.945400
Distillation: Epoch : 18, Loss : 0.989370, Accuracy: 0.941000, Test accuracy: 0.946900
Distillation: Epoch : 19, Loss : 1.002214, Accuracy: 0.946000, Test accuracy: 0.949000
Distillation: Epoch : 20, Loss : 1.001912, Accuracy: 0.940000, Test accuracy: 0.949500
Distillation: Epoch : 21, Loss : 0.969907, Accuracy: 0.950000, Test accuracy: 0.949100
Distillation: Epoch : 22, Loss : 0.968673, Accuracy: 0.947000, Test accuracy: 0.951800
Distillation: Epoch : 23, Loss : 0.983567, Accuracy: 0.952000, Test accuracy: 0.952300
Distillation: Epoch : 24, Loss : 0.969713, Accuracy: 0.946000, Test accuracy: 0.954000
Distillation: Epoch : 25, Loss : 0.937073, Accuracy: 0.951000, Test accuracy: 0.952900
Distillation: Epoch : 26, Loss : 0.984989, Accuracy: 0.949000, Test accuracy: 0.956400
Distillation: Epoch : 27, Loss : 0.954161, Accuracy: 0.953000, Test accuracy: 0.956900
Distillation: Epoch : 28, Loss : 0.976170, Accuracy: 0.954000, Test accuracy: 0.957800
Distillation: Epoch : 29, Loss : 0.953603, Accuracy: 0.963000, Test accuracy: 0.959800
Distillation: Epoch : 30, Loss : 0.934904, Accuracy: 0.965000, Test accuracy: 0.959300
Distillation: Epoch : 31, Loss : 0.956259, Accuracy: 0.946000, Test accuracy: 0.960700
Distillation: Epoch : 32, Loss : 0.967262, Accuracy: 0.955000, Test accuracy: 0.960900
Distillation: Epoch : 33, Loss : 0.931711, Accuracy: 0.964000, Test accuracy: 0.961700
Distillation: Epoch : 34, Loss : 0.970451, Accuracy: 0.946000, Test accuracy: 0.960800
Distillation: Epoch : 35, Loss : 0.949734, Accuracy: 0.959000, Test accuracy: 0.961100
Distillation: Epoch : 36, Loss : 0.963391, Accuracy: 0.951000, Test accuracy: 0.961200
Distillation: Epoch : 37, Loss : 0.906530, Accuracy: 0.983000, Test accuracy: 0.961700
Distillation: Epoch : 38, Loss : 0.934371, Accuracy: 0.955000, Test accuracy: 0.963300
Distillation: Epoch : 39, Loss : 0.940945, Accuracy: 0.954000, Test accuracy: 0.962600
Distillation: Epoch : 40, Loss : 0.929275, Accuracy: 0.974000, Test accuracy: 0.964500
Distillation: Epoch : 41, Loss : 0.947937, Accuracy: 0.972000, Test accuracy: 0.964200
Distillation: Epoch : 42, Loss : 0.939801, Accuracy: 0.955000, Test accuracy: 0.964800
Distillation: Epoch : 43, Loss : 0.935257, Accuracy: 0.970000, Test accuracy: 0.964600
Distillation: Epoch : 44, Loss : 0.934190, Accuracy: 0.964000, Test accuracy: 0.965000
Distillation: Epoch : 45, Loss : 0.945268, Accuracy: 0.958000, Test accuracy: 0.964800
Distillation: Epoch : 46, Loss : 0.919626, Accuracy: 0.964000, Test accuracy: 0.965400
Distillation: Epoch : 47, Loss : 0.923731, Accuracy: 0.966000, Test accuracy: 0.966200
Distillation: Epoch : 48, Loss : 0.919699, Accuracy: 0.967000, Test accuracy: 0.966500
Distillation: Epoch : 49, Loss : 0.929595, Accuracy: 0.958000, Test accuracy: 0.966700
Distillation: Epoch : 50, Loss : 0.939937, Accuracy: 0.962000, Test accuracy: 0.966400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9664
Generating confusion matrix for student4
[[ 964.    0.    4.    0.    1.    1.    6.    2.    6.    6.]
 [   1. 1121.    5.    1.    1.    0.    2.    7.    1.    5.]
 [   1.    4.  988.    2.    1.    1.    0.   22.    3.    1.]
 [   0.    2.    7.  982.    0.    7.    0.    6.    5.   12.]
 [   2.    2.    8.    0.  963.    0.    5.    7.    6.   21.]
 [   0.    0.    0.    6.    0.  866.    4.    0.    2.    8.]
 [   3.    2.    2.    0.    4.    5.  934.    0.    3.    0.]
 [   1.    0.    6.    5.    0.    2.    0.  959.    3.    2.]
 [   3.    4.   10.   13.    4.    8.    7.    3.  940.    7.]
 [   5.    0.    2.    1.    8.    2.    0.   22.    5.  947.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.682840, Accuracy: 0.718000, Test accuracy: 0.754500
Distillation: Epoch : 2, Loss : 1.326394, Accuracy: 0.853000, Test accuracy: 0.849800
Distillation: Epoch : 3, Loss : 1.310765, Accuracy: 0.868000, Test accuracy: 0.875100
Distillation: Epoch : 4, Loss : 1.277372, Accuracy: 0.882000, Test accuracy: 0.886000
Distillation: Epoch : 5, Loss : 1.271976, Accuracy: 0.878000, Test accuracy: 0.894000
Distillation: Epoch : 6, Loss : 1.232562, Accuracy: 0.898000, Test accuracy: 0.897700
Distillation: Epoch : 7, Loss : 1.241752, Accuracy: 0.905000, Test accuracy: 0.908100
Distillation: Epoch : 8, Loss : 1.185403, Accuracy: 0.915000, Test accuracy: 0.913300
Distillation: Epoch : 9, Loss : 1.243854, Accuracy: 0.908000, Test accuracy: 0.919100
Distillation: Epoch : 10, Loss : 1.189323, Accuracy: 0.909000, Test accuracy: 0.923800
Distillation: Epoch : 11, Loss : 1.147782, Accuracy: 0.935000, Test accuracy: 0.928700
Distillation: Epoch : 12, Loss : 1.205902, Accuracy: 0.917000, Test accuracy: 0.934000
Distillation: Epoch : 13, Loss : 1.153393, Accuracy: 0.921000, Test accuracy: 0.937400
Distillation: Epoch : 14, Loss : 1.174605, Accuracy: 0.934000, Test accuracy: 0.941200
Distillation: Epoch : 15, Loss : 1.146247, Accuracy: 0.948000, Test accuracy: 0.944200
Distillation: Epoch : 16, Loss : 1.103863, Accuracy: 0.944000, Test accuracy: 0.946600
Distillation: Epoch : 17, Loss : 1.132949, Accuracy: 0.954000, Test accuracy: 0.947100
Distillation: Epoch : 18, Loss : 1.149058, Accuracy: 0.935000, Test accuracy: 0.948400
Distillation: Epoch : 19, Loss : 1.112720, Accuracy: 0.952000, Test accuracy: 0.949700
Distillation: Epoch : 20, Loss : 1.109866, Accuracy: 0.955000, Test accuracy: 0.951900
Distillation: Epoch : 21, Loss : 1.151827, Accuracy: 0.949000, Test accuracy: 0.954000
Distillation: Epoch : 22, Loss : 1.092567, Accuracy: 0.940000, Test accuracy: 0.953700
Distillation: Epoch : 23, Loss : 1.113920, Accuracy: 0.952000, Test accuracy: 0.953900
Distillation: Epoch : 24, Loss : 1.130464, Accuracy: 0.956000, Test accuracy: 0.956000
Distillation: Epoch : 25, Loss : 1.093594, Accuracy: 0.958000, Test accuracy: 0.956500
Distillation: Epoch : 26, Loss : 1.129133, Accuracy: 0.953000, Test accuracy: 0.957100
Distillation: Epoch : 27, Loss : 1.078390, Accuracy: 0.960000, Test accuracy: 0.958300
Distillation: Epoch : 28, Loss : 1.143179, Accuracy: 0.955000, Test accuracy: 0.959400
Distillation: Epoch : 29, Loss : 1.097269, Accuracy: 0.955000, Test accuracy: 0.960500
Distillation: Epoch : 30, Loss : 1.138160, Accuracy: 0.955000, Test accuracy: 0.959600
Distillation: Epoch : 31, Loss : 1.115836, Accuracy: 0.944000, Test accuracy: 0.961400
Distillation: Epoch : 32, Loss : 1.082603, Accuracy: 0.958000, Test accuracy: 0.960900
Distillation: Epoch : 33, Loss : 1.082583, Accuracy: 0.964000, Test accuracy: 0.961500
Distillation: Epoch : 34, Loss : 1.090325, Accuracy: 0.962000, Test accuracy: 0.961200
Distillation: Epoch : 35, Loss : 1.113602, Accuracy: 0.954000, Test accuracy: 0.962700
Distillation: Epoch : 36, Loss : 1.089049, Accuracy: 0.970000, Test accuracy: 0.961800
Distillation: Epoch : 37, Loss : 1.107471, Accuracy: 0.964000, Test accuracy: 0.961400
Distillation: Epoch : 38, Loss : 1.107007, Accuracy: 0.956000, Test accuracy: 0.962200
Distillation: Epoch : 39, Loss : 1.085293, Accuracy: 0.959000, Test accuracy: 0.962500
Distillation: Epoch : 40, Loss : 1.108630, Accuracy: 0.952000, Test accuracy: 0.962900
Distillation: Epoch : 41, Loss : 1.120254, Accuracy: 0.956000, Test accuracy: 0.962500
Distillation: Epoch : 42, Loss : 1.080104, Accuracy: 0.966000, Test accuracy: 0.963100
Distillation: Epoch : 43, Loss : 1.075278, Accuracy: 0.963000, Test accuracy: 0.962800
Distillation: Epoch : 44, Loss : 1.080876, Accuracy: 0.972000, Test accuracy: 0.963200
Distillation: Epoch : 45, Loss : 1.108423, Accuracy: 0.970000, Test accuracy: 0.963700
Distillation: Epoch : 46, Loss : 1.099635, Accuracy: 0.967000, Test accuracy: 0.964600
Distillation: Epoch : 47, Loss : 1.062498, Accuracy: 0.973000, Test accuracy: 0.964400
Distillation: Epoch : 48, Loss : 1.074460, Accuracy: 0.961000, Test accuracy: 0.964400
Distillation: Epoch : 49, Loss : 1.114427, Accuracy: 0.953000, Test accuracy: 0.964700
Distillation: Epoch : 50, Loss : 1.095274, Accuracy: 0.964000, Test accuracy: 0.966400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9664
Generating confusion matrix for student4
[[ 967.    0.    4.    2.    0.    2.    4.    1.    7.    5.]
 [   1. 1110.    6.    0.    0.    0.    2.    4.    1.    4.]
 [   0.    3.  987.    3.    3.    0.    0.   14.    5.    1.]
 [   0.    1.    5.  986.    1.   11.    0.    3.    8.    7.]
 [   2.    1.    4.    0.  959.    1.    3.    1.    6.   11.]
 [   1.    1.    0.    3.    0.  851.   10.    1.    5.    5.]
 [   4.    3.    3.    0.    4.    4.  936.    0.    2.    0.]
 [   3.    1.    5.    5.    0.    0.    0.  976.    3.    7.]
 [   1.   15.   17.    9.    4.   19.    3.    6.  930.    7.]
 [   1.    0.    1.    2.   11.    4.    0.   22.    7.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.711832, Accuracy: 0.764000, Test accuracy: 0.788100
Distillation: Epoch : 2, Loss : 1.443258, Accuracy: 0.862000, Test accuracy: 0.867900
Distillation: Epoch : 3, Loss : 1.432666, Accuracy: 0.868000, Test accuracy: 0.879700
Distillation: Epoch : 4, Loss : 1.401968, Accuracy: 0.879000, Test accuracy: 0.885700
Distillation: Epoch : 5, Loss : 1.383570, Accuracy: 0.896000, Test accuracy: 0.891800
Distillation: Epoch : 6, Loss : 1.376404, Accuracy: 0.896000, Test accuracy: 0.894000
Distillation: Epoch : 7, Loss : 1.373090, Accuracy: 0.874000, Test accuracy: 0.895500
Distillation: Epoch : 8, Loss : 1.368454, Accuracy: 0.890000, Test accuracy: 0.897200
Distillation: Epoch : 9, Loss : 1.381042, Accuracy: 0.901000, Test accuracy: 0.897500
Distillation: Epoch : 10, Loss : 1.382927, Accuracy: 0.894000, Test accuracy: 0.898700
Distillation: Epoch : 11, Loss : 1.380566, Accuracy: 0.893000, Test accuracy: 0.900200
Distillation: Epoch : 12, Loss : 1.339578, Accuracy: 0.896000, Test accuracy: 0.899800
Distillation: Epoch : 13, Loss : 1.370605, Accuracy: 0.900000, Test accuracy: 0.901200
Distillation: Epoch : 14, Loss : 1.375193, Accuracy: 0.895000, Test accuracy: 0.900900
Distillation: Epoch : 15, Loss : 1.395163, Accuracy: 0.895000, Test accuracy: 0.902300
Distillation: Epoch : 16, Loss : 1.382903, Accuracy: 0.897000, Test accuracy: 0.902300
Distillation: Epoch : 17, Loss : 1.340172, Accuracy: 0.900000, Test accuracy: 0.904200
Distillation: Epoch : 18, Loss : 1.382991, Accuracy: 0.879000, Test accuracy: 0.904100
Distillation: Epoch : 19, Loss : 1.337280, Accuracy: 0.891000, Test accuracy: 0.902200
Distillation: Epoch : 20, Loss : 1.354467, Accuracy: 0.902000, Test accuracy: 0.905600
Distillation: Epoch : 21, Loss : 1.350158, Accuracy: 0.920000, Test accuracy: 0.903600
Distillation: Epoch : 22, Loss : 1.359637, Accuracy: 0.899000, Test accuracy: 0.905200
Distillation: Epoch : 23, Loss : 1.366042, Accuracy: 0.898000, Test accuracy: 0.904800
Distillation: Epoch : 24, Loss : 1.376047, Accuracy: 0.890000, Test accuracy: 0.906200
Distillation: Epoch : 25, Loss : 1.329685, Accuracy: 0.916000, Test accuracy: 0.907000
Distillation: Epoch : 26, Loss : 1.372692, Accuracy: 0.882000, Test accuracy: 0.906400
Distillation: Epoch : 27, Loss : 1.342113, Accuracy: 0.898000, Test accuracy: 0.907800
Distillation: Epoch : 28, Loss : 1.360887, Accuracy: 0.912000, Test accuracy: 0.907800
Distillation: Epoch : 29, Loss : 1.367656, Accuracy: 0.922000, Test accuracy: 0.908200
Distillation: Epoch : 30, Loss : 1.380585, Accuracy: 0.904000, Test accuracy: 0.908500
Distillation: Epoch : 31, Loss : 1.336988, Accuracy: 0.899000, Test accuracy: 0.908900
Distillation: Epoch : 32, Loss : 1.360302, Accuracy: 0.899000, Test accuracy: 0.910600
Distillation: Epoch : 33, Loss : 1.310707, Accuracy: 0.924000, Test accuracy: 0.914000
Distillation: Epoch : 34, Loss : 1.301228, Accuracy: 0.914000, Test accuracy: 0.915900
Distillation: Epoch : 35, Loss : 1.378249, Accuracy: 0.896000, Test accuracy: 0.917100
Distillation: Epoch : 36, Loss : 1.356466, Accuracy: 0.898000, Test accuracy: 0.919500
Distillation: Epoch : 37, Loss : 1.325355, Accuracy: 0.920000, Test accuracy: 0.925100
Distillation: Epoch : 38, Loss : 1.319489, Accuracy: 0.914000, Test accuracy: 0.926800
Distillation: Epoch : 39, Loss : 1.282976, Accuracy: 0.917000, Test accuracy: 0.928700
Distillation: Epoch : 40, Loss : 1.311240, Accuracy: 0.933000, Test accuracy: 0.933000
Distillation: Epoch : 41, Loss : 1.295232, Accuracy: 0.927000, Test accuracy: 0.933300
Distillation: Epoch : 42, Loss : 1.325241, Accuracy: 0.927000, Test accuracy: 0.935800
Distillation: Epoch : 43, Loss : 1.321395, Accuracy: 0.924000, Test accuracy: 0.939200
Distillation: Epoch : 44, Loss : 1.293304, Accuracy: 0.937000, Test accuracy: 0.941000
Distillation: Epoch : 45, Loss : 1.280210, Accuracy: 0.936000, Test accuracy: 0.944500
Distillation: Epoch : 46, Loss : 1.299096, Accuracy: 0.921000, Test accuracy: 0.943400
Distillation: Epoch : 47, Loss : 1.292149, Accuracy: 0.941000, Test accuracy: 0.947500
Distillation: Epoch : 48, Loss : 1.311822, Accuracy: 0.929000, Test accuracy: 0.948200
Distillation: Epoch : 49, Loss : 1.266084, Accuracy: 0.959000, Test accuracy: 0.948800
Distillation: Epoch : 50, Loss : 1.280106, Accuracy: 0.952000, Test accuracy: 0.950900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9509
Generating confusion matrix for student4
[[ 966.    0.    9.    0.    1.    3.    9.    2.    9.    4.]
 [   1. 1098.    1.    0.    1.    1.    3.    3.    2.    4.]
 [   2.    2.  953.   10.    3.    0.    2.   20.    8.    1.]
 [   0.    3.   11.  973.    0.   20.    0.    8.    6.   15.]
 [   2.    2.   11.    0.  955.    0.    3.    8.    5.   22.]
 [   0.    3.    0.    9.    0.  831.   13.    4.   11.   10.]
 [   3.    5.    8.    0.    3.    9.  924.    0.    1.    0.]
 [   2.    0.    5.    4.    0.    1.    0.  951.    4.    8.]
 [   4.   22.   32.   11.    5.   23.    4.    6.  920.    7.]
 [   0.    0.    2.    3.   14.    4.    0.   26.    8.  938.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.695115, Accuracy: 0.795000, Test accuracy: 0.794100
Distillation: Epoch : 2, Loss : 1.587344, Accuracy: 0.838000, Test accuracy: 0.866800
Distillation: Epoch : 3, Loss : 1.513257, Accuracy: 0.872000, Test accuracy: 0.879500
Distillation: Epoch : 4, Loss : 1.543064, Accuracy: 0.873000, Test accuracy: 0.884700
Distillation: Epoch : 5, Loss : 1.504852, Accuracy: 0.885000, Test accuracy: 0.888700
Distillation: Epoch : 6, Loss : 1.499678, Accuracy: 0.874000, Test accuracy: 0.891600
Distillation: Epoch : 7, Loss : 1.511345, Accuracy: 0.883000, Test accuracy: 0.897700
Distillation: Epoch : 8, Loss : 1.495345, Accuracy: 0.904000, Test accuracy: 0.899100
Distillation: Epoch : 9, Loss : 1.490324, Accuracy: 0.898000, Test accuracy: 0.903100
Distillation: Epoch : 10, Loss : 1.515610, Accuracy: 0.882000, Test accuracy: 0.905300
Distillation: Epoch : 11, Loss : 1.465173, Accuracy: 0.910000, Test accuracy: 0.908200
Distillation: Epoch : 12, Loss : 1.465659, Accuracy: 0.915000, Test accuracy: 0.911700
Distillation: Epoch : 13, Loss : 1.480281, Accuracy: 0.879000, Test accuracy: 0.913200
Distillation: Epoch : 14, Loss : 1.465373, Accuracy: 0.914000, Test accuracy: 0.916700
Distillation: Epoch : 15, Loss : 1.454143, Accuracy: 0.916000, Test accuracy: 0.919000
Distillation: Epoch : 16, Loss : 1.438762, Accuracy: 0.921000, Test accuracy: 0.922200
Distillation: Epoch : 17, Loss : 1.419950, Accuracy: 0.925000, Test accuracy: 0.923900
Distillation: Epoch : 18, Loss : 1.448953, Accuracy: 0.922000, Test accuracy: 0.927700
Distillation: Epoch : 19, Loss : 1.460306, Accuracy: 0.926000, Test accuracy: 0.930800
Distillation: Epoch : 20, Loss : 1.420846, Accuracy: 0.911000, Test accuracy: 0.932500
Distillation: Epoch : 21, Loss : 1.461044, Accuracy: 0.921000, Test accuracy: 0.935700
Distillation: Epoch : 22, Loss : 1.431929, Accuracy: 0.939000, Test accuracy: 0.937900
Distillation: Epoch : 23, Loss : 1.438048, Accuracy: 0.927000, Test accuracy: 0.939900
Distillation: Epoch : 24, Loss : 1.418332, Accuracy: 0.939000, Test accuracy: 0.941900
Distillation: Epoch : 25, Loss : 1.425146, Accuracy: 0.941000, Test accuracy: 0.942600
Distillation: Epoch : 26, Loss : 1.433113, Accuracy: 0.932000, Test accuracy: 0.942800
Distillation: Epoch : 27, Loss : 1.452049, Accuracy: 0.932000, Test accuracy: 0.944300
Distillation: Epoch : 28, Loss : 1.425084, Accuracy: 0.940000, Test accuracy: 0.946000
Distillation: Epoch : 29, Loss : 1.419978, Accuracy: 0.942000, Test accuracy: 0.945700
Distillation: Epoch : 30, Loss : 1.401018, Accuracy: 0.937000, Test accuracy: 0.947000
Distillation: Epoch : 31, Loss : 1.392220, Accuracy: 0.949000, Test accuracy: 0.948500
Distillation: Epoch : 32, Loss : 1.403910, Accuracy: 0.949000, Test accuracy: 0.949000
Distillation: Epoch : 33, Loss : 1.403668, Accuracy: 0.954000, Test accuracy: 0.948700
Distillation: Epoch : 34, Loss : 1.434142, Accuracy: 0.936000, Test accuracy: 0.949300
Distillation: Epoch : 35, Loss : 1.398015, Accuracy: 0.946000, Test accuracy: 0.949600
Distillation: Epoch : 36, Loss : 1.407544, Accuracy: 0.944000, Test accuracy: 0.950100
Distillation: Epoch : 37, Loss : 1.428753, Accuracy: 0.949000, Test accuracy: 0.951100
Distillation: Epoch : 38, Loss : 1.414088, Accuracy: 0.945000, Test accuracy: 0.950400
Distillation: Epoch : 39, Loss : 1.395147, Accuracy: 0.944000, Test accuracy: 0.951500
Distillation: Epoch : 40, Loss : 1.416528, Accuracy: 0.951000, Test accuracy: 0.952000
Distillation: Epoch : 41, Loss : 1.410729, Accuracy: 0.952000, Test accuracy: 0.950800
Distillation: Epoch : 42, Loss : 1.411592, Accuracy: 0.951000, Test accuracy: 0.951000
Distillation: Epoch : 43, Loss : 1.386615, Accuracy: 0.951000, Test accuracy: 0.953000
Distillation: Epoch : 44, Loss : 1.380563, Accuracy: 0.948000, Test accuracy: 0.951500
Distillation: Epoch : 45, Loss : 1.435516, Accuracy: 0.941000, Test accuracy: 0.952000
Distillation: Epoch : 46, Loss : 1.408063, Accuracy: 0.947000, Test accuracy: 0.953100
Distillation: Epoch : 47, Loss : 1.372625, Accuracy: 0.944000, Test accuracy: 0.953600
Distillation: Epoch : 48, Loss : 1.423882, Accuracy: 0.942000, Test accuracy: 0.953500
Distillation: Epoch : 49, Loss : 1.369173, Accuracy: 0.959000, Test accuracy: 0.952900
Distillation: Epoch : 50, Loss : 1.392471, Accuracy: 0.956000, Test accuracy: 0.953800
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9538
Generating confusion matrix for student4
[[ 963.    0.    7.    2.    0.    4.    9.    1.    8.    2.]
 [   0. 1111.    8.    2.    1.    0.    3.    7.    4.    6.]
 [   0.    1.  968.    6.    2.    1.    2.   19.    5.    1.]
 [   0.    3.    8.  950.    0.   11.    1.    2.    6.    5.]
 [   5.    0.   14.    3.  956.    1.    6.   13.    8.   35.]
 [   1.    0.    0.   20.    1.  842.    2.    2.    4.    7.]
 [   4.    5.    1.    0.    3.    9.  926.    0.    5.    3.]
 [   0.    0.   10.   13.    2.    2.    0.  967.    5.    4.]
 [   5.   15.   13.   12.    5.   15.    9.    3.  924.   15.]
 [   2.    0.    3.    2.   12.    7.    0.   14.    5.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.050298, Accuracy: 0.717000, Test accuracy: 0.719400
Distillation: Epoch : 2, Loss : 1.812467, Accuracy: 0.849000, Test accuracy: 0.851700
Distillation: Epoch : 3, Loss : 1.786527, Accuracy: 0.853000, Test accuracy: 0.875100
Distillation: Epoch : 4, Loss : 1.780254, Accuracy: 0.883000, Test accuracy: 0.885600
Distillation: Epoch : 5, Loss : 1.781512, Accuracy: 0.887000, Test accuracy: 0.895300
Distillation: Epoch : 6, Loss : 1.762767, Accuracy: 0.894000, Test accuracy: 0.902500
Distillation: Epoch : 7, Loss : 1.750273, Accuracy: 0.898000, Test accuracy: 0.904400
Distillation: Epoch : 8, Loss : 1.743992, Accuracy: 0.904000, Test accuracy: 0.910500
Distillation: Epoch : 9, Loss : 1.745816, Accuracy: 0.897000, Test accuracy: 0.916900
Distillation: Epoch : 10, Loss : 1.740080, Accuracy: 0.905000, Test accuracy: 0.919400
Distillation: Epoch : 11, Loss : 1.718487, Accuracy: 0.910000, Test accuracy: 0.923400
Distillation: Epoch : 12, Loss : 1.719456, Accuracy: 0.930000, Test accuracy: 0.930400
Distillation: Epoch : 13, Loss : 1.722122, Accuracy: 0.938000, Test accuracy: 0.933100
Distillation: Epoch : 14, Loss : 1.720447, Accuracy: 0.924000, Test accuracy: 0.936900
Distillation: Epoch : 15, Loss : 1.703648, Accuracy: 0.929000, Test accuracy: 0.941000
Distillation: Epoch : 16, Loss : 1.706693, Accuracy: 0.941000, Test accuracy: 0.942700
Distillation: Epoch : 17, Loss : 1.699295, Accuracy: 0.941000, Test accuracy: 0.946200
Distillation: Epoch : 18, Loss : 1.720219, Accuracy: 0.934000, Test accuracy: 0.948600
Distillation: Epoch : 19, Loss : 1.693126, Accuracy: 0.957000, Test accuracy: 0.950400
Distillation: Epoch : 20, Loss : 1.682642, Accuracy: 0.947000, Test accuracy: 0.952600
Distillation: Epoch : 21, Loss : 1.673197, Accuracy: 0.953000, Test accuracy: 0.954600
Distillation: Epoch : 22, Loss : 1.692531, Accuracy: 0.953000, Test accuracy: 0.955600
Distillation: Epoch : 23, Loss : 1.694913, Accuracy: 0.959000, Test accuracy: 0.957600
Distillation: Epoch : 24, Loss : 1.685497, Accuracy: 0.951000, Test accuracy: 0.957800
Distillation: Epoch : 25, Loss : 1.683871, Accuracy: 0.951000, Test accuracy: 0.959300
Distillation: Epoch : 26, Loss : 1.688783, Accuracy: 0.948000, Test accuracy: 0.959400
Distillation: Epoch : 27, Loss : 1.665734, Accuracy: 0.965000, Test accuracy: 0.960200
Distillation: Epoch : 28, Loss : 1.698606, Accuracy: 0.954000, Test accuracy: 0.960400
Distillation: Epoch : 29, Loss : 1.675635, Accuracy: 0.955000, Test accuracy: 0.960900
Distillation: Epoch : 30, Loss : 1.690264, Accuracy: 0.966000, Test accuracy: 0.961400
Distillation: Epoch : 31, Loss : 1.684392, Accuracy: 0.961000, Test accuracy: 0.962400
Distillation: Epoch : 32, Loss : 1.662457, Accuracy: 0.961000, Test accuracy: 0.962700
Distillation: Epoch : 33, Loss : 1.664683, Accuracy: 0.965000, Test accuracy: 0.963100
Distillation: Epoch : 34, Loss : 1.678199, Accuracy: 0.954000, Test accuracy: 0.963500
Distillation: Epoch : 35, Loss : 1.706553, Accuracy: 0.957000, Test accuracy: 0.963700
Distillation: Epoch : 36, Loss : 1.683068, Accuracy: 0.960000, Test accuracy: 0.964300
Distillation: Epoch : 37, Loss : 1.686075, Accuracy: 0.965000, Test accuracy: 0.964600
Distillation: Epoch : 38, Loss : 1.674766, Accuracy: 0.967000, Test accuracy: 0.964900
Distillation: Epoch : 39, Loss : 1.680570, Accuracy: 0.966000, Test accuracy: 0.965000
Distillation: Epoch : 40, Loss : 1.689796, Accuracy: 0.960000, Test accuracy: 0.965600
Distillation: Epoch : 41, Loss : 1.674884, Accuracy: 0.963000, Test accuracy: 0.965900
Distillation: Epoch : 42, Loss : 1.681928, Accuracy: 0.960000, Test accuracy: 0.966600
Distillation: Epoch : 43, Loss : 1.669043, Accuracy: 0.953000, Test accuracy: 0.966000
Distillation: Epoch : 44, Loss : 1.678759, Accuracy: 0.970000, Test accuracy: 0.966400
Distillation: Epoch : 45, Loss : 1.674646, Accuracy: 0.965000, Test accuracy: 0.967400
Distillation: Epoch : 46, Loss : 1.673001, Accuracy: 0.962000, Test accuracy: 0.967100
Distillation: Epoch : 47, Loss : 1.695161, Accuracy: 0.945000, Test accuracy: 0.967200
Distillation: Epoch : 48, Loss : 1.681744, Accuracy: 0.966000, Test accuracy: 0.966900
Distillation: Epoch : 49, Loss : 1.666438, Accuracy: 0.970000, Test accuracy: 0.967100
Distillation: Epoch : 50, Loss : 1.682829, Accuracy: 0.975000, Test accuracy: 0.967500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9675
Generating confusion matrix for student4
[[ 969.    0.    8.    0.    2.    2.    8.    1.    5.    4.]
 [   0. 1116.    3.    1.    0.    0.    3.    6.    1.    6.]
 [   1.    3.  985.    4.    1.    1.    0.   17.    4.    1.]
 [   0.    1.    5.  974.    0.    7.    0.    3.    2.    8.]
 [   2.    0.    5.    0.  966.    0.    5.    7.    5.   20.]
 [   0.    0.    0.    6.    0.  858.    6.    1.    2.    3.]
 [   2.    3.    0.    0.    3.    3.  931.    0.    3.    0.]
 [   1.    0.    6.    6.    0.    1.    0.  972.    4.    4.]
 [   3.   12.   19.   15.    2.   16.    5.    1.  945.    4.]
 [   2.    0.    1.    4.    8.    4.    0.   20.    3.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.204921, Accuracy: 0.472000, Test accuracy: 0.485800
Distillation: Epoch : 2, Loss : 2.041265, Accuracy: 0.845000, Test accuracy: 0.852000
Distillation: Epoch : 3, Loss : 2.033790, Accuracy: 0.862000, Test accuracy: 0.866200
Distillation: Epoch : 4, Loss : 2.025769, Accuracy: 0.871000, Test accuracy: 0.872800
Distillation: Epoch : 5, Loss : 2.010211, Accuracy: 0.878000, Test accuracy: 0.880100
Distillation: Epoch : 6, Loss : 2.024397, Accuracy: 0.881000, Test accuracy: 0.880700
Distillation: Epoch : 7, Loss : 2.027001, Accuracy: 0.866000, Test accuracy: 0.882500
Distillation: Epoch : 8, Loss : 2.015637, Accuracy: 0.892000, Test accuracy: 0.884300
Distillation: Epoch : 9, Loss : 2.021414, Accuracy: 0.877000, Test accuracy: 0.883600
Distillation: Epoch : 10, Loss : 2.010884, Accuracy: 0.895000, Test accuracy: 0.885500
Distillation: Epoch : 11, Loss : 2.012321, Accuracy: 0.874000, Test accuracy: 0.886400
Distillation: Epoch : 12, Loss : 2.016728, Accuracy: 0.872000, Test accuracy: 0.887200
Distillation: Epoch : 13, Loss : 2.011715, Accuracy: 0.881000, Test accuracy: 0.888700
Distillation: Epoch : 14, Loss : 2.021877, Accuracy: 0.876000, Test accuracy: 0.888500
Distillation: Epoch : 15, Loss : 2.011515, Accuracy: 0.890000, Test accuracy: 0.888800
Distillation: Epoch : 16, Loss : 2.010835, Accuracy: 0.884000, Test accuracy: 0.891100
Distillation: Epoch : 17, Loss : 2.006034, Accuracy: 0.868000, Test accuracy: 0.893500
Distillation: Epoch : 18, Loss : 2.006861, Accuracy: 0.877000, Test accuracy: 0.896100
Distillation: Epoch : 19, Loss : 2.019951, Accuracy: 0.887000, Test accuracy: 0.894000
Distillation: Epoch : 20, Loss : 2.004136, Accuracy: 0.890000, Test accuracy: 0.899300
Distillation: Epoch : 21, Loss : 1.999005, Accuracy: 0.882000, Test accuracy: 0.902400
Distillation: Epoch : 22, Loss : 1.990556, Accuracy: 0.907000, Test accuracy: 0.906900
Distillation: Epoch : 23, Loss : 2.012325, Accuracy: 0.896000, Test accuracy: 0.911700
Distillation: Epoch : 24, Loss : 1.986259, Accuracy: 0.919000, Test accuracy: 0.918200
Distillation: Epoch : 25, Loss : 1.977737, Accuracy: 0.914000, Test accuracy: 0.921200
Distillation: Epoch : 26, Loss : 1.991875, Accuracy: 0.920000, Test accuracy: 0.925800
Distillation: Epoch : 27, Loss : 1.995714, Accuracy: 0.918000, Test accuracy: 0.929500
Distillation: Epoch : 28, Loss : 1.984422, Accuracy: 0.924000, Test accuracy: 0.932300
Distillation: Epoch : 29, Loss : 1.983574, Accuracy: 0.927000, Test accuracy: 0.936900
Distillation: Epoch : 30, Loss : 1.974434, Accuracy: 0.935000, Test accuracy: 0.938500
Distillation: Epoch : 31, Loss : 1.984254, Accuracy: 0.929000, Test accuracy: 0.938800
Distillation: Epoch : 32, Loss : 1.977747, Accuracy: 0.930000, Test accuracy: 0.939700
Distillation: Epoch : 33, Loss : 1.974448, Accuracy: 0.943000, Test accuracy: 0.940000
Distillation: Epoch : 34, Loss : 1.973906, Accuracy: 0.935000, Test accuracy: 0.940400
Distillation: Epoch : 35, Loss : 1.977764, Accuracy: 0.927000, Test accuracy: 0.943000
Distillation: Epoch : 36, Loss : 1.976277, Accuracy: 0.932000, Test accuracy: 0.942400
Distillation: Epoch : 37, Loss : 1.967052, Accuracy: 0.949000, Test accuracy: 0.945200
Distillation: Epoch : 38, Loss : 1.965233, Accuracy: 0.940000, Test accuracy: 0.944100
Distillation: Epoch : 39, Loss : 1.981958, Accuracy: 0.928000, Test accuracy: 0.944700
Distillation: Epoch : 40, Loss : 1.970672, Accuracy: 0.939000, Test accuracy: 0.945000
Distillation: Epoch : 41, Loss : 1.973957, Accuracy: 0.951000, Test accuracy: 0.945700
Distillation: Epoch : 42, Loss : 1.957223, Accuracy: 0.929000, Test accuracy: 0.946500
Distillation: Epoch : 43, Loss : 1.970211, Accuracy: 0.947000, Test accuracy: 0.948000
Distillation: Epoch : 44, Loss : 1.970836, Accuracy: 0.940000, Test accuracy: 0.946400
Distillation: Epoch : 45, Loss : 1.964804, Accuracy: 0.943000, Test accuracy: 0.948100
Distillation: Epoch : 46, Loss : 1.959290, Accuracy: 0.939000, Test accuracy: 0.948100
Distillation: Epoch : 47, Loss : 1.980788, Accuracy: 0.938000, Test accuracy: 0.948100
Distillation: Epoch : 48, Loss : 1.962187, Accuracy: 0.938000, Test accuracy: 0.948600
Distillation: Epoch : 49, Loss : 1.971402, Accuracy: 0.934000, Test accuracy: 0.949600
Distillation: Epoch : 50, Loss : 1.975526, Accuracy: 0.954000, Test accuracy: 0.949500
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9495
Generating confusion matrix for student4
[[ 963.    0.    3.    0.    1.    1.   11.    3.    7.    6.]
 [   0. 1093.    6.    1.    1.    0.    4.    8.    3.    5.]
 [   1.    4.  956.    4.    0.    0.    0.   11.    6.    1.]
 [   1.    0.    9.  976.    0.   12.    0.    6.    5.    8.]
 [   2.    2.   14.    3.  961.    2.   10.   23.    9.   37.]
 [   1.    0.    0.    5.    0.  843.    7.    1.    3.    4.]
 [   7.    4.    3.    0.    3.    5.  919.    0.    4.    0.]
 [   0.    1.    5.    7.    0.    1.    0.  926.    7.    5.]
 [   4.   31.   33.   11.    7.   21.    7.    8.  924.    9.]
 [   1.    0.    3.    3.    9.    7.    0.   42.    6.  934.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.843742, Accuracy: 0.789000, Test accuracy: 0.798200
Distillation: Epoch : 2, Loss : 0.447232, Accuracy: 0.872000, Test accuracy: 0.876900
Distillation: Epoch : 3, Loss : 0.351599, Accuracy: 0.899000, Test accuracy: 0.891200
Distillation: Epoch : 4, Loss : 0.384073, Accuracy: 0.881000, Test accuracy: 0.899000
Distillation: Epoch : 5, Loss : 0.356712, Accuracy: 0.894000, Test accuracy: 0.903400
Distillation: Epoch : 6, Loss : 0.309772, Accuracy: 0.905000, Test accuracy: 0.906100
Distillation: Epoch : 7, Loss : 0.317662, Accuracy: 0.902000, Test accuracy: 0.911600
Distillation: Epoch : 8, Loss : 0.327672, Accuracy: 0.903000, Test accuracy: 0.912400
Distillation: Epoch : 9, Loss : 0.309508, Accuracy: 0.918000, Test accuracy: 0.915100
Distillation: Epoch : 10, Loss : 0.305232, Accuracy: 0.918000, Test accuracy: 0.915100
Distillation: Epoch : 11, Loss : 0.306059, Accuracy: 0.914000, Test accuracy: 0.917800
Distillation: Epoch : 12, Loss : 0.305856, Accuracy: 0.920000, Test accuracy: 0.919500
Distillation: Epoch : 13, Loss : 0.249150, Accuracy: 0.925000, Test accuracy: 0.920300
Distillation: Epoch : 14, Loss : 0.304634, Accuracy: 0.922000, Test accuracy: 0.923200
Distillation: Epoch : 15, Loss : 0.253288, Accuracy: 0.933000, Test accuracy: 0.925300
Distillation: Epoch : 16, Loss : 0.280064, Accuracy: 0.919000, Test accuracy: 0.927300
Distillation: Epoch : 17, Loss : 0.238445, Accuracy: 0.932000, Test accuracy: 0.928800
Distillation: Epoch : 18, Loss : 0.246816, Accuracy: 0.928000, Test accuracy: 0.930800
Distillation: Epoch : 19, Loss : 0.220624, Accuracy: 0.931000, Test accuracy: 0.931300
Distillation: Epoch : 20, Loss : 0.250411, Accuracy: 0.930000, Test accuracy: 0.933400
Distillation: Epoch : 21, Loss : 0.274856, Accuracy: 0.915000, Test accuracy: 0.935300
Distillation: Epoch : 22, Loss : 0.252760, Accuracy: 0.931000, Test accuracy: 0.937400
Distillation: Epoch : 23, Loss : 0.222321, Accuracy: 0.941000, Test accuracy: 0.937300
Distillation: Epoch : 24, Loss : 0.218001, Accuracy: 0.931000, Test accuracy: 0.940200
Distillation: Epoch : 25, Loss : 0.185084, Accuracy: 0.948000, Test accuracy: 0.941600
Distillation: Epoch : 26, Loss : 0.215716, Accuracy: 0.942000, Test accuracy: 0.942800
Distillation: Epoch : 27, Loss : 0.197470, Accuracy: 0.938000, Test accuracy: 0.943500
Distillation: Epoch : 28, Loss : 0.218014, Accuracy: 0.942000, Test accuracy: 0.945200
Distillation: Epoch : 29, Loss : 0.159239, Accuracy: 0.956000, Test accuracy: 0.947500
Distillation: Epoch : 30, Loss : 0.153180, Accuracy: 0.957000, Test accuracy: 0.947100
Distillation: Epoch : 31, Loss : 0.193342, Accuracy: 0.949000, Test accuracy: 0.948800
Distillation: Epoch : 32, Loss : 0.168708, Accuracy: 0.954000, Test accuracy: 0.949000
Distillation: Epoch : 33, Loss : 0.143687, Accuracy: 0.958000, Test accuracy: 0.950600
Distillation: Epoch : 34, Loss : 0.157327, Accuracy: 0.951000, Test accuracy: 0.952700
Distillation: Epoch : 35, Loss : 0.156162, Accuracy: 0.957000, Test accuracy: 0.953300
Distillation: Epoch : 36, Loss : 0.167764, Accuracy: 0.949000, Test accuracy: 0.953600
Distillation: Epoch : 37, Loss : 0.148441, Accuracy: 0.949000, Test accuracy: 0.954200
Distillation: Epoch : 38, Loss : 0.175576, Accuracy: 0.948000, Test accuracy: 0.955800
Distillation: Epoch : 39, Loss : 0.184303, Accuracy: 0.953000, Test accuracy: 0.956200
Distillation: Epoch : 40, Loss : 0.192873, Accuracy: 0.940000, Test accuracy: 0.956700
Distillation: Epoch : 41, Loss : 0.141199, Accuracy: 0.964000, Test accuracy: 0.956700
Distillation: Epoch : 42, Loss : 0.155594, Accuracy: 0.958000, Test accuracy: 0.956600
Distillation: Epoch : 43, Loss : 0.141720, Accuracy: 0.960000, Test accuracy: 0.957900
Distillation: Epoch : 44, Loss : 0.181594, Accuracy: 0.949000, Test accuracy: 0.958500
Distillation: Epoch : 45, Loss : 0.121405, Accuracy: 0.967000, Test accuracy: 0.958400
Distillation: Epoch : 46, Loss : 0.147030, Accuracy: 0.959000, Test accuracy: 0.959700
Distillation: Epoch : 47, Loss : 0.101244, Accuracy: 0.967000, Test accuracy: 0.959000
Distillation: Epoch : 48, Loss : 0.139023, Accuracy: 0.961000, Test accuracy: 0.960400
Distillation: Epoch : 49, Loss : 0.140392, Accuracy: 0.962000, Test accuracy: 0.961100
Distillation: Epoch : 50, Loss : 0.118040, Accuracy: 0.964000, Test accuracy: 0.961400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9614
Generating confusion matrix for student5
[[ 970.    0.    2.    1.    2.    2.    8.    1.    8.    6.]
 [   0. 1119.    9.    1.    2.    3.    2.    8.    8.    8.]
 [   1.    4.  978.    9.    5.    1.    2.   15.    6.    1.]
 [   0.    0.   13.  977.    0.   15.    0.    7.   13.    8.]
 [   1.    0.    5.    1.  952.    1.    4.    3.    5.   18.]
 [   1.    0.    0.    5.    0.  852.    6.    1.    7.    3.]
 [   3.    2.    4.    0.    2.    9.  935.    0.    7.    1.]
 [   2.    1.    9.    7.    1.    4.    0.  973.    6.    7.]
 [   2.    9.    9.    7.    2.    1.    1.    1.  908.    7.]
 [   0.    0.    3.    2.   16.    4.    0.   19.    6.  950.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.964962, Accuracy: 0.776000, Test accuracy: 0.805300
Distillation: Epoch : 2, Loss : 0.507527, Accuracy: 0.848000, Test accuracy: 0.876100
Distillation: Epoch : 3, Loss : 0.384817, Accuracy: 0.905000, Test accuracy: 0.892200
Distillation: Epoch : 4, Loss : 0.362456, Accuracy: 0.893000, Test accuracy: 0.898800
Distillation: Epoch : 5, Loss : 0.458709, Accuracy: 0.863000, Test accuracy: 0.903200
Distillation: Epoch : 6, Loss : 0.358161, Accuracy: 0.900000, Test accuracy: 0.906800
Distillation: Epoch : 7, Loss : 0.384513, Accuracy: 0.905000, Test accuracy: 0.906600
Distillation: Epoch : 8, Loss : 0.346232, Accuracy: 0.916000, Test accuracy: 0.910200
Distillation: Epoch : 9, Loss : 0.403806, Accuracy: 0.882000, Test accuracy: 0.908900
Distillation: Epoch : 10, Loss : 0.364880, Accuracy: 0.902000, Test accuracy: 0.910300
Distillation: Epoch : 11, Loss : 0.341957, Accuracy: 0.903000, Test accuracy: 0.910500
Distillation: Epoch : 12, Loss : 0.340518, Accuracy: 0.900000, Test accuracy: 0.911000
Distillation: Epoch : 13, Loss : 0.361058, Accuracy: 0.917000, Test accuracy: 0.911200
Distillation: Epoch : 14, Loss : 0.341187, Accuracy: 0.910000, Test accuracy: 0.910700
Distillation: Epoch : 15, Loss : 0.328806, Accuracy: 0.916000, Test accuracy: 0.912700
Distillation: Epoch : 16, Loss : 0.321248, Accuracy: 0.906000, Test accuracy: 0.913000
Distillation: Epoch : 17, Loss : 0.363564, Accuracy: 0.901000, Test accuracy: 0.913300
Distillation: Epoch : 18, Loss : 0.296340, Accuracy: 0.920000, Test accuracy: 0.914900
Distillation: Epoch : 19, Loss : 0.350404, Accuracy: 0.901000, Test accuracy: 0.916200
Distillation: Epoch : 20, Loss : 0.337924, Accuracy: 0.902000, Test accuracy: 0.914700
Distillation: Epoch : 21, Loss : 0.270883, Accuracy: 0.933000, Test accuracy: 0.915400
Distillation: Epoch : 22, Loss : 0.330654, Accuracy: 0.912000, Test accuracy: 0.914500
Distillation: Epoch : 23, Loss : 0.348542, Accuracy: 0.905000, Test accuracy: 0.916600
Distillation: Epoch : 24, Loss : 0.262560, Accuracy: 0.927000, Test accuracy: 0.915500
Distillation: Epoch : 25, Loss : 0.259753, Accuracy: 0.928000, Test accuracy: 0.914700
Distillation: Epoch : 26, Loss : 0.319861, Accuracy: 0.915000, Test accuracy: 0.915300
Distillation: Epoch : 27, Loss : 0.256304, Accuracy: 0.929000, Test accuracy: 0.916500
Distillation: Epoch : 28, Loss : 0.324437, Accuracy: 0.919000, Test accuracy: 0.916600
Distillation: Epoch : 29, Loss : 0.315220, Accuracy: 0.909000, Test accuracy: 0.918400
Distillation: Epoch : 30, Loss : 0.333737, Accuracy: 0.916000, Test accuracy: 0.917800
Distillation: Epoch : 31, Loss : 0.324560, Accuracy: 0.905000, Test accuracy: 0.917600
Distillation: Epoch : 32, Loss : 0.295586, Accuracy: 0.930000, Test accuracy: 0.917300
Distillation: Epoch : 33, Loss : 0.311760, Accuracy: 0.926000, Test accuracy: 0.918200
Distillation: Epoch : 34, Loss : 0.365360, Accuracy: 0.910000, Test accuracy: 0.916900
Distillation: Epoch : 35, Loss : 0.280799, Accuracy: 0.923000, Test accuracy: 0.917700
Distillation: Epoch : 36, Loss : 0.337369, Accuracy: 0.902000, Test accuracy: 0.917800
Distillation: Epoch : 37, Loss : 0.309435, Accuracy: 0.914000, Test accuracy: 0.919200
Distillation: Epoch : 38, Loss : 0.372110, Accuracy: 0.912000, Test accuracy: 0.919300
Distillation: Epoch : 39, Loss : 0.286648, Accuracy: 0.921000, Test accuracy: 0.919500
Distillation: Epoch : 40, Loss : 0.323816, Accuracy: 0.917000, Test accuracy: 0.918500
Distillation: Epoch : 41, Loss : 0.255304, Accuracy: 0.936000, Test accuracy: 0.920300
Distillation: Epoch : 42, Loss : 0.331169, Accuracy: 0.909000, Test accuracy: 0.921100
Distillation: Epoch : 43, Loss : 0.334266, Accuracy: 0.905000, Test accuracy: 0.920500
Distillation: Epoch : 44, Loss : 0.265251, Accuracy: 0.934000, Test accuracy: 0.919400
Distillation: Epoch : 45, Loss : 0.285220, Accuracy: 0.921000, Test accuracy: 0.918400
Distillation: Epoch : 46, Loss : 0.309229, Accuracy: 0.917000, Test accuracy: 0.918300
Distillation: Epoch : 47, Loss : 0.297478, Accuracy: 0.921000, Test accuracy: 0.921700
Distillation: Epoch : 48, Loss : 0.318384, Accuracy: 0.924000, Test accuracy: 0.919100
Distillation: Epoch : 49, Loss : 0.265878, Accuracy: 0.926000, Test accuracy: 0.919900
Distillation: Epoch : 50, Loss : 0.296204, Accuracy: 0.924000, Test accuracy: 0.922200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9222
Generating confusion matrix for student5
[[ 957.    0.    9.    2.    1.    9.   10.    1.   11.   13.]
 [   0. 1110.   11.    0.    3.    2.    3.    6.    6.    7.]
 [   1.    4.  915.   21.    6.    5.    7.   24.    7.    1.]
 [   2.    2.   18.  927.    1.   41.    1.    8.   23.   11.]
 [   0.    0.    9.    1.  910.   10.    7.    8.   10.   24.]
 [   7.    2.    4.   20.    1.  759.   10.    0.   23.    5.]
 [   8.    4.   13.    2.   11.   16.  916.    0.    9.    0.]
 [   2.    1.   10.   10.    2.    5.    2.  937.    8.   18.]
 [   3.   12.   36.   16.    4.   36.    2.    2.  867.    6.]
 [   0.    0.    7.   11.   43.    9.    0.   42.   10.  924.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.573686, Accuracy: 0.739000, Test accuracy: 0.748800
Distillation: Epoch : 2, Loss : 0.822079, Accuracy: 0.842000, Test accuracy: 0.860500
Distillation: Epoch : 3, Loss : 0.730055, Accuracy: 0.861000, Test accuracy: 0.885000
Distillation: Epoch : 4, Loss : 0.652473, Accuracy: 0.894000, Test accuracy: 0.896300
Distillation: Epoch : 5, Loss : 0.662144, Accuracy: 0.890000, Test accuracy: 0.902100
Distillation: Epoch : 6, Loss : 0.634244, Accuracy: 0.895000, Test accuracy: 0.906000
Distillation: Epoch : 7, Loss : 0.601145, Accuracy: 0.923000, Test accuracy: 0.907300
Distillation: Epoch : 8, Loss : 0.614344, Accuracy: 0.899000, Test accuracy: 0.910000
Distillation: Epoch : 9, Loss : 0.611353, Accuracy: 0.911000, Test accuracy: 0.910200
Distillation: Epoch : 10, Loss : 0.608988, Accuracy: 0.922000, Test accuracy: 0.913500
Distillation: Epoch : 11, Loss : 0.623152, Accuracy: 0.893000, Test accuracy: 0.913600
Distillation: Epoch : 12, Loss : 0.589329, Accuracy: 0.915000, Test accuracy: 0.914500
Distillation: Epoch : 13, Loss : 0.566976, Accuracy: 0.915000, Test accuracy: 0.916200
Distillation: Epoch : 14, Loss : 0.606058, Accuracy: 0.901000, Test accuracy: 0.916200
Distillation: Epoch : 15, Loss : 0.582593, Accuracy: 0.913000, Test accuracy: 0.917700
Distillation: Epoch : 16, Loss : 0.584329, Accuracy: 0.919000, Test accuracy: 0.919100
Distillation: Epoch : 17, Loss : 0.624291, Accuracy: 0.911000, Test accuracy: 0.918900
Distillation: Epoch : 18, Loss : 0.586143, Accuracy: 0.917000, Test accuracy: 0.919500
Distillation: Epoch : 19, Loss : 0.608697, Accuracy: 0.907000, Test accuracy: 0.919100
Distillation: Epoch : 20, Loss : 0.584927, Accuracy: 0.909000, Test accuracy: 0.920000
Distillation: Epoch : 21, Loss : 0.557170, Accuracy: 0.919000, Test accuracy: 0.920300
Distillation: Epoch : 22, Loss : 0.603205, Accuracy: 0.923000, Test accuracy: 0.920700
Distillation: Epoch : 23, Loss : 0.591447, Accuracy: 0.911000, Test accuracy: 0.920900
Distillation: Epoch : 24, Loss : 0.583076, Accuracy: 0.914000, Test accuracy: 0.921000
Distillation: Epoch : 25, Loss : 0.593154, Accuracy: 0.924000, Test accuracy: 0.921200
Distillation: Epoch : 26, Loss : 0.603961, Accuracy: 0.908000, Test accuracy: 0.922000
Distillation: Epoch : 27, Loss : 0.609700, Accuracy: 0.918000, Test accuracy: 0.922500
Distillation: Epoch : 28, Loss : 0.593081, Accuracy: 0.917000, Test accuracy: 0.923500
Distillation: Epoch : 29, Loss : 0.593943, Accuracy: 0.921000, Test accuracy: 0.923600
Distillation: Epoch : 30, Loss : 0.594046, Accuracy: 0.912000, Test accuracy: 0.923400
Distillation: Epoch : 31, Loss : 0.591216, Accuracy: 0.914000, Test accuracy: 0.924600
Distillation: Epoch : 32, Loss : 0.553706, Accuracy: 0.930000, Test accuracy: 0.924000
Distillation: Epoch : 33, Loss : 0.577943, Accuracy: 0.909000, Test accuracy: 0.925000
Distillation: Epoch : 34, Loss : 0.538652, Accuracy: 0.933000, Test accuracy: 0.925000
Distillation: Epoch : 35, Loss : 0.575001, Accuracy: 0.920000, Test accuracy: 0.924900
Distillation: Epoch : 36, Loss : 0.550974, Accuracy: 0.921000, Test accuracy: 0.925200
Distillation: Epoch : 37, Loss : 0.593463, Accuracy: 0.910000, Test accuracy: 0.926400
Distillation: Epoch : 38, Loss : 0.565757, Accuracy: 0.917000, Test accuracy: 0.925300
Distillation: Epoch : 39, Loss : 0.570791, Accuracy: 0.913000, Test accuracy: 0.926900
Distillation: Epoch : 40, Loss : 0.597789, Accuracy: 0.906000, Test accuracy: 0.926900
Distillation: Epoch : 41, Loss : 0.586702, Accuracy: 0.910000, Test accuracy: 0.926400
Distillation: Epoch : 42, Loss : 0.587518, Accuracy: 0.907000, Test accuracy: 0.927200
Distillation: Epoch : 43, Loss : 0.536220, Accuracy: 0.921000, Test accuracy: 0.927400
Distillation: Epoch : 44, Loss : 0.536342, Accuracy: 0.921000, Test accuracy: 0.928500
Distillation: Epoch : 45, Loss : 0.559817, Accuracy: 0.934000, Test accuracy: 0.928600
Distillation: Epoch : 46, Loss : 0.575497, Accuracy: 0.920000, Test accuracy: 0.927800
Distillation: Epoch : 47, Loss : 0.544366, Accuracy: 0.917000, Test accuracy: 0.929500
Distillation: Epoch : 48, Loss : 0.549357, Accuracy: 0.925000, Test accuracy: 0.929900
Distillation: Epoch : 49, Loss : 0.600889, Accuracy: 0.912000, Test accuracy: 0.929500
Distillation: Epoch : 50, Loss : 0.548835, Accuracy: 0.919000, Test accuracy: 0.929900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9299
Generating confusion matrix for student5
[[ 955.    0.    9.    4.    1.   10.    8.    2.    6.    9.]
 [   0. 1106.    6.    1.    1.    2.    3.    8.    7.    7.]
 [   1.    3.  933.   20.    5.    3.    5.   23.    6.    1.]
 [   1.    4.   15.  925.    1.   24.    0.    5.   17.    9.]
 [   1.    0.    9.    0.  931.   11.    7.   11.   10.   41.]
 [   6.    2.    2.   18.    0.  791.   12.    0.   21.    7.]
 [  10.    3.    9.    0.    7.   10.  919.    1.    6.    1.]
 [   1.    1.    9.   13.    1.    5.    1.  940.    6.   18.]
 [   5.   16.   34.   21.   10.   30.    3.    3.  892.    9.]
 [   0.    0.    6.    8.   25.    6.    0.   35.    3.  907.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.008868, Accuracy: 0.594000, Test accuracy: 0.589900
Distillation: Epoch : 2, Loss : 1.173656, Accuracy: 0.785000, Test accuracy: 0.811100
Distillation: Epoch : 3, Loss : 0.955936, Accuracy: 0.845000, Test accuracy: 0.845400
Distillation: Epoch : 4, Loss : 0.864537, Accuracy: 0.884000, Test accuracy: 0.862800
Distillation: Epoch : 5, Loss : 0.879363, Accuracy: 0.865000, Test accuracy: 0.875900
Distillation: Epoch : 6, Loss : 0.883564, Accuracy: 0.845000, Test accuracy: 0.882300
Distillation: Epoch : 7, Loss : 0.853008, Accuracy: 0.870000, Test accuracy: 0.888500
Distillation: Epoch : 8, Loss : 0.842906, Accuracy: 0.875000, Test accuracy: 0.895800
Distillation: Epoch : 9, Loss : 0.790573, Accuracy: 0.874000, Test accuracy: 0.902900
Distillation: Epoch : 10, Loss : 0.755324, Accuracy: 0.903000, Test accuracy: 0.907300
Distillation: Epoch : 11, Loss : 0.721120, Accuracy: 0.920000, Test accuracy: 0.911600
Distillation: Epoch : 12, Loss : 0.768379, Accuracy: 0.911000, Test accuracy: 0.916000
Distillation: Epoch : 13, Loss : 0.745017, Accuracy: 0.913000, Test accuracy: 0.920600
Distillation: Epoch : 14, Loss : 0.697699, Accuracy: 0.916000, Test accuracy: 0.923900
Distillation: Epoch : 15, Loss : 0.760626, Accuracy: 0.913000, Test accuracy: 0.927700
Distillation: Epoch : 16, Loss : 0.717896, Accuracy: 0.927000, Test accuracy: 0.930800
Distillation: Epoch : 17, Loss : 0.696048, Accuracy: 0.930000, Test accuracy: 0.935100
Distillation: Epoch : 18, Loss : 0.710658, Accuracy: 0.921000, Test accuracy: 0.936700
Distillation: Epoch : 19, Loss : 0.714074, Accuracy: 0.924000, Test accuracy: 0.938900
Distillation: Epoch : 20, Loss : 0.689773, Accuracy: 0.931000, Test accuracy: 0.940700
Distillation: Epoch : 21, Loss : 0.678909, Accuracy: 0.947000, Test accuracy: 0.943300
Distillation: Epoch : 22, Loss : 0.660063, Accuracy: 0.947000, Test accuracy: 0.945000
Distillation: Epoch : 23, Loss : 0.677381, Accuracy: 0.940000, Test accuracy: 0.947200
Distillation: Epoch : 24, Loss : 0.694199, Accuracy: 0.943000, Test accuracy: 0.948400
Distillation: Epoch : 25, Loss : 0.651686, Accuracy: 0.955000, Test accuracy: 0.950700
Distillation: Epoch : 26, Loss : 0.654171, Accuracy: 0.951000, Test accuracy: 0.950900
Distillation: Epoch : 27, Loss : 0.652210, Accuracy: 0.951000, Test accuracy: 0.953100
Distillation: Epoch : 28, Loss : 0.636913, Accuracy: 0.948000, Test accuracy: 0.952900
Distillation: Epoch : 29, Loss : 0.613208, Accuracy: 0.969000, Test accuracy: 0.954300
Distillation: Epoch : 30, Loss : 0.618710, Accuracy: 0.959000, Test accuracy: 0.954500
Distillation: Epoch : 31, Loss : 0.652977, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 32, Loss : 0.638419, Accuracy: 0.946000, Test accuracy: 0.956000
Distillation: Epoch : 33, Loss : 0.618681, Accuracy: 0.963000, Test accuracy: 0.955400
Distillation: Epoch : 34, Loss : 0.652613, Accuracy: 0.951000, Test accuracy: 0.956700
Distillation: Epoch : 35, Loss : 0.673355, Accuracy: 0.942000, Test accuracy: 0.957100
Distillation: Epoch : 36, Loss : 0.620108, Accuracy: 0.965000, Test accuracy: 0.956900
Distillation: Epoch : 37, Loss : 0.627174, Accuracy: 0.961000, Test accuracy: 0.957300
Distillation: Epoch : 38, Loss : 0.650647, Accuracy: 0.952000, Test accuracy: 0.957100
Distillation: Epoch : 39, Loss : 0.623337, Accuracy: 0.951000, Test accuracy: 0.957700
Distillation: Epoch : 40, Loss : 0.609507, Accuracy: 0.952000, Test accuracy: 0.958500
Distillation: Epoch : 41, Loss : 0.632153, Accuracy: 0.960000, Test accuracy: 0.958300
Distillation: Epoch : 42, Loss : 0.610298, Accuracy: 0.962000, Test accuracy: 0.957900
Distillation: Epoch : 43, Loss : 0.610090, Accuracy: 0.954000, Test accuracy: 0.958700
Distillation: Epoch : 44, Loss : 0.621480, Accuracy: 0.951000, Test accuracy: 0.959500
Distillation: Epoch : 45, Loss : 0.614758, Accuracy: 0.956000, Test accuracy: 0.958700
Distillation: Epoch : 46, Loss : 0.647646, Accuracy: 0.957000, Test accuracy: 0.958900
Distillation: Epoch : 47, Loss : 0.650193, Accuracy: 0.948000, Test accuracy: 0.959600
Distillation: Epoch : 48, Loss : 0.617609, Accuracy: 0.969000, Test accuracy: 0.961100
Distillation: Epoch : 49, Loss : 0.616612, Accuracy: 0.958000, Test accuracy: 0.959800
Distillation: Epoch : 50, Loss : 0.628785, Accuracy: 0.957000, Test accuracy: 0.959900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9599
Generating confusion matrix for student5
[[ 960.    0.    2.    0.    0.    2.    3.    2.    5.    7.]
 [   0. 1120.    5.    0.    0.    1.    4.    5.    2.    5.]
 [   1.    3.  965.    6.    1.    1.    3.   19.    4.    1.]
 [   2.    1.    8.  971.    0.   10.    0.    7.    9.    9.]
 [   0.    1.   11.    0.  959.    0.    7.    5.    9.   15.]
 [   2.    0.    4.   10.    0.  852.    4.    1.    2.    4.]
 [   8.    4.    2.    0.    6.    5.  931.    0.    2.    0.]
 [   3.    0.    6.    2.    1.    2.    0.  962.   12.    8.]
 [   3.    6.   26.   16.    5.   16.    6.    6.  925.    6.]
 [   1.    0.    3.    5.   10.    3.    0.   21.    4.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.966057, Accuracy: 0.554000, Test accuracy: 0.557500
Distillation: Epoch : 2, Loss : 1.160940, Accuracy: 0.825000, Test accuracy: 0.822600
Distillation: Epoch : 3, Loss : 1.040746, Accuracy: 0.854000, Test accuracy: 0.868700
Distillation: Epoch : 4, Loss : 0.987717, Accuracy: 0.880000, Test accuracy: 0.884000
Distillation: Epoch : 5, Loss : 0.936073, Accuracy: 0.888000, Test accuracy: 0.892400
Distillation: Epoch : 6, Loss : 0.986952, Accuracy: 0.884000, Test accuracy: 0.898100
Distillation: Epoch : 7, Loss : 0.919541, Accuracy: 0.899000, Test accuracy: 0.901700
Distillation: Epoch : 8, Loss : 0.897651, Accuracy: 0.909000, Test accuracy: 0.904400
Distillation: Epoch : 9, Loss : 0.940532, Accuracy: 0.898000, Test accuracy: 0.905900
Distillation: Epoch : 10, Loss : 0.933723, Accuracy: 0.897000, Test accuracy: 0.907000
Distillation: Epoch : 11, Loss : 0.921645, Accuracy: 0.905000, Test accuracy: 0.910200
Distillation: Epoch : 12, Loss : 0.930421, Accuracy: 0.905000, Test accuracy: 0.910800
Distillation: Epoch : 13, Loss : 0.912250, Accuracy: 0.911000, Test accuracy: 0.912500
Distillation: Epoch : 14, Loss : 0.907016, Accuracy: 0.898000, Test accuracy: 0.912900
Distillation: Epoch : 15, Loss : 0.922083, Accuracy: 0.904000, Test accuracy: 0.913500
Distillation: Epoch : 16, Loss : 0.895706, Accuracy: 0.915000, Test accuracy: 0.914500
Distillation: Epoch : 17, Loss : 0.921646, Accuracy: 0.911000, Test accuracy: 0.915800
Distillation: Epoch : 18, Loss : 0.929515, Accuracy: 0.894000, Test accuracy: 0.915500
Distillation: Epoch : 19, Loss : 0.902175, Accuracy: 0.909000, Test accuracy: 0.917000
Distillation: Epoch : 20, Loss : 0.913052, Accuracy: 0.908000, Test accuracy: 0.918200
Distillation: Epoch : 21, Loss : 0.932778, Accuracy: 0.913000, Test accuracy: 0.918700
Distillation: Epoch : 22, Loss : 0.906965, Accuracy: 0.914000, Test accuracy: 0.919000
Distillation: Epoch : 23, Loss : 0.919616, Accuracy: 0.901000, Test accuracy: 0.919100
Distillation: Epoch : 24, Loss : 0.906147, Accuracy: 0.903000, Test accuracy: 0.920900
Distillation: Epoch : 25, Loss : 0.896252, Accuracy: 0.922000, Test accuracy: 0.921000
Distillation: Epoch : 26, Loss : 0.900981, Accuracy: 0.917000, Test accuracy: 0.921500
Distillation: Epoch : 27, Loss : 0.920042, Accuracy: 0.910000, Test accuracy: 0.921200
Distillation: Epoch : 28, Loss : 0.896635, Accuracy: 0.910000, Test accuracy: 0.921200
Distillation: Epoch : 29, Loss : 0.900705, Accuracy: 0.903000, Test accuracy: 0.922300
Distillation: Epoch : 30, Loss : 0.899850, Accuracy: 0.914000, Test accuracy: 0.922400
Distillation: Epoch : 31, Loss : 0.902086, Accuracy: 0.920000, Test accuracy: 0.923600
Distillation: Epoch : 32, Loss : 0.893834, Accuracy: 0.899000, Test accuracy: 0.924300
Distillation: Epoch : 33, Loss : 0.869801, Accuracy: 0.928000, Test accuracy: 0.925000
Distillation: Epoch : 34, Loss : 0.865537, Accuracy: 0.924000, Test accuracy: 0.925000
Distillation: Epoch : 35, Loss : 0.897515, Accuracy: 0.915000, Test accuracy: 0.926300
Distillation: Epoch : 36, Loss : 0.863526, Accuracy: 0.926000, Test accuracy: 0.926800
Distillation: Epoch : 37, Loss : 0.909951, Accuracy: 0.916000, Test accuracy: 0.927200
Distillation: Epoch : 38, Loss : 0.906812, Accuracy: 0.925000, Test accuracy: 0.927600
Distillation: Epoch : 39, Loss : 0.882140, Accuracy: 0.923000, Test accuracy: 0.927400
Distillation: Epoch : 40, Loss : 0.865214, Accuracy: 0.935000, Test accuracy: 0.928900
Distillation: Epoch : 41, Loss : 0.877955, Accuracy: 0.911000, Test accuracy: 0.929200
Distillation: Epoch : 42, Loss : 0.859300, Accuracy: 0.930000, Test accuracy: 0.929500
Distillation: Epoch : 43, Loss : 0.905467, Accuracy: 0.900000, Test accuracy: 0.929200
Distillation: Epoch : 44, Loss : 0.878263, Accuracy: 0.923000, Test accuracy: 0.929900
Distillation: Epoch : 45, Loss : 0.894204, Accuracy: 0.925000, Test accuracy: 0.931300
Distillation: Epoch : 46, Loss : 0.881868, Accuracy: 0.919000, Test accuracy: 0.931200
Distillation: Epoch : 47, Loss : 0.859523, Accuracy: 0.924000, Test accuracy: 0.932600
Distillation: Epoch : 48, Loss : 0.851903, Accuracy: 0.930000, Test accuracy: 0.933000
Distillation: Epoch : 49, Loss : 0.856781, Accuracy: 0.922000, Test accuracy: 0.932800
Distillation: Epoch : 50, Loss : 0.864868, Accuracy: 0.929000, Test accuracy: 0.933700
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9337
Generating confusion matrix for student5
[[ 953.    0.    9.    3.    2.    6.    7.    1.    9.    7.]
 [   0. 1102.    5.    1.    0.    1.    3.    8.    5.    4.]
 [   2.    3.  928.   15.    2.    1.    1.   20.    5.    2.]
 [   3.    3.   16.  942.    2.   27.    0.    4.   16.    9.]
 [   1.    1.   22.    3.  944.    5.    5.   19.    9.   43.]
 [   4.    2.    1.   12.    0.  807.   19.    1.   14.    9.]
 [   6.    5.    9.    0.    8.   14.  920.    1.    6.    0.]
 [   2.    1.    6.   14.    0.    3.    0.  924.    4.   12.]
 [   7.   18.   34.   17.    4.   21.    3.    3.  903.    9.]
 [   2.    0.    2.    3.   20.    7.    0.   47.    3.  914.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.055188, Accuracy: 0.511000, Test accuracy: 0.494600
Distillation: Epoch : 2, Loss : 1.240535, Accuracy: 0.832000, Test accuracy: 0.831500
Distillation: Epoch : 3, Loss : 1.199268, Accuracy: 0.851000, Test accuracy: 0.867000
Distillation: Epoch : 4, Loss : 1.145710, Accuracy: 0.866000, Test accuracy: 0.879100
Distillation: Epoch : 5, Loss : 1.124132, Accuracy: 0.878000, Test accuracy: 0.886800
Distillation: Epoch : 6, Loss : 1.121202, Accuracy: 0.880000, Test accuracy: 0.892300
Distillation: Epoch : 7, Loss : 1.129124, Accuracy: 0.879000, Test accuracy: 0.896100
Distillation: Epoch : 8, Loss : 1.121366, Accuracy: 0.890000, Test accuracy: 0.897300
Distillation: Epoch : 9, Loss : 1.122346, Accuracy: 0.868000, Test accuracy: 0.900700
Distillation: Epoch : 10, Loss : 1.109125, Accuracy: 0.890000, Test accuracy: 0.902100
Distillation: Epoch : 11, Loss : 1.098924, Accuracy: 0.902000, Test accuracy: 0.903700
Distillation: Epoch : 12, Loss : 1.071645, Accuracy: 0.904000, Test accuracy: 0.903500
Distillation: Epoch : 13, Loss : 1.105670, Accuracy: 0.892000, Test accuracy: 0.903400
Distillation: Epoch : 14, Loss : 1.086049, Accuracy: 0.892000, Test accuracy: 0.904800
Distillation: Epoch : 15, Loss : 1.086323, Accuracy: 0.906000, Test accuracy: 0.906500
Distillation: Epoch : 16, Loss : 1.064124, Accuracy: 0.901000, Test accuracy: 0.906800
Distillation: Epoch : 17, Loss : 1.080525, Accuracy: 0.904000, Test accuracy: 0.907900
Distillation: Epoch : 18, Loss : 1.093736, Accuracy: 0.883000, Test accuracy: 0.907200
Distillation: Epoch : 19, Loss : 1.122276, Accuracy: 0.883000, Test accuracy: 0.907300
Distillation: Epoch : 20, Loss : 1.079851, Accuracy: 0.894000, Test accuracy: 0.908300
Distillation: Epoch : 21, Loss : 1.076838, Accuracy: 0.910000, Test accuracy: 0.909000
Distillation: Epoch : 22, Loss : 1.108834, Accuracy: 0.900000, Test accuracy: 0.910000
Distillation: Epoch : 23, Loss : 1.063517, Accuracy: 0.902000, Test accuracy: 0.910900
Distillation: Epoch : 24, Loss : 1.055686, Accuracy: 0.908000, Test accuracy: 0.908900
Distillation: Epoch : 25, Loss : 1.067858, Accuracy: 0.901000, Test accuracy: 0.910900
Distillation: Epoch : 26, Loss : 1.084815, Accuracy: 0.896000, Test accuracy: 0.910000
Distillation: Epoch : 27, Loss : 1.049382, Accuracy: 0.912000, Test accuracy: 0.911200
Distillation: Epoch : 28, Loss : 1.097294, Accuracy: 0.904000, Test accuracy: 0.910900
Distillation: Epoch : 29, Loss : 1.082072, Accuracy: 0.900000, Test accuracy: 0.911300
Distillation: Epoch : 30, Loss : 1.080903, Accuracy: 0.901000, Test accuracy: 0.911700
Distillation: Epoch : 31, Loss : 1.058673, Accuracy: 0.919000, Test accuracy: 0.910700
Distillation: Epoch : 32, Loss : 1.087560, Accuracy: 0.896000, Test accuracy: 0.911700
Distillation: Epoch : 33, Loss : 1.097250, Accuracy: 0.895000, Test accuracy: 0.911100
Distillation: Epoch : 34, Loss : 1.093688, Accuracy: 0.902000, Test accuracy: 0.911300
Distillation: Epoch : 35, Loss : 1.041131, Accuracy: 0.897000, Test accuracy: 0.911800
Distillation: Epoch : 36, Loss : 1.076753, Accuracy: 0.899000, Test accuracy: 0.912100
Distillation: Epoch : 37, Loss : 1.087744, Accuracy: 0.892000, Test accuracy: 0.912500
Distillation: Epoch : 38, Loss : 1.091298, Accuracy: 0.900000, Test accuracy: 0.912500
Distillation: Epoch : 39, Loss : 1.083401, Accuracy: 0.901000, Test accuracy: 0.911800
Distillation: Epoch : 40, Loss : 1.106198, Accuracy: 0.899000, Test accuracy: 0.911600
Distillation: Epoch : 41, Loss : 1.074788, Accuracy: 0.891000, Test accuracy: 0.913400
Distillation: Epoch : 42, Loss : 1.110530, Accuracy: 0.898000, Test accuracy: 0.913200
Distillation: Epoch : 43, Loss : 1.099615, Accuracy: 0.904000, Test accuracy: 0.913100
Distillation: Epoch : 44, Loss : 1.080558, Accuracy: 0.891000, Test accuracy: 0.913000
Distillation: Epoch : 45, Loss : 1.079810, Accuracy: 0.915000, Test accuracy: 0.912700
Distillation: Epoch : 46, Loss : 1.074760, Accuracy: 0.894000, Test accuracy: 0.912200
Distillation: Epoch : 47, Loss : 1.079018, Accuracy: 0.912000, Test accuracy: 0.913600
Distillation: Epoch : 48, Loss : 1.085219, Accuracy: 0.892000, Test accuracy: 0.912800
Distillation: Epoch : 49, Loss : 1.071223, Accuracy: 0.908000, Test accuracy: 0.915400
Distillation: Epoch : 50, Loss : 1.061845, Accuracy: 0.917000, Test accuracy: 0.914100
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9141
Generating confusion matrix for student5
[[ 947.    0.    8.    5.    2.   10.    8.    1.    6.    8.]
 [   0. 1092.    5.    1.    1.    1.    3.   14.    9.    5.]
 [   1.    3.  902.   14.    5.    1.    5.   16.    5.    2.]
 [   3.    4.   24.  922.    2.   40.    0.    7.   24.   12.]
 [   3.    1.   22.    3.  932.   12.   13.   14.   11.   63.]
 [   7.    3.    1.   19.    1.  760.   19.    1.   19.    7.]
 [  10.    4.   10.    3.    7.   15.  900.    0.    9.    0.]
 [   2.    1.   11.    9.    1.    7.    2.  926.    5.   17.]
 [   6.   27.   46.   30.    9.   38.    8.    3.  881.   16.]
 [   1.    0.    3.    4.   22.    8.    0.   46.    5.  879.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.890881, Accuracy: 0.634000, Test accuracy: 0.645900
Distillation: Epoch : 2, Loss : 1.343107, Accuracy: 0.847000, Test accuracy: 0.848800
Distillation: Epoch : 3, Loss : 1.295049, Accuracy: 0.862000, Test accuracy: 0.874100
Distillation: Epoch : 4, Loss : 1.289527, Accuracy: 0.883000, Test accuracy: 0.883200
Distillation: Epoch : 5, Loss : 1.283122, Accuracy: 0.871000, Test accuracy: 0.887800
Distillation: Epoch : 6, Loss : 1.299155, Accuracy: 0.858000, Test accuracy: 0.889800
Distillation: Epoch : 7, Loss : 1.296847, Accuracy: 0.872000, Test accuracy: 0.892100
Distillation: Epoch : 8, Loss : 1.317820, Accuracy: 0.877000, Test accuracy: 0.893900
Distillation: Epoch : 9, Loss : 1.268957, Accuracy: 0.878000, Test accuracy: 0.896200
Distillation: Epoch : 10, Loss : 1.245857, Accuracy: 0.885000, Test accuracy: 0.896900
Distillation: Epoch : 11, Loss : 1.266472, Accuracy: 0.891000, Test accuracy: 0.897700
Distillation: Epoch : 12, Loss : 1.236378, Accuracy: 0.904000, Test accuracy: 0.899400
Distillation: Epoch : 13, Loss : 1.238128, Accuracy: 0.890000, Test accuracy: 0.898100
Distillation: Epoch : 14, Loss : 1.222131, Accuracy: 0.901000, Test accuracy: 0.900400
Distillation: Epoch : 15, Loss : 1.253903, Accuracy: 0.889000, Test accuracy: 0.901000
Distillation: Epoch : 16, Loss : 1.254812, Accuracy: 0.887000, Test accuracy: 0.900000
Distillation: Epoch : 17, Loss : 1.255777, Accuracy: 0.897000, Test accuracy: 0.903000
Distillation: Epoch : 18, Loss : 1.271103, Accuracy: 0.884000, Test accuracy: 0.902900
Distillation: Epoch : 19, Loss : 1.253149, Accuracy: 0.899000, Test accuracy: 0.902300
Distillation: Epoch : 20, Loss : 1.211183, Accuracy: 0.910000, Test accuracy: 0.904500
Distillation: Epoch : 21, Loss : 1.256422, Accuracy: 0.891000, Test accuracy: 0.903600
Distillation: Epoch : 22, Loss : 1.233764, Accuracy: 0.899000, Test accuracy: 0.905300
Distillation: Epoch : 23, Loss : 1.247863, Accuracy: 0.899000, Test accuracy: 0.904600
Distillation: Epoch : 24, Loss : 1.261647, Accuracy: 0.897000, Test accuracy: 0.904800
Distillation: Epoch : 25, Loss : 1.235385, Accuracy: 0.911000, Test accuracy: 0.904900
Distillation: Epoch : 26, Loss : 1.230406, Accuracy: 0.907000, Test accuracy: 0.905500
Distillation: Epoch : 27, Loss : 1.232258, Accuracy: 0.878000, Test accuracy: 0.905800
Distillation: Epoch : 28, Loss : 1.222967, Accuracy: 0.901000, Test accuracy: 0.906200
Distillation: Epoch : 29, Loss : 1.234800, Accuracy: 0.893000, Test accuracy: 0.906900
Distillation: Epoch : 30, Loss : 1.228600, Accuracy: 0.904000, Test accuracy: 0.907300
Distillation: Epoch : 31, Loss : 1.243122, Accuracy: 0.898000, Test accuracy: 0.906900
Distillation: Epoch : 32, Loss : 1.218075, Accuracy: 0.905000, Test accuracy: 0.908100
Distillation: Epoch : 33, Loss : 1.238665, Accuracy: 0.906000, Test accuracy: 0.906300
Distillation: Epoch : 34, Loss : 1.231380, Accuracy: 0.894000, Test accuracy: 0.908500
Distillation: Epoch : 35, Loss : 1.182327, Accuracy: 0.907000, Test accuracy: 0.907200
Distillation: Epoch : 36, Loss : 1.241861, Accuracy: 0.890000, Test accuracy: 0.908700
Distillation: Epoch : 37, Loss : 1.256083, Accuracy: 0.903000, Test accuracy: 0.908500
Distillation: Epoch : 38, Loss : 1.229637, Accuracy: 0.888000, Test accuracy: 0.907500
Distillation: Epoch : 39, Loss : 1.216986, Accuracy: 0.895000, Test accuracy: 0.909900
Distillation: Epoch : 40, Loss : 1.246871, Accuracy: 0.891000, Test accuracy: 0.909100
Distillation: Epoch : 41, Loss : 1.190338, Accuracy: 0.926000, Test accuracy: 0.911000
Distillation: Epoch : 42, Loss : 1.204944, Accuracy: 0.893000, Test accuracy: 0.909500
Distillation: Epoch : 43, Loss : 1.248926, Accuracy: 0.891000, Test accuracy: 0.909900
Distillation: Epoch : 44, Loss : 1.220650, Accuracy: 0.906000, Test accuracy: 0.909800
Distillation: Epoch : 45, Loss : 1.241124, Accuracy: 0.903000, Test accuracy: 0.911000
Distillation: Epoch : 46, Loss : 1.213491, Accuracy: 0.905000, Test accuracy: 0.912000
Distillation: Epoch : 47, Loss : 1.223991, Accuracy: 0.895000, Test accuracy: 0.910000
Distillation: Epoch : 48, Loss : 1.237279, Accuracy: 0.910000, Test accuracy: 0.910100
Distillation: Epoch : 49, Loss : 1.216889, Accuracy: 0.907000, Test accuracy: 0.911100
Distillation: Epoch : 50, Loss : 1.244962, Accuracy: 0.893000, Test accuracy: 0.912300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9123
Generating confusion matrix for student5
[[ 950.    0.    8.    4.    1.    9.    7.    1.    7.    8.]
 [   0. 1102.    6.    1.    0.    2.    4.   17.    8.    7.]
 [   1.    3.  908.   21.    6.    2.    5.   19.    7.    1.]
 [   2.    3.   22.  920.    1.   45.    1.    4.   18.   13.]
 [   5.    1.   18.    3.  932.   17.   11.   24.   13.   58.]
 [   6.    4.    1.   18.    1.  744.   17.    2.   20.    8.]
 [  11.    4.   12.    3.    8.   16.  905.    1.   12.    1.]
 [   1.    1.   10.    9.    1.    8.    1.  900.    5.   14.]
 [   4.   17.   40.   26.    8.   40.    7.    2.  875.   12.]
 [   0.    0.    7.    5.   24.    9.    0.   58.    9.  887.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.264382, Accuracy: 0.102000, Test accuracy: 0.097400
Distillation: Epoch : 2, Loss : 1.654100, Accuracy: 0.752000, Test accuracy: 0.795000
Distillation: Epoch : 3, Loss : 1.501723, Accuracy: 0.827000, Test accuracy: 0.839100
Distillation: Epoch : 4, Loss : 1.449728, Accuracy: 0.836000, Test accuracy: 0.854300
Distillation: Epoch : 5, Loss : 1.415031, Accuracy: 0.861000, Test accuracy: 0.865400
Distillation: Epoch : 6, Loss : 1.423196, Accuracy: 0.849000, Test accuracy: 0.874000
Distillation: Epoch : 7, Loss : 1.373654, Accuracy: 0.883000, Test accuracy: 0.878600
Distillation: Epoch : 8, Loss : 1.386238, Accuracy: 0.888000, Test accuracy: 0.884100
Distillation: Epoch : 9, Loss : 1.411417, Accuracy: 0.886000, Test accuracy: 0.889100
Distillation: Epoch : 10, Loss : 1.339458, Accuracy: 0.890000, Test accuracy: 0.893500
Distillation: Epoch : 11, Loss : 1.379111, Accuracy: 0.903000, Test accuracy: 0.899500
Distillation: Epoch : 12, Loss : 1.358843, Accuracy: 0.897000, Test accuracy: 0.901900
Distillation: Epoch : 13, Loss : 1.364529, Accuracy: 0.905000, Test accuracy: 0.904700
Distillation: Epoch : 14, Loss : 1.374822, Accuracy: 0.884000, Test accuracy: 0.907900
Distillation: Epoch : 15, Loss : 1.351447, Accuracy: 0.916000, Test accuracy: 0.908800
Distillation: Epoch : 16, Loss : 1.340234, Accuracy: 0.916000, Test accuracy: 0.910400
Distillation: Epoch : 17, Loss : 1.324936, Accuracy: 0.912000, Test accuracy: 0.914300
Distillation: Epoch : 18, Loss : 1.354505, Accuracy: 0.894000, Test accuracy: 0.915000
Distillation: Epoch : 19, Loss : 1.347263, Accuracy: 0.907000, Test accuracy: 0.914800
Distillation: Epoch : 20, Loss : 1.311879, Accuracy: 0.897000, Test accuracy: 0.916100
Distillation: Epoch : 21, Loss : 1.319124, Accuracy: 0.920000, Test accuracy: 0.918000
Distillation: Epoch : 22, Loss : 1.346175, Accuracy: 0.887000, Test accuracy: 0.918000
Distillation: Epoch : 23, Loss : 1.305064, Accuracy: 0.933000, Test accuracy: 0.920100
Distillation: Epoch : 24, Loss : 1.315789, Accuracy: 0.925000, Test accuracy: 0.920600
Distillation: Epoch : 25, Loss : 1.305777, Accuracy: 0.935000, Test accuracy: 0.922100
Distillation: Epoch : 26, Loss : 1.305070, Accuracy: 0.916000, Test accuracy: 0.922800
Distillation: Epoch : 27, Loss : 1.335916, Accuracy: 0.907000, Test accuracy: 0.924400
Distillation: Epoch : 28, Loss : 1.320553, Accuracy: 0.924000, Test accuracy: 0.924400
Distillation: Epoch : 29, Loss : 1.334733, Accuracy: 0.919000, Test accuracy: 0.924600
Distillation: Epoch : 30, Loss : 1.312926, Accuracy: 0.917000, Test accuracy: 0.925800
Distillation: Epoch : 31, Loss : 1.321635, Accuracy: 0.920000, Test accuracy: 0.927900
Distillation: Epoch : 32, Loss : 1.309165, Accuracy: 0.919000, Test accuracy: 0.929000
Distillation: Epoch : 33, Loss : 1.295645, Accuracy: 0.939000, Test accuracy: 0.928600
Distillation: Epoch : 34, Loss : 1.324615, Accuracy: 0.929000, Test accuracy: 0.928800
Distillation: Epoch : 35, Loss : 1.298515, Accuracy: 0.934000, Test accuracy: 0.931500
Distillation: Epoch : 36, Loss : 1.322957, Accuracy: 0.926000, Test accuracy: 0.931800
Distillation: Epoch : 37, Loss : 1.311291, Accuracy: 0.930000, Test accuracy: 0.933400
Distillation: Epoch : 38, Loss : 1.308284, Accuracy: 0.917000, Test accuracy: 0.933900
Distillation: Epoch : 39, Loss : 1.321468, Accuracy: 0.923000, Test accuracy: 0.934300
Distillation: Epoch : 40, Loss : 1.298387, Accuracy: 0.921000, Test accuracy: 0.934500
Distillation: Epoch : 41, Loss : 1.307628, Accuracy: 0.929000, Test accuracy: 0.938200
Distillation: Epoch : 42, Loss : 1.295120, Accuracy: 0.935000, Test accuracy: 0.940400
Distillation: Epoch : 43, Loss : 1.286261, Accuracy: 0.947000, Test accuracy: 0.940400
Distillation: Epoch : 44, Loss : 1.263586, Accuracy: 0.945000, Test accuracy: 0.942500
Distillation: Epoch : 45, Loss : 1.273762, Accuracy: 0.927000, Test accuracy: 0.943500
Distillation: Epoch : 46, Loss : 1.278039, Accuracy: 0.949000, Test accuracy: 0.944800
Distillation: Epoch : 47, Loss : 1.264354, Accuracy: 0.955000, Test accuracy: 0.947600
Distillation: Epoch : 48, Loss : 1.286628, Accuracy: 0.945000, Test accuracy: 0.948100
Distillation: Epoch : 49, Loss : 1.264782, Accuracy: 0.938000, Test accuracy: 0.948600
Distillation: Epoch : 50, Loss : 1.266062, Accuracy: 0.947000, Test accuracy: 0.949200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9492
Generating confusion matrix for student5
[[ 969.    0.    6.    3.    2.    3.    7.    1.    5.    2.]
 [   0. 1095.    2.    0.    1.    1.    5.    6.    3.    4.]
 [   0.    6.  963.   13.    1.    1.    1.   24.    4.    2.]
 [   0.    2.   10.  952.    0.   17.    1.    2.    3.   10.]
 [   0.    0.   13.    2.  951.    1.    7.   15.    8.   32.]
 [   0.    0.    1.   11.    0.  842.    8.    2.    3.    8.]
 [   4.    5.    5.    2.    7.    7.  918.    0.    5.    0.]
 [   0.    0.   14.   13.    1.    3.    0.  938.    4.   10.]
 [   5.   27.   16.   14.    6.   12.   11.    5.  934.   11.]
 [   2.    0.    2.    0.   13.    5.    0.   35.    5.  930.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.272032, Accuracy: 0.087000, Test accuracy: 0.097400
Distillation: Epoch : 2, Loss : 2.099535, Accuracy: 0.634000, Test accuracy: 0.636700
Distillation: Epoch : 3, Loss : 1.662277, Accuracy: 0.775000, Test accuracy: 0.803500
Distillation: Epoch : 4, Loss : 1.565469, Accuracy: 0.847000, Test accuracy: 0.854100
Distillation: Epoch : 5, Loss : 1.531492, Accuracy: 0.858000, Test accuracy: 0.874700
Distillation: Epoch : 6, Loss : 1.507161, Accuracy: 0.885000, Test accuracy: 0.883500
Distillation: Epoch : 7, Loss : 1.511727, Accuracy: 0.880000, Test accuracy: 0.891100
Distillation: Epoch : 8, Loss : 1.508097, Accuracy: 0.899000, Test accuracy: 0.896400
Distillation: Epoch : 9, Loss : 1.513272, Accuracy: 0.876000, Test accuracy: 0.901700
Distillation: Epoch : 10, Loss : 1.474105, Accuracy: 0.901000, Test accuracy: 0.905400
Distillation: Epoch : 11, Loss : 1.441436, Accuracy: 0.915000, Test accuracy: 0.911000
Distillation: Epoch : 12, Loss : 1.501534, Accuracy: 0.882000, Test accuracy: 0.912200
Distillation: Epoch : 13, Loss : 1.484512, Accuracy: 0.902000, Test accuracy: 0.914900
Distillation: Epoch : 14, Loss : 1.454373, Accuracy: 0.912000, Test accuracy: 0.916600
Distillation: Epoch : 15, Loss : 1.451403, Accuracy: 0.924000, Test accuracy: 0.918700
Distillation: Epoch : 16, Loss : 1.419333, Accuracy: 0.921000, Test accuracy: 0.921800
Distillation: Epoch : 17, Loss : 1.452662, Accuracy: 0.908000, Test accuracy: 0.923500
Distillation: Epoch : 18, Loss : 1.431957, Accuracy: 0.922000, Test accuracy: 0.924600
Distillation: Epoch : 19, Loss : 1.449044, Accuracy: 0.903000, Test accuracy: 0.926100
Distillation: Epoch : 20, Loss : 1.457090, Accuracy: 0.912000, Test accuracy: 0.927400
Distillation: Epoch : 21, Loss : 1.420679, Accuracy: 0.924000, Test accuracy: 0.928900
Distillation: Epoch : 22, Loss : 1.411359, Accuracy: 0.939000, Test accuracy: 0.931000
Distillation: Epoch : 23, Loss : 1.428908, Accuracy: 0.925000, Test accuracy: 0.933000
Distillation: Epoch : 24, Loss : 1.410886, Accuracy: 0.942000, Test accuracy: 0.934200
Distillation: Epoch : 25, Loss : 1.402737, Accuracy: 0.926000, Test accuracy: 0.936300
Distillation: Epoch : 26, Loss : 1.436670, Accuracy: 0.923000, Test accuracy: 0.937900
Distillation: Epoch : 27, Loss : 1.445167, Accuracy: 0.918000, Test accuracy: 0.938100
Distillation: Epoch : 28, Loss : 1.427555, Accuracy: 0.927000, Test accuracy: 0.938700
Distillation: Epoch : 29, Loss : 1.443684, Accuracy: 0.927000, Test accuracy: 0.939600
Distillation: Epoch : 30, Loss : 1.431712, Accuracy: 0.928000, Test accuracy: 0.940900
Distillation: Epoch : 31, Loss : 1.420777, Accuracy: 0.932000, Test accuracy: 0.942100
Distillation: Epoch : 32, Loss : 1.433895, Accuracy: 0.933000, Test accuracy: 0.941900
Distillation: Epoch : 33, Loss : 1.402801, Accuracy: 0.940000, Test accuracy: 0.944200
Distillation: Epoch : 34, Loss : 1.420807, Accuracy: 0.935000, Test accuracy: 0.945500
Distillation: Epoch : 35, Loss : 1.394710, Accuracy: 0.937000, Test accuracy: 0.945200
Distillation: Epoch : 36, Loss : 1.419806, Accuracy: 0.946000, Test accuracy: 0.946600
Distillation: Epoch : 37, Loss : 1.420345, Accuracy: 0.927000, Test accuracy: 0.947100
Distillation: Epoch : 38, Loss : 1.390014, Accuracy: 0.949000, Test accuracy: 0.947600
Distillation: Epoch : 39, Loss : 1.397739, Accuracy: 0.947000, Test accuracy: 0.947200
Distillation: Epoch : 40, Loss : 1.411562, Accuracy: 0.944000, Test accuracy: 0.948900
Distillation: Epoch : 41, Loss : 1.413854, Accuracy: 0.939000, Test accuracy: 0.949900
Distillation: Epoch : 42, Loss : 1.393675, Accuracy: 0.944000, Test accuracy: 0.950100
Distillation: Epoch : 43, Loss : 1.400538, Accuracy: 0.945000, Test accuracy: 0.950000
Distillation: Epoch : 44, Loss : 1.404401, Accuracy: 0.945000, Test accuracy: 0.950700
Distillation: Epoch : 45, Loss : 1.409255, Accuracy: 0.936000, Test accuracy: 0.950600
Distillation: Epoch : 46, Loss : 1.404926, Accuracy: 0.944000, Test accuracy: 0.951400
Distillation: Epoch : 47, Loss : 1.387795, Accuracy: 0.945000, Test accuracy: 0.952100
Distillation: Epoch : 48, Loss : 1.400094, Accuracy: 0.945000, Test accuracy: 0.953200
Distillation: Epoch : 49, Loss : 1.409361, Accuracy: 0.943000, Test accuracy: 0.953600
Distillation: Epoch : 50, Loss : 1.393347, Accuracy: 0.947000, Test accuracy: 0.954000
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.954
Generating confusion matrix for student5
[[ 961.    0.    8.    0.    0.    3.    5.    0.    8.    3.]
 [   0. 1107.    4.    0.    0.    0.    2.    5.    3.    7.]
 [   2.    3.  972.    5.    5.    1.    0.   13.    6.    2.]
 [   0.    1.    5.  967.    0.    8.    0.    5.   10.    5.]
 [   4.    2.    9.    2.  934.    3.    6.   13.    7.   35.]
 [   2.    0.    0.   13.    1.  854.   12.    2.   10.    7.]
 [   5.    4.    4.    0.    3.    6.  927.    0.    1.    1.]
 [   1.    0.    9.    4.    1.    0.    0.  961.    3.    6.]
 [   4.   18.   20.   16.   14.   15.    6.    5.  919.    5.]
 [   1.    0.    1.    3.   24.    2.    0.   24.    7.  938.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.175135, Accuracy: 0.370000, Test accuracy: 0.363100
Distillation: Epoch : 2, Loss : 1.849541, Accuracy: 0.846000, Test accuracy: 0.837700
Distillation: Epoch : 3, Loss : 1.813072, Accuracy: 0.860000, Test accuracy: 0.866900
Distillation: Epoch : 4, Loss : 1.791169, Accuracy: 0.865000, Test accuracy: 0.878800
Distillation: Epoch : 5, Loss : 1.783401, Accuracy: 0.871000, Test accuracy: 0.886700
Distillation: Epoch : 6, Loss : 1.772482, Accuracy: 0.899000, Test accuracy: 0.894800
Distillation: Epoch : 7, Loss : 1.782664, Accuracy: 0.887000, Test accuracy: 0.901500
Distillation: Epoch : 8, Loss : 1.749762, Accuracy: 0.900000, Test accuracy: 0.907300
Distillation: Epoch : 9, Loss : 1.763371, Accuracy: 0.894000, Test accuracy: 0.913700
Distillation: Epoch : 10, Loss : 1.735742, Accuracy: 0.912000, Test accuracy: 0.918000
Distillation: Epoch : 11, Loss : 1.741010, Accuracy: 0.917000, Test accuracy: 0.921800
Distillation: Epoch : 12, Loss : 1.726957, Accuracy: 0.923000, Test accuracy: 0.925900
Distillation: Epoch : 13, Loss : 1.746536, Accuracy: 0.914000, Test accuracy: 0.928600
Distillation: Epoch : 14, Loss : 1.717387, Accuracy: 0.913000, Test accuracy: 0.931900
Distillation: Epoch : 15, Loss : 1.722890, Accuracy: 0.927000, Test accuracy: 0.935300
Distillation: Epoch : 16, Loss : 1.717121, Accuracy: 0.926000, Test accuracy: 0.938100
Distillation: Epoch : 17, Loss : 1.724252, Accuracy: 0.922000, Test accuracy: 0.940400
Distillation: Epoch : 18, Loss : 1.713629, Accuracy: 0.925000, Test accuracy: 0.943100
Distillation: Epoch : 19, Loss : 1.695731, Accuracy: 0.941000, Test accuracy: 0.945500
Distillation: Epoch : 20, Loss : 1.714369, Accuracy: 0.929000, Test accuracy: 0.947100
Distillation: Epoch : 21, Loss : 1.699901, Accuracy: 0.933000, Test accuracy: 0.946900
Distillation: Epoch : 22, Loss : 1.715144, Accuracy: 0.933000, Test accuracy: 0.949000
Distillation: Epoch : 23, Loss : 1.692577, Accuracy: 0.945000, Test accuracy: 0.950800
Distillation: Epoch : 24, Loss : 1.696758, Accuracy: 0.947000, Test accuracy: 0.952000
Distillation: Epoch : 25, Loss : 1.692279, Accuracy: 0.940000, Test accuracy: 0.951500
Distillation: Epoch : 26, Loss : 1.684583, Accuracy: 0.948000, Test accuracy: 0.953000
Distillation: Epoch : 27, Loss : 1.698034, Accuracy: 0.960000, Test accuracy: 0.953200
Distillation: Epoch : 28, Loss : 1.704778, Accuracy: 0.952000, Test accuracy: 0.952900
Distillation: Epoch : 29, Loss : 1.669160, Accuracy: 0.949000, Test accuracy: 0.953300
Distillation: Epoch : 30, Loss : 1.690866, Accuracy: 0.943000, Test accuracy: 0.953500
Distillation: Epoch : 31, Loss : 1.684225, Accuracy: 0.954000, Test accuracy: 0.954700
Distillation: Epoch : 32, Loss : 1.690342, Accuracy: 0.942000, Test accuracy: 0.955400
Distillation: Epoch : 33, Loss : 1.695697, Accuracy: 0.946000, Test accuracy: 0.955500
Distillation: Epoch : 34, Loss : 1.688321, Accuracy: 0.949000, Test accuracy: 0.956100
Distillation: Epoch : 35, Loss : 1.679181, Accuracy: 0.960000, Test accuracy: 0.956800
Distillation: Epoch : 36, Loss : 1.698315, Accuracy: 0.951000, Test accuracy: 0.955900
Distillation: Epoch : 37, Loss : 1.684322, Accuracy: 0.955000, Test accuracy: 0.957200
Distillation: Epoch : 38, Loss : 1.702459, Accuracy: 0.948000, Test accuracy: 0.956200
Distillation: Epoch : 39, Loss : 1.703777, Accuracy: 0.960000, Test accuracy: 0.956200
Distillation: Epoch : 40, Loss : 1.712197, Accuracy: 0.943000, Test accuracy: 0.957300
Distillation: Epoch : 41, Loss : 1.677491, Accuracy: 0.951000, Test accuracy: 0.956500
Distillation: Epoch : 42, Loss : 1.688284, Accuracy: 0.946000, Test accuracy: 0.957600
Distillation: Epoch : 43, Loss : 1.689866, Accuracy: 0.952000, Test accuracy: 0.957000
Distillation: Epoch : 44, Loss : 1.702355, Accuracy: 0.936000, Test accuracy: 0.958100
Distillation: Epoch : 45, Loss : 1.693890, Accuracy: 0.962000, Test accuracy: 0.957800
Distillation: Epoch : 46, Loss : 1.704424, Accuracy: 0.954000, Test accuracy: 0.958400
Distillation: Epoch : 47, Loss : 1.661476, Accuracy: 0.949000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 1.680570, Accuracy: 0.952000, Test accuracy: 0.958000
Distillation: Epoch : 49, Loss : 1.686593, Accuracy: 0.961000, Test accuracy: 0.958500
Distillation: Epoch : 50, Loss : 1.666622, Accuracy: 0.952000, Test accuracy: 0.958500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9585
Generating confusion matrix for student5
[[ 963.    0.    4.    0.    1.    1.    9.    1.    5.    4.]
 [   0. 1102.    6.    1.    1.    1.    3.    6.    2.    7.]
 [   0.    1.  970.    4.    0.    1.    0.   16.    4.    0.]
 [   0.    1.    6.  973.    0.   12.    0.    3.    4.    7.]
 [   3.    2.   11.    2.  964.    1.    7.    6.    7.   24.]
 [   0.    0.    1.    8.    0.  846.    3.    2.    4.    7.]
 [   7.    4.    2.    0.    3.    6.  927.    0.    2.    1.]
 [   0.    0.    5.    9.    0.    1.    0.  952.    6.    4.]
 [   4.   25.   24.    9.    6.   20.    9.    7.  937.    4.]
 [   3.    0.    3.    4.    7.    3.    0.   35.    3.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.143555, Accuracy: 0.702000, Test accuracy: 0.706100
Distillation: Epoch : 2, Loss : 2.045257, Accuracy: 0.840000, Test accuracy: 0.848100
Distillation: Epoch : 3, Loss : 2.030199, Accuracy: 0.855000, Test accuracy: 0.862900
Distillation: Epoch : 4, Loss : 2.030562, Accuracy: 0.862000, Test accuracy: 0.868200
Distillation: Epoch : 5, Loss : 2.027015, Accuracy: 0.857000, Test accuracy: 0.875600
Distillation: Epoch : 6, Loss : 2.019480, Accuracy: 0.863000, Test accuracy: 0.879200
Distillation: Epoch : 7, Loss : 2.032759, Accuracy: 0.880000, Test accuracy: 0.881000
Distillation: Epoch : 8, Loss : 2.031934, Accuracy: 0.851000, Test accuracy: 0.885200
Distillation: Epoch : 9, Loss : 2.023706, Accuracy: 0.868000, Test accuracy: 0.883100
Distillation: Epoch : 10, Loss : 2.018873, Accuracy: 0.868000, Test accuracy: 0.885900
Distillation: Epoch : 11, Loss : 2.030619, Accuracy: 0.877000, Test accuracy: 0.886800
Distillation: Epoch : 12, Loss : 2.012912, Accuracy: 0.879000, Test accuracy: 0.886200
Distillation: Epoch : 13, Loss : 2.019315, Accuracy: 0.871000, Test accuracy: 0.884900
Distillation: Epoch : 14, Loss : 2.019548, Accuracy: 0.890000, Test accuracy: 0.886800
Distillation: Epoch : 15, Loss : 2.017071, Accuracy: 0.879000, Test accuracy: 0.886400
Distillation: Epoch : 16, Loss : 2.015854, Accuracy: 0.864000, Test accuracy: 0.886500
Distillation: Epoch : 17, Loss : 2.012985, Accuracy: 0.884000, Test accuracy: 0.887800
Distillation: Epoch : 18, Loss : 2.024103, Accuracy: 0.896000, Test accuracy: 0.888300
Distillation: Epoch : 19, Loss : 2.016427, Accuracy: 0.872000, Test accuracy: 0.887500
Distillation: Epoch : 20, Loss : 2.006658, Accuracy: 0.892000, Test accuracy: 0.889600
Distillation: Epoch : 21, Loss : 2.011099, Accuracy: 0.870000, Test accuracy: 0.887700
Distillation: Epoch : 22, Loss : 2.006770, Accuracy: 0.893000, Test accuracy: 0.888600
Distillation: Epoch : 23, Loss : 2.015068, Accuracy: 0.877000, Test accuracy: 0.889300
Distillation: Epoch : 24, Loss : 2.014779, Accuracy: 0.880000, Test accuracy: 0.888700
Distillation: Epoch : 25, Loss : 2.017189, Accuracy: 0.874000, Test accuracy: 0.888600
Distillation: Epoch : 26, Loss : 2.017656, Accuracy: 0.876000, Test accuracy: 0.889400
Distillation: Epoch : 27, Loss : 2.019627, Accuracy: 0.883000, Test accuracy: 0.889600
Distillation: Epoch : 28, Loss : 2.015034, Accuracy: 0.891000, Test accuracy: 0.889600
Distillation: Epoch : 29, Loss : 2.007093, Accuracy: 0.880000, Test accuracy: 0.889900
Distillation: Epoch : 30, Loss : 2.000522, Accuracy: 0.910000, Test accuracy: 0.892400
Distillation: Epoch : 31, Loss : 2.012280, Accuracy: 0.874000, Test accuracy: 0.890600
Distillation: Epoch : 32, Loss : 2.016300, Accuracy: 0.884000, Test accuracy: 0.889300
Distillation: Epoch : 33, Loss : 2.011823, Accuracy: 0.893000, Test accuracy: 0.889600
Distillation: Epoch : 34, Loss : 2.005304, Accuracy: 0.880000, Test accuracy: 0.890000
Distillation: Epoch : 35, Loss : 2.003590, Accuracy: 0.879000, Test accuracy: 0.888600
Distillation: Epoch : 36, Loss : 1.998701, Accuracy: 0.882000, Test accuracy: 0.891600
Distillation: Epoch : 37, Loss : 2.009539, Accuracy: 0.884000, Test accuracy: 0.893100
Distillation: Epoch : 38, Loss : 2.015527, Accuracy: 0.881000, Test accuracy: 0.890500
Distillation: Epoch : 39, Loss : 2.012173, Accuracy: 0.893000, Test accuracy: 0.891200
Distillation: Epoch : 40, Loss : 2.006595, Accuracy: 0.891000, Test accuracy: 0.891800
Distillation: Epoch : 41, Loss : 2.011461, Accuracy: 0.880000, Test accuracy: 0.891500
Distillation: Epoch : 42, Loss : 2.019979, Accuracy: 0.881000, Test accuracy: 0.890800
Distillation: Epoch : 43, Loss : 2.007493, Accuracy: 0.876000, Test accuracy: 0.890700
Distillation: Epoch : 44, Loss : 2.001578, Accuracy: 0.887000, Test accuracy: 0.890600
Distillation: Epoch : 45, Loss : 2.009990, Accuracy: 0.871000, Test accuracy: 0.891200
Distillation: Epoch : 46, Loss : 2.015397, Accuracy: 0.874000, Test accuracy: 0.889500
Distillation: Epoch : 47, Loss : 2.013478, Accuracy: 0.867000, Test accuracy: 0.891100
Distillation: Epoch : 48, Loss : 2.010403, Accuracy: 0.887000, Test accuracy: 0.890100
Distillation: Epoch : 49, Loss : 2.009370, Accuracy: 0.901000, Test accuracy: 0.890900
Distillation: Epoch : 50, Loss : 2.013224, Accuracy: 0.893000, Test accuracy: 0.892400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.8924
Generating confusion matrix for student5
[[ 936.    0.   11.    6.    1.   12.    9.    1.    5.   11.]
 [   0. 1080.   14.    1.    0.    2.    4.   18.    8.    6.]
 [   1.    3.  855.   17.    3.    1.    3.   17.    6.    1.]
 [   2.    4.   26.  904.    0.   41.    0.    5.   21.   13.]
 [   6.    1.   32.    3.  931.   20.   17.   32.   13.   77.]
 [  10.    5.    1.   25.    2.  726.   20.    2.   20.    8.]
 [  15.    4.   21.    5.    8.   17.  892.    1.   11.    2.]
 [   1.    0.   11.   16.    1.    8.    1.  869.    3.   17.]
 [   7.   38.   57.   29.   17.   56.   12.    3.  881.   24.]
 [   2.    0.    4.    4.   19.    9.    0.   80.    6.  850.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.655130, Accuracy: 0.811000, Test accuracy: 0.835000
Distillation: Epoch : 2, Loss : 0.374475, Accuracy: 0.897000, Test accuracy: 0.897300
Distillation: Epoch : 3, Loss : 0.268938, Accuracy: 0.927000, Test accuracy: 0.914900
Distillation: Epoch : 4, Loss : 0.275756, Accuracy: 0.911000, Test accuracy: 0.927000
Distillation: Epoch : 5, Loss : 0.219515, Accuracy: 0.926000, Test accuracy: 0.934100
Distillation: Epoch : 6, Loss : 0.196851, Accuracy: 0.938000, Test accuracy: 0.940400
Distillation: Epoch : 7, Loss : 0.169266, Accuracy: 0.953000, Test accuracy: 0.946200
Distillation: Epoch : 8, Loss : 0.196525, Accuracy: 0.943000, Test accuracy: 0.952000
Distillation: Epoch : 9, Loss : 0.146402, Accuracy: 0.960000, Test accuracy: 0.955300
Distillation: Epoch : 10, Loss : 0.121058, Accuracy: 0.958000, Test accuracy: 0.957200
Distillation: Epoch : 11, Loss : 0.131801, Accuracy: 0.953000, Test accuracy: 0.958800
Distillation: Epoch : 12, Loss : 0.125097, Accuracy: 0.964000, Test accuracy: 0.963800
Distillation: Epoch : 13, Loss : 0.139477, Accuracy: 0.966000, Test accuracy: 0.963600
Distillation: Epoch : 14, Loss : 0.108863, Accuracy: 0.965000, Test accuracy: 0.966400
Distillation: Epoch : 15, Loss : 0.092501, Accuracy: 0.973000, Test accuracy: 0.967300
Distillation: Epoch : 16, Loss : 0.125232, Accuracy: 0.970000, Test accuracy: 0.967900
Distillation: Epoch : 17, Loss : 0.124489, Accuracy: 0.960000, Test accuracy: 0.969600
Distillation: Epoch : 18, Loss : 0.098633, Accuracy: 0.968000, Test accuracy: 0.970100
Distillation: Epoch : 19, Loss : 0.106306, Accuracy: 0.970000, Test accuracy: 0.970400
Distillation: Epoch : 20, Loss : 0.107687, Accuracy: 0.967000, Test accuracy: 0.971800
Distillation: Epoch : 21, Loss : 0.076184, Accuracy: 0.981000, Test accuracy: 0.972500
Distillation: Epoch : 22, Loss : 0.071390, Accuracy: 0.975000, Test accuracy: 0.973600
Distillation: Epoch : 23, Loss : 0.072776, Accuracy: 0.983000, Test accuracy: 0.973800
Distillation: Epoch : 24, Loss : 0.093742, Accuracy: 0.970000, Test accuracy: 0.975100
Distillation: Epoch : 25, Loss : 0.078770, Accuracy: 0.976000, Test accuracy: 0.974900
Distillation: Epoch : 26, Loss : 0.092058, Accuracy: 0.970000, Test accuracy: 0.976500
Distillation: Epoch : 27, Loss : 0.098434, Accuracy: 0.969000, Test accuracy: 0.976400
Distillation: Epoch : 28, Loss : 0.081928, Accuracy: 0.975000, Test accuracy: 0.975400
Distillation: Epoch : 29, Loss : 0.102257, Accuracy: 0.976000, Test accuracy: 0.977700
Distillation: Epoch : 30, Loss : 0.074203, Accuracy: 0.973000, Test accuracy: 0.977000
Distillation: Epoch : 31, Loss : 0.080731, Accuracy: 0.975000, Test accuracy: 0.978400
Distillation: Epoch : 32, Loss : 0.075858, Accuracy: 0.974000, Test accuracy: 0.978200
Distillation: Epoch : 33, Loss : 0.093730, Accuracy: 0.972000, Test accuracy: 0.980000
Distillation: Epoch : 34, Loss : 0.070798, Accuracy: 0.973000, Test accuracy: 0.979400
Distillation: Epoch : 35, Loss : 0.078968, Accuracy: 0.972000, Test accuracy: 0.978300
Distillation: Epoch : 36, Loss : 0.067839, Accuracy: 0.981000, Test accuracy: 0.979800
Distillation: Epoch : 37, Loss : 0.062655, Accuracy: 0.984000, Test accuracy: 0.980000
Distillation: Epoch : 38, Loss : 0.045374, Accuracy: 0.986000, Test accuracy: 0.980000
Distillation: Epoch : 39, Loss : 0.069461, Accuracy: 0.974000, Test accuracy: 0.979700
Distillation: Epoch : 40, Loss : 0.062860, Accuracy: 0.982000, Test accuracy: 0.981200
Distillation: Epoch : 41, Loss : 0.053763, Accuracy: 0.981000, Test accuracy: 0.980600
Distillation: Epoch : 42, Loss : 0.051960, Accuracy: 0.986000, Test accuracy: 0.980400
Distillation: Epoch : 43, Loss : 0.062777, Accuracy: 0.981000, Test accuracy: 0.980400
Distillation: Epoch : 44, Loss : 0.076259, Accuracy: 0.975000, Test accuracy: 0.980800
Distillation: Epoch : 45, Loss : 0.068607, Accuracy: 0.976000, Test accuracy: 0.981500
Distillation: Epoch : 46, Loss : 0.058520, Accuracy: 0.981000, Test accuracy: 0.982000
Distillation: Epoch : 47, Loss : 0.064584, Accuracy: 0.980000, Test accuracy: 0.982300
Distillation: Epoch : 48, Loss : 0.039338, Accuracy: 0.988000, Test accuracy: 0.981400
Distillation: Epoch : 49, Loss : 0.046618, Accuracy: 0.987000, Test accuracy: 0.982700
Distillation: Epoch : 50, Loss : 0.048627, Accuracy: 0.984000, Test accuracy: 0.980900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9809
Generating confusion matrix for student
[[ 975.    0.    3.    1.    2.    3.    6.    1.    7.    5.]
 [   0. 1121.    2.    0.    0.    0.    3.    2.    0.    4.]
 [   0.    4. 1008.    0.    1.    0.    0.    6.    4.    1.]
 [   0.    0.    3.  995.    0.    6.    1.    6.    3.    7.]
 [   0.    1.    2.    0.  966.    0.    3.    1.    2.    7.]
 [   1.    1.    0.    3.    0.  877.    2.    0.    1.    2.]
 [   1.    1.    0.    0.    2.    3.  940.    0.    2.    0.]
 [   1.    1.    6.    4.    4.    1.    0. 1004.    4.    6.]
 [   2.    6.    8.    6.    1.    0.    3.    2.  946.    0.]
 [   0.    0.    0.    1.    6.    2.    0.    6.    5.  977.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.960670, Accuracy: 0.765000, Test accuracy: 0.789300
Distillation: Epoch : 2, Loss : 0.520958, Accuracy: 0.848000, Test accuracy: 0.859500
Distillation: Epoch : 3, Loss : 0.444610, Accuracy: 0.874000, Test accuracy: 0.881500
Distillation: Epoch : 4, Loss : 0.373021, Accuracy: 0.895000, Test accuracy: 0.895500
Distillation: Epoch : 5, Loss : 0.360378, Accuracy: 0.893000, Test accuracy: 0.901900
Distillation: Epoch : 6, Loss : 0.338204, Accuracy: 0.897000, Test accuracy: 0.908200
Distillation: Epoch : 7, Loss : 0.334807, Accuracy: 0.909000, Test accuracy: 0.915700
Distillation: Epoch : 8, Loss : 0.307170, Accuracy: 0.909000, Test accuracy: 0.921100
Distillation: Epoch : 9, Loss : 0.266059, Accuracy: 0.930000, Test accuracy: 0.924800
Distillation: Epoch : 10, Loss : 0.253561, Accuracy: 0.931000, Test accuracy: 0.929000
Distillation: Epoch : 11, Loss : 0.240240, Accuracy: 0.928000, Test accuracy: 0.935400
Distillation: Epoch : 12, Loss : 0.247036, Accuracy: 0.922000, Test accuracy: 0.937700
Distillation: Epoch : 13, Loss : 0.209130, Accuracy: 0.949000, Test accuracy: 0.940000
Distillation: Epoch : 14, Loss : 0.233913, Accuracy: 0.930000, Test accuracy: 0.944900
Distillation: Epoch : 15, Loss : 0.185842, Accuracy: 0.951000, Test accuracy: 0.946500
Distillation: Epoch : 16, Loss : 0.219924, Accuracy: 0.943000, Test accuracy: 0.950500
Distillation: Epoch : 17, Loss : 0.196491, Accuracy: 0.945000, Test accuracy: 0.952700
Distillation: Epoch : 18, Loss : 0.174505, Accuracy: 0.950000, Test accuracy: 0.956800
Distillation: Epoch : 19, Loss : 0.156764, Accuracy: 0.955000, Test accuracy: 0.957900
Distillation: Epoch : 20, Loss : 0.164551, Accuracy: 0.961000, Test accuracy: 0.960300
Distillation: Epoch : 21, Loss : 0.128201, Accuracy: 0.966000, Test accuracy: 0.961200
Distillation: Epoch : 22, Loss : 0.161414, Accuracy: 0.960000, Test accuracy: 0.963400
Distillation: Epoch : 23, Loss : 0.177004, Accuracy: 0.958000, Test accuracy: 0.961200
Distillation: Epoch : 24, Loss : 0.138919, Accuracy: 0.971000, Test accuracy: 0.965200
Distillation: Epoch : 25, Loss : 0.148846, Accuracy: 0.961000, Test accuracy: 0.965900
Distillation: Epoch : 26, Loss : 0.136451, Accuracy: 0.969000, Test accuracy: 0.967900
Distillation: Epoch : 27, Loss : 0.130522, Accuracy: 0.971000, Test accuracy: 0.967300
Distillation: Epoch : 28, Loss : 0.116268, Accuracy: 0.969000, Test accuracy: 0.969000
Distillation: Epoch : 29, Loss : 0.123315, Accuracy: 0.970000, Test accuracy: 0.969100
Distillation: Epoch : 30, Loss : 0.118579, Accuracy: 0.970000, Test accuracy: 0.969900
Distillation: Epoch : 31, Loss : 0.130794, Accuracy: 0.964000, Test accuracy: 0.972600
Distillation: Epoch : 32, Loss : 0.130239, Accuracy: 0.970000, Test accuracy: 0.971400
Distillation: Epoch : 33, Loss : 0.116007, Accuracy: 0.970000, Test accuracy: 0.972500
Distillation: Epoch : 34, Loss : 0.099981, Accuracy: 0.978000, Test accuracy: 0.973400
Distillation: Epoch : 35, Loss : 0.136600, Accuracy: 0.963000, Test accuracy: 0.974600
Distillation: Epoch : 36, Loss : 0.113841, Accuracy: 0.975000, Test accuracy: 0.976100
Distillation: Epoch : 37, Loss : 0.130580, Accuracy: 0.968000, Test accuracy: 0.975300
Distillation: Epoch : 38, Loss : 0.095514, Accuracy: 0.979000, Test accuracy: 0.975900
Distillation: Epoch : 39, Loss : 0.139183, Accuracy: 0.973000, Test accuracy: 0.975500
Distillation: Epoch : 40, Loss : 0.112704, Accuracy: 0.970000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 0.142652, Accuracy: 0.964000, Test accuracy: 0.977100
Distillation: Epoch : 42, Loss : 0.113333, Accuracy: 0.966000, Test accuracy: 0.976900
Distillation: Epoch : 43, Loss : 0.088227, Accuracy: 0.982000, Test accuracy: 0.977100
Distillation: Epoch : 44, Loss : 0.094173, Accuracy: 0.973000, Test accuracy: 0.977700
Distillation: Epoch : 45, Loss : 0.127238, Accuracy: 0.972000, Test accuracy: 0.977100
Distillation: Epoch : 46, Loss : 0.103831, Accuracy: 0.970000, Test accuracy: 0.977300
Distillation: Epoch : 47, Loss : 0.087143, Accuracy: 0.978000, Test accuracy: 0.976900
Distillation: Epoch : 48, Loss : 0.115111, Accuracy: 0.973000, Test accuracy: 0.977900
Distillation: Epoch : 49, Loss : 0.092107, Accuracy: 0.977000, Test accuracy: 0.979000
Distillation: Epoch : 50, Loss : 0.092807, Accuracy: 0.981000, Test accuracy: 0.978100
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9781
Generating confusion matrix for student
[[ 971.    0.    3.    0.    0.    3.    6.    0.    5.    3.]
 [   0. 1125.    5.    1.    0.    2.    2.    4.    0.    7.]
 [   1.    2. 1003.    4.    3.    0.    1.   12.    3.    0.]
 [   0.    1.    3.  991.    0.    3.    0.    2.    3.    3.]
 [   0.    0.    3.    0.  960.    0.    1.    0.    3.    8.]
 [   0.    0.    0.    1.    0.  865.    3.    0.    0.    3.]
 [   2.    1.    1.    0.    2.    3.  942.    0.    0.    1.]
 [   1.    0.    3.    6.    1.    1.    0.  999.    2.    8.]
 [   5.    6.   11.    5.    6.   12.    3.    2.  953.    4.]
 [   0.    0.    0.    2.   10.    3.    0.    9.    5.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.070097, Accuracy: 0.765000, Test accuracy: 0.789300
Distillation: Epoch : 2, Loss : 0.782248, Accuracy: 0.841000, Test accuracy: 0.864000
Distillation: Epoch : 3, Loss : 0.683035, Accuracy: 0.882000, Test accuracy: 0.890400
Distillation: Epoch : 4, Loss : 0.636420, Accuracy: 0.904000, Test accuracy: 0.906100
Distillation: Epoch : 5, Loss : 0.604500, Accuracy: 0.907000, Test accuracy: 0.916100
Distillation: Epoch : 6, Loss : 0.574581, Accuracy: 0.915000, Test accuracy: 0.922900
Distillation: Epoch : 7, Loss : 0.563052, Accuracy: 0.911000, Test accuracy: 0.928900
Distillation: Epoch : 8, Loss : 0.546305, Accuracy: 0.931000, Test accuracy: 0.933900
Distillation: Epoch : 9, Loss : 0.517374, Accuracy: 0.936000, Test accuracy: 0.936800
Distillation: Epoch : 10, Loss : 0.500101, Accuracy: 0.949000, Test accuracy: 0.944200
Distillation: Epoch : 11, Loss : 0.494307, Accuracy: 0.942000, Test accuracy: 0.947400
Distillation: Epoch : 12, Loss : 0.500156, Accuracy: 0.946000, Test accuracy: 0.954100
Distillation: Epoch : 13, Loss : 0.482263, Accuracy: 0.948000, Test accuracy: 0.955400
Distillation: Epoch : 14, Loss : 0.427572, Accuracy: 0.966000, Test accuracy: 0.959000
Distillation: Epoch : 15, Loss : 0.459829, Accuracy: 0.957000, Test accuracy: 0.962800
Distillation: Epoch : 16, Loss : 0.465824, Accuracy: 0.956000, Test accuracy: 0.963400
Distillation: Epoch : 17, Loss : 0.450428, Accuracy: 0.960000, Test accuracy: 0.966300
Distillation: Epoch : 18, Loss : 0.411459, Accuracy: 0.966000, Test accuracy: 0.966800
Distillation: Epoch : 19, Loss : 0.452428, Accuracy: 0.963000, Test accuracy: 0.969400
Distillation: Epoch : 20, Loss : 0.449330, Accuracy: 0.963000, Test accuracy: 0.971200
Distillation: Epoch : 21, Loss : 0.431820, Accuracy: 0.969000, Test accuracy: 0.970700
Distillation: Epoch : 22, Loss : 0.413274, Accuracy: 0.971000, Test accuracy: 0.972500
Distillation: Epoch : 23, Loss : 0.433780, Accuracy: 0.969000, Test accuracy: 0.971900
Distillation: Epoch : 24, Loss : 0.418791, Accuracy: 0.978000, Test accuracy: 0.972200
Distillation: Epoch : 25, Loss : 0.415504, Accuracy: 0.966000, Test accuracy: 0.972600
Distillation: Epoch : 26, Loss : 0.419945, Accuracy: 0.976000, Test accuracy: 0.974800
Distillation: Epoch : 27, Loss : 0.410886, Accuracy: 0.971000, Test accuracy: 0.974400
Distillation: Epoch : 28, Loss : 0.442549, Accuracy: 0.971000, Test accuracy: 0.975700
Distillation: Epoch : 29, Loss : 0.430284, Accuracy: 0.966000, Test accuracy: 0.976700
Distillation: Epoch : 30, Loss : 0.431367, Accuracy: 0.971000, Test accuracy: 0.976000
Distillation: Epoch : 31, Loss : 0.400672, Accuracy: 0.976000, Test accuracy: 0.976900
Distillation: Epoch : 32, Loss : 0.417119, Accuracy: 0.966000, Test accuracy: 0.976600
Distillation: Epoch : 33, Loss : 0.404938, Accuracy: 0.973000, Test accuracy: 0.977300
Distillation: Epoch : 34, Loss : 0.427121, Accuracy: 0.974000, Test accuracy: 0.976400
Distillation: Epoch : 35, Loss : 0.419974, Accuracy: 0.967000, Test accuracy: 0.977800
Distillation: Epoch : 36, Loss : 0.410549, Accuracy: 0.979000, Test accuracy: 0.978000
Distillation: Epoch : 37, Loss : 0.422995, Accuracy: 0.969000, Test accuracy: 0.977900
Distillation: Epoch : 38, Loss : 0.401878, Accuracy: 0.984000, Test accuracy: 0.978900
Distillation: Epoch : 39, Loss : 0.407681, Accuracy: 0.977000, Test accuracy: 0.978900
Distillation: Epoch : 40, Loss : 0.419525, Accuracy: 0.970000, Test accuracy: 0.980400
Distillation: Epoch : 41, Loss : 0.381250, Accuracy: 0.980000, Test accuracy: 0.979600
Distillation: Epoch : 42, Loss : 0.392376, Accuracy: 0.974000, Test accuracy: 0.978600
Distillation: Epoch : 43, Loss : 0.393063, Accuracy: 0.979000, Test accuracy: 0.979900
Distillation: Epoch : 44, Loss : 0.386314, Accuracy: 0.977000, Test accuracy: 0.979100
Distillation: Epoch : 45, Loss : 0.401863, Accuracy: 0.975000, Test accuracy: 0.979700
Distillation: Epoch : 46, Loss : 0.399817, Accuracy: 0.980000, Test accuracy: 0.980200
Distillation: Epoch : 47, Loss : 0.423666, Accuracy: 0.975000, Test accuracy: 0.979700
Distillation: Epoch : 48, Loss : 0.415656, Accuracy: 0.974000, Test accuracy: 0.980200
Distillation: Epoch : 49, Loss : 0.389025, Accuracy: 0.985000, Test accuracy: 0.980500
Distillation: Epoch : 50, Loss : 0.390349, Accuracy: 0.980000, Test accuracy: 0.981800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9818
Generating confusion matrix for student
[[ 971.    0.    2.    1.    0.    1.    4.    0.    5.    5.]
 [   0. 1123.    1.    0.    0.    0.    1.    3.    0.    4.]
 [   1.    4. 1006.    1.    0.    1.    0.    8.    2.    1.]
 [   0.    1.    4.  992.    0.    5.    0.    3.    2.    3.]
 [   1.    1.    3.    0.  968.    0.    3.    4.    3.    3.]
 [   0.    0.    0.    5.    0.  874.    2.    0.    2.    3.]
 [   3.    1.    1.    0.    2.    2.  946.    0.    1.    0.]
 [   1.    1.    3.    2.    0.    0.    0. 1003.    2.    2.]
 [   3.    4.   11.    7.    4.    6.    2.    2.  954.    7.]
 [   0.    0.    1.    2.    8.    3.    0.    5.    3.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.222626, Accuracy: 0.759000, Test accuracy: 0.771500
Distillation: Epoch : 2, Loss : 0.886597, Accuracy: 0.851000, Test accuracy: 0.861600
Distillation: Epoch : 3, Loss : 0.813968, Accuracy: 0.889000, Test accuracy: 0.884100
Distillation: Epoch : 4, Loss : 0.783122, Accuracy: 0.912000, Test accuracy: 0.899000
Distillation: Epoch : 5, Loss : 0.783294, Accuracy: 0.895000, Test accuracy: 0.907700
Distillation: Epoch : 6, Loss : 0.723485, Accuracy: 0.910000, Test accuracy: 0.911900
Distillation: Epoch : 7, Loss : 0.734239, Accuracy: 0.906000, Test accuracy: 0.917800
Distillation: Epoch : 8, Loss : 0.703962, Accuracy: 0.928000, Test accuracy: 0.922200
Distillation: Epoch : 9, Loss : 0.707733, Accuracy: 0.917000, Test accuracy: 0.929400
Distillation: Epoch : 10, Loss : 0.675585, Accuracy: 0.939000, Test accuracy: 0.934500
Distillation: Epoch : 11, Loss : 0.659349, Accuracy: 0.937000, Test accuracy: 0.939500
Distillation: Epoch : 12, Loss : 0.645088, Accuracy: 0.946000, Test accuracy: 0.943900
Distillation: Epoch : 13, Loss : 0.647712, Accuracy: 0.950000, Test accuracy: 0.948700
Distillation: Epoch : 14, Loss : 0.651583, Accuracy: 0.947000, Test accuracy: 0.950500
Distillation: Epoch : 15, Loss : 0.607379, Accuracy: 0.962000, Test accuracy: 0.953100
Distillation: Epoch : 16, Loss : 0.634186, Accuracy: 0.952000, Test accuracy: 0.957400
Distillation: Epoch : 17, Loss : 0.615975, Accuracy: 0.951000, Test accuracy: 0.959100
Distillation: Epoch : 18, Loss : 0.621747, Accuracy: 0.953000, Test accuracy: 0.959400
Distillation: Epoch : 19, Loss : 0.601413, Accuracy: 0.956000, Test accuracy: 0.960500
Distillation: Epoch : 20, Loss : 0.585057, Accuracy: 0.966000, Test accuracy: 0.962900
Distillation: Epoch : 21, Loss : 0.620159, Accuracy: 0.958000, Test accuracy: 0.964000
Distillation: Epoch : 22, Loss : 0.626225, Accuracy: 0.966000, Test accuracy: 0.964900
Distillation: Epoch : 23, Loss : 0.596060, Accuracy: 0.960000, Test accuracy: 0.965200
Distillation: Epoch : 24, Loss : 0.607301, Accuracy: 0.960000, Test accuracy: 0.966800
Distillation: Epoch : 25, Loss : 0.593653, Accuracy: 0.966000, Test accuracy: 0.966800
Distillation: Epoch : 26, Loss : 0.600944, Accuracy: 0.966000, Test accuracy: 0.968800
Distillation: Epoch : 27, Loss : 0.610757, Accuracy: 0.955000, Test accuracy: 0.968400
Distillation: Epoch : 28, Loss : 0.582742, Accuracy: 0.968000, Test accuracy: 0.970400
Distillation: Epoch : 29, Loss : 0.571173, Accuracy: 0.973000, Test accuracy: 0.969100
Distillation: Epoch : 30, Loss : 0.612552, Accuracy: 0.956000, Test accuracy: 0.970500
Distillation: Epoch : 31, Loss : 0.613678, Accuracy: 0.952000, Test accuracy: 0.971600
Distillation: Epoch : 32, Loss : 0.584445, Accuracy: 0.972000, Test accuracy: 0.972000
Distillation: Epoch : 33, Loss : 0.583568, Accuracy: 0.974000, Test accuracy: 0.972700
Distillation: Epoch : 34, Loss : 0.581296, Accuracy: 0.966000, Test accuracy: 0.973400
Distillation: Epoch : 35, Loss : 0.571357, Accuracy: 0.964000, Test accuracy: 0.972700
Distillation: Epoch : 36, Loss : 0.598182, Accuracy: 0.968000, Test accuracy: 0.974200
Distillation: Epoch : 37, Loss : 0.572880, Accuracy: 0.972000, Test accuracy: 0.974400
Distillation: Epoch : 38, Loss : 0.571299, Accuracy: 0.974000, Test accuracy: 0.974100
Distillation: Epoch : 39, Loss : 0.612879, Accuracy: 0.968000, Test accuracy: 0.974100
Distillation: Epoch : 40, Loss : 0.541769, Accuracy: 0.980000, Test accuracy: 0.974400
Distillation: Epoch : 41, Loss : 0.572361, Accuracy: 0.967000, Test accuracy: 0.975300
Distillation: Epoch : 42, Loss : 0.582305, Accuracy: 0.974000, Test accuracy: 0.974300
Distillation: Epoch : 43, Loss : 0.600627, Accuracy: 0.964000, Test accuracy: 0.975500
Distillation: Epoch : 44, Loss : 0.553918, Accuracy: 0.976000, Test accuracy: 0.976100
Distillation: Epoch : 45, Loss : 0.575499, Accuracy: 0.967000, Test accuracy: 0.976000
Distillation: Epoch : 46, Loss : 0.587423, Accuracy: 0.973000, Test accuracy: 0.976700
Distillation: Epoch : 47, Loss : 0.574430, Accuracy: 0.975000, Test accuracy: 0.977100
Distillation: Epoch : 48, Loss : 0.549034, Accuracy: 0.983000, Test accuracy: 0.977000
Distillation: Epoch : 49, Loss : 0.560265, Accuracy: 0.977000, Test accuracy: 0.978100
Distillation: Epoch : 50, Loss : 0.572896, Accuracy: 0.975000, Test accuracy: 0.976800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9768
Generating confusion matrix for student
[[ 968.    0.    3.    1.    1.    2.    4.    0.    4.    2.]
 [   0. 1127.    2.    0.    0.    0.    2.    2.    0.    5.]
 [   0.    3. 1007.    1.    2.    0.    0.   15.    2.    1.]
 [   0.    0.    4.  982.    0.    8.    1.    2.    5.    4.]
 [   0.    1.    0.    0.  962.    0.    4.    1.    3.    8.]
 [   3.    0.    0.    6.    0.  863.    4.    0.    0.    5.]
 [   2.    0.    0.    0.    3.    4.  937.    0.    0.    0.]
 [   1.    0.    4.    5.    0.    0.    0.  994.    2.    4.]
 [   4.    4.   10.   13.    4.   14.    6.    4.  955.    7.]
 [   2.    0.    2.    2.   10.    1.    0.   10.    3.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.283945, Accuracy: 0.800000, Test accuracy: 0.806900
Distillation: Epoch : 2, Loss : 1.009180, Accuracy: 0.875000, Test accuracy: 0.877500
Distillation: Epoch : 3, Loss : 0.974711, Accuracy: 0.883000, Test accuracy: 0.895000
Distillation: Epoch : 4, Loss : 0.938751, Accuracy: 0.906000, Test accuracy: 0.908600
Distillation: Epoch : 5, Loss : 0.911465, Accuracy: 0.901000, Test accuracy: 0.915500
Distillation: Epoch : 6, Loss : 0.881833, Accuracy: 0.916000, Test accuracy: 0.920100
Distillation: Epoch : 7, Loss : 0.860565, Accuracy: 0.922000, Test accuracy: 0.927200
Distillation: Epoch : 8, Loss : 0.856797, Accuracy: 0.929000, Test accuracy: 0.934600
Distillation: Epoch : 9, Loss : 0.829692, Accuracy: 0.937000, Test accuracy: 0.939100
Distillation: Epoch : 10, Loss : 0.842524, Accuracy: 0.930000, Test accuracy: 0.945500
Distillation: Epoch : 11, Loss : 0.842873, Accuracy: 0.935000, Test accuracy: 0.952400
Distillation: Epoch : 12, Loss : 0.789584, Accuracy: 0.949000, Test accuracy: 0.955100
Distillation: Epoch : 13, Loss : 0.798004, Accuracy: 0.954000, Test accuracy: 0.958000
Distillation: Epoch : 14, Loss : 0.769991, Accuracy: 0.963000, Test accuracy: 0.960900
Distillation: Epoch : 15, Loss : 0.781716, Accuracy: 0.959000, Test accuracy: 0.961200
Distillation: Epoch : 16, Loss : 0.800130, Accuracy: 0.958000, Test accuracy: 0.963900
Distillation: Epoch : 17, Loss : 0.778351, Accuracy: 0.959000, Test accuracy: 0.965300
Distillation: Epoch : 18, Loss : 0.782305, Accuracy: 0.960000, Test accuracy: 0.966100
Distillation: Epoch : 19, Loss : 0.750602, Accuracy: 0.968000, Test accuracy: 0.966500
Distillation: Epoch : 20, Loss : 0.768169, Accuracy: 0.964000, Test accuracy: 0.968800
Distillation: Epoch : 21, Loss : 0.738644, Accuracy: 0.973000, Test accuracy: 0.968000
Distillation: Epoch : 22, Loss : 0.766086, Accuracy: 0.965000, Test accuracy: 0.968300
Distillation: Epoch : 23, Loss : 0.756673, Accuracy: 0.953000, Test accuracy: 0.969700
Distillation: Epoch : 24, Loss : 0.799831, Accuracy: 0.959000, Test accuracy: 0.970700
Distillation: Epoch : 25, Loss : 0.748157, Accuracy: 0.966000, Test accuracy: 0.970800
Distillation: Epoch : 26, Loss : 0.736692, Accuracy: 0.972000, Test accuracy: 0.972300
Distillation: Epoch : 27, Loss : 0.766639, Accuracy: 0.967000, Test accuracy: 0.972200
Distillation: Epoch : 28, Loss : 0.775425, Accuracy: 0.967000, Test accuracy: 0.972900
Distillation: Epoch : 29, Loss : 0.746272, Accuracy: 0.969000, Test accuracy: 0.973000
Distillation: Epoch : 30, Loss : 0.776360, Accuracy: 0.968000, Test accuracy: 0.972700
Distillation: Epoch : 31, Loss : 0.774208, Accuracy: 0.968000, Test accuracy: 0.974200
Distillation: Epoch : 32, Loss : 0.751681, Accuracy: 0.977000, Test accuracy: 0.974000
Distillation: Epoch : 33, Loss : 0.747943, Accuracy: 0.976000, Test accuracy: 0.973800
Distillation: Epoch : 34, Loss : 0.783222, Accuracy: 0.976000, Test accuracy: 0.975000
Distillation: Epoch : 35, Loss : 0.785440, Accuracy: 0.964000, Test accuracy: 0.975100
Distillation: Epoch : 36, Loss : 0.757763, Accuracy: 0.974000, Test accuracy: 0.974700
Distillation: Epoch : 37, Loss : 0.729784, Accuracy: 0.970000, Test accuracy: 0.975000
Distillation: Epoch : 38, Loss : 0.746185, Accuracy: 0.978000, Test accuracy: 0.975100
Distillation: Epoch : 39, Loss : 0.773099, Accuracy: 0.983000, Test accuracy: 0.974700
Distillation: Epoch : 40, Loss : 0.734285, Accuracy: 0.973000, Test accuracy: 0.975900
Distillation: Epoch : 41, Loss : 0.741813, Accuracy: 0.978000, Test accuracy: 0.975900
Distillation: Epoch : 42, Loss : 0.760415, Accuracy: 0.975000, Test accuracy: 0.976400
Distillation: Epoch : 43, Loss : 0.729210, Accuracy: 0.980000, Test accuracy: 0.975300
Distillation: Epoch : 44, Loss : 0.774739, Accuracy: 0.976000, Test accuracy: 0.975800
Distillation: Epoch : 45, Loss : 0.766055, Accuracy: 0.973000, Test accuracy: 0.975800
Distillation: Epoch : 46, Loss : 0.754305, Accuracy: 0.977000, Test accuracy: 0.976200
Distillation: Epoch : 47, Loss : 0.768576, Accuracy: 0.974000, Test accuracy: 0.976800
Distillation: Epoch : 48, Loss : 0.747452, Accuracy: 0.974000, Test accuracy: 0.977400
Distillation: Epoch : 49, Loss : 0.751051, Accuracy: 0.975000, Test accuracy: 0.977500
Distillation: Epoch : 50, Loss : 0.724244, Accuracy: 0.976000, Test accuracy: 0.977400
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9774
Generating confusion matrix for student
[[ 973.    0.    4.    0.    0.    2.    6.    0.    5.    2.]
 [   0. 1121.    1.    0.    0.    0.    2.    2.    1.    4.]
 [   1.    4. 1003.    1.    2.    0.    0.   13.    1.    1.]
 [   0.    0.    4.  986.    0.    8.    1.    2.    2.    5.]
 [   0.    0.    5.    0.  959.    0.    5.    3.    2.    6.]
 [   0.    0.    0.    3.    0.  868.    2.    0.    0.    3.]
 [   1.    3.    0.    0.    2.    6.  937.    0.    0.    0.]
 [   1.    0.    3.    4.    0.    1.    0.  990.    1.    1.]
 [   4.    7.   11.   13.    4.    5.    5.    1.  959.    9.]
 [   0.    0.    1.    3.   15.    2.    0.   17.    3.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.462252, Accuracy: 0.768000, Test accuracy: 0.773200
Distillation: Epoch : 2, Loss : 1.226185, Accuracy: 0.841000, Test accuracy: 0.869100
Distillation: Epoch : 3, Loss : 1.149453, Accuracy: 0.881000, Test accuracy: 0.887700
Distillation: Epoch : 4, Loss : 1.096470, Accuracy: 0.898000, Test accuracy: 0.895500
Distillation: Epoch : 5, Loss : 1.113176, Accuracy: 0.871000, Test accuracy: 0.904800
Distillation: Epoch : 6, Loss : 1.070482, Accuracy: 0.913000, Test accuracy: 0.908000
Distillation: Epoch : 7, Loss : 1.058909, Accuracy: 0.910000, Test accuracy: 0.914400
Distillation: Epoch : 8, Loss : 1.054591, Accuracy: 0.925000, Test accuracy: 0.920900
Distillation: Epoch : 9, Loss : 1.012393, Accuracy: 0.940000, Test accuracy: 0.928500
Distillation: Epoch : 10, Loss : 1.025165, Accuracy: 0.924000, Test accuracy: 0.934200
Distillation: Epoch : 11, Loss : 1.021460, Accuracy: 0.934000, Test accuracy: 0.938800
Distillation: Epoch : 12, Loss : 0.990279, Accuracy: 0.936000, Test accuracy: 0.942700
Distillation: Epoch : 13, Loss : 0.971944, Accuracy: 0.949000, Test accuracy: 0.942900
Distillation: Epoch : 14, Loss : 0.976508, Accuracy: 0.949000, Test accuracy: 0.948100
Distillation: Epoch : 15, Loss : 0.977771, Accuracy: 0.948000, Test accuracy: 0.950600
Distillation: Epoch : 16, Loss : 0.992488, Accuracy: 0.947000, Test accuracy: 0.952700
Distillation: Epoch : 17, Loss : 0.981636, Accuracy: 0.942000, Test accuracy: 0.956100
Distillation: Epoch : 18, Loss : 0.944322, Accuracy: 0.953000, Test accuracy: 0.957600
Distillation: Epoch : 19, Loss : 0.954557, Accuracy: 0.949000, Test accuracy: 0.957100
Distillation: Epoch : 20, Loss : 0.969269, Accuracy: 0.947000, Test accuracy: 0.961300
Distillation: Epoch : 21, Loss : 0.929535, Accuracy: 0.961000, Test accuracy: 0.961300
Distillation: Epoch : 22, Loss : 0.937919, Accuracy: 0.967000, Test accuracy: 0.962900
Distillation: Epoch : 23, Loss : 0.940693, Accuracy: 0.956000, Test accuracy: 0.963900
Distillation: Epoch : 24, Loss : 0.943422, Accuracy: 0.961000, Test accuracy: 0.966100
Distillation: Epoch : 25, Loss : 0.952271, Accuracy: 0.957000, Test accuracy: 0.968100
Distillation: Epoch : 26, Loss : 0.946375, Accuracy: 0.956000, Test accuracy: 0.969200
Distillation: Epoch : 27, Loss : 0.954537, Accuracy: 0.960000, Test accuracy: 0.967900
Distillation: Epoch : 28, Loss : 0.944907, Accuracy: 0.960000, Test accuracy: 0.968600
Distillation: Epoch : 29, Loss : 0.942018, Accuracy: 0.970000, Test accuracy: 0.969800
Distillation: Epoch : 30, Loss : 0.931533, Accuracy: 0.962000, Test accuracy: 0.970600
Distillation: Epoch : 31, Loss : 0.949296, Accuracy: 0.959000, Test accuracy: 0.969300
Distillation: Epoch : 32, Loss : 0.944719, Accuracy: 0.975000, Test accuracy: 0.971400
Distillation: Epoch : 33, Loss : 0.933445, Accuracy: 0.959000, Test accuracy: 0.971200
Distillation: Epoch : 34, Loss : 0.925552, Accuracy: 0.962000, Test accuracy: 0.972700
Distillation: Epoch : 35, Loss : 0.955078, Accuracy: 0.968000, Test accuracy: 0.973000
Distillation: Epoch : 36, Loss : 0.948886, Accuracy: 0.960000, Test accuracy: 0.973700
Distillation: Epoch : 37, Loss : 0.941335, Accuracy: 0.966000, Test accuracy: 0.974500
Distillation: Epoch : 38, Loss : 0.945158, Accuracy: 0.974000, Test accuracy: 0.974100
Distillation: Epoch : 39, Loss : 0.919150, Accuracy: 0.972000, Test accuracy: 0.974000
Distillation: Epoch : 40, Loss : 0.926221, Accuracy: 0.972000, Test accuracy: 0.975600
Distillation: Epoch : 41, Loss : 0.910378, Accuracy: 0.974000, Test accuracy: 0.975000
Distillation: Epoch : 42, Loss : 0.942968, Accuracy: 0.972000, Test accuracy: 0.975800
Distillation: Epoch : 43, Loss : 0.933310, Accuracy: 0.957000, Test accuracy: 0.975500
Distillation: Epoch : 44, Loss : 0.960643, Accuracy: 0.967000, Test accuracy: 0.975200
Distillation: Epoch : 45, Loss : 0.938636, Accuracy: 0.977000, Test accuracy: 0.976400
Distillation: Epoch : 46, Loss : 0.915858, Accuracy: 0.976000, Test accuracy: 0.976500
Distillation: Epoch : 47, Loss : 0.919670, Accuracy: 0.977000, Test accuracy: 0.975800
Distillation: Epoch : 48, Loss : 0.937699, Accuracy: 0.969000, Test accuracy: 0.977300
Distillation: Epoch : 49, Loss : 0.926658, Accuracy: 0.965000, Test accuracy: 0.976100
Distillation: Epoch : 50, Loss : 0.903196, Accuracy: 0.976000, Test accuracy: 0.976200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9762
Generating confusion matrix for student
[[ 974.    0.    4.    1.    1.    2.    6.    1.    3.    2.]
 [   0. 1118.    0.    0.    1.    0.    3.    2.    0.    4.]
 [   0.    4. 1003.    4.    2.    0.    0.   12.    2.    1.]
 [   0.    2.    5.  979.    0.    6.    0.    4.    3.    7.]
 [   0.    0.    4.    0.  962.    1.    4.    4.    4.    7.]
 [   0.    0.    0.    8.    0.  867.    3.    0.    2.    2.]
 [   1.    3.    0.    0.    2.    3.  938.    0.    0.    0.]
 [   1.    0.    2.    3.    0.    0.    0.  988.    1.    1.]
 [   4.    8.   13.   13.    3.   12.    4.    3.  955.    7.]
 [   0.    0.    1.    2.   11.    1.    0.   14.    4.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.608981, Accuracy: 0.719000, Test accuracy: 0.730300
Distillation: Epoch : 2, Loss : 1.343546, Accuracy: 0.859000, Test accuracy: 0.875200
Distillation: Epoch : 3, Loss : 1.251690, Accuracy: 0.893000, Test accuracy: 0.898400
Distillation: Epoch : 4, Loss : 1.206273, Accuracy: 0.903000, Test accuracy: 0.913100
Distillation: Epoch : 5, Loss : 1.219944, Accuracy: 0.903000, Test accuracy: 0.924700
Distillation: Epoch : 6, Loss : 1.170614, Accuracy: 0.939000, Test accuracy: 0.931100
Distillation: Epoch : 7, Loss : 1.171049, Accuracy: 0.929000, Test accuracy: 0.937200
Distillation: Epoch : 8, Loss : 1.134210, Accuracy: 0.950000, Test accuracy: 0.940800
Distillation: Epoch : 9, Loss : 1.143181, Accuracy: 0.945000, Test accuracy: 0.944500
Distillation: Epoch : 10, Loss : 1.185886, Accuracy: 0.937000, Test accuracy: 0.950600
Distillation: Epoch : 11, Loss : 1.113565, Accuracy: 0.952000, Test accuracy: 0.954200
Distillation: Epoch : 12, Loss : 1.135100, Accuracy: 0.956000, Test accuracy: 0.956500
Distillation: Epoch : 13, Loss : 1.125122, Accuracy: 0.960000, Test accuracy: 0.959200
Distillation: Epoch : 14, Loss : 1.137136, Accuracy: 0.962000, Test accuracy: 0.961300
Distillation: Epoch : 15, Loss : 1.089187, Accuracy: 0.960000, Test accuracy: 0.962900
Distillation: Epoch : 16, Loss : 1.104410, Accuracy: 0.965000, Test accuracy: 0.963800
Distillation: Epoch : 17, Loss : 1.098250, Accuracy: 0.960000, Test accuracy: 0.965900
Distillation: Epoch : 18, Loss : 1.104016, Accuracy: 0.970000, Test accuracy: 0.965400
Distillation: Epoch : 19, Loss : 1.104685, Accuracy: 0.954000, Test accuracy: 0.966100
Distillation: Epoch : 20, Loss : 1.087811, Accuracy: 0.974000, Test accuracy: 0.966900
Distillation: Epoch : 21, Loss : 1.098984, Accuracy: 0.973000, Test accuracy: 0.969300
Distillation: Epoch : 22, Loss : 1.108351, Accuracy: 0.972000, Test accuracy: 0.969200
Distillation: Epoch : 23, Loss : 1.127212, Accuracy: 0.969000, Test accuracy: 0.970100
Distillation: Epoch : 24, Loss : 1.104070, Accuracy: 0.972000, Test accuracy: 0.970100
Distillation: Epoch : 25, Loss : 1.092786, Accuracy: 0.971000, Test accuracy: 0.971100
Distillation: Epoch : 26, Loss : 1.107752, Accuracy: 0.965000, Test accuracy: 0.973400
Distillation: Epoch : 27, Loss : 1.082578, Accuracy: 0.971000, Test accuracy: 0.972800
Distillation: Epoch : 28, Loss : 1.066337, Accuracy: 0.977000, Test accuracy: 0.973100
Distillation: Epoch : 29, Loss : 1.095922, Accuracy: 0.971000, Test accuracy: 0.972700
Distillation: Epoch : 30, Loss : 1.075862, Accuracy: 0.968000, Test accuracy: 0.973900
Distillation: Epoch : 31, Loss : 1.098427, Accuracy: 0.964000, Test accuracy: 0.974600
Distillation: Epoch : 32, Loss : 1.090417, Accuracy: 0.974000, Test accuracy: 0.974600
Distillation: Epoch : 33, Loss : 1.080873, Accuracy: 0.968000, Test accuracy: 0.975300
Distillation: Epoch : 34, Loss : 1.082828, Accuracy: 0.978000, Test accuracy: 0.974500
Distillation: Epoch : 35, Loss : 1.096165, Accuracy: 0.980000, Test accuracy: 0.975600
Distillation: Epoch : 36, Loss : 1.084450, Accuracy: 0.966000, Test accuracy: 0.975900
Distillation: Epoch : 37, Loss : 1.085072, Accuracy: 0.980000, Test accuracy: 0.975700
Distillation: Epoch : 38, Loss : 1.074821, Accuracy: 0.978000, Test accuracy: 0.976100
Distillation: Epoch : 39, Loss : 1.066789, Accuracy: 0.971000, Test accuracy: 0.977000
Distillation: Epoch : 40, Loss : 1.093094, Accuracy: 0.972000, Test accuracy: 0.976700
Distillation: Epoch : 41, Loss : 1.088827, Accuracy: 0.973000, Test accuracy: 0.976600
Distillation: Epoch : 42, Loss : 1.076916, Accuracy: 0.982000, Test accuracy: 0.977100
Distillation: Epoch : 43, Loss : 1.075725, Accuracy: 0.971000, Test accuracy: 0.977300
Distillation: Epoch : 44, Loss : 1.081232, Accuracy: 0.978000, Test accuracy: 0.977100
Distillation: Epoch : 45, Loss : 1.047631, Accuracy: 0.976000, Test accuracy: 0.978000
Distillation: Epoch : 46, Loss : 1.075679, Accuracy: 0.983000, Test accuracy: 0.976400
Distillation: Epoch : 47, Loss : 1.077346, Accuracy: 0.979000, Test accuracy: 0.978400
Distillation: Epoch : 48, Loss : 1.038543, Accuracy: 0.983000, Test accuracy: 0.978000
Distillation: Epoch : 49, Loss : 1.078055, Accuracy: 0.976000, Test accuracy: 0.978200
Distillation: Epoch : 50, Loss : 1.052932, Accuracy: 0.976000, Test accuracy: 0.978600
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9786
Generating confusion matrix for student
[[ 974.    0.    2.    0.    0.    2.    5.    2.    5.    3.]
 [   0. 1125.    1.    0.    0.    0.    1.    3.    1.    4.]
 [   0.    3.  998.    1.    1.    0.    0.   20.    1.    0.]
 [   0.    1.    5.  992.    0.    9.    0.    0.    2.    3.]
 [   0.    0.    3.    0.  972.    0.    7.    1.    1.    7.]
 [   0.    0.    0.    3.    0.  866.    3.    0.    0.    1.]
 [   2.    2.    0.    0.    1.    4.  935.    0.    1.    1.]
 [   1.    0.    6.    2.    0.    2.    0.  986.    1.    2.]
 [   3.    4.   17.    9.    3.    8.    7.    3.  957.    7.]
 [   0.    0.    0.    3.    5.    1.    0.   13.    5.  981.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.641343, Accuracy: 0.760000, Test accuracy: 0.780100
Distillation: Epoch : 2, Loss : 1.414989, Accuracy: 0.877000, Test accuracy: 0.876700
Distillation: Epoch : 3, Loss : 1.410458, Accuracy: 0.876000, Test accuracy: 0.894000
Distillation: Epoch : 4, Loss : 1.355813, Accuracy: 0.902000, Test accuracy: 0.906200
Distillation: Epoch : 5, Loss : 1.350880, Accuracy: 0.900000, Test accuracy: 0.918400
Distillation: Epoch : 6, Loss : 1.327060, Accuracy: 0.918000, Test accuracy: 0.925800
Distillation: Epoch : 7, Loss : 1.327706, Accuracy: 0.925000, Test accuracy: 0.933700
Distillation: Epoch : 8, Loss : 1.300188, Accuracy: 0.943000, Test accuracy: 0.941200
Distillation: Epoch : 9, Loss : 1.296313, Accuracy: 0.936000, Test accuracy: 0.947400
Distillation: Epoch : 10, Loss : 1.307382, Accuracy: 0.941000, Test accuracy: 0.951300
Distillation: Epoch : 11, Loss : 1.278394, Accuracy: 0.945000, Test accuracy: 0.954800
Distillation: Epoch : 12, Loss : 1.264712, Accuracy: 0.960000, Test accuracy: 0.957100
Distillation: Epoch : 13, Loss : 1.248924, Accuracy: 0.958000, Test accuracy: 0.958400
Distillation: Epoch : 14, Loss : 1.252257, Accuracy: 0.958000, Test accuracy: 0.962100
Distillation: Epoch : 15, Loss : 1.254617, Accuracy: 0.953000, Test accuracy: 0.963500
Distillation: Epoch : 16, Loss : 1.246193, Accuracy: 0.955000, Test accuracy: 0.964500
Distillation: Epoch : 17, Loss : 1.266948, Accuracy: 0.962000, Test accuracy: 0.964700
Distillation: Epoch : 18, Loss : 1.223972, Accuracy: 0.966000, Test accuracy: 0.967300
Distillation: Epoch : 19, Loss : 1.253698, Accuracy: 0.961000, Test accuracy: 0.967000
Distillation: Epoch : 20, Loss : 1.260078, Accuracy: 0.962000, Test accuracy: 0.967900
Distillation: Epoch : 21, Loss : 1.234158, Accuracy: 0.951000, Test accuracy: 0.970100
Distillation: Epoch : 22, Loss : 1.243451, Accuracy: 0.972000, Test accuracy: 0.969500
Distillation: Epoch : 23, Loss : 1.231704, Accuracy: 0.960000, Test accuracy: 0.971200
Distillation: Epoch : 24, Loss : 1.242586, Accuracy: 0.970000, Test accuracy: 0.970700
Distillation: Epoch : 25, Loss : 1.239956, Accuracy: 0.973000, Test accuracy: 0.972200
Distillation: Epoch : 26, Loss : 1.256222, Accuracy: 0.963000, Test accuracy: 0.972200
Distillation: Epoch : 27, Loss : 1.245846, Accuracy: 0.962000, Test accuracy: 0.971700
Distillation: Epoch : 28, Loss : 1.227687, Accuracy: 0.971000, Test accuracy: 0.972700
Distillation: Epoch : 29, Loss : 1.246255, Accuracy: 0.968000, Test accuracy: 0.973200
Distillation: Epoch : 30, Loss : 1.227577, Accuracy: 0.975000, Test accuracy: 0.974000
Distillation: Epoch : 31, Loss : 1.242587, Accuracy: 0.967000, Test accuracy: 0.974800
Distillation: Epoch : 32, Loss : 1.233939, Accuracy: 0.969000, Test accuracy: 0.973400
Distillation: Epoch : 33, Loss : 1.240862, Accuracy: 0.974000, Test accuracy: 0.974300
Distillation: Epoch : 34, Loss : 1.248144, Accuracy: 0.961000, Test accuracy: 0.975100
Distillation: Epoch : 35, Loss : 1.243500, Accuracy: 0.957000, Test accuracy: 0.975700
Distillation: Epoch : 36, Loss : 1.236348, Accuracy: 0.967000, Test accuracy: 0.974000
Distillation: Epoch : 37, Loss : 1.223477, Accuracy: 0.979000, Test accuracy: 0.975100
Distillation: Epoch : 38, Loss : 1.218063, Accuracy: 0.977000, Test accuracy: 0.975000
Distillation: Epoch : 39, Loss : 1.214737, Accuracy: 0.972000, Test accuracy: 0.974500
Distillation: Epoch : 40, Loss : 1.238901, Accuracy: 0.973000, Test accuracy: 0.975600
Distillation: Epoch : 41, Loss : 1.227419, Accuracy: 0.981000, Test accuracy: 0.975300
Distillation: Epoch : 42, Loss : 1.223184, Accuracy: 0.980000, Test accuracy: 0.976700
Distillation: Epoch : 43, Loss : 1.206250, Accuracy: 0.975000, Test accuracy: 0.975200
Distillation: Epoch : 44, Loss : 1.219503, Accuracy: 0.974000, Test accuracy: 0.976200
Distillation: Epoch : 45, Loss : 1.236270, Accuracy: 0.975000, Test accuracy: 0.976500
Distillation: Epoch : 46, Loss : 1.232802, Accuracy: 0.981000, Test accuracy: 0.977400
Distillation: Epoch : 47, Loss : 1.239290, Accuracy: 0.973000, Test accuracy: 0.976900
Distillation: Epoch : 48, Loss : 1.211796, Accuracy: 0.975000, Test accuracy: 0.977500
Distillation: Epoch : 49, Loss : 1.211862, Accuracy: 0.980000, Test accuracy: 0.978100
Distillation: Epoch : 50, Loss : 1.227132, Accuracy: 0.977000, Test accuracy: 0.977900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9779
Generating confusion matrix for student
[[ 970.    0.    4.    0.    0.    1.    2.    0.    4.    0.]
 [   0. 1125.    3.    0.    0.    0.    2.    2.    0.    4.]
 [   0.    1. 1004.    0.    0.    1.    0.   11.    1.    0.]
 [   0.    3.    5.  989.    0.    5.    0.    1.    5.    5.]
 [   0.    0.    4.    0.  966.    1.    5.    2.    1.   12.]
 [   0.    0.    0.    5.    0.  868.    2.    0.    0.    1.]
 [   4.    2.    2.    0.    4.    1.  942.    0.    3.    1.]
 [   1.    1.    4.    4.    0.    2.    0.  988.    1.    3.]
 [   4.    3.    6.    8.    3.    8.    5.    3.  953.    9.]
 [   1.    0.    0.    4.    9.    5.    0.   21.    6.  974.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.728573, Accuracy: 0.757000, Test accuracy: 0.778300
Distillation: Epoch : 2, Loss : 1.532871, Accuracy: 0.881000, Test accuracy: 0.881200
Distillation: Epoch : 3, Loss : 1.509554, Accuracy: 0.891000, Test accuracy: 0.905200
Distillation: Epoch : 4, Loss : 1.434288, Accuracy: 0.931000, Test accuracy: 0.917100
Distillation: Epoch : 5, Loss : 1.444917, Accuracy: 0.929000, Test accuracy: 0.929200
Distillation: Epoch : 6, Loss : 1.458303, Accuracy: 0.920000, Test accuracy: 0.936500
Distillation: Epoch : 7, Loss : 1.424319, Accuracy: 0.946000, Test accuracy: 0.943900
Distillation: Epoch : 8, Loss : 1.427325, Accuracy: 0.927000, Test accuracy: 0.947500
Distillation: Epoch : 9, Loss : 1.408336, Accuracy: 0.945000, Test accuracy: 0.953000
Distillation: Epoch : 10, Loss : 1.361766, Accuracy: 0.940000, Test accuracy: 0.954700
Distillation: Epoch : 11, Loss : 1.396335, Accuracy: 0.948000, Test accuracy: 0.958300
Distillation: Epoch : 12, Loss : 1.384007, Accuracy: 0.961000, Test accuracy: 0.960100
Distillation: Epoch : 13, Loss : 1.416296, Accuracy: 0.948000, Test accuracy: 0.962200
Distillation: Epoch : 14, Loss : 1.389425, Accuracy: 0.955000, Test accuracy: 0.964900
Distillation: Epoch : 15, Loss : 1.374365, Accuracy: 0.959000, Test accuracy: 0.966200
Distillation: Epoch : 16, Loss : 1.392042, Accuracy: 0.962000, Test accuracy: 0.967900
Distillation: Epoch : 17, Loss : 1.380410, Accuracy: 0.963000, Test accuracy: 0.969500
Distillation: Epoch : 18, Loss : 1.369875, Accuracy: 0.969000, Test accuracy: 0.970100
Distillation: Epoch : 19, Loss : 1.371818, Accuracy: 0.951000, Test accuracy: 0.970200
Distillation: Epoch : 20, Loss : 1.364605, Accuracy: 0.968000, Test accuracy: 0.971100
Distillation: Epoch : 21, Loss : 1.348995, Accuracy: 0.965000, Test accuracy: 0.972400
Distillation: Epoch : 22, Loss : 1.385344, Accuracy: 0.959000, Test accuracy: 0.972200
Distillation: Epoch : 23, Loss : 1.367572, Accuracy: 0.961000, Test accuracy: 0.972800
Distillation: Epoch : 24, Loss : 1.360644, Accuracy: 0.972000, Test accuracy: 0.972600
Distillation: Epoch : 25, Loss : 1.355234, Accuracy: 0.981000, Test accuracy: 0.974500
Distillation: Epoch : 26, Loss : 1.378868, Accuracy: 0.964000, Test accuracy: 0.974400
Distillation: Epoch : 27, Loss : 1.385624, Accuracy: 0.962000, Test accuracy: 0.973900
Distillation: Epoch : 28, Loss : 1.382581, Accuracy: 0.966000, Test accuracy: 0.974500
Distillation: Epoch : 29, Loss : 1.369590, Accuracy: 0.967000, Test accuracy: 0.974700
Distillation: Epoch : 30, Loss : 1.369566, Accuracy: 0.966000, Test accuracy: 0.975700
Distillation: Epoch : 31, Loss : 1.339962, Accuracy: 0.967000, Test accuracy: 0.975400
Distillation: Epoch : 32, Loss : 1.378282, Accuracy: 0.972000, Test accuracy: 0.976200
Distillation: Epoch : 33, Loss : 1.346153, Accuracy: 0.979000, Test accuracy: 0.976200
Distillation: Epoch : 34, Loss : 1.350909, Accuracy: 0.976000, Test accuracy: 0.976000
Distillation: Epoch : 35, Loss : 1.365435, Accuracy: 0.975000, Test accuracy: 0.976800
Distillation: Epoch : 36, Loss : 1.356283, Accuracy: 0.975000, Test accuracy: 0.976900
Distillation: Epoch : 37, Loss : 1.372732, Accuracy: 0.977000, Test accuracy: 0.975900
Distillation: Epoch : 38, Loss : 1.361780, Accuracy: 0.972000, Test accuracy: 0.977200
Distillation: Epoch : 39, Loss : 1.380413, Accuracy: 0.966000, Test accuracy: 0.977100
Distillation: Epoch : 40, Loss : 1.354410, Accuracy: 0.975000, Test accuracy: 0.977600
Distillation: Epoch : 41, Loss : 1.386276, Accuracy: 0.968000, Test accuracy: 0.977900
Distillation: Epoch : 42, Loss : 1.381010, Accuracy: 0.972000, Test accuracy: 0.977700
Distillation: Epoch : 43, Loss : 1.369397, Accuracy: 0.968000, Test accuracy: 0.978200
Distillation: Epoch : 44, Loss : 1.355493, Accuracy: 0.977000, Test accuracy: 0.978600
Distillation: Epoch : 45, Loss : 1.362564, Accuracy: 0.977000, Test accuracy: 0.978900
Distillation: Epoch : 46, Loss : 1.359879, Accuracy: 0.973000, Test accuracy: 0.978600
Distillation: Epoch : 47, Loss : 1.374712, Accuracy: 0.963000, Test accuracy: 0.978000
Distillation: Epoch : 48, Loss : 1.369472, Accuracy: 0.973000, Test accuracy: 0.978800
Distillation: Epoch : 49, Loss : 1.337374, Accuracy: 0.973000, Test accuracy: 0.979100
Distillation: Epoch : 50, Loss : 1.376024, Accuracy: 0.976000, Test accuracy: 0.979500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9795
Generating confusion matrix for student
[[ 970.    0.    2.    0.    1.    1.    4.    1.    4.    3.]
 [   1. 1123.    0.    0.    0.    0.    2.    2.    0.    5.]
 [   1.    3. 1005.    1.    1.    0.    0.   12.    3.    0.]
 [   0.    1.    5.  994.    0.    3.    0.    3.    2.    5.]
 [   1.    2.    5.    0.  972.    0.    3.    6.    1.   13.]
 [   0.    0.    0.    4.    0.  872.    4.    0.    2.    1.]
 [   2.    1.    0.    0.    0.    8.  941.    0.    0.    0.]
 [   0.    1.    4.    3.    0.    2.    0.  987.    1.    1.]
 [   2.    4.   11.    7.    2.    4.    4.    4.  959.    9.]
 [   3.    0.    0.    1.    6.    2.    0.   13.    2.  972.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.897068, Accuracy: 0.746000, Test accuracy: 0.767100
Distillation: Epoch : 2, Loss : 1.824609, Accuracy: 0.831000, Test accuracy: 0.850300
Distillation: Epoch : 3, Loss : 1.789081, Accuracy: 0.870000, Test accuracy: 0.871100
Distillation: Epoch : 4, Loss : 1.767102, Accuracy: 0.887000, Test accuracy: 0.883100
Distillation: Epoch : 5, Loss : 1.748308, Accuracy: 0.898000, Test accuracy: 0.898100
Distillation: Epoch : 6, Loss : 1.748510, Accuracy: 0.907000, Test accuracy: 0.907900
Distillation: Epoch : 7, Loss : 1.737023, Accuracy: 0.921000, Test accuracy: 0.923400
Distillation: Epoch : 8, Loss : 1.731119, Accuracy: 0.935000, Test accuracy: 0.932400
Distillation: Epoch : 9, Loss : 1.724706, Accuracy: 0.935000, Test accuracy: 0.938400
Distillation: Epoch : 10, Loss : 1.694470, Accuracy: 0.958000, Test accuracy: 0.943900
Distillation: Epoch : 11, Loss : 1.714415, Accuracy: 0.937000, Test accuracy: 0.949500
Distillation: Epoch : 12, Loss : 1.694875, Accuracy: 0.952000, Test accuracy: 0.952100
Distillation: Epoch : 13, Loss : 1.690673, Accuracy: 0.939000, Test accuracy: 0.955400
Distillation: Epoch : 14, Loss : 1.675850, Accuracy: 0.957000, Test accuracy: 0.955200
Distillation: Epoch : 15, Loss : 1.679308, Accuracy: 0.966000, Test accuracy: 0.959400
Distillation: Epoch : 16, Loss : 1.693009, Accuracy: 0.963000, Test accuracy: 0.959800
Distillation: Epoch : 17, Loss : 1.689035, Accuracy: 0.961000, Test accuracy: 0.959800
Distillation: Epoch : 18, Loss : 1.673482, Accuracy: 0.958000, Test accuracy: 0.961200
Distillation: Epoch : 19, Loss : 1.707865, Accuracy: 0.955000, Test accuracy: 0.961800
Distillation: Epoch : 20, Loss : 1.679001, Accuracy: 0.959000, Test accuracy: 0.963300
Distillation: Epoch : 21, Loss : 1.668602, Accuracy: 0.964000, Test accuracy: 0.964400
Distillation: Epoch : 22, Loss : 1.691135, Accuracy: 0.969000, Test accuracy: 0.963400
Distillation: Epoch : 23, Loss : 1.663523, Accuracy: 0.969000, Test accuracy: 0.966000
Distillation: Epoch : 24, Loss : 1.666364, Accuracy: 0.962000, Test accuracy: 0.965800
Distillation: Epoch : 25, Loss : 1.692065, Accuracy: 0.964000, Test accuracy: 0.964500
Distillation: Epoch : 26, Loss : 1.681636, Accuracy: 0.960000, Test accuracy: 0.965300
Distillation: Epoch : 27, Loss : 1.681702, Accuracy: 0.965000, Test accuracy: 0.966300
Distillation: Epoch : 28, Loss : 1.670368, Accuracy: 0.963000, Test accuracy: 0.966200
Distillation: Epoch : 29, Loss : 1.658861, Accuracy: 0.961000, Test accuracy: 0.968600
Distillation: Epoch : 30, Loss : 1.675242, Accuracy: 0.962000, Test accuracy: 0.967800
Distillation: Epoch : 31, Loss : 1.688992, Accuracy: 0.977000, Test accuracy: 0.967400
Distillation: Epoch : 32, Loss : 1.662502, Accuracy: 0.979000, Test accuracy: 0.968200
Distillation: Epoch : 33, Loss : 1.667046, Accuracy: 0.976000, Test accuracy: 0.969600
Distillation: Epoch : 34, Loss : 1.675300, Accuracy: 0.972000, Test accuracy: 0.968600
Distillation: Epoch : 35, Loss : 1.668787, Accuracy: 0.967000, Test accuracy: 0.969800
Distillation: Epoch : 36, Loss : 1.689465, Accuracy: 0.959000, Test accuracy: 0.970100
Distillation: Epoch : 37, Loss : 1.650062, Accuracy: 0.975000, Test accuracy: 0.970700
Distillation: Epoch : 38, Loss : 1.671241, Accuracy: 0.953000, Test accuracy: 0.971500
Distillation: Epoch : 39, Loss : 1.651620, Accuracy: 0.973000, Test accuracy: 0.972700
Distillation: Epoch : 40, Loss : 1.680825, Accuracy: 0.970000, Test accuracy: 0.972200
Distillation: Epoch : 41, Loss : 1.679225, Accuracy: 0.971000, Test accuracy: 0.972500
Distillation: Epoch : 42, Loss : 1.665340, Accuracy: 0.972000, Test accuracy: 0.972600
Distillation: Epoch : 43, Loss : 1.671025, Accuracy: 0.969000, Test accuracy: 0.972200
Distillation: Epoch : 44, Loss : 1.672838, Accuracy: 0.978000, Test accuracy: 0.972500
Distillation: Epoch : 45, Loss : 1.675891, Accuracy: 0.970000, Test accuracy: 0.973700
Distillation: Epoch : 46, Loss : 1.670092, Accuracy: 0.973000, Test accuracy: 0.974300
Distillation: Epoch : 47, Loss : 1.673732, Accuracy: 0.960000, Test accuracy: 0.973600
Distillation: Epoch : 48, Loss : 1.676961, Accuracy: 0.976000, Test accuracy: 0.974400
Distillation: Epoch : 49, Loss : 1.662210, Accuracy: 0.976000, Test accuracy: 0.974200
Distillation: Epoch : 50, Loss : 1.670244, Accuracy: 0.970000, Test accuracy: 0.974200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9742
Generating confusion matrix for student
[[ 970.    0.    6.    0.    1.    2.    5.    0.    4.    3.]
 [   0. 1115.    2.    0.    0.    0.    3.    2.    0.    4.]
 [   0.    6.  996.    3.    0.    0.    0.   12.    1.    0.]
 [   0.    1.    5.  989.    1.   10.    0.    2.    4.    6.]
 [   0.    0.    4.    0.  967.    0.    6.    9.    2.    6.]
 [   1.    0.    0.    3.    0.  861.    5.    1.    0.    1.]
 [   2.    2.    1.    0.    3.    6.  934.    0.    0.    1.]
 [   1.    0.    2.    1.    0.    1.    0.  979.    2.    1.]
 [   5.   11.   16.   11.    2.   10.    5.    4.  958.   14.]
 [   1.    0.    0.    3.    8.    2.    0.   19.    3.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.099870, Accuracy: 0.768000, Test accuracy: 0.772000
Distillation: Epoch : 2, Loss : 2.049457, Accuracy: 0.816000, Test accuracy: 0.832800
Distillation: Epoch : 3, Loss : 2.025381, Accuracy: 0.866000, Test accuracy: 0.870700
Distillation: Epoch : 4, Loss : 2.011086, Accuracy: 0.897000, Test accuracy: 0.880100
Distillation: Epoch : 5, Loss : 1.998929, Accuracy: 0.903000, Test accuracy: 0.895400
Distillation: Epoch : 6, Loss : 1.998307, Accuracy: 0.908000, Test accuracy: 0.904700
Distillation: Epoch : 7, Loss : 1.990803, Accuracy: 0.911000, Test accuracy: 0.913400
Distillation: Epoch : 8, Loss : 1.995370, Accuracy: 0.917000, Test accuracy: 0.923700
Distillation: Epoch : 9, Loss : 1.979153, Accuracy: 0.930000, Test accuracy: 0.930100
Distillation: Epoch : 10, Loss : 1.978870, Accuracy: 0.929000, Test accuracy: 0.937300
Distillation: Epoch : 11, Loss : 1.987352, Accuracy: 0.942000, Test accuracy: 0.942000
Distillation: Epoch : 12, Loss : 1.972816, Accuracy: 0.931000, Test accuracy: 0.946100
Distillation: Epoch : 13, Loss : 1.970719, Accuracy: 0.956000, Test accuracy: 0.950900
Distillation: Epoch : 14, Loss : 1.961071, Accuracy: 0.937000, Test accuracy: 0.953400
Distillation: Epoch : 15, Loss : 1.968526, Accuracy: 0.952000, Test accuracy: 0.955000
Distillation: Epoch : 16, Loss : 1.969839, Accuracy: 0.956000, Test accuracy: 0.956300
Distillation: Epoch : 17, Loss : 1.959977, Accuracy: 0.954000, Test accuracy: 0.957100
Distillation: Epoch : 18, Loss : 1.966332, Accuracy: 0.966000, Test accuracy: 0.960500
Distillation: Epoch : 19, Loss : 1.964472, Accuracy: 0.955000, Test accuracy: 0.959800
Distillation: Epoch : 20, Loss : 1.953879, Accuracy: 0.966000, Test accuracy: 0.962200
Distillation: Epoch : 21, Loss : 1.965635, Accuracy: 0.953000, Test accuracy: 0.963000
Distillation: Epoch : 22, Loss : 1.960143, Accuracy: 0.950000, Test accuracy: 0.963400
Distillation: Epoch : 23, Loss : 1.952112, Accuracy: 0.976000, Test accuracy: 0.964300
Distillation: Epoch : 24, Loss : 1.964607, Accuracy: 0.960000, Test accuracy: 0.965600
Distillation: Epoch : 25, Loss : 1.965886, Accuracy: 0.962000, Test accuracy: 0.966000
Distillation: Epoch : 26, Loss : 1.949764, Accuracy: 0.972000, Test accuracy: 0.966700
Distillation: Epoch : 27, Loss : 1.954872, Accuracy: 0.968000, Test accuracy: 0.967700
Distillation: Epoch : 28, Loss : 1.946141, Accuracy: 0.968000, Test accuracy: 0.967700
Distillation: Epoch : 29, Loss : 1.961599, Accuracy: 0.969000, Test accuracy: 0.968800
Distillation: Epoch : 30, Loss : 1.955495, Accuracy: 0.968000, Test accuracy: 0.968500
Distillation: Epoch : 31, Loss : 1.959216, Accuracy: 0.965000, Test accuracy: 0.969700
Distillation: Epoch : 32, Loss : 1.949681, Accuracy: 0.968000, Test accuracy: 0.970200
Distillation: Epoch : 33, Loss : 1.963086, Accuracy: 0.973000, Test accuracy: 0.970900
Distillation: Epoch : 34, Loss : 1.948905, Accuracy: 0.972000, Test accuracy: 0.971200
Distillation: Epoch : 35, Loss : 1.953399, Accuracy: 0.973000, Test accuracy: 0.971100
Distillation: Epoch : 36, Loss : 1.953372, Accuracy: 0.968000, Test accuracy: 0.972000
Distillation: Epoch : 37, Loss : 1.944799, Accuracy: 0.962000, Test accuracy: 0.971100
Distillation: Epoch : 38, Loss : 1.960986, Accuracy: 0.967000, Test accuracy: 0.972900
Distillation: Epoch : 39, Loss : 1.942069, Accuracy: 0.976000, Test accuracy: 0.972200
Distillation: Epoch : 40, Loss : 1.953964, Accuracy: 0.968000, Test accuracy: 0.972000
Distillation: Epoch : 41, Loss : 1.951004, Accuracy: 0.965000, Test accuracy: 0.973500
Distillation: Epoch : 42, Loss : 1.953318, Accuracy: 0.964000, Test accuracy: 0.973000
Distillation: Epoch : 43, Loss : 1.949550, Accuracy: 0.973000, Test accuracy: 0.972600
Distillation: Epoch : 44, Loss : 1.954967, Accuracy: 0.968000, Test accuracy: 0.972600
Distillation: Epoch : 45, Loss : 1.952673, Accuracy: 0.975000, Test accuracy: 0.974400
Distillation: Epoch : 46, Loss : 1.954188, Accuracy: 0.964000, Test accuracy: 0.973600
Distillation: Epoch : 47, Loss : 1.954741, Accuracy: 0.977000, Test accuracy: 0.974300
Distillation: Epoch : 48, Loss : 1.957572, Accuracy: 0.968000, Test accuracy: 0.973900
Distillation: Epoch : 49, Loss : 1.935518, Accuracy: 0.965000, Test accuracy: 0.974500
Distillation: Epoch : 50, Loss : 1.951788, Accuracy: 0.971000, Test accuracy: 0.974700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9747
Generating confusion matrix for student
[[ 970.    0.    5.    0.    0.    2.    5.    0.    3.    1.]
 [   0. 1120.    0.    0.    0.    0.    2.    4.    1.    6.]
 [   0.    5. 1001.    2.    3.    0.    0.   11.    3.    1.]
 [   0.    0.    3.  977.    0.    4.    1.    2.    3.    4.]
 [   1.    0.    3.    0.  958.    1.    5.    4.    1.   10.]
 [   2.    0.    0.    9.    0.  874.    7.    0.    0.    1.]
 [   3.    5.    0.    0.    2.    3.  931.    0.    1.    1.]
 [   0.    0.    2.    5.    0.    1.    0.  983.    1.    3.]
 [   3.    5.   18.   12.    3.    7.    7.    4.  957.    6.]
 [   1.    0.    0.    5.   16.    0.    0.   20.    4.  976.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.769141, Accuracy: 0.806000, Test accuracy: 0.812700
Distillation: Epoch : 2, Loss : 0.471264, Accuracy: 0.860000, Test accuracy: 0.871400
Distillation: Epoch : 3, Loss : 0.375889, Accuracy: 0.888000, Test accuracy: 0.892700
Distillation: Epoch : 4, Loss : 0.358346, Accuracy: 0.886000, Test accuracy: 0.899200
Distillation: Epoch : 5, Loss : 0.310390, Accuracy: 0.906000, Test accuracy: 0.907200
Distillation: Epoch : 6, Loss : 0.323173, Accuracy: 0.904000, Test accuracy: 0.911800
Distillation: Epoch : 7, Loss : 0.302750, Accuracy: 0.910000, Test accuracy: 0.914000
Distillation: Epoch : 8, Loss : 0.291605, Accuracy: 0.908000, Test accuracy: 0.914800
Distillation: Epoch : 9, Loss : 0.305284, Accuracy: 0.906000, Test accuracy: 0.917700
Distillation: Epoch : 10, Loss : 0.245811, Accuracy: 0.914000, Test accuracy: 0.918200
Distillation: Epoch : 11, Loss : 0.247085, Accuracy: 0.925000, Test accuracy: 0.919300
Distillation: Epoch : 12, Loss : 0.311508, Accuracy: 0.914000, Test accuracy: 0.920400
Distillation: Epoch : 13, Loss : 0.256019, Accuracy: 0.922000, Test accuracy: 0.922800
Distillation: Epoch : 14, Loss : 0.271573, Accuracy: 0.916000, Test accuracy: 0.923500
Distillation: Epoch : 15, Loss : 0.296080, Accuracy: 0.910000, Test accuracy: 0.925500
Distillation: Epoch : 16, Loss : 0.278428, Accuracy: 0.926000, Test accuracy: 0.926900
Distillation: Epoch : 17, Loss : 0.276018, Accuracy: 0.915000, Test accuracy: 0.927500
Distillation: Epoch : 18, Loss : 0.240948, Accuracy: 0.935000, Test accuracy: 0.928900
Distillation: Epoch : 19, Loss : 0.288361, Accuracy: 0.916000, Test accuracy: 0.930900
Distillation: Epoch : 20, Loss : 0.246111, Accuracy: 0.924000, Test accuracy: 0.931700
Distillation: Epoch : 21, Loss : 0.209043, Accuracy: 0.936000, Test accuracy: 0.933200
Distillation: Epoch : 22, Loss : 0.206197, Accuracy: 0.937000, Test accuracy: 0.935100
Distillation: Epoch : 23, Loss : 0.193212, Accuracy: 0.941000, Test accuracy: 0.933800
Distillation: Epoch : 24, Loss : 0.197387, Accuracy: 0.932000, Test accuracy: 0.937000
Distillation: Epoch : 25, Loss : 0.227401, Accuracy: 0.930000, Test accuracy: 0.937700
Distillation: Epoch : 26, Loss : 0.195693, Accuracy: 0.942000, Test accuracy: 0.940900
Distillation: Epoch : 27, Loss : 0.253522, Accuracy: 0.922000, Test accuracy: 0.940800
Distillation: Epoch : 28, Loss : 0.210797, Accuracy: 0.948000, Test accuracy: 0.942700
Distillation: Epoch : 29, Loss : 0.201115, Accuracy: 0.938000, Test accuracy: 0.943900
Distillation: Epoch : 30, Loss : 0.204254, Accuracy: 0.942000, Test accuracy: 0.947300
Distillation: Epoch : 31, Loss : 0.198916, Accuracy: 0.943000, Test accuracy: 0.947900
Distillation: Epoch : 32, Loss : 0.182741, Accuracy: 0.946000, Test accuracy: 0.948900
Distillation: Epoch : 33, Loss : 0.193704, Accuracy: 0.941000, Test accuracy: 0.950800
Distillation: Epoch : 34, Loss : 0.181168, Accuracy: 0.944000, Test accuracy: 0.952800
Distillation: Epoch : 35, Loss : 0.199339, Accuracy: 0.937000, Test accuracy: 0.953800
Distillation: Epoch : 36, Loss : 0.172870, Accuracy: 0.945000, Test accuracy: 0.953900
Distillation: Epoch : 37, Loss : 0.154856, Accuracy: 0.956000, Test accuracy: 0.956000
Distillation: Epoch : 38, Loss : 0.122433, Accuracy: 0.967000, Test accuracy: 0.957200
Distillation: Epoch : 39, Loss : 0.154255, Accuracy: 0.961000, Test accuracy: 0.958900
Distillation: Epoch : 40, Loss : 0.158236, Accuracy: 0.958000, Test accuracy: 0.958500
Distillation: Epoch : 41, Loss : 0.141474, Accuracy: 0.955000, Test accuracy: 0.959900
Distillation: Epoch : 42, Loss : 0.137108, Accuracy: 0.966000, Test accuracy: 0.959300
Distillation: Epoch : 43, Loss : 0.119674, Accuracy: 0.968000, Test accuracy: 0.961700
Distillation: Epoch : 44, Loss : 0.121059, Accuracy: 0.964000, Test accuracy: 0.961900
Distillation: Epoch : 45, Loss : 0.152562, Accuracy: 0.957000, Test accuracy: 0.962000
Distillation: Epoch : 46, Loss : 0.107916, Accuracy: 0.975000, Test accuracy: 0.962900
Distillation: Epoch : 47, Loss : 0.122858, Accuracy: 0.967000, Test accuracy: 0.963300
Distillation: Epoch : 48, Loss : 0.125202, Accuracy: 0.964000, Test accuracy: 0.963400
Distillation: Epoch : 49, Loss : 0.125741, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 50, Loss : 0.127427, Accuracy: 0.963000, Test accuracy: 0.963400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9634
Generating confusion matrix for student2
[[ 966.    0.    6.    0.    2.    3.   11.    2.    5.    7.]
 [   0. 1120.    5.    0.    1.    1.    3.    7.    2.    6.]
 [   2.    2.  980.    4.    4.    0.    1.   14.    5.    1.]
 [   0.    1.    9.  987.    0.   20.    1.    5.   14.   12.]
 [   0.    0.    3.    0.  949.    0.    4.    1.    4.    9.]
 [   0.    1.    0.    2.    0.  843.    2.    0.    1.    3.]
 [   6.    4.    4.    0.    5.    7.  933.    0.    6.    0.]
 [   2.    1.    6.    2.    4.    2.    0.  983.    6.   16.]
 [   3.    6.   18.   11.    4.   13.    3.    3.  920.    2.]
 [   1.    0.    1.    4.   13.    3.    0.   13.   11.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.266066, Accuracy: 0.774000, Test accuracy: 0.799800
Distillation: Epoch : 2, Loss : 0.614153, Accuracy: 0.847000, Test accuracy: 0.859400
Distillation: Epoch : 3, Loss : 0.495208, Accuracy: 0.865000, Test accuracy: 0.885400
Distillation: Epoch : 4, Loss : 0.382394, Accuracy: 0.890000, Test accuracy: 0.900800
Distillation: Epoch : 5, Loss : 0.398348, Accuracy: 0.885000, Test accuracy: 0.911600
Distillation: Epoch : 6, Loss : 0.335149, Accuracy: 0.897000, Test accuracy: 0.918400
Distillation: Epoch : 7, Loss : 0.299888, Accuracy: 0.915000, Test accuracy: 0.922900
Distillation: Epoch : 8, Loss : 0.296171, Accuracy: 0.921000, Test accuracy: 0.925800
Distillation: Epoch : 9, Loss : 0.298864, Accuracy: 0.922000, Test accuracy: 0.928900
Distillation: Epoch : 10, Loss : 0.260444, Accuracy: 0.926000, Test accuracy: 0.932000
Distillation: Epoch : 11, Loss : 0.246692, Accuracy: 0.936000, Test accuracy: 0.936000
Distillation: Epoch : 12, Loss : 0.272230, Accuracy: 0.924000, Test accuracy: 0.937500
Distillation: Epoch : 13, Loss : 0.237774, Accuracy: 0.945000, Test accuracy: 0.941800
Distillation: Epoch : 14, Loss : 0.240325, Accuracy: 0.939000, Test accuracy: 0.943400
Distillation: Epoch : 15, Loss : 0.203947, Accuracy: 0.951000, Test accuracy: 0.944600
Distillation: Epoch : 16, Loss : 0.230084, Accuracy: 0.937000, Test accuracy: 0.946800
Distillation: Epoch : 17, Loss : 0.209454, Accuracy: 0.948000, Test accuracy: 0.947700
Distillation: Epoch : 18, Loss : 0.204976, Accuracy: 0.948000, Test accuracy: 0.949200
Distillation: Epoch : 19, Loss : 0.169184, Accuracy: 0.956000, Test accuracy: 0.950700
Distillation: Epoch : 20, Loss : 0.183101, Accuracy: 0.943000, Test accuracy: 0.952500
Distillation: Epoch : 21, Loss : 0.178179, Accuracy: 0.957000, Test accuracy: 0.953600
Distillation: Epoch : 22, Loss : 0.175843, Accuracy: 0.955000, Test accuracy: 0.955300
Distillation: Epoch : 23, Loss : 0.170640, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 24, Loss : 0.166766, Accuracy: 0.950000, Test accuracy: 0.957700
Distillation: Epoch : 25, Loss : 0.155918, Accuracy: 0.958000, Test accuracy: 0.958300
Distillation: Epoch : 26, Loss : 0.162714, Accuracy: 0.956000, Test accuracy: 0.959800
Distillation: Epoch : 27, Loss : 0.201401, Accuracy: 0.947000, Test accuracy: 0.960300
Distillation: Epoch : 28, Loss : 0.174120, Accuracy: 0.953000, Test accuracy: 0.961800
Distillation: Epoch : 29, Loss : 0.183498, Accuracy: 0.954000, Test accuracy: 0.962300
Distillation: Epoch : 30, Loss : 0.152198, Accuracy: 0.962000, Test accuracy: 0.962900
Distillation: Epoch : 31, Loss : 0.156353, Accuracy: 0.966000, Test accuracy: 0.964000
Distillation: Epoch : 32, Loss : 0.134095, Accuracy: 0.964000, Test accuracy: 0.964500
Distillation: Epoch : 33, Loss : 0.139077, Accuracy: 0.974000, Test accuracy: 0.965300
Distillation: Epoch : 34, Loss : 0.164985, Accuracy: 0.956000, Test accuracy: 0.966200
Distillation: Epoch : 35, Loss : 0.128902, Accuracy: 0.971000, Test accuracy: 0.965600
Distillation: Epoch : 36, Loss : 0.153661, Accuracy: 0.957000, Test accuracy: 0.965800
Distillation: Epoch : 37, Loss : 0.154007, Accuracy: 0.961000, Test accuracy: 0.966900
Distillation: Epoch : 38, Loss : 0.148870, Accuracy: 0.970000, Test accuracy: 0.966900
Distillation: Epoch : 39, Loss : 0.136116, Accuracy: 0.971000, Test accuracy: 0.967100
Distillation: Epoch : 40, Loss : 0.130326, Accuracy: 0.971000, Test accuracy: 0.966600
Distillation: Epoch : 41, Loss : 0.137976, Accuracy: 0.962000, Test accuracy: 0.966100
Distillation: Epoch : 42, Loss : 0.126579, Accuracy: 0.964000, Test accuracy: 0.967300
Distillation: Epoch : 43, Loss : 0.121717, Accuracy: 0.974000, Test accuracy: 0.967500
Distillation: Epoch : 44, Loss : 0.115335, Accuracy: 0.977000, Test accuracy: 0.967600
Distillation: Epoch : 45, Loss : 0.131824, Accuracy: 0.967000, Test accuracy: 0.968600
Distillation: Epoch : 46, Loss : 0.121546, Accuracy: 0.975000, Test accuracy: 0.968000
Distillation: Epoch : 47, Loss : 0.128465, Accuracy: 0.967000, Test accuracy: 0.968200
Distillation: Epoch : 48, Loss : 0.120895, Accuracy: 0.973000, Test accuracy: 0.969300
Distillation: Epoch : 49, Loss : 0.130799, Accuracy: 0.964000, Test accuracy: 0.969400
Distillation: Epoch : 50, Loss : 0.121788, Accuracy: 0.971000, Test accuracy: 0.968300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9683
Generating confusion matrix for student2
[[ 972.    0.    4.    0.    1.    2.    7.    1.    5.    4.]
 [   0. 1126.    5.    0.    2.    0.    3.    5.    2.    6.]
 [   1.    3.  989.    5.    2.    0.    0.   18.    6.    1.]
 [   1.    0.    7.  981.    0.    7.    1.    4.   10.    2.]
 [   0.    0.    3.    1.  952.    0.    6.    3.    2.   10.]
 [   0.    1.    0.    6.    0.  859.    2.    0.    4.    5.]
 [   1.    2.    1.    0.    4.    6.  934.    0.    2.    0.]
 [   1.    0.    8.    5.    2.    2.    0.  977.    8.    8.]
 [   3.    3.   12.    6.    3.   11.    5.    3.  926.    6.]
 [   1.    0.    3.    6.   16.    5.    0.   17.    9.  967.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.414915, Accuracy: 0.794000, Test accuracy: 0.796700
Distillation: Epoch : 2, Loss : 0.886905, Accuracy: 0.843000, Test accuracy: 0.851500
Distillation: Epoch : 3, Loss : 0.738526, Accuracy: 0.866000, Test accuracy: 0.876100
Distillation: Epoch : 4, Loss : 0.706666, Accuracy: 0.875000, Test accuracy: 0.888600
Distillation: Epoch : 5, Loss : 0.662047, Accuracy: 0.881000, Test accuracy: 0.896500
Distillation: Epoch : 6, Loss : 0.652958, Accuracy: 0.888000, Test accuracy: 0.901900
Distillation: Epoch : 7, Loss : 0.645351, Accuracy: 0.887000, Test accuracy: 0.905500
Distillation: Epoch : 8, Loss : 0.627854, Accuracy: 0.898000, Test accuracy: 0.907700
Distillation: Epoch : 9, Loss : 0.635001, Accuracy: 0.908000, Test accuracy: 0.910000
Distillation: Epoch : 10, Loss : 0.567289, Accuracy: 0.918000, Test accuracy: 0.912600
Distillation: Epoch : 11, Loss : 0.595168, Accuracy: 0.912000, Test accuracy: 0.915400
Distillation: Epoch : 12, Loss : 0.579826, Accuracy: 0.910000, Test accuracy: 0.915900
Distillation: Epoch : 13, Loss : 0.590845, Accuracy: 0.921000, Test accuracy: 0.918300
Distillation: Epoch : 14, Loss : 0.613541, Accuracy: 0.920000, Test accuracy: 0.920100
Distillation: Epoch : 15, Loss : 0.573651, Accuracy: 0.915000, Test accuracy: 0.921300
Distillation: Epoch : 16, Loss : 0.603765, Accuracy: 0.906000, Test accuracy: 0.922400
Distillation: Epoch : 17, Loss : 0.584628, Accuracy: 0.921000, Test accuracy: 0.924600
Distillation: Epoch : 18, Loss : 0.601877, Accuracy: 0.900000, Test accuracy: 0.926600
Distillation: Epoch : 19, Loss : 0.548430, Accuracy: 0.928000, Test accuracy: 0.927700
Distillation: Epoch : 20, Loss : 0.543316, Accuracy: 0.932000, Test accuracy: 0.929500
Distillation: Epoch : 21, Loss : 0.535003, Accuracy: 0.933000, Test accuracy: 0.930100
Distillation: Epoch : 22, Loss : 0.548691, Accuracy: 0.929000, Test accuracy: 0.932200
Distillation: Epoch : 23, Loss : 0.508706, Accuracy: 0.948000, Test accuracy: 0.934400
Distillation: Epoch : 24, Loss : 0.565734, Accuracy: 0.928000, Test accuracy: 0.935100
Distillation: Epoch : 25, Loss : 0.529600, Accuracy: 0.940000, Test accuracy: 0.936300
Distillation: Epoch : 26, Loss : 0.504824, Accuracy: 0.944000, Test accuracy: 0.938700
Distillation: Epoch : 27, Loss : 0.541270, Accuracy: 0.930000, Test accuracy: 0.940900
Distillation: Epoch : 28, Loss : 0.514743, Accuracy: 0.935000, Test accuracy: 0.942100
Distillation: Epoch : 29, Loss : 0.524966, Accuracy: 0.938000, Test accuracy: 0.943200
Distillation: Epoch : 30, Loss : 0.505791, Accuracy: 0.927000, Test accuracy: 0.945000
Distillation: Epoch : 31, Loss : 0.470005, Accuracy: 0.938000, Test accuracy: 0.946800
Distillation: Epoch : 32, Loss : 0.487580, Accuracy: 0.937000, Test accuracy: 0.947500
Distillation: Epoch : 33, Loss : 0.517223, Accuracy: 0.936000, Test accuracy: 0.949100
Distillation: Epoch : 34, Loss : 0.489867, Accuracy: 0.950000, Test accuracy: 0.949900
Distillation: Epoch : 35, Loss : 0.461044, Accuracy: 0.950000, Test accuracy: 0.951100
Distillation: Epoch : 36, Loss : 0.473888, Accuracy: 0.950000, Test accuracy: 0.952300
Distillation: Epoch : 37, Loss : 0.453959, Accuracy: 0.960000, Test accuracy: 0.953300
Distillation: Epoch : 38, Loss : 0.449357, Accuracy: 0.957000, Test accuracy: 0.954000
Distillation: Epoch : 39, Loss : 0.469818, Accuracy: 0.954000, Test accuracy: 0.955800
Distillation: Epoch : 40, Loss : 0.477482, Accuracy: 0.942000, Test accuracy: 0.955100
Distillation: Epoch : 41, Loss : 0.478249, Accuracy: 0.951000, Test accuracy: 0.956700
Distillation: Epoch : 42, Loss : 0.445580, Accuracy: 0.961000, Test accuracy: 0.957600
Distillation: Epoch : 43, Loss : 0.502313, Accuracy: 0.942000, Test accuracy: 0.959600
Distillation: Epoch : 44, Loss : 0.428628, Accuracy: 0.966000, Test accuracy: 0.960100
Distillation: Epoch : 45, Loss : 0.464323, Accuracy: 0.961000, Test accuracy: 0.961000
Distillation: Epoch : 46, Loss : 0.467460, Accuracy: 0.953000, Test accuracy: 0.962000
Distillation: Epoch : 47, Loss : 0.445232, Accuracy: 0.962000, Test accuracy: 0.961000
Distillation: Epoch : 48, Loss : 0.449849, Accuracy: 0.959000, Test accuracy: 0.961000
Distillation: Epoch : 49, Loss : 0.473135, Accuracy: 0.960000, Test accuracy: 0.962100
Distillation: Epoch : 50, Loss : 0.435045, Accuracy: 0.961000, Test accuracy: 0.962500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9625
Generating confusion matrix for student2
[[ 966.    0.    3.    0.    2.    2.    7.    1.    5.    7.]
 [   0. 1123.    5.    0.    2.    1.    3.    5.    3.    6.]
 [   1.    2.  978.    4.    2.    0.    0.   24.    7.    1.]
 [   1.    1.    3.  973.    0.    5.    1.    3.    9.   12.]
 [   1.    1.    6.    1.  955.    0.    4.    1.    6.   20.]
 [   0.    1.    0.    6.    0.  860.    7.    1.    4.    3.]
 [   5.    3.    3.    0.    5.    7.  933.    0.    1.    0.]
 [   1.    0.    5.    4.    0.    2.    0.  961.    5.    5.]
 [   3.    4.   25.   19.    2.   13.    3.    5.  925.    4.]
 [   2.    0.    4.    3.   14.    2.    0.   27.    9.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.574644, Accuracy: 0.775000, Test accuracy: 0.783500
Distillation: Epoch : 2, Loss : 1.001343, Accuracy: 0.842000, Test accuracy: 0.855700
Distillation: Epoch : 3, Loss : 0.852995, Accuracy: 0.890000, Test accuracy: 0.884600
Distillation: Epoch : 4, Loss : 0.816768, Accuracy: 0.876000, Test accuracy: 0.899600
Distillation: Epoch : 5, Loss : 0.748744, Accuracy: 0.897000, Test accuracy: 0.907700
Distillation: Epoch : 6, Loss : 0.737859, Accuracy: 0.906000, Test accuracy: 0.914600
Distillation: Epoch : 7, Loss : 0.717896, Accuracy: 0.918000, Test accuracy: 0.917500
Distillation: Epoch : 8, Loss : 0.762183, Accuracy: 0.926000, Test accuracy: 0.921900
Distillation: Epoch : 9, Loss : 0.709886, Accuracy: 0.923000, Test accuracy: 0.925400
Distillation: Epoch : 10, Loss : 0.746499, Accuracy: 0.910000, Test accuracy: 0.928000
Distillation: Epoch : 11, Loss : 0.664672, Accuracy: 0.930000, Test accuracy: 0.931000
Distillation: Epoch : 12, Loss : 0.695977, Accuracy: 0.932000, Test accuracy: 0.934000
Distillation: Epoch : 13, Loss : 0.718282, Accuracy: 0.919000, Test accuracy: 0.935800
Distillation: Epoch : 14, Loss : 0.701991, Accuracy: 0.929000, Test accuracy: 0.937400
Distillation: Epoch : 15, Loss : 0.693960, Accuracy: 0.936000, Test accuracy: 0.938400
Distillation: Epoch : 16, Loss : 0.672634, Accuracy: 0.941000, Test accuracy: 0.941900
Distillation: Epoch : 17, Loss : 0.652941, Accuracy: 0.938000, Test accuracy: 0.944200
Distillation: Epoch : 18, Loss : 0.638735, Accuracy: 0.953000, Test accuracy: 0.944600
Distillation: Epoch : 19, Loss : 0.674912, Accuracy: 0.939000, Test accuracy: 0.945900
Distillation: Epoch : 20, Loss : 0.668748, Accuracy: 0.925000, Test accuracy: 0.946600
Distillation: Epoch : 21, Loss : 0.658415, Accuracy: 0.934000, Test accuracy: 0.947400
Distillation: Epoch : 22, Loss : 0.643744, Accuracy: 0.944000, Test accuracy: 0.949000
Distillation: Epoch : 23, Loss : 0.651456, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 24, Loss : 0.655500, Accuracy: 0.940000, Test accuracy: 0.951600
Distillation: Epoch : 25, Loss : 0.610187, Accuracy: 0.954000, Test accuracy: 0.952300
Distillation: Epoch : 26, Loss : 0.631515, Accuracy: 0.945000, Test accuracy: 0.953500
Distillation: Epoch : 27, Loss : 0.671850, Accuracy: 0.934000, Test accuracy: 0.955200
Distillation: Epoch : 28, Loss : 0.641962, Accuracy: 0.948000, Test accuracy: 0.956200
Distillation: Epoch : 29, Loss : 0.629441, Accuracy: 0.962000, Test accuracy: 0.955600
Distillation: Epoch : 30, Loss : 0.611572, Accuracy: 0.949000, Test accuracy: 0.956600
Distillation: Epoch : 31, Loss : 0.658008, Accuracy: 0.932000, Test accuracy: 0.956300
Distillation: Epoch : 32, Loss : 0.606120, Accuracy: 0.963000, Test accuracy: 0.957600
Distillation: Epoch : 33, Loss : 0.637542, Accuracy: 0.946000, Test accuracy: 0.957300
Distillation: Epoch : 34, Loss : 0.612189, Accuracy: 0.962000, Test accuracy: 0.957700
Distillation: Epoch : 35, Loss : 0.647443, Accuracy: 0.958000, Test accuracy: 0.958700
Distillation: Epoch : 36, Loss : 0.606913, Accuracy: 0.961000, Test accuracy: 0.959100
Distillation: Epoch : 37, Loss : 0.593891, Accuracy: 0.961000, Test accuracy: 0.958900
Distillation: Epoch : 38, Loss : 0.618833, Accuracy: 0.951000, Test accuracy: 0.958200
Distillation: Epoch : 39, Loss : 0.622219, Accuracy: 0.959000, Test accuracy: 0.960300
Distillation: Epoch : 40, Loss : 0.633097, Accuracy: 0.960000, Test accuracy: 0.959700
Distillation: Epoch : 41, Loss : 0.607688, Accuracy: 0.959000, Test accuracy: 0.961000
Distillation: Epoch : 42, Loss : 0.649742, Accuracy: 0.941000, Test accuracy: 0.960900
Distillation: Epoch : 43, Loss : 0.636017, Accuracy: 0.954000, Test accuracy: 0.960300
Distillation: Epoch : 44, Loss : 0.625835, Accuracy: 0.955000, Test accuracy: 0.961000
Distillation: Epoch : 45, Loss : 0.604837, Accuracy: 0.964000, Test accuracy: 0.961300
Distillation: Epoch : 46, Loss : 0.599469, Accuracy: 0.968000, Test accuracy: 0.960700
Distillation: Epoch : 47, Loss : 0.631324, Accuracy: 0.957000, Test accuracy: 0.961100
Distillation: Epoch : 48, Loss : 0.616994, Accuracy: 0.962000, Test accuracy: 0.961400
Distillation: Epoch : 49, Loss : 0.637514, Accuracy: 0.947000, Test accuracy: 0.961000
Distillation: Epoch : 50, Loss : 0.588152, Accuracy: 0.974000, Test accuracy: 0.961200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9612
Generating confusion matrix for student2
[[ 969.    0.    3.    0.    1.    2.    3.    2.    9.    2.]
 [   0. 1117.    3.    0.    2.    1.    4.    5.    3.    5.]
 [   1.    4.  978.    6.    2.    0.    1.   18.    6.    0.]
 [   0.    1.    9.  976.    0.   11.    1.    4.    7.    7.]
 [   1.    1.    7.    1.  953.    0.    7.    8.    6.   20.]
 [   0.    0.    1.    9.    0.  851.    5.    0.    6.    8.]
 [   3.    3.    3.    0.    5.    6.  933.    0.    5.    0.]
 [   1.    0.    5.    2.    2.    2.    0.  962.    4.    9.]
 [   3.    9.   21.   11.    4.   14.    4.    3.  921.    6.]
 [   2.    0.    2.    5.   13.    5.    0.   26.    7.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.797946, Accuracy: 0.751000, Test accuracy: 0.769200
Distillation: Epoch : 2, Loss : 1.186328, Accuracy: 0.837000, Test accuracy: 0.846000
Distillation: Epoch : 3, Loss : 1.038550, Accuracy: 0.865000, Test accuracy: 0.884200
Distillation: Epoch : 4, Loss : 0.981140, Accuracy: 0.891000, Test accuracy: 0.898700
Distillation: Epoch : 5, Loss : 0.937477, Accuracy: 0.900000, Test accuracy: 0.908800
Distillation: Epoch : 6, Loss : 0.923440, Accuracy: 0.906000, Test accuracy: 0.914700
Distillation: Epoch : 7, Loss : 0.894173, Accuracy: 0.915000, Test accuracy: 0.920400
Distillation: Epoch : 8, Loss : 0.876782, Accuracy: 0.916000, Test accuracy: 0.924700
Distillation: Epoch : 9, Loss : 0.874750, Accuracy: 0.933000, Test accuracy: 0.929100
Distillation: Epoch : 10, Loss : 0.871125, Accuracy: 0.928000, Test accuracy: 0.932700
Distillation: Epoch : 11, Loss : 0.872258, Accuracy: 0.935000, Test accuracy: 0.935500
Distillation: Epoch : 12, Loss : 0.831473, Accuracy: 0.943000, Test accuracy: 0.939000
Distillation: Epoch : 13, Loss : 0.828672, Accuracy: 0.937000, Test accuracy: 0.940400
Distillation: Epoch : 14, Loss : 0.829256, Accuracy: 0.940000, Test accuracy: 0.942700
Distillation: Epoch : 15, Loss : 0.819365, Accuracy: 0.945000, Test accuracy: 0.944900
Distillation: Epoch : 16, Loss : 0.819132, Accuracy: 0.947000, Test accuracy: 0.947300
Distillation: Epoch : 17, Loss : 0.822703, Accuracy: 0.947000, Test accuracy: 0.948700
Distillation: Epoch : 18, Loss : 0.838040, Accuracy: 0.944000, Test accuracy: 0.951000
Distillation: Epoch : 19, Loss : 0.789039, Accuracy: 0.943000, Test accuracy: 0.952900
Distillation: Epoch : 20, Loss : 0.813717, Accuracy: 0.957000, Test accuracy: 0.953900
Distillation: Epoch : 21, Loss : 0.803267, Accuracy: 0.953000, Test accuracy: 0.954900
Distillation: Epoch : 22, Loss : 0.834898, Accuracy: 0.947000, Test accuracy: 0.956000
Distillation: Epoch : 23, Loss : 0.781669, Accuracy: 0.965000, Test accuracy: 0.957300
Distillation: Epoch : 24, Loss : 0.777363, Accuracy: 0.968000, Test accuracy: 0.957800
Distillation: Epoch : 25, Loss : 0.826755, Accuracy: 0.952000, Test accuracy: 0.959500
Distillation: Epoch : 26, Loss : 0.785094, Accuracy: 0.956000, Test accuracy: 0.959800
Distillation: Epoch : 27, Loss : 0.780390, Accuracy: 0.963000, Test accuracy: 0.961600
Distillation: Epoch : 28, Loss : 0.782909, Accuracy: 0.954000, Test accuracy: 0.962600
Distillation: Epoch : 29, Loss : 0.781205, Accuracy: 0.959000, Test accuracy: 0.963200
Distillation: Epoch : 30, Loss : 0.767314, Accuracy: 0.957000, Test accuracy: 0.963200
Distillation: Epoch : 31, Loss : 0.775782, Accuracy: 0.958000, Test accuracy: 0.963400
Distillation: Epoch : 32, Loss : 0.774048, Accuracy: 0.959000, Test accuracy: 0.963200
Distillation: Epoch : 33, Loss : 0.801224, Accuracy: 0.961000, Test accuracy: 0.964200
Distillation: Epoch : 34, Loss : 0.778535, Accuracy: 0.968000, Test accuracy: 0.964800
Distillation: Epoch : 35, Loss : 0.758460, Accuracy: 0.962000, Test accuracy: 0.964700
Distillation: Epoch : 36, Loss : 0.796049, Accuracy: 0.958000, Test accuracy: 0.965700
Distillation: Epoch : 37, Loss : 0.796468, Accuracy: 0.963000, Test accuracy: 0.965800
Distillation: Epoch : 38, Loss : 0.760543, Accuracy: 0.967000, Test accuracy: 0.964900
Distillation: Epoch : 39, Loss : 0.759030, Accuracy: 0.973000, Test accuracy: 0.966200
Distillation: Epoch : 40, Loss : 0.772054, Accuracy: 0.967000, Test accuracy: 0.966500
Distillation: Epoch : 41, Loss : 0.799067, Accuracy: 0.949000, Test accuracy: 0.967900
Distillation: Epoch : 42, Loss : 0.770101, Accuracy: 0.964000, Test accuracy: 0.967700
Distillation: Epoch : 43, Loss : 0.744165, Accuracy: 0.973000, Test accuracy: 0.968000
Distillation: Epoch : 44, Loss : 0.768938, Accuracy: 0.955000, Test accuracy: 0.967700
Distillation: Epoch : 45, Loss : 0.752290, Accuracy: 0.969000, Test accuracy: 0.968500
Distillation: Epoch : 46, Loss : 0.773928, Accuracy: 0.960000, Test accuracy: 0.967600
Distillation: Epoch : 47, Loss : 0.756939, Accuracy: 0.961000, Test accuracy: 0.967800
Distillation: Epoch : 48, Loss : 0.759544, Accuracy: 0.959000, Test accuracy: 0.967600
Distillation: Epoch : 49, Loss : 0.798822, Accuracy: 0.952000, Test accuracy: 0.968700
Distillation: Epoch : 50, Loss : 0.776118, Accuracy: 0.964000, Test accuracy: 0.968600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9686
Generating confusion matrix for student2
[[ 968.    0.    3.    0.    1.    2.    6.    2.    7.    4.]
 [   0. 1114.    3.    0.    0.    0.    3.    4.    3.    5.]
 [   0.    4.  983.    2.    0.    1.    0.   16.    4.    1.]
 [   0.    1.    6.  985.    0.   11.    0.    4.    2.    2.]
 [   1.    1.    5.    0.  961.    0.    5.    2.    4.   18.]
 [   0.    0.    1.    6.    0.  859.    2.    1.    2.    6.]
 [   6.    3.    1.    0.    3.    2.  938.    0.    3.    0.]
 [   2.    0.    2.    5.    2.    2.    0.  980.    6.    6.]
 [   2.   11.   27.   11.    3.   13.    4.    8.  939.    8.]
 [   1.    1.    1.    1.   12.    2.    0.   11.    4.  959.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.854000, Accuracy: 0.709000, Test accuracy: 0.749000
Distillation: Epoch : 2, Loss : 1.325691, Accuracy: 0.817000, Test accuracy: 0.837200
Distillation: Epoch : 3, Loss : 1.210257, Accuracy: 0.849000, Test accuracy: 0.873800
Distillation: Epoch : 4, Loss : 1.125360, Accuracy: 0.889000, Test accuracy: 0.891900
Distillation: Epoch : 5, Loss : 1.121350, Accuracy: 0.878000, Test accuracy: 0.901200
Distillation: Epoch : 6, Loss : 1.083196, Accuracy: 0.910000, Test accuracy: 0.907500
Distillation: Epoch : 7, Loss : 1.038122, Accuracy: 0.912000, Test accuracy: 0.913900
Distillation: Epoch : 8, Loss : 1.028922, Accuracy: 0.917000, Test accuracy: 0.918100
Distillation: Epoch : 9, Loss : 1.051091, Accuracy: 0.906000, Test accuracy: 0.923300
Distillation: Epoch : 10, Loss : 1.041916, Accuracy: 0.922000, Test accuracy: 0.925600
Distillation: Epoch : 11, Loss : 1.019295, Accuracy: 0.917000, Test accuracy: 0.930000
Distillation: Epoch : 12, Loss : 1.029079, Accuracy: 0.932000, Test accuracy: 0.933600
Distillation: Epoch : 13, Loss : 0.995803, Accuracy: 0.933000, Test accuracy: 0.937800
Distillation: Epoch : 14, Loss : 1.000973, Accuracy: 0.945000, Test accuracy: 0.940100
Distillation: Epoch : 15, Loss : 1.028176, Accuracy: 0.936000, Test accuracy: 0.942100
Distillation: Epoch : 16, Loss : 1.001589, Accuracy: 0.940000, Test accuracy: 0.946600
Distillation: Epoch : 17, Loss : 0.977458, Accuracy: 0.936000, Test accuracy: 0.946700
Distillation: Epoch : 18, Loss : 0.974895, Accuracy: 0.946000, Test accuracy: 0.948300
Distillation: Epoch : 19, Loss : 0.982080, Accuracy: 0.944000, Test accuracy: 0.949800
Distillation: Epoch : 20, Loss : 0.988727, Accuracy: 0.947000, Test accuracy: 0.950100
Distillation: Epoch : 21, Loss : 0.974193, Accuracy: 0.944000, Test accuracy: 0.951500
Distillation: Epoch : 22, Loss : 0.964604, Accuracy: 0.963000, Test accuracy: 0.953400
Distillation: Epoch : 23, Loss : 0.948476, Accuracy: 0.948000, Test accuracy: 0.953200
Distillation: Epoch : 24, Loss : 0.949370, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 25, Loss : 0.974565, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 26, Loss : 0.942386, Accuracy: 0.964000, Test accuracy: 0.956800
Distillation: Epoch : 27, Loss : 0.958143, Accuracy: 0.970000, Test accuracy: 0.957500
Distillation: Epoch : 28, Loss : 0.948007, Accuracy: 0.966000, Test accuracy: 0.957900
Distillation: Epoch : 29, Loss : 0.962173, Accuracy: 0.946000, Test accuracy: 0.957900
Distillation: Epoch : 30, Loss : 0.925749, Accuracy: 0.962000, Test accuracy: 0.958600
Distillation: Epoch : 31, Loss : 0.954102, Accuracy: 0.953000, Test accuracy: 0.959000
Distillation: Epoch : 32, Loss : 0.938410, Accuracy: 0.957000, Test accuracy: 0.959600
Distillation: Epoch : 33, Loss : 0.925270, Accuracy: 0.955000, Test accuracy: 0.959800
Distillation: Epoch : 34, Loss : 0.942199, Accuracy: 0.967000, Test accuracy: 0.960300
Distillation: Epoch : 35, Loss : 0.917163, Accuracy: 0.962000, Test accuracy: 0.960500
Distillation: Epoch : 36, Loss : 0.948369, Accuracy: 0.966000, Test accuracy: 0.960800
Distillation: Epoch : 37, Loss : 0.920829, Accuracy: 0.969000, Test accuracy: 0.961400
Distillation: Epoch : 38, Loss : 0.948776, Accuracy: 0.960000, Test accuracy: 0.961500
Distillation: Epoch : 39, Loss : 0.940206, Accuracy: 0.967000, Test accuracy: 0.962300
Distillation: Epoch : 40, Loss : 0.950322, Accuracy: 0.965000, Test accuracy: 0.961700
Distillation: Epoch : 41, Loss : 0.953939, Accuracy: 0.963000, Test accuracy: 0.961800
Distillation: Epoch : 42, Loss : 0.941636, Accuracy: 0.962000, Test accuracy: 0.962300
Distillation: Epoch : 43, Loss : 0.924186, Accuracy: 0.966000, Test accuracy: 0.963100
Distillation: Epoch : 44, Loss : 0.941006, Accuracy: 0.976000, Test accuracy: 0.962700
Distillation: Epoch : 45, Loss : 0.937479, Accuracy: 0.952000, Test accuracy: 0.962900
Distillation: Epoch : 46, Loss : 0.952065, Accuracy: 0.956000, Test accuracy: 0.962200
Distillation: Epoch : 47, Loss : 0.944867, Accuracy: 0.969000, Test accuracy: 0.963500
Distillation: Epoch : 48, Loss : 0.915060, Accuracy: 0.979000, Test accuracy: 0.964500
Distillation: Epoch : 49, Loss : 0.926341, Accuracy: 0.967000, Test accuracy: 0.963800
Distillation: Epoch : 50, Loss : 0.918683, Accuracy: 0.969000, Test accuracy: 0.963500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9635
Generating confusion matrix for student2
[[ 964.    0.    3.    2.    1.    2.    4.    1.    4.    4.]
 [   0. 1118.    4.    0.    1.    0.    2.    4.    1.    4.]
 [   2.    4.  976.    6.    2.    0.    0.   14.    6.    0.]
 [   0.    1.    6.  973.    0.   11.    0.    4.    7.    4.]
 [   1.    1.    4.    0.  959.    2.    7.    4.    7.   18.]
 [   1.    1.    0.    7.    0.  848.    8.    1.    4.   11.]
 [   9.    4.    4.    1.    2.    8.  932.    0.    0.    2.]
 [   1.    1.    4.    3.    0.    2.    0.  981.    3.    8.]
 [   2.    4.   28.   17.    3.   18.    5.    4.  932.    6.]
 [   0.    1.    3.    1.   14.    1.    0.   15.   10.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.716804, Accuracy: 0.747000, Test accuracy: 0.764100
Distillation: Epoch : 2, Loss : 1.387430, Accuracy: 0.825000, Test accuracy: 0.841300
Distillation: Epoch : 3, Loss : 1.295134, Accuracy: 0.877000, Test accuracy: 0.868400
Distillation: Epoch : 4, Loss : 1.275235, Accuracy: 0.866000, Test accuracy: 0.883000
Distillation: Epoch : 5, Loss : 1.271722, Accuracy: 0.877000, Test accuracy: 0.887400
Distillation: Epoch : 6, Loss : 1.246579, Accuracy: 0.886000, Test accuracy: 0.892200
Distillation: Epoch : 7, Loss : 1.262216, Accuracy: 0.881000, Test accuracy: 0.895000
Distillation: Epoch : 8, Loss : 1.252898, Accuracy: 0.884000, Test accuracy: 0.897200
Distillation: Epoch : 9, Loss : 1.240932, Accuracy: 0.893000, Test accuracy: 0.900300
Distillation: Epoch : 10, Loss : 1.224657, Accuracy: 0.902000, Test accuracy: 0.902500
Distillation: Epoch : 11, Loss : 1.217359, Accuracy: 0.890000, Test accuracy: 0.903700
Distillation: Epoch : 12, Loss : 1.188777, Accuracy: 0.912000, Test accuracy: 0.904100
Distillation: Epoch : 13, Loss : 1.235171, Accuracy: 0.903000, Test accuracy: 0.905000
Distillation: Epoch : 14, Loss : 1.213911, Accuracy: 0.914000, Test accuracy: 0.907400
Distillation: Epoch : 15, Loss : 1.206406, Accuracy: 0.904000, Test accuracy: 0.908200
Distillation: Epoch : 16, Loss : 1.216773, Accuracy: 0.910000, Test accuracy: 0.911300
Distillation: Epoch : 17, Loss : 1.205562, Accuracy: 0.902000, Test accuracy: 0.912600
Distillation: Epoch : 18, Loss : 1.195348, Accuracy: 0.905000, Test accuracy: 0.914400
Distillation: Epoch : 19, Loss : 1.216458, Accuracy: 0.911000, Test accuracy: 0.914500
Distillation: Epoch : 20, Loss : 1.216023, Accuracy: 0.907000, Test accuracy: 0.917200
Distillation: Epoch : 21, Loss : 1.198027, Accuracy: 0.901000, Test accuracy: 0.917200
Distillation: Epoch : 22, Loss : 1.168313, Accuracy: 0.928000, Test accuracy: 0.918600
Distillation: Epoch : 23, Loss : 1.189895, Accuracy: 0.906000, Test accuracy: 0.922900
Distillation: Epoch : 24, Loss : 1.198753, Accuracy: 0.913000, Test accuracy: 0.924500
Distillation: Epoch : 25, Loss : 1.183675, Accuracy: 0.914000, Test accuracy: 0.925500
Distillation: Epoch : 26, Loss : 1.165365, Accuracy: 0.921000, Test accuracy: 0.927500
Distillation: Epoch : 27, Loss : 1.182730, Accuracy: 0.920000, Test accuracy: 0.929400
Distillation: Epoch : 28, Loss : 1.177086, Accuracy: 0.920000, Test accuracy: 0.930700
Distillation: Epoch : 29, Loss : 1.195083, Accuracy: 0.931000, Test accuracy: 0.933400
Distillation: Epoch : 30, Loss : 1.163692, Accuracy: 0.933000, Test accuracy: 0.933200
Distillation: Epoch : 31, Loss : 1.141169, Accuracy: 0.936000, Test accuracy: 0.936000
Distillation: Epoch : 32, Loss : 1.191847, Accuracy: 0.933000, Test accuracy: 0.937200
Distillation: Epoch : 33, Loss : 1.161744, Accuracy: 0.937000, Test accuracy: 0.937800
Distillation: Epoch : 34, Loss : 1.159554, Accuracy: 0.920000, Test accuracy: 0.940300
Distillation: Epoch : 35, Loss : 1.142786, Accuracy: 0.941000, Test accuracy: 0.941200
Distillation: Epoch : 36, Loss : 1.148525, Accuracy: 0.927000, Test accuracy: 0.942700
Distillation: Epoch : 37, Loss : 1.131470, Accuracy: 0.945000, Test accuracy: 0.944400
Distillation: Epoch : 38, Loss : 1.132727, Accuracy: 0.942000, Test accuracy: 0.944700
Distillation: Epoch : 39, Loss : 1.108985, Accuracy: 0.941000, Test accuracy: 0.945600
Distillation: Epoch : 40, Loss : 1.111825, Accuracy: 0.950000, Test accuracy: 0.946400
Distillation: Epoch : 41, Loss : 1.111027, Accuracy: 0.963000, Test accuracy: 0.945800
Distillation: Epoch : 42, Loss : 1.140861, Accuracy: 0.946000, Test accuracy: 0.948300
Distillation: Epoch : 43, Loss : 1.141488, Accuracy: 0.935000, Test accuracy: 0.948900
Distillation: Epoch : 44, Loss : 1.130300, Accuracy: 0.943000, Test accuracy: 0.949200
Distillation: Epoch : 45, Loss : 1.134048, Accuracy: 0.952000, Test accuracy: 0.952100
Distillation: Epoch : 46, Loss : 1.114307, Accuracy: 0.949000, Test accuracy: 0.953100
Distillation: Epoch : 47, Loss : 1.101334, Accuracy: 0.947000, Test accuracy: 0.954100
Distillation: Epoch : 48, Loss : 1.100268, Accuracy: 0.941000, Test accuracy: 0.954400
Distillation: Epoch : 49, Loss : 1.130641, Accuracy: 0.958000, Test accuracy: 0.956500
Distillation: Epoch : 50, Loss : 1.113221, Accuracy: 0.957000, Test accuracy: 0.956200
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9562
Generating confusion matrix for student2
[[ 970.    0.    5.    1.    1.    3.    6.    1.    6.    6.]
 [   1. 1108.    4.    1.    2.    1.    3.    5.    4.    5.]
 [   0.    3.  970.    3.    1.    0.    0.   22.    4.    2.]
 [   0.    1.    4.  975.    0.   21.    1.    4.   11.   13.]
 [   2.    1.    9.    1.  955.    0.    4.    6.    6.   21.]
 [   0.    1.    0.    6.    0.  836.   11.    3.    6.    4.]
 [   4.    4.    3.    0.    4.    4.  928.    0.    1.    0.]
 [   1.    0.    4.    6.    0.    2.    0.  948.    4.    7.]
 [   2.   17.   30.   13.    4.   20.    5.    3.  927.    6.]
 [   0.    0.    3.    4.   15.    5.    0.   36.    5.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.826841, Accuracy: 0.739000, Test accuracy: 0.722800
Distillation: Epoch : 2, Loss : 1.525425, Accuracy: 0.829000, Test accuracy: 0.839000
Distillation: Epoch : 3, Loss : 1.443296, Accuracy: 0.866000, Test accuracy: 0.865500
Distillation: Epoch : 4, Loss : 1.435383, Accuracy: 0.846000, Test accuracy: 0.873800
Distillation: Epoch : 5, Loss : 1.397316, Accuracy: 0.870000, Test accuracy: 0.880600
Distillation: Epoch : 6, Loss : 1.429192, Accuracy: 0.866000, Test accuracy: 0.884800
Distillation: Epoch : 7, Loss : 1.377416, Accuracy: 0.882000, Test accuracy: 0.888400
Distillation: Epoch : 8, Loss : 1.402931, Accuracy: 0.881000, Test accuracy: 0.891500
Distillation: Epoch : 9, Loss : 1.384943, Accuracy: 0.878000, Test accuracy: 0.894000
Distillation: Epoch : 10, Loss : 1.373826, Accuracy: 0.875000, Test accuracy: 0.894200
Distillation: Epoch : 11, Loss : 1.379820, Accuracy: 0.898000, Test accuracy: 0.897700
Distillation: Epoch : 12, Loss : 1.370179, Accuracy: 0.891000, Test accuracy: 0.899300
Distillation: Epoch : 13, Loss : 1.371463, Accuracy: 0.902000, Test accuracy: 0.901700
Distillation: Epoch : 14, Loss : 1.371025, Accuracy: 0.901000, Test accuracy: 0.903400
Distillation: Epoch : 15, Loss : 1.375910, Accuracy: 0.887000, Test accuracy: 0.902900
Distillation: Epoch : 16, Loss : 1.387095, Accuracy: 0.892000, Test accuracy: 0.905200
Distillation: Epoch : 17, Loss : 1.347810, Accuracy: 0.905000, Test accuracy: 0.905900
Distillation: Epoch : 18, Loss : 1.369133, Accuracy: 0.888000, Test accuracy: 0.908200
Distillation: Epoch : 19, Loss : 1.354324, Accuracy: 0.899000, Test accuracy: 0.908000
Distillation: Epoch : 20, Loss : 1.355063, Accuracy: 0.913000, Test accuracy: 0.909000
Distillation: Epoch : 21, Loss : 1.345636, Accuracy: 0.906000, Test accuracy: 0.909600
Distillation: Epoch : 22, Loss : 1.315883, Accuracy: 0.918000, Test accuracy: 0.912400
Distillation: Epoch : 23, Loss : 1.342821, Accuracy: 0.905000, Test accuracy: 0.913100
Distillation: Epoch : 24, Loss : 1.340365, Accuracy: 0.909000, Test accuracy: 0.914700
Distillation: Epoch : 25, Loss : 1.349102, Accuracy: 0.913000, Test accuracy: 0.915300
Distillation: Epoch : 26, Loss : 1.321084, Accuracy: 0.914000, Test accuracy: 0.916600
Distillation: Epoch : 27, Loss : 1.326223, Accuracy: 0.909000, Test accuracy: 0.917300
Distillation: Epoch : 28, Loss : 1.348629, Accuracy: 0.886000, Test accuracy: 0.919000
Distillation: Epoch : 29, Loss : 1.355566, Accuracy: 0.910000, Test accuracy: 0.921900
Distillation: Epoch : 30, Loss : 1.335766, Accuracy: 0.912000, Test accuracy: 0.922600
Distillation: Epoch : 31, Loss : 1.295655, Accuracy: 0.919000, Test accuracy: 0.923400
Distillation: Epoch : 32, Loss : 1.284588, Accuracy: 0.922000, Test accuracy: 0.926000
Distillation: Epoch : 33, Loss : 1.326789, Accuracy: 0.922000, Test accuracy: 0.927500
Distillation: Epoch : 34, Loss : 1.279484, Accuracy: 0.935000, Test accuracy: 0.929300
Distillation: Epoch : 35, Loss : 1.310197, Accuracy: 0.922000, Test accuracy: 0.929200
Distillation: Epoch : 36, Loss : 1.302730, Accuracy: 0.927000, Test accuracy: 0.931600
Distillation: Epoch : 37, Loss : 1.299249, Accuracy: 0.925000, Test accuracy: 0.933300
Distillation: Epoch : 38, Loss : 1.313828, Accuracy: 0.934000, Test accuracy: 0.934100
Distillation: Epoch : 39, Loss : 1.340205, Accuracy: 0.927000, Test accuracy: 0.935500
Distillation: Epoch : 40, Loss : 1.295052, Accuracy: 0.929000, Test accuracy: 0.936500
Distillation: Epoch : 41, Loss : 1.286289, Accuracy: 0.938000, Test accuracy: 0.938100
Distillation: Epoch : 42, Loss : 1.296703, Accuracy: 0.926000, Test accuracy: 0.940700
Distillation: Epoch : 43, Loss : 1.307446, Accuracy: 0.926000, Test accuracy: 0.941700
Distillation: Epoch : 44, Loss : 1.284470, Accuracy: 0.951000, Test accuracy: 0.943000
Distillation: Epoch : 45, Loss : 1.302465, Accuracy: 0.943000, Test accuracy: 0.943500
Distillation: Epoch : 46, Loss : 1.275542, Accuracy: 0.941000, Test accuracy: 0.945100
Distillation: Epoch : 47, Loss : 1.281788, Accuracy: 0.941000, Test accuracy: 0.945200
Distillation: Epoch : 48, Loss : 1.274499, Accuracy: 0.942000, Test accuracy: 0.946200
Distillation: Epoch : 49, Loss : 1.264432, Accuracy: 0.953000, Test accuracy: 0.947400
Distillation: Epoch : 50, Loss : 1.267004, Accuracy: 0.953000, Test accuracy: 0.949300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9493
Generating confusion matrix for student2
[[ 961.    0.   10.    0.    1.    6.    7.    1.    2.    4.]
 [   0. 1117.    4.    0.    0.    0.    2.    7.    2.    4.]
 [   3.    3.  954.   12.    1.    1.    0.   16.    1.    2.]
 [   0.    3.   13.  947.    0.    8.    0.    6.    8.    5.]
 [   2.    1.   16.    1.  956.    2.    8.   20.    8.   23.]
 [   3.    2.    0.   11.    0.  821.   15.    1.    7.    5.]
 [   7.    4.    6.    4.    5.   11.  918.    0.    0.    1.]
 [   1.    0.    4.    7.    0.    3.    0.  937.    3.    7.]
 [   3.    5.   22.   24.    4.   33.    8.    1.  936.   12.]
 [   0.    0.    3.    4.   15.    7.    0.   39.    7.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.992530, Accuracy: 0.678000, Test accuracy: 0.692900
Distillation: Epoch : 2, Loss : 1.646492, Accuracy: 0.810000, Test accuracy: 0.834500
Distillation: Epoch : 3, Loss : 1.551200, Accuracy: 0.859000, Test accuracy: 0.863400
Distillation: Epoch : 4, Loss : 1.518403, Accuracy: 0.867000, Test accuracy: 0.877000
Distillation: Epoch : 5, Loss : 1.510167, Accuracy: 0.882000, Test accuracy: 0.882700
Distillation: Epoch : 6, Loss : 1.498836, Accuracy: 0.891000, Test accuracy: 0.890000
Distillation: Epoch : 7, Loss : 1.490585, Accuracy: 0.893000, Test accuracy: 0.893900
Distillation: Epoch : 8, Loss : 1.470292, Accuracy: 0.904000, Test accuracy: 0.897500
Distillation: Epoch : 9, Loss : 1.492592, Accuracy: 0.896000, Test accuracy: 0.901700
Distillation: Epoch : 10, Loss : 1.478613, Accuracy: 0.890000, Test accuracy: 0.904200
Distillation: Epoch : 11, Loss : 1.480886, Accuracy: 0.887000, Test accuracy: 0.906900
Distillation: Epoch : 12, Loss : 1.474707, Accuracy: 0.913000, Test accuracy: 0.907900
Distillation: Epoch : 13, Loss : 1.488132, Accuracy: 0.876000, Test accuracy: 0.910700
Distillation: Epoch : 14, Loss : 1.473835, Accuracy: 0.904000, Test accuracy: 0.912000
Distillation: Epoch : 15, Loss : 1.460690, Accuracy: 0.910000, Test accuracy: 0.915000
Distillation: Epoch : 16, Loss : 1.459885, Accuracy: 0.910000, Test accuracy: 0.915900
Distillation: Epoch : 17, Loss : 1.475150, Accuracy: 0.910000, Test accuracy: 0.918600
Distillation: Epoch : 18, Loss : 1.449787, Accuracy: 0.912000, Test accuracy: 0.920900
Distillation: Epoch : 19, Loss : 1.438217, Accuracy: 0.911000, Test accuracy: 0.922200
Distillation: Epoch : 20, Loss : 1.436645, Accuracy: 0.933000, Test accuracy: 0.924000
Distillation: Epoch : 21, Loss : 1.428521, Accuracy: 0.919000, Test accuracy: 0.924800
Distillation: Epoch : 22, Loss : 1.436114, Accuracy: 0.926000, Test accuracy: 0.928100
Distillation: Epoch : 23, Loss : 1.453168, Accuracy: 0.917000, Test accuracy: 0.928900
Distillation: Epoch : 24, Loss : 1.437610, Accuracy: 0.929000, Test accuracy: 0.930500
Distillation: Epoch : 25, Loss : 1.419674, Accuracy: 0.927000, Test accuracy: 0.932800
Distillation: Epoch : 26, Loss : 1.420978, Accuracy: 0.940000, Test accuracy: 0.934700
Distillation: Epoch : 27, Loss : 1.442361, Accuracy: 0.920000, Test accuracy: 0.935400
Distillation: Epoch : 28, Loss : 1.423708, Accuracy: 0.923000, Test accuracy: 0.936800
Distillation: Epoch : 29, Loss : 1.402654, Accuracy: 0.938000, Test accuracy: 0.937400
Distillation: Epoch : 30, Loss : 1.391363, Accuracy: 0.944000, Test accuracy: 0.940700
Distillation: Epoch : 31, Loss : 1.393437, Accuracy: 0.938000, Test accuracy: 0.941500
Distillation: Epoch : 32, Loss : 1.439316, Accuracy: 0.924000, Test accuracy: 0.942900
Distillation: Epoch : 33, Loss : 1.410038, Accuracy: 0.927000, Test accuracy: 0.944000
Distillation: Epoch : 34, Loss : 1.387681, Accuracy: 0.939000, Test accuracy: 0.945500
Distillation: Epoch : 35, Loss : 1.382329, Accuracy: 0.950000, Test accuracy: 0.946000
Distillation: Epoch : 36, Loss : 1.415452, Accuracy: 0.937000, Test accuracy: 0.947800
Distillation: Epoch : 37, Loss : 1.395196, Accuracy: 0.942000, Test accuracy: 0.949100
Distillation: Epoch : 38, Loss : 1.418462, Accuracy: 0.951000, Test accuracy: 0.950300
Distillation: Epoch : 39, Loss : 1.422745, Accuracy: 0.949000, Test accuracy: 0.952500
Distillation: Epoch : 40, Loss : 1.403818, Accuracy: 0.935000, Test accuracy: 0.953300
Distillation: Epoch : 41, Loss : 1.406137, Accuracy: 0.950000, Test accuracy: 0.953900
Distillation: Epoch : 42, Loss : 1.429442, Accuracy: 0.937000, Test accuracy: 0.954300
Distillation: Epoch : 43, Loss : 1.389453, Accuracy: 0.953000, Test accuracy: 0.955200
Distillation: Epoch : 44, Loss : 1.392933, Accuracy: 0.951000, Test accuracy: 0.956200
Distillation: Epoch : 45, Loss : 1.393832, Accuracy: 0.964000, Test accuracy: 0.955600
Distillation: Epoch : 46, Loss : 1.396593, Accuracy: 0.946000, Test accuracy: 0.957700
Distillation: Epoch : 47, Loss : 1.378171, Accuracy: 0.948000, Test accuracy: 0.958300
Distillation: Epoch : 48, Loss : 1.372348, Accuracy: 0.963000, Test accuracy: 0.958800
Distillation: Epoch : 49, Loss : 1.355953, Accuracy: 0.954000, Test accuracy: 0.959200
Distillation: Epoch : 50, Loss : 1.367407, Accuracy: 0.955000, Test accuracy: 0.959400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9594
Generating confusion matrix for student2
[[ 969.    0.    8.    3.    0.    5.    6.    1.    5.    3.]
 [   0. 1105.    0.    0.    0.    1.    3.    5.    2.    5.]
 [   2.    3.  982.    4.    4.    1.    0.   15.    5.    2.]
 [   0.    2.    3.  979.    0.   10.    0.    0.    7.    7.]
 [   4.    3.   11.    0.  953.    0.    7.   13.    4.   14.]
 [   1.    0.    0.    7.    0.  848.    9.    1.    2.   12.]
 [   0.    5.    3.    0.    5.    7.  925.    0.    2.    0.]
 [   1.    0.    5.    6.    0.    3.    0.  948.    3.    5.]
 [   3.   17.   19.   10.    6.   15.    8.    7.  933.    9.]
 [   0.    0.    1.    1.   14.    2.    0.   38.   11.  952.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.060202, Accuracy: 0.697000, Test accuracy: 0.723200
Distillation: Epoch : 2, Loss : 1.837260, Accuracy: 0.843000, Test accuracy: 0.847000
Distillation: Epoch : 3, Loss : 1.797804, Accuracy: 0.858000, Test accuracy: 0.876900
Distillation: Epoch : 4, Loss : 1.778902, Accuracy: 0.888000, Test accuracy: 0.890500
Distillation: Epoch : 5, Loss : 1.757565, Accuracy: 0.906000, Test accuracy: 0.898200
Distillation: Epoch : 6, Loss : 1.753589, Accuracy: 0.888000, Test accuracy: 0.904500
Distillation: Epoch : 7, Loss : 1.745144, Accuracy: 0.910000, Test accuracy: 0.911500
Distillation: Epoch : 8, Loss : 1.733936, Accuracy: 0.907000, Test accuracy: 0.916900
Distillation: Epoch : 9, Loss : 1.746221, Accuracy: 0.913000, Test accuracy: 0.920600
Distillation: Epoch : 10, Loss : 1.719319, Accuracy: 0.922000, Test accuracy: 0.923800
Distillation: Epoch : 11, Loss : 1.730497, Accuracy: 0.909000, Test accuracy: 0.924200
Distillation: Epoch : 12, Loss : 1.728672, Accuracy: 0.933000, Test accuracy: 0.928300
Distillation: Epoch : 13, Loss : 1.708749, Accuracy: 0.943000, Test accuracy: 0.931700
Distillation: Epoch : 14, Loss : 1.703054, Accuracy: 0.948000, Test accuracy: 0.935900
Distillation: Epoch : 15, Loss : 1.716122, Accuracy: 0.927000, Test accuracy: 0.937000
Distillation: Epoch : 16, Loss : 1.713155, Accuracy: 0.934000, Test accuracy: 0.938400
Distillation: Epoch : 17, Loss : 1.713987, Accuracy: 0.940000, Test accuracy: 0.940800
Distillation: Epoch : 18, Loss : 1.720734, Accuracy: 0.937000, Test accuracy: 0.940200
Distillation: Epoch : 19, Loss : 1.706390, Accuracy: 0.952000, Test accuracy: 0.942800
Distillation: Epoch : 20, Loss : 1.715281, Accuracy: 0.934000, Test accuracy: 0.942400
Distillation: Epoch : 21, Loss : 1.701053, Accuracy: 0.940000, Test accuracy: 0.943400
Distillation: Epoch : 22, Loss : 1.708942, Accuracy: 0.924000, Test accuracy: 0.945100
Distillation: Epoch : 23, Loss : 1.703442, Accuracy: 0.937000, Test accuracy: 0.946400
Distillation: Epoch : 24, Loss : 1.684355, Accuracy: 0.945000, Test accuracy: 0.947700
Distillation: Epoch : 25, Loss : 1.696072, Accuracy: 0.949000, Test accuracy: 0.948200
Distillation: Epoch : 26, Loss : 1.695553, Accuracy: 0.949000, Test accuracy: 0.948200
Distillation: Epoch : 27, Loss : 1.699587, Accuracy: 0.944000, Test accuracy: 0.947700
Distillation: Epoch : 28, Loss : 1.711008, Accuracy: 0.924000, Test accuracy: 0.947700
Distillation: Epoch : 29, Loss : 1.690459, Accuracy: 0.944000, Test accuracy: 0.947800
Distillation: Epoch : 30, Loss : 1.698196, Accuracy: 0.946000, Test accuracy: 0.949000
Distillation: Epoch : 31, Loss : 1.702694, Accuracy: 0.946000, Test accuracy: 0.949800
Distillation: Epoch : 32, Loss : 1.687894, Accuracy: 0.940000, Test accuracy: 0.949100
Distillation: Epoch : 33, Loss : 1.682030, Accuracy: 0.944000, Test accuracy: 0.949600
Distillation: Epoch : 34, Loss : 1.676129, Accuracy: 0.952000, Test accuracy: 0.951200
Distillation: Epoch : 35, Loss : 1.697640, Accuracy: 0.954000, Test accuracy: 0.951400
Distillation: Epoch : 36, Loss : 1.679357, Accuracy: 0.951000, Test accuracy: 0.951500
Distillation: Epoch : 37, Loss : 1.677087, Accuracy: 0.951000, Test accuracy: 0.951200
Distillation: Epoch : 38, Loss : 1.695313, Accuracy: 0.949000, Test accuracy: 0.950900
Distillation: Epoch : 39, Loss : 1.695176, Accuracy: 0.950000, Test accuracy: 0.951400
Distillation: Epoch : 40, Loss : 1.686484, Accuracy: 0.946000, Test accuracy: 0.952200
Distillation: Epoch : 41, Loss : 1.697227, Accuracy: 0.950000, Test accuracy: 0.951900
Distillation: Epoch : 42, Loss : 1.695707, Accuracy: 0.955000, Test accuracy: 0.952900
Distillation: Epoch : 43, Loss : 1.691631, Accuracy: 0.951000, Test accuracy: 0.953000
Distillation: Epoch : 44, Loss : 1.670276, Accuracy: 0.957000, Test accuracy: 0.953100
Distillation: Epoch : 45, Loss : 1.704044, Accuracy: 0.945000, Test accuracy: 0.953500
Distillation: Epoch : 46, Loss : 1.674878, Accuracy: 0.947000, Test accuracy: 0.953400
Distillation: Epoch : 47, Loss : 1.694209, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 48, Loss : 1.687079, Accuracy: 0.955000, Test accuracy: 0.953800
Distillation: Epoch : 49, Loss : 1.668391, Accuracy: 0.965000, Test accuracy: 0.954300
Distillation: Epoch : 50, Loss : 1.684266, Accuracy: 0.956000, Test accuracy: 0.954900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9549
Generating confusion matrix for student2
[[ 963.    0.    4.    1.    1.    2.    8.    1.    9.    6.]
 [   0. 1112.    4.    1.    1.    1.    3.    6.    0.    4.]
 [   0.    4.  967.    3.    0.    1.    0.   20.    6.    1.]
 [   0.    1.    9.  970.    0.   11.    0.    4.    6.    7.]
 [   1.    1.    8.    3.  961.    1.    9.   12.    6.   26.]
 [   0.    0.    1.    8.    0.  845.   11.    1.    3.    2.]
 [   8.    2.    2.    0.    5.    6.  919.    0.    4.    1.]
 [   1.    0.    6.    6.    0.    1.    0.  933.    3.    8.]
 [   5.   15.   29.   15.    5.   21.    8.    5.  928.    3.]
 [   2.    0.    2.    3.    9.    3.    0.   46.    9.  951.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.178741, Accuracy: 0.643000, Test accuracy: 0.653200
Distillation: Epoch : 2, Loss : 2.060727, Accuracy: 0.823000, Test accuracy: 0.832400
Distillation: Epoch : 3, Loss : 2.033405, Accuracy: 0.861000, Test accuracy: 0.855300
Distillation: Epoch : 4, Loss : 2.024808, Accuracy: 0.843000, Test accuracy: 0.868100
Distillation: Epoch : 5, Loss : 2.020803, Accuracy: 0.868000, Test accuracy: 0.874200
Distillation: Epoch : 6, Loss : 2.017098, Accuracy: 0.863000, Test accuracy: 0.881700
Distillation: Epoch : 7, Loss : 2.010656, Accuracy: 0.884000, Test accuracy: 0.884800
Distillation: Epoch : 8, Loss : 2.012975, Accuracy: 0.885000, Test accuracy: 0.888500
Distillation: Epoch : 9, Loss : 2.015470, Accuracy: 0.858000, Test accuracy: 0.891400
Distillation: Epoch : 10, Loss : 2.004332, Accuracy: 0.886000, Test accuracy: 0.892400
Distillation: Epoch : 11, Loss : 2.011080, Accuracy: 0.880000, Test accuracy: 0.897500
Distillation: Epoch : 12, Loss : 2.006584, Accuracy: 0.893000, Test accuracy: 0.900600
Distillation: Epoch : 13, Loss : 2.010409, Accuracy: 0.881000, Test accuracy: 0.905000
Distillation: Epoch : 14, Loss : 1.998176, Accuracy: 0.904000, Test accuracy: 0.908700
Distillation: Epoch : 15, Loss : 1.997180, Accuracy: 0.901000, Test accuracy: 0.912800
Distillation: Epoch : 16, Loss : 1.993484, Accuracy: 0.902000, Test accuracy: 0.914900
Distillation: Epoch : 17, Loss : 1.991776, Accuracy: 0.921000, Test accuracy: 0.918800
Distillation: Epoch : 18, Loss : 1.988229, Accuracy: 0.914000, Test accuracy: 0.922800
Distillation: Epoch : 19, Loss : 1.983763, Accuracy: 0.908000, Test accuracy: 0.927000
Distillation: Epoch : 20, Loss : 1.989159, Accuracy: 0.924000, Test accuracy: 0.931200
Distillation: Epoch : 21, Loss : 1.975159, Accuracy: 0.931000, Test accuracy: 0.933300
Distillation: Epoch : 22, Loss : 1.975184, Accuracy: 0.926000, Test accuracy: 0.936300
Distillation: Epoch : 23, Loss : 1.977630, Accuracy: 0.928000, Test accuracy: 0.938300
Distillation: Epoch : 24, Loss : 1.973804, Accuracy: 0.940000, Test accuracy: 0.940000
Distillation: Epoch : 25, Loss : 1.976669, Accuracy: 0.932000, Test accuracy: 0.943100
Distillation: Epoch : 26, Loss : 1.984971, Accuracy: 0.943000, Test accuracy: 0.945000
Distillation: Epoch : 27, Loss : 1.975939, Accuracy: 0.933000, Test accuracy: 0.946500
Distillation: Epoch : 28, Loss : 1.965663, Accuracy: 0.941000, Test accuracy: 0.948300
Distillation: Epoch : 29, Loss : 1.961609, Accuracy: 0.952000, Test accuracy: 0.950200
Distillation: Epoch : 30, Loss : 1.964333, Accuracy: 0.959000, Test accuracy: 0.951500
Distillation: Epoch : 31, Loss : 1.960109, Accuracy: 0.953000, Test accuracy: 0.952400
Distillation: Epoch : 32, Loss : 1.971552, Accuracy: 0.942000, Test accuracy: 0.953800
Distillation: Epoch : 33, Loss : 1.977311, Accuracy: 0.954000, Test accuracy: 0.953800
Distillation: Epoch : 34, Loss : 1.957416, Accuracy: 0.949000, Test accuracy: 0.954000
Distillation: Epoch : 35, Loss : 1.962754, Accuracy: 0.944000, Test accuracy: 0.954500
Distillation: Epoch : 36, Loss : 1.958525, Accuracy: 0.947000, Test accuracy: 0.956800
Distillation: Epoch : 37, Loss : 1.972259, Accuracy: 0.950000, Test accuracy: 0.957800
Distillation: Epoch : 38, Loss : 1.965947, Accuracy: 0.953000, Test accuracy: 0.957600
Distillation: Epoch : 39, Loss : 1.968653, Accuracy: 0.953000, Test accuracy: 0.958800
Distillation: Epoch : 40, Loss : 1.963653, Accuracy: 0.959000, Test accuracy: 0.959500
Distillation: Epoch : 41, Loss : 1.970430, Accuracy: 0.960000, Test accuracy: 0.959900
Distillation: Epoch : 42, Loss : 1.955912, Accuracy: 0.955000, Test accuracy: 0.960800
Distillation: Epoch : 43, Loss : 1.963043, Accuracy: 0.957000, Test accuracy: 0.960700
Distillation: Epoch : 44, Loss : 1.961790, Accuracy: 0.958000, Test accuracy: 0.962600
Distillation: Epoch : 45, Loss : 1.965794, Accuracy: 0.955000, Test accuracy: 0.961900
Distillation: Epoch : 46, Loss : 1.956537, Accuracy: 0.953000, Test accuracy: 0.962400
Distillation: Epoch : 47, Loss : 1.952806, Accuracy: 0.963000, Test accuracy: 0.962800
Distillation: Epoch : 48, Loss : 1.948755, Accuracy: 0.965000, Test accuracy: 0.962700
Distillation: Epoch : 49, Loss : 1.958593, Accuracy: 0.956000, Test accuracy: 0.964600
Distillation: Epoch : 50, Loss : 1.969351, Accuracy: 0.956000, Test accuracy: 0.965000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.965
Generating confusion matrix for student2
[[ 967.    0.    4.    1.    0.    0.    6.    1.    9.    5.]
 [   1. 1114.    3.    0.    1.    0.    2.    6.    0.    4.]
 [   0.    3.  986.    1.    2.    2.    0.   19.    5.    1.]
 [   0.    1.    7.  988.    0.    7.    0.    3.    6.    3.]
 [   2.    0.    8.    1.  964.    2.    8.    7.    6.   20.]
 [   1.    0.    0.    4.    0.  853.    6.    2.    2.    4.]
 [   5.    4.    0.    0.    3.    4.  931.    0.    1.    0.]
 [   1.    0.    5.    6.    0.    2.    0.  956.    2.    8.]
 [   3.   13.   17.    6.    3.   20.    5.    8.  938.   11.]
 [   0.    0.    2.    3.    9.    2.    0.   26.    5.  953.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.207006, Accuracy: 0.707000, Test accuracy: 0.722700
Distillation: Epoch : 2, Loss : 0.533600, Accuracy: 0.852000, Test accuracy: 0.861800
Distillation: Epoch : 3, Loss : 0.411207, Accuracy: 0.876000, Test accuracy: 0.888900
Distillation: Epoch : 4, Loss : 0.326117, Accuracy: 0.902000, Test accuracy: 0.900400
Distillation: Epoch : 5, Loss : 0.349390, Accuracy: 0.896000, Test accuracy: 0.909400
Distillation: Epoch : 6, Loss : 0.317771, Accuracy: 0.909000, Test accuracy: 0.915600
Distillation: Epoch : 7, Loss : 0.269079, Accuracy: 0.919000, Test accuracy: 0.921200
Distillation: Epoch : 8, Loss : 0.298644, Accuracy: 0.913000, Test accuracy: 0.925500
Distillation: Epoch : 9, Loss : 0.236476, Accuracy: 0.927000, Test accuracy: 0.928200
Distillation: Epoch : 10, Loss : 0.241079, Accuracy: 0.938000, Test accuracy: 0.930700
Distillation: Epoch : 11, Loss : 0.264844, Accuracy: 0.934000, Test accuracy: 0.931300
Distillation: Epoch : 12, Loss : 0.232109, Accuracy: 0.931000, Test accuracy: 0.935600
Distillation: Epoch : 13, Loss : 0.208658, Accuracy: 0.937000, Test accuracy: 0.937800
Distillation: Epoch : 14, Loss : 0.217332, Accuracy: 0.937000, Test accuracy: 0.939600
Distillation: Epoch : 15, Loss : 0.225524, Accuracy: 0.945000, Test accuracy: 0.942000
Distillation: Epoch : 16, Loss : 0.223270, Accuracy: 0.942000, Test accuracy: 0.943000
Distillation: Epoch : 17, Loss : 0.199136, Accuracy: 0.947000, Test accuracy: 0.945600
Distillation: Epoch : 18, Loss : 0.208020, Accuracy: 0.936000, Test accuracy: 0.945200
Distillation: Epoch : 19, Loss : 0.199679, Accuracy: 0.940000, Test accuracy: 0.947200
Distillation: Epoch : 20, Loss : 0.225319, Accuracy: 0.946000, Test accuracy: 0.949500
Distillation: Epoch : 21, Loss : 0.193936, Accuracy: 0.950000, Test accuracy: 0.950100
Distillation: Epoch : 22, Loss : 0.174237, Accuracy: 0.952000, Test accuracy: 0.950800
Distillation: Epoch : 23, Loss : 0.189766, Accuracy: 0.941000, Test accuracy: 0.950500
Distillation: Epoch : 24, Loss : 0.190332, Accuracy: 0.941000, Test accuracy: 0.952500
Distillation: Epoch : 25, Loss : 0.169974, Accuracy: 0.955000, Test accuracy: 0.953200
Distillation: Epoch : 26, Loss : 0.185917, Accuracy: 0.946000, Test accuracy: 0.954100
Distillation: Epoch : 27, Loss : 0.157136, Accuracy: 0.955000, Test accuracy: 0.954200
Distillation: Epoch : 28, Loss : 0.154392, Accuracy: 0.950000, Test accuracy: 0.954100
Distillation: Epoch : 29, Loss : 0.179020, Accuracy: 0.954000, Test accuracy: 0.953600
Distillation: Epoch : 30, Loss : 0.189731, Accuracy: 0.941000, Test accuracy: 0.954600
Distillation: Epoch : 31, Loss : 0.155110, Accuracy: 0.951000, Test accuracy: 0.955400
Distillation: Epoch : 32, Loss : 0.171558, Accuracy: 0.949000, Test accuracy: 0.956200
Distillation: Epoch : 33, Loss : 0.170654, Accuracy: 0.948000, Test accuracy: 0.957400
Distillation: Epoch : 34, Loss : 0.180970, Accuracy: 0.944000, Test accuracy: 0.956200
Distillation: Epoch : 35, Loss : 0.177078, Accuracy: 0.939000, Test accuracy: 0.956100
Distillation: Epoch : 36, Loss : 0.131195, Accuracy: 0.961000, Test accuracy: 0.957200
Distillation: Epoch : 37, Loss : 0.150769, Accuracy: 0.953000, Test accuracy: 0.957500
Distillation: Epoch : 38, Loss : 0.137871, Accuracy: 0.959000, Test accuracy: 0.957600
Distillation: Epoch : 39, Loss : 0.148747, Accuracy: 0.960000, Test accuracy: 0.957600
Distillation: Epoch : 40, Loss : 0.154851, Accuracy: 0.952000, Test accuracy: 0.958500
Distillation: Epoch : 41, Loss : 0.147084, Accuracy: 0.962000, Test accuracy: 0.958200
Distillation: Epoch : 42, Loss : 0.142658, Accuracy: 0.961000, Test accuracy: 0.958900
Distillation: Epoch : 43, Loss : 0.142671, Accuracy: 0.954000, Test accuracy: 0.958600
Distillation: Epoch : 44, Loss : 0.126606, Accuracy: 0.964000, Test accuracy: 0.959400
Distillation: Epoch : 45, Loss : 0.131810, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 46, Loss : 0.158242, Accuracy: 0.956000, Test accuracy: 0.959300
Distillation: Epoch : 47, Loss : 0.113475, Accuracy: 0.960000, Test accuracy: 0.959600
Distillation: Epoch : 48, Loss : 0.147667, Accuracy: 0.948000, Test accuracy: 0.959800
Distillation: Epoch : 49, Loss : 0.130115, Accuracy: 0.962000, Test accuracy: 0.959600
Distillation: Epoch : 50, Loss : 0.101563, Accuracy: 0.975000, Test accuracy: 0.960100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9601
Generating confusion matrix for student3
[[ 969.    0.    5.    3.    1.    3.    5.    2.    7.   10.]
 [   0. 1117.    5.    0.    0.    2.    3.    7.    6.    6.]
 [   1.    3.  970.    1.    3.    0.    2.   17.    7.    1.]
 [   0.    1.   15.  971.    1.   20.    1.    5.   12.    6.]
 [   0.    0.    6.    1.  957.    1.    2.    1.    3.    9.]
 [   1.    1.    0.   11.    0.  838.    7.    0.    7.    4.]
 [   3.    3.    7.    0.    1.    5.  933.    0.    5.    0.]
 [   3.    1.    5.    5.    2.    2.    1.  977.    5.   14.]
 [   3.    9.   18.   13.    3.   17.    4.    3.  915.    5.]
 [   0.    0.    1.    5.   14.    4.    0.   16.    7.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.154019, Accuracy: 0.776000, Test accuracy: 0.771300
Distillation: Epoch : 2, Loss : 0.630384, Accuracy: 0.829000, Test accuracy: 0.841700
Distillation: Epoch : 3, Loss : 0.488697, Accuracy: 0.875000, Test accuracy: 0.873800
Distillation: Epoch : 4, Loss : 0.418849, Accuracy: 0.878000, Test accuracy: 0.886000
Distillation: Epoch : 5, Loss : 0.370277, Accuracy: 0.902000, Test accuracy: 0.894800
Distillation: Epoch : 6, Loss : 0.394636, Accuracy: 0.889000, Test accuracy: 0.897800
Distillation: Epoch : 7, Loss : 0.350332, Accuracy: 0.898000, Test accuracy: 0.902300
Distillation: Epoch : 8, Loss : 0.310528, Accuracy: 0.906000, Test accuracy: 0.905500
Distillation: Epoch : 9, Loss : 0.372720, Accuracy: 0.899000, Test accuracy: 0.907300
Distillation: Epoch : 10, Loss : 0.396966, Accuracy: 0.890000, Test accuracy: 0.908900
Distillation: Epoch : 11, Loss : 0.365733, Accuracy: 0.896000, Test accuracy: 0.910100
Distillation: Epoch : 12, Loss : 0.316260, Accuracy: 0.919000, Test accuracy: 0.910600
Distillation: Epoch : 13, Loss : 0.358143, Accuracy: 0.893000, Test accuracy: 0.911400
Distillation: Epoch : 14, Loss : 0.287958, Accuracy: 0.914000, Test accuracy: 0.912200
Distillation: Epoch : 15, Loss : 0.333384, Accuracy: 0.899000, Test accuracy: 0.914200
Distillation: Epoch : 16, Loss : 0.301198, Accuracy: 0.909000, Test accuracy: 0.915200
Distillation: Epoch : 17, Loss : 0.312326, Accuracy: 0.918000, Test accuracy: 0.915200
Distillation: Epoch : 18, Loss : 0.289921, Accuracy: 0.918000, Test accuracy: 0.915500
Distillation: Epoch : 19, Loss : 0.358482, Accuracy: 0.903000, Test accuracy: 0.916400
Distillation: Epoch : 20, Loss : 0.335001, Accuracy: 0.906000, Test accuracy: 0.916400
Distillation: Epoch : 21, Loss : 0.317879, Accuracy: 0.909000, Test accuracy: 0.917400
Distillation: Epoch : 22, Loss : 0.306720, Accuracy: 0.911000, Test accuracy: 0.917500
Distillation: Epoch : 23, Loss : 0.305332, Accuracy: 0.928000, Test accuracy: 0.919400
Distillation: Epoch : 24, Loss : 0.330988, Accuracy: 0.906000, Test accuracy: 0.919000
Distillation: Epoch : 25, Loss : 0.332699, Accuracy: 0.915000, Test accuracy: 0.919200
Distillation: Epoch : 26, Loss : 0.275594, Accuracy: 0.920000, Test accuracy: 0.920900
Distillation: Epoch : 27, Loss : 0.296027, Accuracy: 0.925000, Test accuracy: 0.920700
Distillation: Epoch : 28, Loss : 0.254771, Accuracy: 0.937000, Test accuracy: 0.922300
Distillation: Epoch : 29, Loss : 0.271470, Accuracy: 0.929000, Test accuracy: 0.921700
Distillation: Epoch : 30, Loss : 0.295605, Accuracy: 0.919000, Test accuracy: 0.923400
Distillation: Epoch : 31, Loss : 0.309157, Accuracy: 0.925000, Test accuracy: 0.923200
Distillation: Epoch : 32, Loss : 0.307230, Accuracy: 0.915000, Test accuracy: 0.924400
Distillation: Epoch : 33, Loss : 0.306493, Accuracy: 0.918000, Test accuracy: 0.923900
Distillation: Epoch : 34, Loss : 0.301826, Accuracy: 0.918000, Test accuracy: 0.924200
Distillation: Epoch : 35, Loss : 0.325677, Accuracy: 0.913000, Test accuracy: 0.924500
Distillation: Epoch : 36, Loss : 0.250958, Accuracy: 0.933000, Test accuracy: 0.925800
Distillation: Epoch : 37, Loss : 0.251701, Accuracy: 0.940000, Test accuracy: 0.925800
Distillation: Epoch : 38, Loss : 0.313539, Accuracy: 0.920000, Test accuracy: 0.926000
Distillation: Epoch : 39, Loss : 0.274585, Accuracy: 0.926000, Test accuracy: 0.926500
Distillation: Epoch : 40, Loss : 0.270187, Accuracy: 0.930000, Test accuracy: 0.927800
Distillation: Epoch : 41, Loss : 0.245418, Accuracy: 0.933000, Test accuracy: 0.926600
Distillation: Epoch : 42, Loss : 0.264376, Accuracy: 0.928000, Test accuracy: 0.928400
Distillation: Epoch : 43, Loss : 0.244531, Accuracy: 0.932000, Test accuracy: 0.927500
Distillation: Epoch : 44, Loss : 0.266531, Accuracy: 0.929000, Test accuracy: 0.928900
Distillation: Epoch : 45, Loss : 0.241784, Accuracy: 0.922000, Test accuracy: 0.930100
Distillation: Epoch : 46, Loss : 0.251800, Accuracy: 0.929000, Test accuracy: 0.930100
Distillation: Epoch : 47, Loss : 0.267241, Accuracy: 0.922000, Test accuracy: 0.932000
Distillation: Epoch : 48, Loss : 0.271678, Accuracy: 0.936000, Test accuracy: 0.931800
Distillation: Epoch : 49, Loss : 0.286571, Accuracy: 0.932000, Test accuracy: 0.931900
Distillation: Epoch : 50, Loss : 0.257643, Accuracy: 0.937000, Test accuracy: 0.932300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9323
Generating confusion matrix for student3
[[ 961.    0.    9.    3.    1.    7.   10.    1.    9.   11.]
 [   0. 1110.    9.    0.    2.    2.    3.    6.    4.    6.]
 [   1.    2.  932.   20.    8.    3.    5.   22.    8.    1.]
 [   2.    2.   15.  932.    1.   26.    2.    6.   14.   12.]
 [   0.    0.    9.    1.  917.    5.    7.    7.    9.   28.]
 [   6.    3.    1.   17.    2.  792.    9.    0.   15.    6.]
 [   7.    4.   11.    3.    8.   16.  919.    0.    9.    0.]
 [   2.    1.    9.    9.    3.    4.    2.  954.    7.   16.]
 [   1.   13.   32.   17.    8.   33.    1.    2.  885.    8.]
 [   0.    0.    5.    8.   32.    4.    0.   30.   14.  921.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.647063, Accuracy: 0.737000, Test accuracy: 0.728200
Distillation: Epoch : 2, Loss : 0.968500, Accuracy: 0.834000, Test accuracy: 0.827200
Distillation: Epoch : 3, Loss : 0.820140, Accuracy: 0.837000, Test accuracy: 0.859300
Distillation: Epoch : 4, Loss : 0.723223, Accuracy: 0.862000, Test accuracy: 0.876700
Distillation: Epoch : 5, Loss : 0.672037, Accuracy: 0.896000, Test accuracy: 0.887700
Distillation: Epoch : 6, Loss : 0.651593, Accuracy: 0.895000, Test accuracy: 0.894000
Distillation: Epoch : 7, Loss : 0.637184, Accuracy: 0.901000, Test accuracy: 0.898000
Distillation: Epoch : 8, Loss : 0.638884, Accuracy: 0.900000, Test accuracy: 0.903000
Distillation: Epoch : 9, Loss : 0.623194, Accuracy: 0.914000, Test accuracy: 0.906000
Distillation: Epoch : 10, Loss : 0.628941, Accuracy: 0.895000, Test accuracy: 0.908500
Distillation: Epoch : 11, Loss : 0.618978, Accuracy: 0.893000, Test accuracy: 0.911100
Distillation: Epoch : 12, Loss : 0.616696, Accuracy: 0.906000, Test accuracy: 0.913600
Distillation: Epoch : 13, Loss : 0.588026, Accuracy: 0.913000, Test accuracy: 0.915300
Distillation: Epoch : 14, Loss : 0.556778, Accuracy: 0.921000, Test accuracy: 0.917200
Distillation: Epoch : 15, Loss : 0.600205, Accuracy: 0.908000, Test accuracy: 0.917500
Distillation: Epoch : 16, Loss : 0.588538, Accuracy: 0.913000, Test accuracy: 0.919400
Distillation: Epoch : 17, Loss : 0.571492, Accuracy: 0.925000, Test accuracy: 0.921600
Distillation: Epoch : 18, Loss : 0.577193, Accuracy: 0.915000, Test accuracy: 0.923200
Distillation: Epoch : 19, Loss : 0.566362, Accuracy: 0.934000, Test accuracy: 0.924700
Distillation: Epoch : 20, Loss : 0.538958, Accuracy: 0.941000, Test accuracy: 0.926000
Distillation: Epoch : 21, Loss : 0.547236, Accuracy: 0.919000, Test accuracy: 0.927100
Distillation: Epoch : 22, Loss : 0.567159, Accuracy: 0.917000, Test accuracy: 0.928800
Distillation: Epoch : 23, Loss : 0.549509, Accuracy: 0.931000, Test accuracy: 0.930800
Distillation: Epoch : 24, Loss : 0.554913, Accuracy: 0.922000, Test accuracy: 0.933700
Distillation: Epoch : 25, Loss : 0.529035, Accuracy: 0.938000, Test accuracy: 0.935700
Distillation: Epoch : 26, Loss : 0.531328, Accuracy: 0.927000, Test accuracy: 0.936600
Distillation: Epoch : 27, Loss : 0.517890, Accuracy: 0.939000, Test accuracy: 0.938100
Distillation: Epoch : 28, Loss : 0.510310, Accuracy: 0.935000, Test accuracy: 0.940100
Distillation: Epoch : 29, Loss : 0.482008, Accuracy: 0.956000, Test accuracy: 0.940600
Distillation: Epoch : 30, Loss : 0.520566, Accuracy: 0.938000, Test accuracy: 0.942000
Distillation: Epoch : 31, Loss : 0.479284, Accuracy: 0.944000, Test accuracy: 0.943800
Distillation: Epoch : 32, Loss : 0.498556, Accuracy: 0.954000, Test accuracy: 0.944600
Distillation: Epoch : 33, Loss : 0.500444, Accuracy: 0.943000, Test accuracy: 0.946300
Distillation: Epoch : 34, Loss : 0.472745, Accuracy: 0.955000, Test accuracy: 0.947200
Distillation: Epoch : 35, Loss : 0.494386, Accuracy: 0.945000, Test accuracy: 0.948100
Distillation: Epoch : 36, Loss : 0.479788, Accuracy: 0.946000, Test accuracy: 0.948400
Distillation: Epoch : 37, Loss : 0.497823, Accuracy: 0.936000, Test accuracy: 0.949100
Distillation: Epoch : 38, Loss : 0.492765, Accuracy: 0.933000, Test accuracy: 0.949700
Distillation: Epoch : 39, Loss : 0.510248, Accuracy: 0.940000, Test accuracy: 0.949900
Distillation: Epoch : 40, Loss : 0.486749, Accuracy: 0.947000, Test accuracy: 0.951200
Distillation: Epoch : 41, Loss : 0.450615, Accuracy: 0.956000, Test accuracy: 0.951500
Distillation: Epoch : 42, Loss : 0.496682, Accuracy: 0.942000, Test accuracy: 0.952800
Distillation: Epoch : 43, Loss : 0.459885, Accuracy: 0.960000, Test accuracy: 0.954200
Distillation: Epoch : 44, Loss : 0.492633, Accuracy: 0.955000, Test accuracy: 0.954200
Distillation: Epoch : 45, Loss : 0.456416, Accuracy: 0.957000, Test accuracy: 0.955300
Distillation: Epoch : 46, Loss : 0.490896, Accuracy: 0.947000, Test accuracy: 0.956500
Distillation: Epoch : 47, Loss : 0.491492, Accuracy: 0.943000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 0.444743, Accuracy: 0.945000, Test accuracy: 0.956100
Distillation: Epoch : 49, Loss : 0.459210, Accuracy: 0.954000, Test accuracy: 0.957800
Distillation: Epoch : 50, Loss : 0.458476, Accuracy: 0.957000, Test accuracy: 0.958100
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9581
Generating confusion matrix for student3
[[ 965.    0.    7.    0.    1.    2.    6.    4.    6.    5.]
 [   0. 1117.    4.    0.    2.    1.    2.    6.    3.    6.]
 [   1.    4.  967.    9.    1.    1.    1.   22.    6.    1.]
 [   0.    1.    7.  969.    0.    8.    1.    5.    9.    6.]
 [   1.    1.    8.    1.  955.    0.    6.    4.    7.   18.]
 [   2.    0.    0.    7.    0.  853.    5.    0.    6.    8.]
 [   6.    4.    4.    0.    4.    5.  935.    0.    4.    1.]
 [   1.    0.    5.    5.    2.    2.    0.  954.    5.   11.]
 [   3.    7.   26.   15.    4.   13.    2.    3.  921.    8.]
 [   1.    1.    4.    4.   13.    7.    0.   30.    7.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.726542, Accuracy: 0.708000, Test accuracy: 0.703600
Distillation: Epoch : 2, Loss : 1.116641, Accuracy: 0.817000, Test accuracy: 0.828200
Distillation: Epoch : 3, Loss : 0.920418, Accuracy: 0.852000, Test accuracy: 0.859700
Distillation: Epoch : 4, Loss : 0.883288, Accuracy: 0.877000, Test accuracy: 0.877400
Distillation: Epoch : 5, Loss : 0.861179, Accuracy: 0.866000, Test accuracy: 0.887400
Distillation: Epoch : 6, Loss : 0.822221, Accuracy: 0.878000, Test accuracy: 0.894700
Distillation: Epoch : 7, Loss : 0.769760, Accuracy: 0.906000, Test accuracy: 0.898900
Distillation: Epoch : 8, Loss : 0.810596, Accuracy: 0.895000, Test accuracy: 0.898100
Distillation: Epoch : 9, Loss : 0.817083, Accuracy: 0.876000, Test accuracy: 0.902500
Distillation: Epoch : 10, Loss : 0.752928, Accuracy: 0.908000, Test accuracy: 0.904800
Distillation: Epoch : 11, Loss : 0.762195, Accuracy: 0.905000, Test accuracy: 0.908100
Distillation: Epoch : 12, Loss : 0.790787, Accuracy: 0.891000, Test accuracy: 0.907800
Distillation: Epoch : 13, Loss : 0.778292, Accuracy: 0.893000, Test accuracy: 0.908200
Distillation: Epoch : 14, Loss : 0.765016, Accuracy: 0.909000, Test accuracy: 0.910200
Distillation: Epoch : 15, Loss : 0.798658, Accuracy: 0.893000, Test accuracy: 0.909700
Distillation: Epoch : 16, Loss : 0.760198, Accuracy: 0.912000, Test accuracy: 0.911800
Distillation: Epoch : 17, Loss : 0.765528, Accuracy: 0.903000, Test accuracy: 0.912900
Distillation: Epoch : 18, Loss : 0.768510, Accuracy: 0.898000, Test accuracy: 0.913100
Distillation: Epoch : 19, Loss : 0.719031, Accuracy: 0.919000, Test accuracy: 0.914900
Distillation: Epoch : 20, Loss : 0.756634, Accuracy: 0.911000, Test accuracy: 0.916300
Distillation: Epoch : 21, Loss : 0.707171, Accuracy: 0.922000, Test accuracy: 0.917500
Distillation: Epoch : 22, Loss : 0.738402, Accuracy: 0.912000, Test accuracy: 0.918300
Distillation: Epoch : 23, Loss : 0.739661, Accuracy: 0.915000, Test accuracy: 0.918800
Distillation: Epoch : 24, Loss : 0.724026, Accuracy: 0.925000, Test accuracy: 0.920700
Distillation: Epoch : 25, Loss : 0.741697, Accuracy: 0.904000, Test accuracy: 0.920200
Distillation: Epoch : 26, Loss : 0.748097, Accuracy: 0.912000, Test accuracy: 0.919900
Distillation: Epoch : 27, Loss : 0.698885, Accuracy: 0.939000, Test accuracy: 0.922300
Distillation: Epoch : 28, Loss : 0.700649, Accuracy: 0.919000, Test accuracy: 0.921900
Distillation: Epoch : 29, Loss : 0.735605, Accuracy: 0.908000, Test accuracy: 0.923100
Distillation: Epoch : 30, Loss : 0.728131, Accuracy: 0.927000, Test accuracy: 0.923700
Distillation: Epoch : 31, Loss : 0.716650, Accuracy: 0.917000, Test accuracy: 0.925400
Distillation: Epoch : 32, Loss : 0.756005, Accuracy: 0.923000, Test accuracy: 0.925200
Distillation: Epoch : 33, Loss : 0.710836, Accuracy: 0.919000, Test accuracy: 0.925700
Distillation: Epoch : 34, Loss : 0.702849, Accuracy: 0.922000, Test accuracy: 0.925600
Distillation: Epoch : 35, Loss : 0.709771, Accuracy: 0.924000, Test accuracy: 0.927000
Distillation: Epoch : 36, Loss : 0.712605, Accuracy: 0.925000, Test accuracy: 0.928000
Distillation: Epoch : 37, Loss : 0.726586, Accuracy: 0.920000, Test accuracy: 0.928100
Distillation: Epoch : 38, Loss : 0.698497, Accuracy: 0.914000, Test accuracy: 0.929600
Distillation: Epoch : 39, Loss : 0.688118, Accuracy: 0.930000, Test accuracy: 0.930000
Distillation: Epoch : 40, Loss : 0.676527, Accuracy: 0.928000, Test accuracy: 0.930600
Distillation: Epoch : 41, Loss : 0.714561, Accuracy: 0.923000, Test accuracy: 0.931000
Distillation: Epoch : 42, Loss : 0.657316, Accuracy: 0.937000, Test accuracy: 0.932100
Distillation: Epoch : 43, Loss : 0.710672, Accuracy: 0.928000, Test accuracy: 0.932700
Distillation: Epoch : 44, Loss : 0.698466, Accuracy: 0.933000, Test accuracy: 0.933600
Distillation: Epoch : 45, Loss : 0.703165, Accuracy: 0.928000, Test accuracy: 0.933300
Distillation: Epoch : 46, Loss : 0.661791, Accuracy: 0.941000, Test accuracy: 0.935000
Distillation: Epoch : 47, Loss : 0.665048, Accuracy: 0.935000, Test accuracy: 0.935000
Distillation: Epoch : 48, Loss : 0.660255, Accuracy: 0.942000, Test accuracy: 0.936000
Distillation: Epoch : 49, Loss : 0.683935, Accuracy: 0.930000, Test accuracy: 0.936300
Distillation: Epoch : 50, Loss : 0.674659, Accuracy: 0.929000, Test accuracy: 0.938000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.938
Generating confusion matrix for student3
[[ 957.    0.   11.    3.    0.    8.    7.    2.    5.    6.]
 [   0. 1113.    2.    1.    0.    2.    3.    8.    3.    5.]
 [   1.    2.  933.   17.    5.    1.    2.   18.    5.    1.]
 [   2.    3.   18.  950.    0.   24.    1.    3.   14.   10.]
 [   3.    1.   16.    2.  935.    6.    8.   16.    9.   28.]
 [   3.    3.    0.   10.    3.  792.   13.    0.   14.    7.]
 [   7.    4.    5.    2.    6.   14.  918.    0.    6.    1.]
 [   1.    0.    7.    8.    0.    4.    0.  940.    4.    9.]
 [   5.    9.   35.   15.    8.   37.    6.    1.  906.    6.]
 [   1.    0.    5.    2.   25.    4.    0.   40.    8.  936.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.858317, Accuracy: 0.685000, Test accuracy: 0.712100
Distillation: Epoch : 2, Loss : 1.286544, Accuracy: 0.825000, Test accuracy: 0.823800
Distillation: Epoch : 3, Loss : 1.082050, Accuracy: 0.848000, Test accuracy: 0.854500
Distillation: Epoch : 4, Loss : 1.025660, Accuracy: 0.863000, Test accuracy: 0.873200
Distillation: Epoch : 5, Loss : 0.989229, Accuracy: 0.886000, Test accuracy: 0.882700
Distillation: Epoch : 6, Loss : 0.953923, Accuracy: 0.901000, Test accuracy: 0.890000
Distillation: Epoch : 7, Loss : 1.008828, Accuracy: 0.871000, Test accuracy: 0.895400
Distillation: Epoch : 8, Loss : 0.939583, Accuracy: 0.898000, Test accuracy: 0.900700
Distillation: Epoch : 9, Loss : 0.949495, Accuracy: 0.891000, Test accuracy: 0.901800
Distillation: Epoch : 10, Loss : 0.931689, Accuracy: 0.890000, Test accuracy: 0.904500
Distillation: Epoch : 11, Loss : 0.897380, Accuracy: 0.910000, Test accuracy: 0.905700
Distillation: Epoch : 12, Loss : 0.897539, Accuracy: 0.915000, Test accuracy: 0.908200
Distillation: Epoch : 13, Loss : 0.949883, Accuracy: 0.897000, Test accuracy: 0.911400
Distillation: Epoch : 14, Loss : 0.889233, Accuracy: 0.908000, Test accuracy: 0.912900
Distillation: Epoch : 15, Loss : 0.910062, Accuracy: 0.914000, Test accuracy: 0.914800
Distillation: Epoch : 16, Loss : 0.884122, Accuracy: 0.899000, Test accuracy: 0.916500
Distillation: Epoch : 17, Loss : 0.893726, Accuracy: 0.914000, Test accuracy: 0.917900
Distillation: Epoch : 18, Loss : 0.901142, Accuracy: 0.911000, Test accuracy: 0.920100
Distillation: Epoch : 19, Loss : 0.868483, Accuracy: 0.924000, Test accuracy: 0.921000
Distillation: Epoch : 20, Loss : 0.904731, Accuracy: 0.904000, Test accuracy: 0.921400
Distillation: Epoch : 21, Loss : 0.880172, Accuracy: 0.926000, Test accuracy: 0.923200
Distillation: Epoch : 22, Loss : 0.897425, Accuracy: 0.912000, Test accuracy: 0.923600
Distillation: Epoch : 23, Loss : 0.878419, Accuracy: 0.914000, Test accuracy: 0.926100
Distillation: Epoch : 24, Loss : 0.876263, Accuracy: 0.918000, Test accuracy: 0.927200
Distillation: Epoch : 25, Loss : 0.879990, Accuracy: 0.922000, Test accuracy: 0.927000
Distillation: Epoch : 26, Loss : 0.820634, Accuracy: 0.925000, Test accuracy: 0.929000
Distillation: Epoch : 27, Loss : 0.873476, Accuracy: 0.926000, Test accuracy: 0.930800
Distillation: Epoch : 28, Loss : 0.847245, Accuracy: 0.943000, Test accuracy: 0.930800
Distillation: Epoch : 29, Loss : 0.851749, Accuracy: 0.927000, Test accuracy: 0.932800
Distillation: Epoch : 30, Loss : 0.886843, Accuracy: 0.914000, Test accuracy: 0.934000
Distillation: Epoch : 31, Loss : 0.835427, Accuracy: 0.933000, Test accuracy: 0.935600
Distillation: Epoch : 32, Loss : 0.893780, Accuracy: 0.921000, Test accuracy: 0.936800
Distillation: Epoch : 33, Loss : 0.869178, Accuracy: 0.932000, Test accuracy: 0.936500
Distillation: Epoch : 34, Loss : 0.858536, Accuracy: 0.924000, Test accuracy: 0.937800
Distillation: Epoch : 35, Loss : 0.838657, Accuracy: 0.931000, Test accuracy: 0.938500
Distillation: Epoch : 36, Loss : 0.846739, Accuracy: 0.923000, Test accuracy: 0.938400
Distillation: Epoch : 37, Loss : 0.847957, Accuracy: 0.930000, Test accuracy: 0.939900
Distillation: Epoch : 38, Loss : 0.817931, Accuracy: 0.930000, Test accuracy: 0.941600
Distillation: Epoch : 39, Loss : 0.819744, Accuracy: 0.944000, Test accuracy: 0.941700
Distillation: Epoch : 40, Loss : 0.850579, Accuracy: 0.932000, Test accuracy: 0.942200
Distillation: Epoch : 41, Loss : 0.823544, Accuracy: 0.938000, Test accuracy: 0.943800
Distillation: Epoch : 42, Loss : 0.840166, Accuracy: 0.933000, Test accuracy: 0.943700
Distillation: Epoch : 43, Loss : 0.831211, Accuracy: 0.938000, Test accuracy: 0.944900
Distillation: Epoch : 44, Loss : 0.812010, Accuracy: 0.939000, Test accuracy: 0.945700
Distillation: Epoch : 45, Loss : 0.822972, Accuracy: 0.941000, Test accuracy: 0.945100
Distillation: Epoch : 46, Loss : 0.806662, Accuracy: 0.944000, Test accuracy: 0.946300
Distillation: Epoch : 47, Loss : 0.858159, Accuracy: 0.938000, Test accuracy: 0.946000
Distillation: Epoch : 48, Loss : 0.803584, Accuracy: 0.962000, Test accuracy: 0.947100
Distillation: Epoch : 49, Loss : 0.842121, Accuracy: 0.935000, Test accuracy: 0.947600
Distillation: Epoch : 50, Loss : 0.835225, Accuracy: 0.948000, Test accuracy: 0.948300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9483
Generating confusion matrix for student3
[[ 968.    0.    5.    5.    0.    9.    8.    2.    9.    5.]
 [   0. 1117.    1.    1.    1.    1.    3.    7.    4.    6.]
 [   0.    5.  950.   14.    6.    1.    1.   20.    6.    0.]
 [   0.    4.   16.  955.    0.   13.    0.    4.    5.    3.]
 [   2.    0.   17.    1.  949.    2.    4.   19.    7.   18.]
 [   1.    1.    0.   11.    0.  819.   11.    0.   12.    5.]
 [   4.    4.    6.    2.    5.   13.  927.    0.    6.    0.]
 [   1.    0.    4.    5.    1.    4.    0.  934.    3.   12.]
 [   4.    4.   30.   13.    5.   24.    4.    4.  915.   11.]
 [   0.    0.    3.    3.   15.    6.    0.   38.    7.  949.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.918722, Accuracy: 0.657000, Test accuracy: 0.686600
Distillation: Epoch : 2, Loss : 1.387658, Accuracy: 0.785000, Test accuracy: 0.820900
Distillation: Epoch : 3, Loss : 1.214640, Accuracy: 0.862000, Test accuracy: 0.852400
Distillation: Epoch : 4, Loss : 1.169380, Accuracy: 0.871000, Test accuracy: 0.869600
Distillation: Epoch : 5, Loss : 1.131128, Accuracy: 0.892000, Test accuracy: 0.881500
Distillation: Epoch : 6, Loss : 1.107773, Accuracy: 0.892000, Test accuracy: 0.886400
Distillation: Epoch : 7, Loss : 1.124055, Accuracy: 0.875000, Test accuracy: 0.892300
Distillation: Epoch : 8, Loss : 1.078403, Accuracy: 0.910000, Test accuracy: 0.895100
Distillation: Epoch : 9, Loss : 1.075744, Accuracy: 0.891000, Test accuracy: 0.898800
Distillation: Epoch : 10, Loss : 1.056850, Accuracy: 0.908000, Test accuracy: 0.900800
Distillation: Epoch : 11, Loss : 1.101132, Accuracy: 0.897000, Test accuracy: 0.903200
Distillation: Epoch : 12, Loss : 1.091947, Accuracy: 0.895000, Test accuracy: 0.905100
Distillation: Epoch : 13, Loss : 1.088679, Accuracy: 0.906000, Test accuracy: 0.907000
Distillation: Epoch : 14, Loss : 1.074837, Accuracy: 0.900000, Test accuracy: 0.908200
Distillation: Epoch : 15, Loss : 1.068673, Accuracy: 0.903000, Test accuracy: 0.910900
Distillation: Epoch : 16, Loss : 1.099511, Accuracy: 0.896000, Test accuracy: 0.912400
Distillation: Epoch : 17, Loss : 1.081067, Accuracy: 0.920000, Test accuracy: 0.912700
Distillation: Epoch : 18, Loss : 1.088464, Accuracy: 0.907000, Test accuracy: 0.915100
Distillation: Epoch : 19, Loss : 1.046836, Accuracy: 0.908000, Test accuracy: 0.916800
Distillation: Epoch : 20, Loss : 1.047883, Accuracy: 0.913000, Test accuracy: 0.917500
Distillation: Epoch : 21, Loss : 1.037780, Accuracy: 0.922000, Test accuracy: 0.918900
Distillation: Epoch : 22, Loss : 1.061283, Accuracy: 0.915000, Test accuracy: 0.919500
Distillation: Epoch : 23, Loss : 1.058481, Accuracy: 0.903000, Test accuracy: 0.921900
Distillation: Epoch : 24, Loss : 1.059885, Accuracy: 0.920000, Test accuracy: 0.922700
Distillation: Epoch : 25, Loss : 1.026805, Accuracy: 0.924000, Test accuracy: 0.923200
Distillation: Epoch : 26, Loss : 1.042266, Accuracy: 0.931000, Test accuracy: 0.925400
Distillation: Epoch : 27, Loss : 1.037806, Accuracy: 0.908000, Test accuracy: 0.926400
Distillation: Epoch : 28, Loss : 1.017355, Accuracy: 0.924000, Test accuracy: 0.927000
Distillation: Epoch : 29, Loss : 1.039264, Accuracy: 0.911000, Test accuracy: 0.928500
Distillation: Epoch : 30, Loss : 1.037950, Accuracy: 0.915000, Test accuracy: 0.930300
Distillation: Epoch : 31, Loss : 1.028601, Accuracy: 0.929000, Test accuracy: 0.930300
Distillation: Epoch : 32, Loss : 1.022885, Accuracy: 0.921000, Test accuracy: 0.932100
Distillation: Epoch : 33, Loss : 1.010968, Accuracy: 0.929000, Test accuracy: 0.932000
Distillation: Epoch : 34, Loss : 0.996768, Accuracy: 0.927000, Test accuracy: 0.933100
Distillation: Epoch : 35, Loss : 1.028818, Accuracy: 0.927000, Test accuracy: 0.934200
Distillation: Epoch : 36, Loss : 1.028878, Accuracy: 0.916000, Test accuracy: 0.934800
Distillation: Epoch : 37, Loss : 1.000221, Accuracy: 0.937000, Test accuracy: 0.935900
Distillation: Epoch : 38, Loss : 1.002056, Accuracy: 0.933000, Test accuracy: 0.936800
Distillation: Epoch : 39, Loss : 1.012504, Accuracy: 0.920000, Test accuracy: 0.937100
Distillation: Epoch : 40, Loss : 0.987765, Accuracy: 0.933000, Test accuracy: 0.937600
Distillation: Epoch : 41, Loss : 1.007781, Accuracy: 0.939000, Test accuracy: 0.938100
Distillation: Epoch : 42, Loss : 1.008317, Accuracy: 0.927000, Test accuracy: 0.939400
Distillation: Epoch : 43, Loss : 1.015980, Accuracy: 0.937000, Test accuracy: 0.939600
Distillation: Epoch : 44, Loss : 1.027554, Accuracy: 0.932000, Test accuracy: 0.940700
Distillation: Epoch : 45, Loss : 0.999323, Accuracy: 0.925000, Test accuracy: 0.941100
Distillation: Epoch : 46, Loss : 1.002622, Accuracy: 0.948000, Test accuracy: 0.942100
Distillation: Epoch : 47, Loss : 0.993432, Accuracy: 0.950000, Test accuracy: 0.942200
Distillation: Epoch : 48, Loss : 0.984268, Accuracy: 0.948000, Test accuracy: 0.944000
Distillation: Epoch : 49, Loss : 0.992468, Accuracy: 0.942000, Test accuracy: 0.944100
Distillation: Epoch : 50, Loss : 0.972180, Accuracy: 0.941000, Test accuracy: 0.944700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9447
Generating confusion matrix for student3
[[ 955.    0.   10.    6.    0.    9.    5.    0.    7.    6.]
 [   0. 1114.    4.    0.    0.    1.    3.    7.    5.    4.]
 [   2.    2.  942.   12.    4.    0.    0.   18.    5.    0.]
 [   1.    2.   12.  953.    0.   16.    0.    6.   10.    8.]
 [   3.    1.   17.    1.  944.    8.   11.   12.    9.   23.]
 [   3.    4.    0.   12.    1.  817.   14.    3.    7.   11.]
 [   8.    3.    4.    2.    5.    9.  920.    0.    0.    1.]
 [   1.    0.    8.    9.    0.    3.    0.  941.    2.    9.]
 [   6.    9.   29.   15.    5.   26.    5.    2.  921.    7.]
 [   1.    0.    6.    0.   23.    3.    0.   39.    8.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.888457, Accuracy: 0.663000, Test accuracy: 0.677100
Distillation: Epoch : 2, Loss : 1.463664, Accuracy: 0.822000, Test accuracy: 0.824500
Distillation: Epoch : 3, Loss : 1.360311, Accuracy: 0.839000, Test accuracy: 0.854600
Distillation: Epoch : 4, Loss : 1.285529, Accuracy: 0.869000, Test accuracy: 0.869000
Distillation: Epoch : 5, Loss : 1.288887, Accuracy: 0.866000, Test accuracy: 0.877000
Distillation: Epoch : 6, Loss : 1.284457, Accuracy: 0.871000, Test accuracy: 0.883900
Distillation: Epoch : 7, Loss : 1.274052, Accuracy: 0.887000, Test accuracy: 0.888900
Distillation: Epoch : 8, Loss : 1.255537, Accuracy: 0.883000, Test accuracy: 0.890700
Distillation: Epoch : 9, Loss : 1.257213, Accuracy: 0.889000, Test accuracy: 0.895300
Distillation: Epoch : 10, Loss : 1.229429, Accuracy: 0.901000, Test accuracy: 0.898000
Distillation: Epoch : 11, Loss : 1.228183, Accuracy: 0.907000, Test accuracy: 0.901100
Distillation: Epoch : 12, Loss : 1.240372, Accuracy: 0.883000, Test accuracy: 0.903900
Distillation: Epoch : 13, Loss : 1.227224, Accuracy: 0.897000, Test accuracy: 0.906100
Distillation: Epoch : 14, Loss : 1.230878, Accuracy: 0.901000, Test accuracy: 0.907800
Distillation: Epoch : 15, Loss : 1.232981, Accuracy: 0.913000, Test accuracy: 0.908300
Distillation: Epoch : 16, Loss : 1.225946, Accuracy: 0.891000, Test accuracy: 0.910000
Distillation: Epoch : 17, Loss : 1.212912, Accuracy: 0.913000, Test accuracy: 0.911100
Distillation: Epoch : 18, Loss : 1.196528, Accuracy: 0.909000, Test accuracy: 0.914300
Distillation: Epoch : 19, Loss : 1.251974, Accuracy: 0.895000, Test accuracy: 0.915300
Distillation: Epoch : 20, Loss : 1.211183, Accuracy: 0.894000, Test accuracy: 0.916300
Distillation: Epoch : 21, Loss : 1.194856, Accuracy: 0.907000, Test accuracy: 0.917300
Distillation: Epoch : 22, Loss : 1.206963, Accuracy: 0.904000, Test accuracy: 0.918200
Distillation: Epoch : 23, Loss : 1.218848, Accuracy: 0.926000, Test accuracy: 0.919700
Distillation: Epoch : 24, Loss : 1.208714, Accuracy: 0.916000, Test accuracy: 0.920700
Distillation: Epoch : 25, Loss : 1.197294, Accuracy: 0.923000, Test accuracy: 0.922000
Distillation: Epoch : 26, Loss : 1.183062, Accuracy: 0.916000, Test accuracy: 0.923400
Distillation: Epoch : 27, Loss : 1.202089, Accuracy: 0.920000, Test accuracy: 0.925100
Distillation: Epoch : 28, Loss : 1.157215, Accuracy: 0.925000, Test accuracy: 0.926400
Distillation: Epoch : 29, Loss : 1.154532, Accuracy: 0.922000, Test accuracy: 0.927500
Distillation: Epoch : 30, Loss : 1.211803, Accuracy: 0.917000, Test accuracy: 0.928500
Distillation: Epoch : 31, Loss : 1.166547, Accuracy: 0.927000, Test accuracy: 0.930400
Distillation: Epoch : 32, Loss : 1.166173, Accuracy: 0.927000, Test accuracy: 0.931400
Distillation: Epoch : 33, Loss : 1.176215, Accuracy: 0.921000, Test accuracy: 0.933000
Distillation: Epoch : 34, Loss : 1.184579, Accuracy: 0.913000, Test accuracy: 0.934500
Distillation: Epoch : 35, Loss : 1.187380, Accuracy: 0.924000, Test accuracy: 0.935200
Distillation: Epoch : 36, Loss : 1.136425, Accuracy: 0.938000, Test accuracy: 0.935400
Distillation: Epoch : 37, Loss : 1.138915, Accuracy: 0.940000, Test accuracy: 0.936700
Distillation: Epoch : 38, Loss : 1.143508, Accuracy: 0.936000, Test accuracy: 0.938400
Distillation: Epoch : 39, Loss : 1.133376, Accuracy: 0.942000, Test accuracy: 0.938900
Distillation: Epoch : 40, Loss : 1.179183, Accuracy: 0.923000, Test accuracy: 0.939800
Distillation: Epoch : 41, Loss : 1.143218, Accuracy: 0.923000, Test accuracy: 0.941000
Distillation: Epoch : 42, Loss : 1.141145, Accuracy: 0.935000, Test accuracy: 0.941300
Distillation: Epoch : 43, Loss : 1.163597, Accuracy: 0.925000, Test accuracy: 0.942200
Distillation: Epoch : 44, Loss : 1.125294, Accuracy: 0.942000, Test accuracy: 0.943000
Distillation: Epoch : 45, Loss : 1.154397, Accuracy: 0.943000, Test accuracy: 0.943300
Distillation: Epoch : 46, Loss : 1.156062, Accuracy: 0.937000, Test accuracy: 0.944100
Distillation: Epoch : 47, Loss : 1.126441, Accuracy: 0.942000, Test accuracy: 0.944100
Distillation: Epoch : 48, Loss : 1.139334, Accuracy: 0.953000, Test accuracy: 0.944700
Distillation: Epoch : 49, Loss : 1.163310, Accuracy: 0.938000, Test accuracy: 0.946600
Distillation: Epoch : 50, Loss : 1.140319, Accuracy: 0.932000, Test accuracy: 0.947300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9473
Generating confusion matrix for student3
[[ 958.    0.    5.    1.    0.    2.    6.    2.    7.    5.]
 [   0. 1114.    5.    0.    1.    1.    3.    8.    2.    5.]
 [   0.    2.  949.    7.    5.    2.    0.   19.    8.    2.]
 [   1.    3.    9.  959.    0.   17.    1.    7.   11.   12.]
 [   4.    1.   11.    2.  949.    0.    6.   13.    8.   27.]
 [   2.    1.    0.   11.    0.  836.   12.    3.   10.    6.]
 [   9.    5.    5.    0.    7.    7.  927.    0.    1.    0.]
 [   1.    0.    7.    3.    1.    1.    0.  926.    3.    6.]
 [   5.    9.   39.   24.    2.   22.    3.    8.  915.    6.]
 [   0.    0.    2.    3.   17.    4.    0.   42.    9.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.095053, Accuracy: 0.537000, Test accuracy: 0.563100
Distillation: Epoch : 2, Loss : 1.680950, Accuracy: 0.776000, Test accuracy: 0.801400
Distillation: Epoch : 3, Loss : 1.500253, Accuracy: 0.841000, Test accuracy: 0.849700
Distillation: Epoch : 4, Loss : 1.417217, Accuracy: 0.847000, Test accuracy: 0.871000
Distillation: Epoch : 5, Loss : 1.425208, Accuracy: 0.871000, Test accuracy: 0.885200
Distillation: Epoch : 6, Loss : 1.374097, Accuracy: 0.898000, Test accuracy: 0.894900
Distillation: Epoch : 7, Loss : 1.389988, Accuracy: 0.899000, Test accuracy: 0.901800
Distillation: Epoch : 8, Loss : 1.380382, Accuracy: 0.884000, Test accuracy: 0.910000
Distillation: Epoch : 9, Loss : 1.311651, Accuracy: 0.898000, Test accuracy: 0.913900
Distillation: Epoch : 10, Loss : 1.374830, Accuracy: 0.899000, Test accuracy: 0.918100
Distillation: Epoch : 11, Loss : 1.305476, Accuracy: 0.922000, Test accuracy: 0.921300
Distillation: Epoch : 12, Loss : 1.341016, Accuracy: 0.920000, Test accuracy: 0.923700
Distillation: Epoch : 13, Loss : 1.334467, Accuracy: 0.906000, Test accuracy: 0.927200
Distillation: Epoch : 14, Loss : 1.296405, Accuracy: 0.930000, Test accuracy: 0.929200
Distillation: Epoch : 15, Loss : 1.316599, Accuracy: 0.932000, Test accuracy: 0.931700
Distillation: Epoch : 16, Loss : 1.286226, Accuracy: 0.941000, Test accuracy: 0.933900
Distillation: Epoch : 17, Loss : 1.309289, Accuracy: 0.938000, Test accuracy: 0.935400
Distillation: Epoch : 18, Loss : 1.331429, Accuracy: 0.925000, Test accuracy: 0.937200
Distillation: Epoch : 19, Loss : 1.275677, Accuracy: 0.941000, Test accuracy: 0.939200
Distillation: Epoch : 20, Loss : 1.300205, Accuracy: 0.935000, Test accuracy: 0.940500
Distillation: Epoch : 21, Loss : 1.293817, Accuracy: 0.920000, Test accuracy: 0.942200
Distillation: Epoch : 22, Loss : 1.301245, Accuracy: 0.940000, Test accuracy: 0.943700
Distillation: Epoch : 23, Loss : 1.310140, Accuracy: 0.929000, Test accuracy: 0.944200
Distillation: Epoch : 24, Loss : 1.280229, Accuracy: 0.935000, Test accuracy: 0.944400
Distillation: Epoch : 25, Loss : 1.290180, Accuracy: 0.936000, Test accuracy: 0.945800
Distillation: Epoch : 26, Loss : 1.280100, Accuracy: 0.937000, Test accuracy: 0.945600
Distillation: Epoch : 27, Loss : 1.276897, Accuracy: 0.947000, Test accuracy: 0.946600
Distillation: Epoch : 28, Loss : 1.295295, Accuracy: 0.950000, Test accuracy: 0.946900
Distillation: Epoch : 29, Loss : 1.282495, Accuracy: 0.940000, Test accuracy: 0.947700
Distillation: Epoch : 30, Loss : 1.287595, Accuracy: 0.926000, Test accuracy: 0.948400
Distillation: Epoch : 31, Loss : 1.281113, Accuracy: 0.946000, Test accuracy: 0.949200
Distillation: Epoch : 32, Loss : 1.293514, Accuracy: 0.944000, Test accuracy: 0.950000
Distillation: Epoch : 33, Loss : 1.295068, Accuracy: 0.934000, Test accuracy: 0.950400
Distillation: Epoch : 34, Loss : 1.296348, Accuracy: 0.941000, Test accuracy: 0.949800
Distillation: Epoch : 35, Loss : 1.263892, Accuracy: 0.946000, Test accuracy: 0.950100
Distillation: Epoch : 36, Loss : 1.255131, Accuracy: 0.953000, Test accuracy: 0.950700
Distillation: Epoch : 37, Loss : 1.284601, Accuracy: 0.940000, Test accuracy: 0.951700
Distillation: Epoch : 38, Loss : 1.255709, Accuracy: 0.952000, Test accuracy: 0.952000
Distillation: Epoch : 39, Loss : 1.279260, Accuracy: 0.949000, Test accuracy: 0.951900
Distillation: Epoch : 40, Loss : 1.277574, Accuracy: 0.955000, Test accuracy: 0.952000
Distillation: Epoch : 41, Loss : 1.276123, Accuracy: 0.955000, Test accuracy: 0.952200
Distillation: Epoch : 42, Loss : 1.244472, Accuracy: 0.953000, Test accuracy: 0.952600
Distillation: Epoch : 43, Loss : 1.271324, Accuracy: 0.944000, Test accuracy: 0.952300
Distillation: Epoch : 44, Loss : 1.271223, Accuracy: 0.948000, Test accuracy: 0.953100
Distillation: Epoch : 45, Loss : 1.273900, Accuracy: 0.953000, Test accuracy: 0.953100
Distillation: Epoch : 46, Loss : 1.278758, Accuracy: 0.945000, Test accuracy: 0.953200
Distillation: Epoch : 47, Loss : 1.261599, Accuracy: 0.948000, Test accuracy: 0.953500
Distillation: Epoch : 48, Loss : 1.259731, Accuracy: 0.950000, Test accuracy: 0.953200
Distillation: Epoch : 49, Loss : 1.253115, Accuracy: 0.952000, Test accuracy: 0.953800
Distillation: Epoch : 50, Loss : 1.262937, Accuracy: 0.947000, Test accuracy: 0.953700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9537
Generating confusion matrix for student3
[[ 964.    0.    6.    1.    0.    4.    7.    2.    5.    4.]
 [   1. 1107.    5.    0.    0.    1.    3.    2.    1.    5.]
 [   1.    2.  952.    5.    4.    1.    2.   20.    7.    1.]
 [   0.    2.   14.  969.    1.   20.    0.    9.    3.    9.]
 [   2.    1.    8.    0.  951.    1.    4.    6.    5.   21.]
 [   0.    2.    0.   10.    0.  831.   10.    2.    5.    7.]
 [   8.    4.    5.    0.    1.    6.  926.    0.    2.    0.]
 [   1.    0.    5.    5.    0.    1.    0.  959.    3.    9.]
 [   3.   17.   36.   17.    5.   22.    6.    8.  935.   10.]
 [   0.    0.    1.    3.   20.    5.    0.   20.    8.  943.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.098311, Accuracy: 0.550000, Test accuracy: 0.577800
Distillation: Epoch : 2, Loss : 1.711223, Accuracy: 0.810000, Test accuracy: 0.829900
Distillation: Epoch : 3, Loss : 1.579804, Accuracy: 0.862000, Test accuracy: 0.859000
Distillation: Epoch : 4, Loss : 1.567449, Accuracy: 0.854000, Test accuracy: 0.875300
Distillation: Epoch : 5, Loss : 1.544589, Accuracy: 0.878000, Test accuracy: 0.881800
Distillation: Epoch : 6, Loss : 1.495119, Accuracy: 0.876000, Test accuracy: 0.888900
Distillation: Epoch : 7, Loss : 1.504754, Accuracy: 0.891000, Test accuracy: 0.892200
Distillation: Epoch : 8, Loss : 1.500877, Accuracy: 0.880000, Test accuracy: 0.895600
Distillation: Epoch : 9, Loss : 1.492770, Accuracy: 0.886000, Test accuracy: 0.899300
Distillation: Epoch : 10, Loss : 1.483543, Accuracy: 0.906000, Test accuracy: 0.903400
Distillation: Epoch : 11, Loss : 1.494011, Accuracy: 0.889000, Test accuracy: 0.907000
Distillation: Epoch : 12, Loss : 1.466249, Accuracy: 0.916000, Test accuracy: 0.908900
Distillation: Epoch : 13, Loss : 1.476501, Accuracy: 0.903000, Test accuracy: 0.911700
Distillation: Epoch : 14, Loss : 1.446924, Accuracy: 0.911000, Test accuracy: 0.915000
Distillation: Epoch : 15, Loss : 1.493880, Accuracy: 0.902000, Test accuracy: 0.917500
Distillation: Epoch : 16, Loss : 1.457655, Accuracy: 0.912000, Test accuracy: 0.920600
Distillation: Epoch : 17, Loss : 1.456189, Accuracy: 0.927000, Test accuracy: 0.921700
Distillation: Epoch : 18, Loss : 1.446333, Accuracy: 0.916000, Test accuracy: 0.924500
Distillation: Epoch : 19, Loss : 1.462570, Accuracy: 0.913000, Test accuracy: 0.926800
Distillation: Epoch : 20, Loss : 1.433810, Accuracy: 0.914000, Test accuracy: 0.928000
Distillation: Epoch : 21, Loss : 1.435390, Accuracy: 0.927000, Test accuracy: 0.930600
Distillation: Epoch : 22, Loss : 1.433051, Accuracy: 0.934000, Test accuracy: 0.933700
Distillation: Epoch : 23, Loss : 1.420137, Accuracy: 0.927000, Test accuracy: 0.936700
Distillation: Epoch : 24, Loss : 1.407905, Accuracy: 0.942000, Test accuracy: 0.937800
Distillation: Epoch : 25, Loss : 1.443439, Accuracy: 0.925000, Test accuracy: 0.937900
Distillation: Epoch : 26, Loss : 1.400397, Accuracy: 0.936000, Test accuracy: 0.939700
Distillation: Epoch : 27, Loss : 1.389294, Accuracy: 0.934000, Test accuracy: 0.941300
Distillation: Epoch : 28, Loss : 1.415526, Accuracy: 0.919000, Test accuracy: 0.943300
Distillation: Epoch : 29, Loss : 1.428403, Accuracy: 0.925000, Test accuracy: 0.944100
Distillation: Epoch : 30, Loss : 1.397133, Accuracy: 0.956000, Test accuracy: 0.945300
Distillation: Epoch : 31, Loss : 1.402677, Accuracy: 0.946000, Test accuracy: 0.945900
Distillation: Epoch : 32, Loss : 1.394375, Accuracy: 0.950000, Test accuracy: 0.947500
Distillation: Epoch : 33, Loss : 1.412102, Accuracy: 0.931000, Test accuracy: 0.949400
Distillation: Epoch : 34, Loss : 1.398237, Accuracy: 0.942000, Test accuracy: 0.949600
Distillation: Epoch : 35, Loss : 1.416696, Accuracy: 0.933000, Test accuracy: 0.950200
Distillation: Epoch : 36, Loss : 1.399985, Accuracy: 0.937000, Test accuracy: 0.951300
Distillation: Epoch : 37, Loss : 1.388831, Accuracy: 0.953000, Test accuracy: 0.951300
Distillation: Epoch : 38, Loss : 1.381121, Accuracy: 0.947000, Test accuracy: 0.952300
Distillation: Epoch : 39, Loss : 1.389763, Accuracy: 0.945000, Test accuracy: 0.951800
Distillation: Epoch : 40, Loss : 1.392487, Accuracy: 0.953000, Test accuracy: 0.952900
Distillation: Epoch : 41, Loss : 1.393745, Accuracy: 0.956000, Test accuracy: 0.953000
Distillation: Epoch : 42, Loss : 1.390325, Accuracy: 0.946000, Test accuracy: 0.954800
Distillation: Epoch : 43, Loss : 1.408471, Accuracy: 0.943000, Test accuracy: 0.954400
Distillation: Epoch : 44, Loss : 1.385161, Accuracy: 0.963000, Test accuracy: 0.954000
Distillation: Epoch : 45, Loss : 1.399809, Accuracy: 0.949000, Test accuracy: 0.955200
Distillation: Epoch : 46, Loss : 1.387761, Accuracy: 0.959000, Test accuracy: 0.955500
Distillation: Epoch : 47, Loss : 1.392970, Accuracy: 0.955000, Test accuracy: 0.955600
Distillation: Epoch : 48, Loss : 1.394977, Accuracy: 0.945000, Test accuracy: 0.955500
Distillation: Epoch : 49, Loss : 1.378839, Accuracy: 0.955000, Test accuracy: 0.956500
Distillation: Epoch : 50, Loss : 1.366322, Accuracy: 0.958000, Test accuracy: 0.955800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9558
Generating confusion matrix for student3
[[ 966.    0.    3.    1.    1.    1.   10.    3.    8.    5.]
 [   1. 1109.    5.    1.    1.    1.    3.    6.    2.    5.]
 [   0.    4.  969.    3.    0.    1.    0.   20.    5.    0.]
 [   0.    0.    8.  972.    0.    7.    1.    3.    7.   13.]
 [   3.    1.    8.    1.  956.    1.    6.   10.    9.   23.]
 [   0.    1.    0.    6.    0.  853.   14.    1.    3.    6.]
 [   7.    4.    4.    1.    7.    5.  917.    0.    5.    0.]
 [   1.    0.    3.    3.    0.    3.    0.  947.    4.    9.]
 [   1.   16.   28.   18.    4.   17.    7.    4.  924.    3.]
 [   1.    0.    4.    4.   13.    3.    0.   34.    7.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.100014, Accuracy: 0.568000, Test accuracy: 0.593800
Distillation: Epoch : 2, Loss : 1.887175, Accuracy: 0.794000, Test accuracy: 0.806800
Distillation: Epoch : 3, Loss : 1.827539, Accuracy: 0.828000, Test accuracy: 0.845500
Distillation: Epoch : 4, Loss : 1.809271, Accuracy: 0.842000, Test accuracy: 0.856200
Distillation: Epoch : 5, Loss : 1.798609, Accuracy: 0.852000, Test accuracy: 0.865400
Distillation: Epoch : 6, Loss : 1.786707, Accuracy: 0.868000, Test accuracy: 0.869000
Distillation: Epoch : 7, Loss : 1.785732, Accuracy: 0.874000, Test accuracy: 0.874200
Distillation: Epoch : 8, Loss : 1.782083, Accuracy: 0.857000, Test accuracy: 0.876800
Distillation: Epoch : 9, Loss : 1.783561, Accuracy: 0.865000, Test accuracy: 0.880200
Distillation: Epoch : 10, Loss : 1.773349, Accuracy: 0.860000, Test accuracy: 0.881900
Distillation: Epoch : 11, Loss : 1.793391, Accuracy: 0.870000, Test accuracy: 0.884200
Distillation: Epoch : 12, Loss : 1.776263, Accuracy: 0.881000, Test accuracy: 0.885500
Distillation: Epoch : 13, Loss : 1.765140, Accuracy: 0.898000, Test accuracy: 0.885800
Distillation: Epoch : 14, Loss : 1.789683, Accuracy: 0.887000, Test accuracy: 0.887600
Distillation: Epoch : 15, Loss : 1.774275, Accuracy: 0.879000, Test accuracy: 0.887500
Distillation: Epoch : 16, Loss : 1.773365, Accuracy: 0.887000, Test accuracy: 0.889300
Distillation: Epoch : 17, Loss : 1.763439, Accuracy: 0.907000, Test accuracy: 0.891000
Distillation: Epoch : 18, Loss : 1.758566, Accuracy: 0.886000, Test accuracy: 0.892400
Distillation: Epoch : 19, Loss : 1.769182, Accuracy: 0.895000, Test accuracy: 0.893200
Distillation: Epoch : 20, Loss : 1.758860, Accuracy: 0.905000, Test accuracy: 0.893700
Distillation: Epoch : 21, Loss : 1.760986, Accuracy: 0.876000, Test accuracy: 0.892700
Distillation: Epoch : 22, Loss : 1.744839, Accuracy: 0.884000, Test accuracy: 0.894100
Distillation: Epoch : 23, Loss : 1.765944, Accuracy: 0.899000, Test accuracy: 0.896200
Distillation: Epoch : 24, Loss : 1.748331, Accuracy: 0.876000, Test accuracy: 0.894800
Distillation: Epoch : 25, Loss : 1.765525, Accuracy: 0.883000, Test accuracy: 0.896900
Distillation: Epoch : 26, Loss : 1.761528, Accuracy: 0.881000, Test accuracy: 0.897300
Distillation: Epoch : 27, Loss : 1.749040, Accuracy: 0.894000, Test accuracy: 0.896900
Distillation: Epoch : 28, Loss : 1.768416, Accuracy: 0.881000, Test accuracy: 0.897900
Distillation: Epoch : 29, Loss : 1.765966, Accuracy: 0.881000, Test accuracy: 0.899000
Distillation: Epoch : 30, Loss : 1.782636, Accuracy: 0.873000, Test accuracy: 0.899000
Distillation: Epoch : 31, Loss : 1.749655, Accuracy: 0.903000, Test accuracy: 0.900900
Distillation: Epoch : 32, Loss : 1.752341, Accuracy: 0.883000, Test accuracy: 0.900800
Distillation: Epoch : 33, Loss : 1.725843, Accuracy: 0.901000, Test accuracy: 0.900100
Distillation: Epoch : 34, Loss : 1.735477, Accuracy: 0.905000, Test accuracy: 0.902500
Distillation: Epoch : 35, Loss : 1.742376, Accuracy: 0.904000, Test accuracy: 0.902900
Distillation: Epoch : 36, Loss : 1.760255, Accuracy: 0.899000, Test accuracy: 0.904500
Distillation: Epoch : 37, Loss : 1.755288, Accuracy: 0.889000, Test accuracy: 0.904600
Distillation: Epoch : 38, Loss : 1.744143, Accuracy: 0.903000, Test accuracy: 0.905400
Distillation: Epoch : 39, Loss : 1.743705, Accuracy: 0.893000, Test accuracy: 0.905900
Distillation: Epoch : 40, Loss : 1.743335, Accuracy: 0.894000, Test accuracy: 0.907300
Distillation: Epoch : 41, Loss : 1.735606, Accuracy: 0.902000, Test accuracy: 0.907600
Distillation: Epoch : 42, Loss : 1.746080, Accuracy: 0.913000, Test accuracy: 0.909900
Distillation: Epoch : 43, Loss : 1.750681, Accuracy: 0.914000, Test accuracy: 0.910000
Distillation: Epoch : 44, Loss : 1.724821, Accuracy: 0.911000, Test accuracy: 0.909800
Distillation: Epoch : 45, Loss : 1.750732, Accuracy: 0.892000, Test accuracy: 0.913000
Distillation: Epoch : 46, Loss : 1.747464, Accuracy: 0.895000, Test accuracy: 0.913600
Distillation: Epoch : 47, Loss : 1.743352, Accuracy: 0.902000, Test accuracy: 0.914400
Distillation: Epoch : 48, Loss : 1.733134, Accuracy: 0.916000, Test accuracy: 0.916200
Distillation: Epoch : 49, Loss : 1.735125, Accuracy: 0.903000, Test accuracy: 0.918700
Distillation: Epoch : 50, Loss : 1.725101, Accuracy: 0.907000, Test accuracy: 0.917800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9178
Generating confusion matrix for student3
[[ 953.    0.   14.    8.    0.    9.   10.    2.    6.    8.]
 [   0. 1096.    4.    1.    0.    3.    3.   11.    5.    4.]
 [   2.    2.  891.   13.    5.    0.    2.   17.    9.    0.]
 [   1.    5.   17.  922.    0.   27.    2.    7.   12.   13.]
 [   4.    1.   26.    3.  937.    8.   11.   27.   14.   55.]
 [   2.    4.    0.   15.    1.  783.   15.    2.   10.    6.]
 [   9.    5.   16.    4.    6.   11.  904.    1.    5.    0.]
 [   1.    0.   10.   10.    0.    2.    0.  890.    3.   11.]
 [   8.   22.   51.   28.   12.   43.   11.    5.  904.   14.]
 [   0.    0.    3.    6.   21.    6.    0.   66.    6.  898.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.205511, Accuracy: 0.508000, Test accuracy: 0.512200
Distillation: Epoch : 2, Loss : 2.086524, Accuracy: 0.778000, Test accuracy: 0.812100
Distillation: Epoch : 3, Loss : 2.056678, Accuracy: 0.801000, Test accuracy: 0.840100
Distillation: Epoch : 4, Loss : 2.027962, Accuracy: 0.865000, Test accuracy: 0.857800
Distillation: Epoch : 5, Loss : 2.032363, Accuracy: 0.860000, Test accuracy: 0.864900
Distillation: Epoch : 6, Loss : 2.018300, Accuracy: 0.850000, Test accuracy: 0.872100
Distillation: Epoch : 7, Loss : 2.020314, Accuracy: 0.878000, Test accuracy: 0.876800
Distillation: Epoch : 8, Loss : 2.024376, Accuracy: 0.870000, Test accuracy: 0.882300
Distillation: Epoch : 9, Loss : 2.012312, Accuracy: 0.869000, Test accuracy: 0.884700
Distillation: Epoch : 10, Loss : 2.012108, Accuracy: 0.893000, Test accuracy: 0.888400
Distillation: Epoch : 11, Loss : 2.012707, Accuracy: 0.868000, Test accuracy: 0.890500
Distillation: Epoch : 12, Loss : 2.021667, Accuracy: 0.887000, Test accuracy: 0.893500
Distillation: Epoch : 13, Loss : 1.995993, Accuracy: 0.892000, Test accuracy: 0.896600
Distillation: Epoch : 14, Loss : 1.999421, Accuracy: 0.881000, Test accuracy: 0.898000
Distillation: Epoch : 15, Loss : 2.000703, Accuracy: 0.891000, Test accuracy: 0.899500
Distillation: Epoch : 16, Loss : 2.001409, Accuracy: 0.899000, Test accuracy: 0.901500
Distillation: Epoch : 17, Loss : 1.992595, Accuracy: 0.910000, Test accuracy: 0.904500
Distillation: Epoch : 18, Loss : 1.992395, Accuracy: 0.910000, Test accuracy: 0.906800
Distillation: Epoch : 19, Loss : 1.993450, Accuracy: 0.903000, Test accuracy: 0.908600
Distillation: Epoch : 20, Loss : 1.991512, Accuracy: 0.904000, Test accuracy: 0.911800
Distillation: Epoch : 21, Loss : 1.984583, Accuracy: 0.908000, Test accuracy: 0.914200
Distillation: Epoch : 22, Loss : 1.994443, Accuracy: 0.888000, Test accuracy: 0.915100
Distillation: Epoch : 23, Loss : 1.991089, Accuracy: 0.900000, Test accuracy: 0.917900
Distillation: Epoch : 24, Loss : 1.982756, Accuracy: 0.918000, Test accuracy: 0.920500
Distillation: Epoch : 25, Loss : 1.986610, Accuracy: 0.914000, Test accuracy: 0.921400
Distillation: Epoch : 26, Loss : 1.986099, Accuracy: 0.905000, Test accuracy: 0.922900
Distillation: Epoch : 27, Loss : 1.987131, Accuracy: 0.913000, Test accuracy: 0.925100
Distillation: Epoch : 28, Loss : 1.977551, Accuracy: 0.921000, Test accuracy: 0.926500
Distillation: Epoch : 29, Loss : 1.981819, Accuracy: 0.914000, Test accuracy: 0.927100
Distillation: Epoch : 30, Loss : 1.977629, Accuracy: 0.919000, Test accuracy: 0.928300
Distillation: Epoch : 31, Loss : 1.990431, Accuracy: 0.920000, Test accuracy: 0.928800
Distillation: Epoch : 32, Loss : 1.983252, Accuracy: 0.917000, Test accuracy: 0.930200
Distillation: Epoch : 33, Loss : 1.987965, Accuracy: 0.915000, Test accuracy: 0.930300
Distillation: Epoch : 34, Loss : 1.974638, Accuracy: 0.934000, Test accuracy: 0.931300
Distillation: Epoch : 35, Loss : 1.975252, Accuracy: 0.928000, Test accuracy: 0.931800
Distillation: Epoch : 36, Loss : 1.977529, Accuracy: 0.921000, Test accuracy: 0.930800
Distillation: Epoch : 37, Loss : 1.988315, Accuracy: 0.925000, Test accuracy: 0.933300
Distillation: Epoch : 38, Loss : 1.982055, Accuracy: 0.924000, Test accuracy: 0.933800
Distillation: Epoch : 39, Loss : 1.970656, Accuracy: 0.938000, Test accuracy: 0.934000
Distillation: Epoch : 40, Loss : 1.983712, Accuracy: 0.934000, Test accuracy: 0.935100
Distillation: Epoch : 41, Loss : 1.961205, Accuracy: 0.930000, Test accuracy: 0.935500
Distillation: Epoch : 42, Loss : 1.971462, Accuracy: 0.952000, Test accuracy: 0.935800
Distillation: Epoch : 43, Loss : 1.985398, Accuracy: 0.936000, Test accuracy: 0.935400
Distillation: Epoch : 44, Loss : 1.972034, Accuracy: 0.936000, Test accuracy: 0.937200
Distillation: Epoch : 45, Loss : 1.980300, Accuracy: 0.954000, Test accuracy: 0.937700
Distillation: Epoch : 46, Loss : 1.971885, Accuracy: 0.936000, Test accuracy: 0.937400
Distillation: Epoch : 47, Loss : 1.973359, Accuracy: 0.942000, Test accuracy: 0.938000
Distillation: Epoch : 48, Loss : 1.974835, Accuracy: 0.941000, Test accuracy: 0.938400
Distillation: Epoch : 49, Loss : 1.986735, Accuracy: 0.922000, Test accuracy: 0.939600
Distillation: Epoch : 50, Loss : 1.970103, Accuracy: 0.939000, Test accuracy: 0.940600
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9406
Generating confusion matrix for student3
[[ 961.    0.    8.    4.    0.    4.    7.    1.    6.    6.]
 [   0. 1087.    5.    1.    1.    1.    5.    7.    4.    6.]
 [   1.    6.  946.    5.    3.    0.    0.   21.    8.    1.]
 [   0.    2.    8.  963.    0.   19.    0.    6.    6.   13.]
 [   4.    1.   11.    1.  950.    2.    9.   14.    8.   34.]
 [   0.    1.    0.    8.    0.  825.   19.    2.    7.    5.]
 [   6.    5.    5.    2.    6.    9.  910.    0.    1.    0.]
 [   1.    0.    8.    7.    0.    2.    0.  912.    4.    7.]
 [   7.   33.   38.   17.    5.   27.    8.    8.  923.    8.]
 [   0.    0.    3.    2.   17.    3.    0.   57.    7.  929.]]
</confusion_matrix>
