Teacher::__init__
Student4:__init__
Student5::__init__
Student::__init__
Student2::__init__
Student3::__init__
> Loading MNIST data...
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
trainingTeacher
Teacher::train
Starting training epoch 0
Epoch : 1, Loss : 0.076633, Accuracy: 0.980000, Test accuracy: 0.963800
Starting training epoch 1
Epoch : 2, Loss : 0.071748, Accuracy: 0.984000, Test accuracy: 0.978000
Starting training epoch 2
Epoch : 3, Loss : 0.062357, Accuracy: 0.984000, Test accuracy: 0.980600
Starting training epoch 3
Epoch : 4, Loss : 0.054340, Accuracy: 0.980000, Test accuracy: 0.983000
Starting training epoch 4
Epoch : 5, Loss : 0.010121, Accuracy: 0.996000, Test accuracy: 0.987400
Starting training epoch 5
Epoch : 6, Loss : 0.006496, Accuracy: 1.000000, Test accuracy: 0.989100
Starting training epoch 6
Epoch : 7, Loss : 0.012879, Accuracy: 1.000000, Test accuracy: 0.988100
Starting training epoch 7
Epoch : 8, Loss : 0.007869, Accuracy: 1.000000, Test accuracy: 0.988600
Starting training epoch 8
Epoch : 9, Loss : 0.015856, Accuracy: 0.996000, Test accuracy: 0.991400
Starting training epoch 9
Epoch : 10, Loss : 0.008701, Accuracy: 1.000000, Test accuracy: 0.991600
Starting training epoch 10
Epoch : 11, Loss : 0.009639, Accuracy: 0.996000, Test accuracy: 0.992000
Starting training epoch 11
Epoch : 12, Loss : 0.003484, Accuracy: 1.000000, Test accuracy: 0.991900
Starting training epoch 12
Epoch : 13, Loss : 0.009336, Accuracy: 0.996000, Test accuracy: 0.991200
Starting training epoch 13
Epoch : 14, Loss : 0.028246, Accuracy: 0.996000, Test accuracy: 0.992500
Starting training epoch 14
Epoch : 15, Loss : 0.004180, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 15
Epoch : 16, Loss : 0.001694, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 16
Epoch : 17, Loss : 0.002180, Accuracy: 1.000000, Test accuracy: 0.990800
Starting training epoch 17
Epoch : 18, Loss : 0.005361, Accuracy: 1.000000, Test accuracy: 0.992900
Starting training epoch 18
Epoch : 19, Loss : 0.001883, Accuracy: 1.000000, Test accuracy: 0.992000
Starting training epoch 19
Epoch : 20, Loss : 0.000553, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 20
Epoch : 21, Loss : 0.003235, Accuracy: 0.996000, Test accuracy: 0.992800
Starting training epoch 21
Epoch : 22, Loss : 0.002793, Accuracy: 1.000000, Test accuracy: 0.992600
Starting training epoch 22
Epoch : 23, Loss : 0.000146, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 23
Epoch : 24, Loss : 0.000249, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 24
Epoch : 25, Loss : 0.000169, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 25
Epoch : 26, Loss : 0.000212, Accuracy: 1.000000, Test accuracy: 0.992800
Starting training epoch 26
Epoch : 27, Loss : 0.000407, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 27
Epoch : 28, Loss : 0.000021, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 28
Epoch : 29, Loss : 0.000070, Accuracy: 1.000000, Test accuracy: 0.994100
Starting training epoch 29
Epoch : 30, Loss : 0.000204, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 30
Epoch : 31, Loss : 0.000049, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 31
Epoch : 32, Loss : 0.001446, Accuracy: 1.000000, Test accuracy: 0.992400
Starting training epoch 32
Epoch : 33, Loss : 0.000111, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 33
Epoch : 34, Loss : 0.000119, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 34
Epoch : 35, Loss : 0.000013, Accuracy: 1.000000, Test accuracy: 0.993800
Starting training epoch 35
Epoch : 36, Loss : 0.000080, Accuracy: 1.000000, Test accuracy: 0.994100
Starting training epoch 36
Epoch : 37, Loss : 0.000474, Accuracy: 1.000000, Test accuracy: 0.993700
Starting training epoch 37
Epoch : 38, Loss : 0.000191, Accuracy: 1.000000, Test accuracy: 0.994500
Starting training epoch 38
Epoch : 39, Loss : 0.000332, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 39
Epoch : 40, Loss : 0.000029, Accuracy: 1.000000, Test accuracy: 0.993300
Starting training epoch 40
Epoch : 41, Loss : 0.000132, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 41
Epoch : 42, Loss : 0.000019, Accuracy: 1.000000, Test accuracy: 0.993600
Starting training epoch 42
Epoch : 43, Loss : 0.000047, Accuracy: 1.000000, Test accuracy: 0.993000
Starting training epoch 43
Epoch : 44, Loss : 0.000039, Accuracy: 1.000000, Test accuracy: 0.993200
Starting training epoch 44
Epoch : 45, Loss : 0.000027, Accuracy: 1.000000, Test accuracy: 0.993400
Starting training epoch 45
Epoch : 46, Loss : 0.000191, Accuracy: 1.000000, Test accuracy: 0.993100
Starting training epoch 46
Epoch : 47, Loss : 0.000060, Accuracy: 1.000000, Test accuracy: 0.994200
Starting training epoch 47
Epoch : 48, Loss : 0.000260, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 48
Epoch : 49, Loss : 0.000051, Accuracy: 1.000000, Test accuracy: 0.993900
Starting training epoch 49
Epoch : 50, Loss : 0.000293, Accuracy: 1.000000, Test accuracy: 0.993300
Saving to teacher/teacher.ckpt
trainingStudents
Student4::train
Starting training epoch 0
Epoch : 1, Loss : 0.786062, Accuracy: 0.796000, Test accuracy: 0.820500
Starting training epoch 1
Epoch : 2, Loss : 0.400052, Accuracy: 0.872000, Test accuracy: 0.884700
Starting training epoch 2
Epoch : 3, Loss : 0.484456, Accuracy: 0.864000, Test accuracy: 0.902600
Starting training epoch 3
Epoch : 4, Loss : 0.342219, Accuracy: 0.920000, Test accuracy: 0.913700
Starting training epoch 4
Epoch : 5, Loss : 0.208070, Accuracy: 0.916000, Test accuracy: 0.921300
Starting training epoch 5
Epoch : 6, Loss : 0.207644, Accuracy: 0.948000, Test accuracy: 0.927500
Starting training epoch 6
Epoch : 7, Loss : 0.229968, Accuracy: 0.920000, Test accuracy: 0.931600
Starting training epoch 7
Epoch : 8, Loss : 0.308533, Accuracy: 0.916000, Test accuracy: 0.936200
Starting training epoch 8
Epoch : 9, Loss : 0.273805, Accuracy: 0.944000, Test accuracy: 0.938500
Starting training epoch 9
Epoch : 10, Loss : 0.122511, Accuracy: 0.944000, Test accuracy: 0.942200
Starting training epoch 10
Epoch : 11, Loss : 0.285197, Accuracy: 0.912000, Test accuracy: 0.945100
Starting training epoch 11
Epoch : 12, Loss : 0.170518, Accuracy: 0.940000, Test accuracy: 0.946100
Starting training epoch 12
Epoch : 13, Loss : 0.189127, Accuracy: 0.936000, Test accuracy: 0.948600
Starting training epoch 13
Epoch : 14, Loss : 0.156165, Accuracy: 0.960000, Test accuracy: 0.949500
Starting training epoch 14
Epoch : 15, Loss : 0.170147, Accuracy: 0.960000, Test accuracy: 0.952100
Starting training epoch 15
Epoch : 16, Loss : 0.201594, Accuracy: 0.940000, Test accuracy: 0.952100
Starting training epoch 16
Epoch : 17, Loss : 0.148017, Accuracy: 0.952000, Test accuracy: 0.954500
Starting training epoch 17
Epoch : 18, Loss : 0.111655, Accuracy: 0.952000, Test accuracy: 0.954500
Starting training epoch 18
Epoch : 19, Loss : 0.205780, Accuracy: 0.948000, Test accuracy: 0.956800
Starting training epoch 19
Epoch : 20, Loss : 0.162799, Accuracy: 0.952000, Test accuracy: 0.956200
Starting training epoch 20
Epoch : 21, Loss : 0.159808, Accuracy: 0.948000, Test accuracy: 0.957800
Starting training epoch 21
Epoch : 22, Loss : 0.144003, Accuracy: 0.948000, Test accuracy: 0.958300
Starting training epoch 22
Epoch : 23, Loss : 0.152457, Accuracy: 0.956000, Test accuracy: 0.958600
Starting training epoch 23
Epoch : 24, Loss : 0.199976, Accuracy: 0.952000, Test accuracy: 0.960100
Starting training epoch 24
Epoch : 25, Loss : 0.185812, Accuracy: 0.952000, Test accuracy: 0.959700
Starting training epoch 25
Epoch : 26, Loss : 0.109811, Accuracy: 0.964000, Test accuracy: 0.961200
Starting training epoch 26
Epoch : 27, Loss : 0.205288, Accuracy: 0.940000, Test accuracy: 0.962100
Starting training epoch 27
Epoch : 28, Loss : 0.149881, Accuracy: 0.948000, Test accuracy: 0.960800
Starting training epoch 28
Epoch : 29, Loss : 0.130792, Accuracy: 0.964000, Test accuracy: 0.961500
Starting training epoch 29
Epoch : 30, Loss : 0.161923, Accuracy: 0.960000, Test accuracy: 0.962200
Starting training epoch 30
Epoch : 31, Loss : 0.206019, Accuracy: 0.952000, Test accuracy: 0.962400
Starting training epoch 31
Epoch : 32, Loss : 0.125974, Accuracy: 0.968000, Test accuracy: 0.963000
Starting training epoch 32
Epoch : 33, Loss : 0.170595, Accuracy: 0.964000, Test accuracy: 0.963300
Starting training epoch 33
Epoch : 34, Loss : 0.146978, Accuracy: 0.944000, Test accuracy: 0.964600
Starting training epoch 34
Epoch : 35, Loss : 0.118837, Accuracy: 0.972000, Test accuracy: 0.964800
Starting training epoch 35
Epoch : 36, Loss : 0.121167, Accuracy: 0.964000, Test accuracy: 0.965100
Starting training epoch 36
Epoch : 37, Loss : 0.110029, Accuracy: 0.968000, Test accuracy: 0.966000
Starting training epoch 37
Epoch : 38, Loss : 0.097484, Accuracy: 0.968000, Test accuracy: 0.964700
Starting training epoch 38
Epoch : 39, Loss : 0.116382, Accuracy: 0.964000, Test accuracy: 0.965600
Starting training epoch 39
Epoch : 40, Loss : 0.101276, Accuracy: 0.968000, Test accuracy: 0.965300
Starting training epoch 40
Epoch : 41, Loss : 0.096793, Accuracy: 0.972000, Test accuracy: 0.967700
Starting training epoch 41
Epoch : 42, Loss : 0.054485, Accuracy: 0.984000, Test accuracy: 0.966700
Starting training epoch 42
Epoch : 43, Loss : 0.111517, Accuracy: 0.964000, Test accuracy: 0.966600
Starting training epoch 43
Epoch : 44, Loss : 0.110665, Accuracy: 0.972000, Test accuracy: 0.967500
Starting training epoch 44
Epoch : 45, Loss : 0.050131, Accuracy: 0.988000, Test accuracy: 0.967100
Starting training epoch 45
Epoch : 46, Loss : 0.077390, Accuracy: 0.976000, Test accuracy: 0.968300
Starting training epoch 46
Epoch : 47, Loss : 0.186417, Accuracy: 0.952000, Test accuracy: 0.968100
Starting training epoch 47
Epoch : 48, Loss : 0.090507, Accuracy: 0.972000, Test accuracy: 0.968000
Starting training epoch 48
Epoch : 49, Loss : 0.149633, Accuracy: 0.948000, Test accuracy: 0.968400
Starting training epoch 49
Epoch : 50, Loss : 0.068720, Accuracy: 0.976000, Test accuracy: 0.968200
Student5::train
Starting training opoch 0
Epoch : 1, Loss : 1.028963, Accuracy: 0.776000, Test accuracy: 0.753200
Starting training opoch 1
Epoch : 2, Loss : 0.511511, Accuracy: 0.860000, Test accuracy: 0.865500
Starting training opoch 2
Epoch : 3, Loss : 0.376280, Accuracy: 0.896000, Test accuracy: 0.887800
Starting training opoch 3
Epoch : 4, Loss : 0.303683, Accuracy: 0.892000, Test accuracy: 0.897700
Starting training opoch 4
Epoch : 5, Loss : 0.417375, Accuracy: 0.896000, Test accuracy: 0.903200
Starting training opoch 5
Epoch : 6, Loss : 0.377739, Accuracy: 0.848000, Test accuracy: 0.905500
Starting training opoch 6
Epoch : 7, Loss : 0.343302, Accuracy: 0.888000, Test accuracy: 0.909300
Starting training opoch 7
Epoch : 8, Loss : 0.286959, Accuracy: 0.920000, Test accuracy: 0.911400
Starting training opoch 8
Epoch : 9, Loss : 0.285688, Accuracy: 0.912000, Test accuracy: 0.913100
Starting training opoch 9
Epoch : 10, Loss : 0.292420, Accuracy: 0.916000, Test accuracy: 0.913800
Starting training opoch 10
Epoch : 11, Loss : 0.337912, Accuracy: 0.904000, Test accuracy: 0.913100
Starting training opoch 11
Epoch : 12, Loss : 0.250020, Accuracy: 0.920000, Test accuracy: 0.916300
Starting training opoch 12
Epoch : 13, Loss : 0.251286, Accuracy: 0.928000, Test accuracy: 0.915700
Starting training opoch 13
Epoch : 14, Loss : 0.445026, Accuracy: 0.868000, Test accuracy: 0.916500
Starting training opoch 14
Epoch : 15, Loss : 0.268979, Accuracy: 0.908000, Test accuracy: 0.917100
Starting training opoch 15
Epoch : 16, Loss : 0.230972, Accuracy: 0.928000, Test accuracy: 0.917400
Starting training opoch 16
Epoch : 17, Loss : 0.288151, Accuracy: 0.892000, Test accuracy: 0.919100
Starting training opoch 17
Epoch : 18, Loss : 0.332631, Accuracy: 0.904000, Test accuracy: 0.919100
Starting training opoch 18
Epoch : 19, Loss : 0.305926, Accuracy: 0.932000, Test accuracy: 0.918900
Starting training opoch 19
Epoch : 20, Loss : 0.335295, Accuracy: 0.912000, Test accuracy: 0.921000
Starting training opoch 20
Epoch : 21, Loss : 0.345015, Accuracy: 0.892000, Test accuracy: 0.921900
Starting training opoch 21
Epoch : 22, Loss : 0.256018, Accuracy: 0.920000, Test accuracy: 0.922500
Starting training opoch 22
Epoch : 23, Loss : 0.285824, Accuracy: 0.920000, Test accuracy: 0.922200
Starting training opoch 23
Epoch : 24, Loss : 0.184288, Accuracy: 0.952000, Test accuracy: 0.921400
Starting training opoch 24
Epoch : 25, Loss : 0.292933, Accuracy: 0.920000, Test accuracy: 0.923000
Starting training opoch 25
Epoch : 26, Loss : 0.195024, Accuracy: 0.936000, Test accuracy: 0.922800
Starting training opoch 26
Epoch : 27, Loss : 0.284760, Accuracy: 0.900000, Test accuracy: 0.922600
Starting training opoch 27
Epoch : 28, Loss : 0.312963, Accuracy: 0.896000, Test accuracy: 0.923300
Starting training opoch 28
Epoch : 29, Loss : 0.322905, Accuracy: 0.928000, Test accuracy: 0.926500
Starting training opoch 29
Epoch : 30, Loss : 0.307888, Accuracy: 0.908000, Test accuracy: 0.925800
Starting training opoch 30
Epoch : 31, Loss : 0.254864, Accuracy: 0.924000, Test accuracy: 0.924800
Starting training opoch 31
Epoch : 32, Loss : 0.333615, Accuracy: 0.904000, Test accuracy: 0.926300
Starting training opoch 32
Epoch : 33, Loss : 0.289430, Accuracy: 0.928000, Test accuracy: 0.926700
Starting training opoch 33
Epoch : 34, Loss : 0.318917, Accuracy: 0.904000, Test accuracy: 0.925700
Starting training opoch 34
Epoch : 35, Loss : 0.313201, Accuracy: 0.908000, Test accuracy: 0.927000
Starting training opoch 35
Epoch : 36, Loss : 0.281126, Accuracy: 0.916000, Test accuracy: 0.926500
Starting training opoch 36
Epoch : 37, Loss : 0.296361, Accuracy: 0.932000, Test accuracy: 0.926700
Starting training opoch 37
Epoch : 38, Loss : 0.249573, Accuracy: 0.928000, Test accuracy: 0.928000
Starting training opoch 38
Epoch : 39, Loss : 0.206916, Accuracy: 0.928000, Test accuracy: 0.928200
Starting training opoch 39
Epoch : 40, Loss : 0.277620, Accuracy: 0.916000, Test accuracy: 0.929500
Starting training opoch 40
Epoch : 41, Loss : 0.286880, Accuracy: 0.904000, Test accuracy: 0.928800
Starting training opoch 41
Epoch : 42, Loss : 0.324061, Accuracy: 0.908000, Test accuracy: 0.929200
Starting training opoch 42
Epoch : 43, Loss : 0.228308, Accuracy: 0.932000, Test accuracy: 0.929000
Starting training opoch 43
Epoch : 44, Loss : 0.266820, Accuracy: 0.928000, Test accuracy: 0.929500
Starting training opoch 44
Epoch : 45, Loss : 0.236648, Accuracy: 0.932000, Test accuracy: 0.931100
Starting training opoch 45
Epoch : 46, Loss : 0.216968, Accuracy: 0.936000, Test accuracy: 0.929900
Starting training opoch 46
Epoch : 47, Loss : 0.203257, Accuracy: 0.932000, Test accuracy: 0.930700
Starting training opoch 47
Epoch : 48, Loss : 0.300223, Accuracy: 0.916000, Test accuracy: 0.931000
Starting training opoch 48
Epoch : 49, Loss : 0.202604, Accuracy: 0.940000, Test accuracy: 0.932100
Starting training opoch 49
Epoch : 50, Loss : 0.200433, Accuracy: 0.944000, Test accuracy: 0.931200
Student::train
Starting training epoch 0
Epoch : 1, Loss : 0.696505, Accuracy: 0.800000, Test accuracy: 0.831900
Starting training epoch 1
Epoch : 2, Loss : 0.392154, Accuracy: 0.912000, Test accuracy: 0.888600
Starting training epoch 2
Epoch : 3, Loss : 0.370136, Accuracy: 0.908000, Test accuracy: 0.904000
Starting training epoch 3
Epoch : 4, Loss : 0.235370, Accuracy: 0.928000, Test accuracy: 0.916100
Starting training epoch 4
Epoch : 5, Loss : 0.243149, Accuracy: 0.936000, Test accuracy: 0.922400
Starting training epoch 5
Epoch : 6, Loss : 0.210336, Accuracy: 0.940000, Test accuracy: 0.930500
Starting training epoch 6
Epoch : 7, Loss : 0.157004, Accuracy: 0.948000, Test accuracy: 0.939300
Starting training epoch 7
Epoch : 8, Loss : 0.181009, Accuracy: 0.940000, Test accuracy: 0.943600
Starting training epoch 8
Epoch : 9, Loss : 0.206045, Accuracy: 0.928000, Test accuracy: 0.948800
Starting training epoch 9
Epoch : 10, Loss : 0.165031, Accuracy: 0.944000, Test accuracy: 0.951100
Starting training epoch 10
Epoch : 11, Loss : 0.197240, Accuracy: 0.936000, Test accuracy: 0.954500
Starting training epoch 11
Epoch : 12, Loss : 0.150476, Accuracy: 0.956000, Test accuracy: 0.959200
Starting training epoch 12
Epoch : 13, Loss : 0.146640, Accuracy: 0.960000, Test accuracy: 0.960000
Starting training epoch 13
Epoch : 14, Loss : 0.138791, Accuracy: 0.960000, Test accuracy: 0.962200
Starting training epoch 14
Epoch : 15, Loss : 0.080928, Accuracy: 0.976000, Test accuracy: 0.964000
Starting training epoch 15
Epoch : 16, Loss : 0.065269, Accuracy: 0.976000, Test accuracy: 0.966300
Starting training epoch 16
Epoch : 17, Loss : 0.109503, Accuracy: 0.968000, Test accuracy: 0.967100
Starting training epoch 17
Epoch : 18, Loss : 0.118965, Accuracy: 0.960000, Test accuracy: 0.968200
Starting training epoch 18
Epoch : 19, Loss : 0.099632, Accuracy: 0.968000, Test accuracy: 0.969300
Starting training epoch 19
Epoch : 20, Loss : 0.152115, Accuracy: 0.956000, Test accuracy: 0.970900
Starting training epoch 20
Epoch : 21, Loss : 0.097145, Accuracy: 0.964000, Test accuracy: 0.970000
Starting training epoch 21
Epoch : 22, Loss : 0.092411, Accuracy: 0.968000, Test accuracy: 0.970600
Starting training epoch 22
Epoch : 23, Loss : 0.061434, Accuracy: 0.984000, Test accuracy: 0.972900
Starting training epoch 23
Epoch : 24, Loss : 0.077447, Accuracy: 0.984000, Test accuracy: 0.972400
Starting training epoch 24
Epoch : 25, Loss : 0.121311, Accuracy: 0.932000, Test accuracy: 0.974400
Starting training epoch 25
Epoch : 26, Loss : 0.043216, Accuracy: 0.988000, Test accuracy: 0.974000
Starting training epoch 26
Epoch : 27, Loss : 0.095038, Accuracy: 0.956000, Test accuracy: 0.974500
Starting training epoch 27
Epoch : 28, Loss : 0.064715, Accuracy: 0.976000, Test accuracy: 0.974000
Starting training epoch 28
Epoch : 29, Loss : 0.092079, Accuracy: 0.972000, Test accuracy: 0.974900
Starting training epoch 29
Epoch : 30, Loss : 0.154974, Accuracy: 0.960000, Test accuracy: 0.976700
Starting training epoch 30
Epoch : 31, Loss : 0.056841, Accuracy: 0.972000, Test accuracy: 0.974900
Starting training epoch 31
Epoch : 32, Loss : 0.081743, Accuracy: 0.980000, Test accuracy: 0.976800
Starting training epoch 32
Epoch : 33, Loss : 0.027678, Accuracy: 0.984000, Test accuracy: 0.977300
Starting training epoch 33
Epoch : 34, Loss : 0.052083, Accuracy: 0.984000, Test accuracy: 0.977600
Starting training epoch 34
Epoch : 35, Loss : 0.088026, Accuracy: 0.972000, Test accuracy: 0.978100
Starting training epoch 35
Epoch : 36, Loss : 0.078129, Accuracy: 0.976000, Test accuracy: 0.976900
Starting training epoch 36
Epoch : 37, Loss : 0.046993, Accuracy: 0.988000, Test accuracy: 0.978200
Starting training epoch 37
Epoch : 38, Loss : 0.103642, Accuracy: 0.968000, Test accuracy: 0.978400
Starting training epoch 38
Epoch : 39, Loss : 0.052320, Accuracy: 0.992000, Test accuracy: 0.978500
Starting training epoch 39
Epoch : 40, Loss : 0.046919, Accuracy: 0.988000, Test accuracy: 0.976900
Starting training epoch 40
Epoch : 41, Loss : 0.042344, Accuracy: 0.984000, Test accuracy: 0.978600
Starting training epoch 41
Epoch : 42, Loss : 0.071925, Accuracy: 0.980000, Test accuracy: 0.978300
Starting training epoch 42
Epoch : 43, Loss : 0.137211, Accuracy: 0.972000, Test accuracy: 0.978300
Starting training epoch 43
Epoch : 44, Loss : 0.059245, Accuracy: 0.988000, Test accuracy: 0.980000
Starting training epoch 44
Epoch : 45, Loss : 0.055946, Accuracy: 0.980000, Test accuracy: 0.979400
Starting training epoch 45
Epoch : 46, Loss : 0.038048, Accuracy: 0.992000, Test accuracy: 0.980200
Starting training epoch 46
Epoch : 47, Loss : 0.056148, Accuracy: 0.980000, Test accuracy: 0.979000
Starting training epoch 47
Epoch : 48, Loss : 0.074072, Accuracy: 0.984000, Test accuracy: 0.980100
Starting training epoch 48
Epoch : 49, Loss : 0.041958, Accuracy: 0.980000, Test accuracy: 0.979600
Starting training epoch 49
Epoch : 50, Loss : 0.119853, Accuracy: 0.968000, Test accuracy: 0.979900
Student2::train
Starting training opoch 0
Epoch : 1, Loss : 0.780062, Accuracy: 0.784000, Test accuracy: 0.835100
Starting training opoch 1
Epoch : 2, Loss : 0.435097, Accuracy: 0.896000, Test accuracy: 0.891400
Starting training opoch 2
Epoch : 3, Loss : 0.380163, Accuracy: 0.892000, Test accuracy: 0.909300
Starting training opoch 3
Epoch : 4, Loss : 0.259682, Accuracy: 0.936000, Test accuracy: 0.920700
Starting training opoch 4
Epoch : 5, Loss : 0.316776, Accuracy: 0.936000, Test accuracy: 0.927900
Starting training opoch 5
Epoch : 6, Loss : 0.221635, Accuracy: 0.932000, Test accuracy: 0.933500
Starting training opoch 6
Epoch : 7, Loss : 0.289499, Accuracy: 0.932000, Test accuracy: 0.936200
Starting training opoch 7
Epoch : 8, Loss : 0.191039, Accuracy: 0.948000, Test accuracy: 0.940800
Starting training opoch 8
Epoch : 9, Loss : 0.208174, Accuracy: 0.944000, Test accuracy: 0.942400
Starting training opoch 9
Epoch : 10, Loss : 0.159238, Accuracy: 0.964000, Test accuracy: 0.946800
Starting training opoch 10
Epoch : 11, Loss : 0.167600, Accuracy: 0.952000, Test accuracy: 0.948700
Starting training opoch 11
Epoch : 12, Loss : 0.152690, Accuracy: 0.956000, Test accuracy: 0.951000
Starting training opoch 12
Epoch : 13, Loss : 0.137468, Accuracy: 0.964000, Test accuracy: 0.953200
Starting training opoch 13
Epoch : 14, Loss : 0.174018, Accuracy: 0.948000, Test accuracy: 0.955900
Starting training opoch 14
Epoch : 15, Loss : 0.172699, Accuracy: 0.932000, Test accuracy: 0.957800
Starting training opoch 15
Epoch : 16, Loss : 0.179066, Accuracy: 0.948000, Test accuracy: 0.958500
Starting training opoch 16
Epoch : 17, Loss : 0.179803, Accuracy: 0.964000, Test accuracy: 0.959900
Starting training opoch 17
Epoch : 18, Loss : 0.184910, Accuracy: 0.948000, Test accuracy: 0.960600
Starting training opoch 18
Epoch : 19, Loss : 0.098704, Accuracy: 0.968000, Test accuracy: 0.961000
Starting training opoch 19
Epoch : 20, Loss : 0.117621, Accuracy: 0.972000, Test accuracy: 0.963500
Starting training opoch 20
Epoch : 21, Loss : 0.181217, Accuracy: 0.952000, Test accuracy: 0.964400
Starting training opoch 21
Epoch : 22, Loss : 0.111222, Accuracy: 0.972000, Test accuracy: 0.965900
Starting training opoch 22
Epoch : 23, Loss : 0.092581, Accuracy: 0.968000, Test accuracy: 0.965800
Starting training opoch 23
Epoch : 24, Loss : 0.037470, Accuracy: 0.996000, Test accuracy: 0.964900
Starting training opoch 24
Epoch : 25, Loss : 0.102742, Accuracy: 0.964000, Test accuracy: 0.967500
Starting training opoch 25
Epoch : 26, Loss : 0.109604, Accuracy: 0.968000, Test accuracy: 0.967200
Starting training opoch 26
Epoch : 27, Loss : 0.112434, Accuracy: 0.956000, Test accuracy: 0.969400
Starting training opoch 27
Epoch : 28, Loss : 0.083323, Accuracy: 0.968000, Test accuracy: 0.968600
Starting training opoch 28
Epoch : 29, Loss : 0.096895, Accuracy: 0.976000, Test accuracy: 0.969900
Starting training opoch 29
Epoch : 30, Loss : 0.113132, Accuracy: 0.960000, Test accuracy: 0.968800
Starting training opoch 30
Epoch : 31, Loss : 0.060688, Accuracy: 0.980000, Test accuracy: 0.968700
Starting training opoch 31
Epoch : 32, Loss : 0.081910, Accuracy: 0.976000, Test accuracy: 0.969800
Starting training opoch 32
Epoch : 33, Loss : 0.116925, Accuracy: 0.960000, Test accuracy: 0.970800
Starting training opoch 33
Epoch : 34, Loss : 0.140756, Accuracy: 0.972000, Test accuracy: 0.970900
Starting training opoch 34
Epoch : 35, Loss : 0.114288, Accuracy: 0.956000, Test accuracy: 0.971000
Starting training opoch 35
Epoch : 36, Loss : 0.217323, Accuracy: 0.940000, Test accuracy: 0.972800
Starting training opoch 36
Epoch : 37, Loss : 0.079727, Accuracy: 0.976000, Test accuracy: 0.971600
Starting training opoch 37
Epoch : 38, Loss : 0.071097, Accuracy: 0.972000, Test accuracy: 0.972600
Starting training opoch 38
Epoch : 39, Loss : 0.101355, Accuracy: 0.964000, Test accuracy: 0.972000
Starting training opoch 39
Epoch : 40, Loss : 0.122507, Accuracy: 0.968000, Test accuracy: 0.973100
Starting training opoch 40
Epoch : 41, Loss : 0.060786, Accuracy: 0.988000, Test accuracy: 0.972400
Starting training opoch 41
Epoch : 42, Loss : 0.109850, Accuracy: 0.964000, Test accuracy: 0.973400
Starting training opoch 42
Epoch : 43, Loss : 0.087917, Accuracy: 0.984000, Test accuracy: 0.973600
Starting training opoch 43
Epoch : 44, Loss : 0.111773, Accuracy: 0.968000, Test accuracy: 0.973500
Starting training opoch 44
Epoch : 45, Loss : 0.090572, Accuracy: 0.984000, Test accuracy: 0.973700
Starting training opoch 45
Epoch : 46, Loss : 0.139011, Accuracy: 0.972000, Test accuracy: 0.974000
Starting training opoch 46
Epoch : 47, Loss : 0.116308, Accuracy: 0.984000, Test accuracy: 0.974500
Starting training opoch 47
Epoch : 48, Loss : 0.064952, Accuracy: 0.988000, Test accuracy: 0.974300
Starting training opoch 48
Epoch : 49, Loss : 0.112065, Accuracy: 0.960000, Test accuracy: 0.974100
Starting training opoch 49
Epoch : 50, Loss : 0.139562, Accuracy: 0.980000, Test accuracy: 0.974900
Student3::train
Starting training opoch 0
Epoch : 1, Loss : 0.848261, Accuracy: 0.760000, Test accuracy: 0.806100
Starting training opoch 1
Epoch : 2, Loss : 0.476460, Accuracy: 0.864000, Test accuracy: 0.872000
Starting training opoch 2
Epoch : 3, Loss : 0.456883, Accuracy: 0.864000, Test accuracy: 0.888600
Starting training opoch 3
Epoch : 4, Loss : 0.407403, Accuracy: 0.908000, Test accuracy: 0.899800
Starting training opoch 4
Epoch : 5, Loss : 0.355425, Accuracy: 0.892000, Test accuracy: 0.907000
Starting training opoch 5
Epoch : 6, Loss : 0.316427, Accuracy: 0.904000, Test accuracy: 0.909100
Starting training opoch 6
Epoch : 7, Loss : 0.358346, Accuracy: 0.888000, Test accuracy: 0.912100
Starting training opoch 7
Epoch : 8, Loss : 0.298462, Accuracy: 0.916000, Test accuracy: 0.915300
Starting training opoch 8
Epoch : 9, Loss : 0.317361, Accuracy: 0.936000, Test accuracy: 0.916200
Starting training opoch 9
Epoch : 10, Loss : 0.266290, Accuracy: 0.932000, Test accuracy: 0.918500
Starting training opoch 10
Epoch : 11, Loss : 0.275171, Accuracy: 0.928000, Test accuracy: 0.920600
Starting training opoch 11
Epoch : 12, Loss : 0.259724, Accuracy: 0.924000, Test accuracy: 0.922800
Starting training opoch 12
Epoch : 13, Loss : 0.218830, Accuracy: 0.940000, Test accuracy: 0.924900
Starting training opoch 13
Epoch : 14, Loss : 0.282748, Accuracy: 0.928000, Test accuracy: 0.924600
Starting training opoch 14
Epoch : 15, Loss : 0.278737, Accuracy: 0.920000, Test accuracy: 0.927600
Starting training opoch 15
Epoch : 16, Loss : 0.232955, Accuracy: 0.920000, Test accuracy: 0.928400
Starting training opoch 16
Epoch : 17, Loss : 0.218565, Accuracy: 0.944000, Test accuracy: 0.929600
Starting training opoch 17
Epoch : 18, Loss : 0.162846, Accuracy: 0.948000, Test accuracy: 0.931500
Starting training opoch 18
Epoch : 19, Loss : 0.318084, Accuracy: 0.940000, Test accuracy: 0.931300
Starting training opoch 19
Epoch : 20, Loss : 0.247380, Accuracy: 0.956000, Test accuracy: 0.932900
Starting training opoch 20
Epoch : 21, Loss : 0.308848, Accuracy: 0.920000, Test accuracy: 0.934400
Starting training opoch 21
Epoch : 22, Loss : 0.207404, Accuracy: 0.928000, Test accuracy: 0.934500
Starting training opoch 22
Epoch : 23, Loss : 0.249096, Accuracy: 0.932000, Test accuracy: 0.935800
Starting training opoch 23
Epoch : 24, Loss : 0.150476, Accuracy: 0.960000, Test accuracy: 0.934600
Starting training opoch 24
Epoch : 25, Loss : 0.318569, Accuracy: 0.916000, Test accuracy: 0.937300
Starting training opoch 25
Epoch : 26, Loss : 0.281073, Accuracy: 0.912000, Test accuracy: 0.939200
Starting training opoch 26
Epoch : 27, Loss : 0.234078, Accuracy: 0.936000, Test accuracy: 0.939000
Starting training opoch 27
Epoch : 28, Loss : 0.236450, Accuracy: 0.940000, Test accuracy: 0.939500
Starting training opoch 28
Epoch : 29, Loss : 0.172314, Accuracy: 0.948000, Test accuracy: 0.940900
Starting training opoch 29
Epoch : 30, Loss : 0.209046, Accuracy: 0.944000, Test accuracy: 0.940500
Starting training opoch 30
Epoch : 31, Loss : 0.193692, Accuracy: 0.948000, Test accuracy: 0.942000
Starting training opoch 31
Epoch : 32, Loss : 0.154765, Accuracy: 0.948000, Test accuracy: 0.941700
Starting training opoch 32
Epoch : 33, Loss : 0.250427, Accuracy: 0.916000, Test accuracy: 0.941900
Starting training opoch 33
Epoch : 34, Loss : 0.140440, Accuracy: 0.964000, Test accuracy: 0.943500
Starting training opoch 34
Epoch : 35, Loss : 0.199625, Accuracy: 0.936000, Test accuracy: 0.940600
Starting training opoch 35
Epoch : 36, Loss : 0.165728, Accuracy: 0.936000, Test accuracy: 0.943100
Starting training opoch 36
Epoch : 37, Loss : 0.203928, Accuracy: 0.944000, Test accuracy: 0.946000
Starting training opoch 37
Epoch : 38, Loss : 0.217554, Accuracy: 0.944000, Test accuracy: 0.944800
Starting training opoch 38
Epoch : 39, Loss : 0.138333, Accuracy: 0.960000, Test accuracy: 0.945800
Starting training opoch 39
Epoch : 40, Loss : 0.207872, Accuracy: 0.920000, Test accuracy: 0.945900
Starting training opoch 40
Epoch : 41, Loss : 0.149989, Accuracy: 0.948000, Test accuracy: 0.947000
Starting training opoch 41
Epoch : 42, Loss : 0.132733, Accuracy: 0.952000, Test accuracy: 0.947800
Starting training opoch 42
Epoch : 43, Loss : 0.154386, Accuracy: 0.948000, Test accuracy: 0.947700
Starting training opoch 43
Epoch : 44, Loss : 0.181759, Accuracy: 0.952000, Test accuracy: 0.947200
Starting training opoch 44
Epoch : 45, Loss : 0.122121, Accuracy: 0.968000, Test accuracy: 0.948700
Starting training opoch 45
Epoch : 46, Loss : 0.165403, Accuracy: 0.956000, Test accuracy: 0.947600
Starting training opoch 46
Epoch : 47, Loss : 0.136318, Accuracy: 0.960000, Test accuracy: 0.948600
Starting training opoch 47
Epoch : 48, Loss : 0.186682, Accuracy: 0.952000, Test accuracy: 0.949600
Starting training opoch 48
Epoch : 49, Loss : 0.201345, Accuracy: 0.952000, Test accuracy: 0.950000
Starting training opoch 49
Epoch : 50, Loss : 0.150047, Accuracy: 0.956000, Test accuracy: 0.949800
distillating
Loading from teacher/teacher.ckpt
Accuracy on the test set
0.9933
Generating soft targets at T = 1
Generating soft targets at T = 3
Generating soft targets at T = 6
Generating soft targets at T = 7
Generating soft targets at T = 8
Generating soft targets at T = 9
Generating soft targets at T = 10
Generating soft targets at T = 11
Generating soft targets at T = 12
Generating soft targets at T = 15
Generating soft targets at T = 20
Distillation: Epoch : 1, Loss : 0.643124, Accuracy: 0.827000, Test accuracy: 0.836200
Distillation: Epoch : 2, Loss : 0.389666, Accuracy: 0.889000, Test accuracy: 0.890900
Distillation: Epoch : 3, Loss : 0.363939, Accuracy: 0.893000, Test accuracy: 0.902800
Distillation: Epoch : 4, Loss : 0.338822, Accuracy: 0.906000, Test accuracy: 0.908900
Distillation: Epoch : 5, Loss : 0.311576, Accuracy: 0.912000, Test accuracy: 0.915000
Distillation: Epoch : 6, Loss : 0.272960, Accuracy: 0.923000, Test accuracy: 0.918800
Distillation: Epoch : 7, Loss : 0.306375, Accuracy: 0.897000, Test accuracy: 0.921100
Distillation: Epoch : 8, Loss : 0.270308, Accuracy: 0.919000, Test accuracy: 0.924900
Distillation: Epoch : 9, Loss : 0.254802, Accuracy: 0.922000, Test accuracy: 0.927000
Distillation: Epoch : 10, Loss : 0.219393, Accuracy: 0.943000, Test accuracy: 0.932100
Distillation: Epoch : 11, Loss : 0.236678, Accuracy: 0.931000, Test accuracy: 0.932900
Distillation: Epoch : 12, Loss : 0.242144, Accuracy: 0.923000, Test accuracy: 0.934700
Distillation: Epoch : 13, Loss : 0.227173, Accuracy: 0.942000, Test accuracy: 0.938700
Distillation: Epoch : 14, Loss : 0.209029, Accuracy: 0.945000, Test accuracy: 0.940300
Distillation: Epoch : 15, Loss : 0.220163, Accuracy: 0.939000, Test accuracy: 0.943400
Distillation: Epoch : 16, Loss : 0.193942, Accuracy: 0.939000, Test accuracy: 0.945300
Distillation: Epoch : 17, Loss : 0.195538, Accuracy: 0.931000, Test accuracy: 0.946700
Distillation: Epoch : 18, Loss : 0.198550, Accuracy: 0.940000, Test accuracy: 0.949400
Distillation: Epoch : 19, Loss : 0.177767, Accuracy: 0.946000, Test accuracy: 0.951000
Distillation: Epoch : 20, Loss : 0.193222, Accuracy: 0.944000, Test accuracy: 0.953000
Distillation: Epoch : 21, Loss : 0.154810, Accuracy: 0.954000, Test accuracy: 0.951500
Distillation: Epoch : 22, Loss : 0.149301, Accuracy: 0.955000, Test accuracy: 0.955500
Distillation: Epoch : 23, Loss : 0.127803, Accuracy: 0.960000, Test accuracy: 0.956200
Distillation: Epoch : 24, Loss : 0.136658, Accuracy: 0.964000, Test accuracy: 0.958200
Distillation: Epoch : 25, Loss : 0.132813, Accuracy: 0.964000, Test accuracy: 0.957600
Distillation: Epoch : 26, Loss : 0.144454, Accuracy: 0.960000, Test accuracy: 0.958700
Distillation: Epoch : 27, Loss : 0.144582, Accuracy: 0.959000, Test accuracy: 0.960600
Distillation: Epoch : 28, Loss : 0.134351, Accuracy: 0.959000, Test accuracy: 0.960500
Distillation: Epoch : 29, Loss : 0.144481, Accuracy: 0.956000, Test accuracy: 0.962100
Distillation: Epoch : 30, Loss : 0.152382, Accuracy: 0.954000, Test accuracy: 0.963400
Distillation: Epoch : 31, Loss : 0.122224, Accuracy: 0.962000, Test accuracy: 0.962000
Distillation: Epoch : 32, Loss : 0.123875, Accuracy: 0.965000, Test accuracy: 0.962400
Distillation: Epoch : 33, Loss : 0.153054, Accuracy: 0.950000, Test accuracy: 0.965000
Distillation: Epoch : 34, Loss : 0.141204, Accuracy: 0.958000, Test accuracy: 0.964800
Distillation: Epoch : 35, Loss : 0.094651, Accuracy: 0.970000, Test accuracy: 0.965100
Distillation: Epoch : 36, Loss : 0.165348, Accuracy: 0.948000, Test accuracy: 0.964800
Distillation: Epoch : 37, Loss : 0.157424, Accuracy: 0.952000, Test accuracy: 0.966100
Distillation: Epoch : 38, Loss : 0.137857, Accuracy: 0.957000, Test accuracy: 0.966000
Distillation: Epoch : 39, Loss : 0.119002, Accuracy: 0.966000, Test accuracy: 0.964700
Distillation: Epoch : 40, Loss : 0.106407, Accuracy: 0.967000, Test accuracy: 0.966500
Distillation: Epoch : 41, Loss : 0.129557, Accuracy: 0.963000, Test accuracy: 0.965100
Distillation: Epoch : 42, Loss : 0.149409, Accuracy: 0.962000, Test accuracy: 0.967200
Distillation: Epoch : 43, Loss : 0.104989, Accuracy: 0.969000, Test accuracy: 0.967000
Distillation: Epoch : 44, Loss : 0.099600, Accuracy: 0.970000, Test accuracy: 0.966200
Distillation: Epoch : 45, Loss : 0.123644, Accuracy: 0.963000, Test accuracy: 0.967500
Distillation: Epoch : 46, Loss : 0.099295, Accuracy: 0.960000, Test accuracy: 0.967500
Distillation: Epoch : 47, Loss : 0.109644, Accuracy: 0.972000, Test accuracy: 0.967000
Distillation: Epoch : 48, Loss : 0.132558, Accuracy: 0.960000, Test accuracy: 0.967100
Distillation: Epoch : 49, Loss : 0.098436, Accuracy: 0.965000, Test accuracy: 0.967200
Distillation: Epoch : 50, Loss : 0.112944, Accuracy: 0.964000, Test accuracy: 0.968600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9686
Generating confusion matrix for student4
[[ 973.    0.    4.    1.    1.    2.    9.    2.    9.    7.]
 [   0. 1121.    9.    1.    1.    3.    3.    5.    2.    6.]
 [   1.    4.  993.    9.    3.    1.    1.   15.    2.    2.]
 [   0.    0.    6.  967.    0.   11.    1.    4.    4.    6.]
 [   0.    0.    3.    1.  960.    0.    3.    2.    5.   16.]
 [   0.    0.    1.   12.    0.  860.    1.    0.    3.    6.]
 [   2.    2.    0.    0.    3.    4.  934.    0.    9.    0.]
 [   1.    1.    7.    6.    1.    3.    0.  991.    7.    8.]
 [   3.    7.    8.    9.    3.    4.    6.    1.  931.    2.]
 [   0.    0.    1.    4.   10.    4.    0.    8.    2.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.926688, Accuracy: 0.795000, Test accuracy: 0.812900
Distillation: Epoch : 2, Loss : 0.494989, Accuracy: 0.862000, Test accuracy: 0.876300
Distillation: Epoch : 3, Loss : 0.410090, Accuracy: 0.875000, Test accuracy: 0.894000
Distillation: Epoch : 4, Loss : 0.353709, Accuracy: 0.895000, Test accuracy: 0.902900
Distillation: Epoch : 5, Loss : 0.366833, Accuracy: 0.901000, Test accuracy: 0.908700
Distillation: Epoch : 6, Loss : 0.347793, Accuracy: 0.914000, Test accuracy: 0.913900
Distillation: Epoch : 7, Loss : 0.294954, Accuracy: 0.918000, Test accuracy: 0.917600
Distillation: Epoch : 8, Loss : 0.332858, Accuracy: 0.907000, Test accuracy: 0.920500
Distillation: Epoch : 9, Loss : 0.259774, Accuracy: 0.939000, Test accuracy: 0.924200
Distillation: Epoch : 10, Loss : 0.287908, Accuracy: 0.922000, Test accuracy: 0.927400
Distillation: Epoch : 11, Loss : 0.326183, Accuracy: 0.910000, Test accuracy: 0.929900
Distillation: Epoch : 12, Loss : 0.273407, Accuracy: 0.918000, Test accuracy: 0.933300
Distillation: Epoch : 13, Loss : 0.253618, Accuracy: 0.930000, Test accuracy: 0.936200
Distillation: Epoch : 14, Loss : 0.232446, Accuracy: 0.940000, Test accuracy: 0.939600
Distillation: Epoch : 15, Loss : 0.223450, Accuracy: 0.938000, Test accuracy: 0.941700
Distillation: Epoch : 16, Loss : 0.248200, Accuracy: 0.938000, Test accuracy: 0.943100
Distillation: Epoch : 17, Loss : 0.218804, Accuracy: 0.939000, Test accuracy: 0.945900
Distillation: Epoch : 18, Loss : 0.204302, Accuracy: 0.947000, Test accuracy: 0.948000
Distillation: Epoch : 19, Loss : 0.218646, Accuracy: 0.941000, Test accuracy: 0.948900
Distillation: Epoch : 20, Loss : 0.168391, Accuracy: 0.956000, Test accuracy: 0.951500
Distillation: Epoch : 21, Loss : 0.205661, Accuracy: 0.940000, Test accuracy: 0.952800
Distillation: Epoch : 22, Loss : 0.216090, Accuracy: 0.938000, Test accuracy: 0.953900
Distillation: Epoch : 23, Loss : 0.171520, Accuracy: 0.958000, Test accuracy: 0.955800
Distillation: Epoch : 24, Loss : 0.183351, Accuracy: 0.949000, Test accuracy: 0.957000
Distillation: Epoch : 25, Loss : 0.167796, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 26, Loss : 0.196449, Accuracy: 0.955000, Test accuracy: 0.959300
Distillation: Epoch : 27, Loss : 0.200736, Accuracy: 0.953000, Test accuracy: 0.959900
Distillation: Epoch : 28, Loss : 0.151056, Accuracy: 0.956000, Test accuracy: 0.960600
Distillation: Epoch : 29, Loss : 0.178184, Accuracy: 0.956000, Test accuracy: 0.962200
Distillation: Epoch : 30, Loss : 0.156122, Accuracy: 0.956000, Test accuracy: 0.961300
Distillation: Epoch : 31, Loss : 0.131579, Accuracy: 0.969000, Test accuracy: 0.961800
Distillation: Epoch : 32, Loss : 0.163383, Accuracy: 0.952000, Test accuracy: 0.963000
Distillation: Epoch : 33, Loss : 0.142944, Accuracy: 0.962000, Test accuracy: 0.963100
Distillation: Epoch : 34, Loss : 0.149737, Accuracy: 0.962000, Test accuracy: 0.964000
Distillation: Epoch : 35, Loss : 0.140932, Accuracy: 0.965000, Test accuracy: 0.964000
Distillation: Epoch : 36, Loss : 0.153174, Accuracy: 0.958000, Test accuracy: 0.964700
Distillation: Epoch : 37, Loss : 0.156711, Accuracy: 0.970000, Test accuracy: 0.965300
Distillation: Epoch : 38, Loss : 0.130657, Accuracy: 0.967000, Test accuracy: 0.965500
Distillation: Epoch : 39, Loss : 0.126087, Accuracy: 0.976000, Test accuracy: 0.966000
Distillation: Epoch : 40, Loss : 0.148926, Accuracy: 0.963000, Test accuracy: 0.966200
Distillation: Epoch : 41, Loss : 0.157762, Accuracy: 0.962000, Test accuracy: 0.966600
Distillation: Epoch : 42, Loss : 0.139069, Accuracy: 0.964000, Test accuracy: 0.965800
Distillation: Epoch : 43, Loss : 0.126939, Accuracy: 0.971000, Test accuracy: 0.968500
Distillation: Epoch : 44, Loss : 0.149655, Accuracy: 0.965000, Test accuracy: 0.966700
Distillation: Epoch : 45, Loss : 0.123127, Accuracy: 0.971000, Test accuracy: 0.968300
Distillation: Epoch : 46, Loss : 0.141807, Accuracy: 0.969000, Test accuracy: 0.967100
Distillation: Epoch : 47, Loss : 0.139331, Accuracy: 0.971000, Test accuracy: 0.969300
Distillation: Epoch : 48, Loss : 0.117778, Accuracy: 0.977000, Test accuracy: 0.968400
Distillation: Epoch : 49, Loss : 0.151910, Accuracy: 0.970000, Test accuracy: 0.968700
Distillation: Epoch : 50, Loss : 0.147080, Accuracy: 0.969000, Test accuracy: 0.969600
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9696
Generating confusion matrix for student4
[[ 972.    0.    1.    0.    2.    2.    6.    0.    6.    5.]
 [   0. 1119.    8.    0.    1.    1.    3.    6.    3.    5.]
 [   1.    6.  996.    9.    2.    1.    1.   23.    4.    1.]
 [   0.    0.    7.  982.    0.   11.    1.    5.   11.    8.]
 [   0.    0.    3.    0.  958.    0.    3.    2.    3.    9.]
 [   2.    0.    0.    4.    0.  864.    4.    2.    4.    3.]
 [   1.    2.    1.    0.    4.    4.  935.    0.    4.    0.]
 [   2.    1.    5.    4.    1.    2.    0.  977.    4.   10.]
 [   2.    7.    9.    8.    3.    5.    5.    3.  932.    7.]
 [   0.    0.    2.    3.   11.    2.    0.   10.    3.  961.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.655330, Accuracy: 0.704000, Test accuracy: 0.716700
Distillation: Epoch : 2, Loss : 0.829189, Accuracy: 0.850000, Test accuracy: 0.850100
Distillation: Epoch : 3, Loss : 0.716016, Accuracy: 0.864000, Test accuracy: 0.882600
Distillation: Epoch : 4, Loss : 0.619321, Accuracy: 0.900000, Test accuracy: 0.901100
Distillation: Epoch : 5, Loss : 0.648144, Accuracy: 0.896000, Test accuracy: 0.909900
Distillation: Epoch : 6, Loss : 0.626708, Accuracy: 0.905000, Test accuracy: 0.915000
Distillation: Epoch : 7, Loss : 0.588871, Accuracy: 0.917000, Test accuracy: 0.919800
Distillation: Epoch : 8, Loss : 0.552862, Accuracy: 0.916000, Test accuracy: 0.924300
Distillation: Epoch : 9, Loss : 0.578086, Accuracy: 0.921000, Test accuracy: 0.931600
Distillation: Epoch : 10, Loss : 0.517613, Accuracy: 0.947000, Test accuracy: 0.934300
Distillation: Epoch : 11, Loss : 0.546827, Accuracy: 0.923000, Test accuracy: 0.937900
Distillation: Epoch : 12, Loss : 0.519594, Accuracy: 0.940000, Test accuracy: 0.938900
Distillation: Epoch : 13, Loss : 0.538307, Accuracy: 0.935000, Test accuracy: 0.943200
Distillation: Epoch : 14, Loss : 0.513519, Accuracy: 0.946000, Test accuracy: 0.945700
Distillation: Epoch : 15, Loss : 0.523775, Accuracy: 0.944000, Test accuracy: 0.948400
Distillation: Epoch : 16, Loss : 0.502180, Accuracy: 0.955000, Test accuracy: 0.951100
Distillation: Epoch : 17, Loss : 0.515616, Accuracy: 0.952000, Test accuracy: 0.952900
Distillation: Epoch : 18, Loss : 0.520717, Accuracy: 0.948000, Test accuracy: 0.953800
Distillation: Epoch : 19, Loss : 0.503072, Accuracy: 0.954000, Test accuracy: 0.954600
Distillation: Epoch : 20, Loss : 0.511148, Accuracy: 0.952000, Test accuracy: 0.958200
Distillation: Epoch : 21, Loss : 0.509534, Accuracy: 0.951000, Test accuracy: 0.957900
Distillation: Epoch : 22, Loss : 0.486003, Accuracy: 0.957000, Test accuracy: 0.960000
Distillation: Epoch : 23, Loss : 0.482911, Accuracy: 0.955000, Test accuracy: 0.960700
Distillation: Epoch : 24, Loss : 0.458430, Accuracy: 0.959000, Test accuracy: 0.961400
Distillation: Epoch : 25, Loss : 0.490477, Accuracy: 0.956000, Test accuracy: 0.961600
Distillation: Epoch : 26, Loss : 0.491466, Accuracy: 0.949000, Test accuracy: 0.963100
Distillation: Epoch : 27, Loss : 0.460001, Accuracy: 0.963000, Test accuracy: 0.964000
Distillation: Epoch : 28, Loss : 0.471075, Accuracy: 0.952000, Test accuracy: 0.964600
Distillation: Epoch : 29, Loss : 0.470956, Accuracy: 0.952000, Test accuracy: 0.964200
Distillation: Epoch : 30, Loss : 0.484324, Accuracy: 0.962000, Test accuracy: 0.964600
Distillation: Epoch : 31, Loss : 0.466472, Accuracy: 0.966000, Test accuracy: 0.965800
Distillation: Epoch : 32, Loss : 0.485845, Accuracy: 0.959000, Test accuracy: 0.966500
Distillation: Epoch : 33, Loss : 0.467558, Accuracy: 0.953000, Test accuracy: 0.966400
Distillation: Epoch : 34, Loss : 0.462930, Accuracy: 0.958000, Test accuracy: 0.965900
Distillation: Epoch : 35, Loss : 0.470341, Accuracy: 0.960000, Test accuracy: 0.966000
Distillation: Epoch : 36, Loss : 0.458221, Accuracy: 0.956000, Test accuracy: 0.966600
Distillation: Epoch : 37, Loss : 0.473773, Accuracy: 0.961000, Test accuracy: 0.967200
Distillation: Epoch : 38, Loss : 0.461048, Accuracy: 0.958000, Test accuracy: 0.965500
Distillation: Epoch : 39, Loss : 0.446553, Accuracy: 0.968000, Test accuracy: 0.967600
Distillation: Epoch : 40, Loss : 0.447484, Accuracy: 0.971000, Test accuracy: 0.966800
Distillation: Epoch : 41, Loss : 0.443149, Accuracy: 0.973000, Test accuracy: 0.966600
Distillation: Epoch : 42, Loss : 0.449220, Accuracy: 0.966000, Test accuracy: 0.966700
Distillation: Epoch : 43, Loss : 0.490442, Accuracy: 0.954000, Test accuracy: 0.968100
Distillation: Epoch : 44, Loss : 0.445992, Accuracy: 0.970000, Test accuracy: 0.967200
Distillation: Epoch : 45, Loss : 0.442336, Accuracy: 0.953000, Test accuracy: 0.967900
Distillation: Epoch : 46, Loss : 0.469239, Accuracy: 0.959000, Test accuracy: 0.968100
Distillation: Epoch : 47, Loss : 0.469699, Accuracy: 0.962000, Test accuracy: 0.968200
Distillation: Epoch : 48, Loss : 0.465967, Accuracy: 0.962000, Test accuracy: 0.967000
Distillation: Epoch : 49, Loss : 0.446147, Accuracy: 0.965000, Test accuracy: 0.968200
Distillation: Epoch : 50, Loss : 0.475779, Accuracy: 0.962000, Test accuracy: 0.968700
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9687
Generating confusion matrix for student4
[[ 963.    0.    4.    0.    1.    1.    6.    1.    5.    7.]
 [   1. 1120.    8.    0.    0.    0.    2.    2.    1.    6.]
 [   1.    3.  991.    3.    3.    1.    2.   18.    6.    1.]
 [   0.    0.    3.  983.    0.   11.    0.    7.    6.   10.]
 [   1.    0.    3.    0.  957.    1.    2.    1.    4.    6.]
 [   2.    1.    0.    5.    0.  862.    7.    2.    6.    8.]
 [   7.    5.    2.    0.    6.    4.  937.    0.    2.    0.]
 [   2.    0.    3.    6.    1.    1.    0.  979.    4.    9.]
 [   3.    6.   17.   10.    4.    9.    2.    4.  934.    1.]
 [   0.    0.    1.    3.   10.    2.    0.   14.    6.  961.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.198469, Accuracy: 0.770000, Test accuracy: 0.766300
Distillation: Epoch : 2, Loss : 0.937865, Accuracy: 0.838000, Test accuracy: 0.864000
Distillation: Epoch : 3, Loss : 0.850539, Accuracy: 0.875000, Test accuracy: 0.883200
Distillation: Epoch : 4, Loss : 0.844902, Accuracy: 0.893000, Test accuracy: 0.891200
Distillation: Epoch : 5, Loss : 0.834940, Accuracy: 0.890000, Test accuracy: 0.896200
Distillation: Epoch : 6, Loss : 0.827304, Accuracy: 0.893000, Test accuracy: 0.900300
Distillation: Epoch : 7, Loss : 0.834417, Accuracy: 0.895000, Test accuracy: 0.902500
Distillation: Epoch : 8, Loss : 0.811681, Accuracy: 0.891000, Test accuracy: 0.902000
Distillation: Epoch : 9, Loss : 0.805231, Accuracy: 0.896000, Test accuracy: 0.907200
Distillation: Epoch : 10, Loss : 0.784108, Accuracy: 0.905000, Test accuracy: 0.906800
Distillation: Epoch : 11, Loss : 0.773579, Accuracy: 0.920000, Test accuracy: 0.909500
Distillation: Epoch : 12, Loss : 0.789393, Accuracy: 0.911000, Test accuracy: 0.911600
Distillation: Epoch : 13, Loss : 0.777266, Accuracy: 0.896000, Test accuracy: 0.911300
Distillation: Epoch : 14, Loss : 0.792505, Accuracy: 0.909000, Test accuracy: 0.914400
Distillation: Epoch : 15, Loss : 0.799224, Accuracy: 0.914000, Test accuracy: 0.915400
Distillation: Epoch : 16, Loss : 0.796600, Accuracy: 0.905000, Test accuracy: 0.916600
Distillation: Epoch : 17, Loss : 0.734391, Accuracy: 0.928000, Test accuracy: 0.918200
Distillation: Epoch : 18, Loss : 0.761122, Accuracy: 0.918000, Test accuracy: 0.920800
Distillation: Epoch : 19, Loss : 0.772298, Accuracy: 0.922000, Test accuracy: 0.922700
Distillation: Epoch : 20, Loss : 0.705759, Accuracy: 0.926000, Test accuracy: 0.926000
Distillation: Epoch : 21, Loss : 0.733294, Accuracy: 0.936000, Test accuracy: 0.927800
Distillation: Epoch : 22, Loss : 0.745606, Accuracy: 0.932000, Test accuracy: 0.930300
Distillation: Epoch : 23, Loss : 0.729598, Accuracy: 0.937000, Test accuracy: 0.931800
Distillation: Epoch : 24, Loss : 0.712491, Accuracy: 0.929000, Test accuracy: 0.936400
Distillation: Epoch : 25, Loss : 0.716364, Accuracy: 0.941000, Test accuracy: 0.935500
Distillation: Epoch : 26, Loss : 0.714767, Accuracy: 0.937000, Test accuracy: 0.938200
Distillation: Epoch : 27, Loss : 0.697130, Accuracy: 0.947000, Test accuracy: 0.939800
Distillation: Epoch : 28, Loss : 0.679551, Accuracy: 0.953000, Test accuracy: 0.942800
Distillation: Epoch : 29, Loss : 0.690010, Accuracy: 0.935000, Test accuracy: 0.944000
Distillation: Epoch : 30, Loss : 0.672417, Accuracy: 0.935000, Test accuracy: 0.945000
Distillation: Epoch : 31, Loss : 0.679903, Accuracy: 0.942000, Test accuracy: 0.946200
Distillation: Epoch : 32, Loss : 0.715947, Accuracy: 0.931000, Test accuracy: 0.946500
Distillation: Epoch : 33, Loss : 0.723608, Accuracy: 0.933000, Test accuracy: 0.946900
Distillation: Epoch : 34, Loss : 0.680734, Accuracy: 0.951000, Test accuracy: 0.948200
Distillation: Epoch : 35, Loss : 0.707660, Accuracy: 0.941000, Test accuracy: 0.949000
Distillation: Epoch : 36, Loss : 0.667120, Accuracy: 0.956000, Test accuracy: 0.950500
Distillation: Epoch : 37, Loss : 0.653924, Accuracy: 0.956000, Test accuracy: 0.950900
Distillation: Epoch : 38, Loss : 0.661597, Accuracy: 0.956000, Test accuracy: 0.951800
Distillation: Epoch : 39, Loss : 0.711351, Accuracy: 0.942000, Test accuracy: 0.952300
Distillation: Epoch : 40, Loss : 0.662622, Accuracy: 0.951000, Test accuracy: 0.952800
Distillation: Epoch : 41, Loss : 0.694174, Accuracy: 0.945000, Test accuracy: 0.953100
Distillation: Epoch : 42, Loss : 0.689023, Accuracy: 0.947000, Test accuracy: 0.954200
Distillation: Epoch : 43, Loss : 0.648218, Accuracy: 0.951000, Test accuracy: 0.954200
Distillation: Epoch : 44, Loss : 0.672695, Accuracy: 0.949000, Test accuracy: 0.953300
Distillation: Epoch : 45, Loss : 0.668634, Accuracy: 0.947000, Test accuracy: 0.956100
Distillation: Epoch : 46, Loss : 0.648978, Accuracy: 0.957000, Test accuracy: 0.955100
Distillation: Epoch : 47, Loss : 0.650307, Accuracy: 0.957000, Test accuracy: 0.956100
Distillation: Epoch : 48, Loss : 0.662064, Accuracy: 0.952000, Test accuracy: 0.956200
Distillation: Epoch : 49, Loss : 0.657149, Accuracy: 0.949000, Test accuracy: 0.955400
Distillation: Epoch : 50, Loss : 0.683840, Accuracy: 0.945000, Test accuracy: 0.956000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.956
Generating confusion matrix for student4
[[ 954.    0.    1.    0.    0.    2.    4.    0.    5.    3.]
 [   1. 1115.    3.    0.    1.    1.    2.    5.    3.    5.]
 [   2.    3.  984.    8.    7.    1.    0.   20.    7.    4.]
 [   0.    1.    8.  971.    1.   21.    0.    8.   20.   14.]
 [   2.    0.    3.    2.  928.    1.    3.    0.    6.   12.]
 [   6.    1.    2.    8.    1.  847.   14.    2.   13.    9.]
 [   8.    6.    3.    0.    8.    4.  931.    0.    3.    0.]
 [   2.    1.    5.    6.    3.    1.    1.  977.    4.    9.]
 [   4.    8.   20.   12.    5.   11.    3.    2.  908.    8.]
 [   1.    0.    3.    3.   28.    3.    0.   14.    5.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.539430, Accuracy: 0.728000, Test accuracy: 0.755000
Distillation: Epoch : 2, Loss : 1.076887, Accuracy: 0.855000, Test accuracy: 0.854200
Distillation: Epoch : 3, Loss : 1.015178, Accuracy: 0.876000, Test accuracy: 0.879100
Distillation: Epoch : 4, Loss : 1.005503, Accuracy: 0.881000, Test accuracy: 0.889000
Distillation: Epoch : 5, Loss : 0.959063, Accuracy: 0.908000, Test accuracy: 0.898800
Distillation: Epoch : 6, Loss : 0.965189, Accuracy: 0.886000, Test accuracy: 0.904600
Distillation: Epoch : 7, Loss : 0.953671, Accuracy: 0.914000, Test accuracy: 0.910200
Distillation: Epoch : 8, Loss : 0.916037, Accuracy: 0.917000, Test accuracy: 0.913800
Distillation: Epoch : 9, Loss : 0.936456, Accuracy: 0.909000, Test accuracy: 0.919400
Distillation: Epoch : 10, Loss : 0.902866, Accuracy: 0.917000, Test accuracy: 0.921800
Distillation: Epoch : 11, Loss : 0.905085, Accuracy: 0.919000, Test accuracy: 0.927000
Distillation: Epoch : 12, Loss : 0.895433, Accuracy: 0.927000, Test accuracy: 0.931200
Distillation: Epoch : 13, Loss : 0.865665, Accuracy: 0.922000, Test accuracy: 0.935800
Distillation: Epoch : 14, Loss : 0.887404, Accuracy: 0.942000, Test accuracy: 0.939500
Distillation: Epoch : 15, Loss : 0.884465, Accuracy: 0.931000, Test accuracy: 0.943800
Distillation: Epoch : 16, Loss : 0.857896, Accuracy: 0.945000, Test accuracy: 0.945800
Distillation: Epoch : 17, Loss : 0.827569, Accuracy: 0.957000, Test accuracy: 0.947900
Distillation: Epoch : 18, Loss : 0.855244, Accuracy: 0.941000, Test accuracy: 0.951300
Distillation: Epoch : 19, Loss : 0.819041, Accuracy: 0.956000, Test accuracy: 0.952700
Distillation: Epoch : 20, Loss : 0.836647, Accuracy: 0.967000, Test accuracy: 0.954100
Distillation: Epoch : 21, Loss : 0.854946, Accuracy: 0.948000, Test accuracy: 0.954100
Distillation: Epoch : 22, Loss : 0.859480, Accuracy: 0.962000, Test accuracy: 0.956900
Distillation: Epoch : 23, Loss : 0.851893, Accuracy: 0.943000, Test accuracy: 0.955600
Distillation: Epoch : 24, Loss : 0.832131, Accuracy: 0.956000, Test accuracy: 0.958400
Distillation: Epoch : 25, Loss : 0.819821, Accuracy: 0.956000, Test accuracy: 0.957400
Distillation: Epoch : 26, Loss : 0.845483, Accuracy: 0.947000, Test accuracy: 0.958100
Distillation: Epoch : 27, Loss : 0.845312, Accuracy: 0.958000, Test accuracy: 0.958700
Distillation: Epoch : 28, Loss : 0.814032, Accuracy: 0.966000, Test accuracy: 0.958400
Distillation: Epoch : 29, Loss : 0.826716, Accuracy: 0.951000, Test accuracy: 0.959300
Distillation: Epoch : 30, Loss : 0.813054, Accuracy: 0.957000, Test accuracy: 0.959700
Distillation: Epoch : 31, Loss : 0.789919, Accuracy: 0.953000, Test accuracy: 0.959700
Distillation: Epoch : 32, Loss : 0.799019, Accuracy: 0.961000, Test accuracy: 0.959800
Distillation: Epoch : 33, Loss : 0.831112, Accuracy: 0.963000, Test accuracy: 0.960100
Distillation: Epoch : 34, Loss : 0.826816, Accuracy: 0.957000, Test accuracy: 0.960600
Distillation: Epoch : 35, Loss : 0.844190, Accuracy: 0.959000, Test accuracy: 0.961900
Distillation: Epoch : 36, Loss : 0.817077, Accuracy: 0.959000, Test accuracy: 0.960800
Distillation: Epoch : 37, Loss : 0.835308, Accuracy: 0.954000, Test accuracy: 0.960600
Distillation: Epoch : 38, Loss : 0.812076, Accuracy: 0.959000, Test accuracy: 0.961100
Distillation: Epoch : 39, Loss : 0.837885, Accuracy: 0.955000, Test accuracy: 0.961600
Distillation: Epoch : 40, Loss : 0.840782, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 41, Loss : 0.811811, Accuracy: 0.966000, Test accuracy: 0.961200
Distillation: Epoch : 42, Loss : 0.841148, Accuracy: 0.958000, Test accuracy: 0.962000
Distillation: Epoch : 43, Loss : 0.800800, Accuracy: 0.966000, Test accuracy: 0.961400
Distillation: Epoch : 44, Loss : 0.826826, Accuracy: 0.961000, Test accuracy: 0.961800
Distillation: Epoch : 45, Loss : 0.846687, Accuracy: 0.961000, Test accuracy: 0.961900
Distillation: Epoch : 46, Loss : 0.824269, Accuracy: 0.961000, Test accuracy: 0.961800
Distillation: Epoch : 47, Loss : 0.822159, Accuracy: 0.954000, Test accuracy: 0.962900
Distillation: Epoch : 48, Loss : 0.793986, Accuracy: 0.973000, Test accuracy: 0.962000
Distillation: Epoch : 49, Loss : 0.828184, Accuracy: 0.961000, Test accuracy: 0.962100
Distillation: Epoch : 50, Loss : 0.823120, Accuracy: 0.959000, Test accuracy: 0.964000
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.964
Generating confusion matrix for student4
[[ 963.    0.    3.    0.    1.    2.    6.    2.    5.    6.]
 [   1. 1115.    4.    0.    0.    0.    3.    2.    1.    4.]
 [   3.    1.  994.    5.    5.    1.    0.   20.   11.    1.]
 [   1.    2.    3.  982.    1.   15.    0.    9.    9.   15.]
 [   0.    2.    3.    2.  949.    1.    2.    2.    4.    6.]
 [   1.    0.    0.    4.    0.  849.    8.    2.    8.    8.]
 [   5.    5.    2.    0.    5.    4.  937.    0.    2.    0.]
 [   2.    0.    3.    5.    1.    1.    0.  972.    4.   10.]
 [   4.   10.   18.   10.    4.   14.    2.    6.  925.    5.]
 [   0.    0.    2.    2.   16.    5.    0.   13.    5.  954.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.740207, Accuracy: 0.703000, Test accuracy: 0.709800
Distillation: Epoch : 2, Loss : 1.256887, Accuracy: 0.836000, Test accuracy: 0.844700
Distillation: Epoch : 3, Loss : 1.196916, Accuracy: 0.856000, Test accuracy: 0.871800
Distillation: Epoch : 4, Loss : 1.177059, Accuracy: 0.878000, Test accuracy: 0.884100
Distillation: Epoch : 5, Loss : 1.117084, Accuracy: 0.888000, Test accuracy: 0.889100
Distillation: Epoch : 6, Loss : 1.162581, Accuracy: 0.878000, Test accuracy: 0.894000
Distillation: Epoch : 7, Loss : 1.162775, Accuracy: 0.886000, Test accuracy: 0.896800
Distillation: Epoch : 8, Loss : 1.145103, Accuracy: 0.887000, Test accuracy: 0.901200
Distillation: Epoch : 9, Loss : 1.158825, Accuracy: 0.866000, Test accuracy: 0.901100
Distillation: Epoch : 10, Loss : 1.118897, Accuracy: 0.894000, Test accuracy: 0.903000
Distillation: Epoch : 11, Loss : 1.150237, Accuracy: 0.882000, Test accuracy: 0.904100
Distillation: Epoch : 12, Loss : 1.115892, Accuracy: 0.894000, Test accuracy: 0.903700
Distillation: Epoch : 13, Loss : 1.092131, Accuracy: 0.907000, Test accuracy: 0.904600
Distillation: Epoch : 14, Loss : 1.125139, Accuracy: 0.915000, Test accuracy: 0.905800
Distillation: Epoch : 15, Loss : 1.107420, Accuracy: 0.894000, Test accuracy: 0.906200
Distillation: Epoch : 16, Loss : 1.113171, Accuracy: 0.889000, Test accuracy: 0.906100
Distillation: Epoch : 17, Loss : 1.117435, Accuracy: 0.899000, Test accuracy: 0.907900
Distillation: Epoch : 18, Loss : 1.155556, Accuracy: 0.895000, Test accuracy: 0.907200
Distillation: Epoch : 19, Loss : 1.128816, Accuracy: 0.896000, Test accuracy: 0.907900
Distillation: Epoch : 20, Loss : 1.126948, Accuracy: 0.892000, Test accuracy: 0.909000
Distillation: Epoch : 21, Loss : 1.108402, Accuracy: 0.897000, Test accuracy: 0.908700
Distillation: Epoch : 22, Loss : 1.118859, Accuracy: 0.901000, Test accuracy: 0.909300
Distillation: Epoch : 23, Loss : 1.121150, Accuracy: 0.905000, Test accuracy: 0.909000
Distillation: Epoch : 24, Loss : 1.121471, Accuracy: 0.908000, Test accuracy: 0.908100
Distillation: Epoch : 25, Loss : 1.139045, Accuracy: 0.886000, Test accuracy: 0.909300
Distillation: Epoch : 26, Loss : 1.122273, Accuracy: 0.923000, Test accuracy: 0.911000
Distillation: Epoch : 27, Loss : 1.110832, Accuracy: 0.902000, Test accuracy: 0.910500
Distillation: Epoch : 28, Loss : 1.084187, Accuracy: 0.913000, Test accuracy: 0.911100
Distillation: Epoch : 29, Loss : 1.076760, Accuracy: 0.920000, Test accuracy: 0.910300
Distillation: Epoch : 30, Loss : 1.103049, Accuracy: 0.898000, Test accuracy: 0.910800
Distillation: Epoch : 31, Loss : 1.123929, Accuracy: 0.888000, Test accuracy: 0.910400
Distillation: Epoch : 32, Loss : 1.128312, Accuracy: 0.900000, Test accuracy: 0.912700
Distillation: Epoch : 33, Loss : 1.106807, Accuracy: 0.908000, Test accuracy: 0.913600
Distillation: Epoch : 34, Loss : 1.082796, Accuracy: 0.919000, Test accuracy: 0.912300
Distillation: Epoch : 35, Loss : 1.097471, Accuracy: 0.902000, Test accuracy: 0.911000
Distillation: Epoch : 36, Loss : 1.115491, Accuracy: 0.896000, Test accuracy: 0.913600
Distillation: Epoch : 37, Loss : 1.101001, Accuracy: 0.916000, Test accuracy: 0.912400
Distillation: Epoch : 38, Loss : 1.100006, Accuracy: 0.902000, Test accuracy: 0.913900
Distillation: Epoch : 39, Loss : 1.103275, Accuracy: 0.918000, Test accuracy: 0.914000
Distillation: Epoch : 40, Loss : 1.109406, Accuracy: 0.893000, Test accuracy: 0.914200
Distillation: Epoch : 41, Loss : 1.126274, Accuracy: 0.905000, Test accuracy: 0.915500
Distillation: Epoch : 42, Loss : 1.131529, Accuracy: 0.892000, Test accuracy: 0.915800
Distillation: Epoch : 43, Loss : 1.073103, Accuracy: 0.916000, Test accuracy: 0.917500
Distillation: Epoch : 44, Loss : 1.114324, Accuracy: 0.901000, Test accuracy: 0.916400
Distillation: Epoch : 45, Loss : 1.098934, Accuracy: 0.920000, Test accuracy: 0.918500
Distillation: Epoch : 46, Loss : 1.085800, Accuracy: 0.916000, Test accuracy: 0.920300
Distillation: Epoch : 47, Loss : 1.075939, Accuracy: 0.918000, Test accuracy: 0.922800
Distillation: Epoch : 48, Loss : 1.088277, Accuracy: 0.913000, Test accuracy: 0.925600
Distillation: Epoch : 49, Loss : 1.077571, Accuracy: 0.928000, Test accuracy: 0.925400
Distillation: Epoch : 50, Loss : 1.042389, Accuracy: 0.944000, Test accuracy: 0.929200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9292
Generating confusion matrix for student4
[[ 946.    0.    7.    1.    1.    6.    6.    3.    4.    9.]
 [   0. 1112.    5.    3.    2.    3.    4.   16.    8.    4.]
 [   2.    3.  930.   28.    6.    1.    6.   17.   10.    1.]
 [   3.    1.   27.  942.    1.   39.    0.    8.   30.   16.]
 [   1.    0.   13.    0.  934.    0.    6.    2.    7.   32.]
 [   3.    3.    0.   14.    0.  790.   19.    2.   29.    9.]
 [  16.    5.    8.    1.    6.   12.  916.    0.   11.    1.]
 [   3.    0.    6.    8.    2.    7.    0.  951.    9.   19.]
 [   4.   11.   31.   10.    7.   24.    1.    1.  861.    8.]
 [   2.    0.    5.    3.   23.   10.    0.   28.    5.  910.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.729039, Accuracy: 0.758000, Test accuracy: 0.758700
Distillation: Epoch : 2, Loss : 1.391486, Accuracy: 0.844000, Test accuracy: 0.854200
Distillation: Epoch : 3, Loss : 1.319086, Accuracy: 0.867000, Test accuracy: 0.878800
Distillation: Epoch : 4, Loss : 1.270651, Accuracy: 0.882000, Test accuracy: 0.889200
Distillation: Epoch : 5, Loss : 1.293070, Accuracy: 0.877000, Test accuracy: 0.894300
Distillation: Epoch : 6, Loss : 1.250132, Accuracy: 0.903000, Test accuracy: 0.903300
Distillation: Epoch : 7, Loss : 1.219355, Accuracy: 0.918000, Test accuracy: 0.907800
Distillation: Epoch : 8, Loss : 1.209153, Accuracy: 0.920000, Test accuracy: 0.915100
Distillation: Epoch : 9, Loss : 1.228736, Accuracy: 0.928000, Test accuracy: 0.921000
Distillation: Epoch : 10, Loss : 1.227549, Accuracy: 0.919000, Test accuracy: 0.927700
Distillation: Epoch : 11, Loss : 1.198014, Accuracy: 0.934000, Test accuracy: 0.932300
Distillation: Epoch : 12, Loss : 1.223640, Accuracy: 0.921000, Test accuracy: 0.937700
Distillation: Epoch : 13, Loss : 1.196761, Accuracy: 0.929000, Test accuracy: 0.942100
Distillation: Epoch : 14, Loss : 1.181598, Accuracy: 0.947000, Test accuracy: 0.945400
Distillation: Epoch : 15, Loss : 1.189356, Accuracy: 0.944000, Test accuracy: 0.948200
Distillation: Epoch : 16, Loss : 1.164196, Accuracy: 0.943000, Test accuracy: 0.950700
Distillation: Epoch : 17, Loss : 1.167137, Accuracy: 0.937000, Test accuracy: 0.953000
Distillation: Epoch : 18, Loss : 1.176608, Accuracy: 0.948000, Test accuracy: 0.955000
Distillation: Epoch : 19, Loss : 1.177063, Accuracy: 0.948000, Test accuracy: 0.955800
Distillation: Epoch : 20, Loss : 1.155751, Accuracy: 0.948000, Test accuracy: 0.956200
Distillation: Epoch : 21, Loss : 1.160974, Accuracy: 0.955000, Test accuracy: 0.956800
Distillation: Epoch : 22, Loss : 1.165998, Accuracy: 0.943000, Test accuracy: 0.957900
Distillation: Epoch : 23, Loss : 1.142904, Accuracy: 0.958000, Test accuracy: 0.958300
Distillation: Epoch : 24, Loss : 1.180908, Accuracy: 0.953000, Test accuracy: 0.958600
Distillation: Epoch : 25, Loss : 1.164203, Accuracy: 0.953000, Test accuracy: 0.960100
Distillation: Epoch : 26, Loss : 1.134958, Accuracy: 0.966000, Test accuracy: 0.960400
Distillation: Epoch : 27, Loss : 1.141617, Accuracy: 0.960000, Test accuracy: 0.960600
Distillation: Epoch : 28, Loss : 1.140553, Accuracy: 0.958000, Test accuracy: 0.960400
Distillation: Epoch : 29, Loss : 1.153224, Accuracy: 0.954000, Test accuracy: 0.960700
Distillation: Epoch : 30, Loss : 1.146977, Accuracy: 0.961000, Test accuracy: 0.960900
Distillation: Epoch : 31, Loss : 1.157391, Accuracy: 0.954000, Test accuracy: 0.961400
Distillation: Epoch : 32, Loss : 1.136834, Accuracy: 0.957000, Test accuracy: 0.961700
Distillation: Epoch : 33, Loss : 1.159379, Accuracy: 0.959000, Test accuracy: 0.962000
Distillation: Epoch : 34, Loss : 1.148073, Accuracy: 0.961000, Test accuracy: 0.962100
Distillation: Epoch : 35, Loss : 1.173077, Accuracy: 0.965000, Test accuracy: 0.961700
Distillation: Epoch : 36, Loss : 1.122768, Accuracy: 0.958000, Test accuracy: 0.962100
Distillation: Epoch : 37, Loss : 1.130596, Accuracy: 0.966000, Test accuracy: 0.962000
Distillation: Epoch : 38, Loss : 1.171720, Accuracy: 0.956000, Test accuracy: 0.961900
Distillation: Epoch : 39, Loss : 1.130693, Accuracy: 0.966000, Test accuracy: 0.962700
Distillation: Epoch : 40, Loss : 1.145475, Accuracy: 0.964000, Test accuracy: 0.962600
Distillation: Epoch : 41, Loss : 1.167683, Accuracy: 0.959000, Test accuracy: 0.963000
Distillation: Epoch : 42, Loss : 1.136000, Accuracy: 0.949000, Test accuracy: 0.963500
Distillation: Epoch : 43, Loss : 1.139680, Accuracy: 0.959000, Test accuracy: 0.963300
Distillation: Epoch : 44, Loss : 1.133306, Accuracy: 0.960000, Test accuracy: 0.963900
Distillation: Epoch : 45, Loss : 1.148391, Accuracy: 0.968000, Test accuracy: 0.964200
Distillation: Epoch : 46, Loss : 1.138581, Accuracy: 0.959000, Test accuracy: 0.964400
Distillation: Epoch : 47, Loss : 1.128505, Accuracy: 0.965000, Test accuracy: 0.964400
Distillation: Epoch : 48, Loss : 1.145648, Accuracy: 0.962000, Test accuracy: 0.964800
Distillation: Epoch : 49, Loss : 1.178141, Accuracy: 0.958000, Test accuracy: 0.964400
Distillation: Epoch : 50, Loss : 1.134293, Accuracy: 0.959000, Test accuracy: 0.964200
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9642
Generating confusion matrix for student4
[[ 962.    0.    0.    0.    0.    1.    5.    2.    5.    7.]
 [   1. 1116.    6.    0.    0.    0.    3.    3.    1.    6.]
 [   3.    1.  995.    4.    7.    2.    0.   20.   13.    1.]
 [   1.    3.    6.  987.    1.   20.    0.    8.   15.   17.]
 [   1.    1.    4.    2.  947.    1.    1.    1.    3.    6.]
 [   1.    0.    0.    5.    1.  853.   12.    1.    6.    6.]
 [   7.    5.    1.    0.    2.    5.  935.    0.    3.    2.]
 [   2.    0.    7.    4.    4.    2.    0.  976.    3.    4.]
 [   2.    9.   11.    8.    2.    7.    2.    5.  915.    4.]
 [   0.    0.    2.    0.   18.    1.    0.   12.   10.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.659433, Accuracy: 0.770000, Test accuracy: 0.770900
Distillation: Epoch : 2, Loss : 1.469649, Accuracy: 0.863000, Test accuracy: 0.862300
Distillation: Epoch : 3, Loss : 1.452906, Accuracy: 0.858000, Test accuracy: 0.878000
Distillation: Epoch : 4, Loss : 1.416228, Accuracy: 0.881000, Test accuracy: 0.885700
Distillation: Epoch : 5, Loss : 1.433070, Accuracy: 0.878000, Test accuracy: 0.889800
Distillation: Epoch : 6, Loss : 1.430613, Accuracy: 0.880000, Test accuracy: 0.895500
Distillation: Epoch : 7, Loss : 1.398969, Accuracy: 0.888000, Test accuracy: 0.899400
Distillation: Epoch : 8, Loss : 1.424783, Accuracy: 0.890000, Test accuracy: 0.900800
Distillation: Epoch : 9, Loss : 1.415693, Accuracy: 0.903000, Test accuracy: 0.902000
Distillation: Epoch : 10, Loss : 1.374276, Accuracy: 0.909000, Test accuracy: 0.905500
Distillation: Epoch : 11, Loss : 1.407091, Accuracy: 0.899000, Test accuracy: 0.907500
Distillation: Epoch : 12, Loss : 1.372120, Accuracy: 0.908000, Test accuracy: 0.908700
Distillation: Epoch : 13, Loss : 1.356333, Accuracy: 0.899000, Test accuracy: 0.911500
Distillation: Epoch : 14, Loss : 1.386551, Accuracy: 0.898000, Test accuracy: 0.913600
Distillation: Epoch : 15, Loss : 1.345291, Accuracy: 0.923000, Test accuracy: 0.916700
Distillation: Epoch : 16, Loss : 1.354712, Accuracy: 0.921000, Test accuracy: 0.917900
Distillation: Epoch : 17, Loss : 1.358668, Accuracy: 0.914000, Test accuracy: 0.920300
Distillation: Epoch : 18, Loss : 1.363678, Accuracy: 0.922000, Test accuracy: 0.922900
Distillation: Epoch : 19, Loss : 1.377891, Accuracy: 0.917000, Test accuracy: 0.927600
Distillation: Epoch : 20, Loss : 1.350632, Accuracy: 0.928000, Test accuracy: 0.930500
Distillation: Epoch : 21, Loss : 1.358322, Accuracy: 0.922000, Test accuracy: 0.934700
Distillation: Epoch : 22, Loss : 1.358700, Accuracy: 0.917000, Test accuracy: 0.936600
Distillation: Epoch : 23, Loss : 1.337224, Accuracy: 0.943000, Test accuracy: 0.939000
Distillation: Epoch : 24, Loss : 1.334044, Accuracy: 0.934000, Test accuracy: 0.943100
Distillation: Epoch : 25, Loss : 1.313711, Accuracy: 0.941000, Test accuracy: 0.944500
Distillation: Epoch : 26, Loss : 1.335295, Accuracy: 0.938000, Test accuracy: 0.945300
Distillation: Epoch : 27, Loss : 1.332335, Accuracy: 0.939000, Test accuracy: 0.947700
Distillation: Epoch : 28, Loss : 1.338808, Accuracy: 0.940000, Test accuracy: 0.948400
Distillation: Epoch : 29, Loss : 1.341320, Accuracy: 0.938000, Test accuracy: 0.949600
Distillation: Epoch : 30, Loss : 1.321669, Accuracy: 0.936000, Test accuracy: 0.950700
Distillation: Epoch : 31, Loss : 1.331125, Accuracy: 0.941000, Test accuracy: 0.951300
Distillation: Epoch : 32, Loss : 1.292276, Accuracy: 0.942000, Test accuracy: 0.952400
Distillation: Epoch : 33, Loss : 1.287984, Accuracy: 0.955000, Test accuracy: 0.953700
Distillation: Epoch : 34, Loss : 1.314076, Accuracy: 0.953000, Test accuracy: 0.953800
Distillation: Epoch : 35, Loss : 1.280791, Accuracy: 0.955000, Test accuracy: 0.954500
Distillation: Epoch : 36, Loss : 1.333380, Accuracy: 0.931000, Test accuracy: 0.955000
Distillation: Epoch : 37, Loss : 1.291858, Accuracy: 0.956000, Test accuracy: 0.955000
Distillation: Epoch : 38, Loss : 1.300349, Accuracy: 0.949000, Test accuracy: 0.956500
Distillation: Epoch : 39, Loss : 1.266449, Accuracy: 0.951000, Test accuracy: 0.956000
Distillation: Epoch : 40, Loss : 1.311607, Accuracy: 0.937000, Test accuracy: 0.956100
Distillation: Epoch : 41, Loss : 1.313895, Accuracy: 0.946000, Test accuracy: 0.955200
Distillation: Epoch : 42, Loss : 1.298660, Accuracy: 0.960000, Test accuracy: 0.955900
Distillation: Epoch : 43, Loss : 1.332063, Accuracy: 0.954000, Test accuracy: 0.956100
Distillation: Epoch : 44, Loss : 1.296669, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 45, Loss : 1.269964, Accuracy: 0.965000, Test accuracy: 0.956200
Distillation: Epoch : 46, Loss : 1.281875, Accuracy: 0.963000, Test accuracy: 0.957200
Distillation: Epoch : 47, Loss : 1.295506, Accuracy: 0.959000, Test accuracy: 0.956400
Distillation: Epoch : 48, Loss : 1.303139, Accuracy: 0.959000, Test accuracy: 0.957700
Distillation: Epoch : 49, Loss : 1.303292, Accuracy: 0.952000, Test accuracy: 0.957800
Distillation: Epoch : 50, Loss : 1.311235, Accuracy: 0.958000, Test accuracy: 0.956800
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9568
Generating confusion matrix for student4
[[ 963.    0.    1.    0.    1.    1.    4.    2.    7.    6.]
 [   0. 1110.   10.    1.    2.    1.    3.   10.   11.    7.]
 [   2.    5.  987.    6.    3.    0.    0.   17.    7.    1.]
 [   0.    2.    6.  980.    0.   20.    0.    6.   15.   15.]
 [   1.    0.    5.    0.  941.    0.    6.    2.    9.   15.]
 [   1.    0.    0.    5.    0.  855.    7.    0.    6.    5.]
 [  10.    5.    2.    0.    5.    5.  936.    0.   10.    1.]
 [   1.    1.    8.    8.    2.    2.    0.  963.   10.   16.]
 [   2.   12.   12.    7.    6.    3.    2.    2.  891.    1.]
 [   0.    0.    1.    3.   22.    5.    0.   26.    8.  942.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.901084, Accuracy: 0.754000, Test accuracy: 0.779200
Distillation: Epoch : 2, Loss : 1.606647, Accuracy: 0.833000, Test accuracy: 0.861200
Distillation: Epoch : 3, Loss : 1.553438, Accuracy: 0.876000, Test accuracy: 0.881200
Distillation: Epoch : 4, Loss : 1.523035, Accuracy: 0.892000, Test accuracy: 0.893900
Distillation: Epoch : 5, Loss : 1.523376, Accuracy: 0.893000, Test accuracy: 0.902700
Distillation: Epoch : 6, Loss : 1.519865, Accuracy: 0.899000, Test accuracy: 0.908900
Distillation: Epoch : 7, Loss : 1.505280, Accuracy: 0.917000, Test accuracy: 0.917000
Distillation: Epoch : 8, Loss : 1.468561, Accuracy: 0.919000, Test accuracy: 0.922200
Distillation: Epoch : 9, Loss : 1.510844, Accuracy: 0.911000, Test accuracy: 0.928500
Distillation: Epoch : 10, Loss : 1.483381, Accuracy: 0.936000, Test accuracy: 0.933400
Distillation: Epoch : 11, Loss : 1.464314, Accuracy: 0.924000, Test accuracy: 0.936500
Distillation: Epoch : 12, Loss : 1.471326, Accuracy: 0.936000, Test accuracy: 0.940600
Distillation: Epoch : 13, Loss : 1.454727, Accuracy: 0.937000, Test accuracy: 0.944600
Distillation: Epoch : 14, Loss : 1.433220, Accuracy: 0.948000, Test accuracy: 0.947200
Distillation: Epoch : 15, Loss : 1.437673, Accuracy: 0.943000, Test accuracy: 0.949400
Distillation: Epoch : 16, Loss : 1.431606, Accuracy: 0.949000, Test accuracy: 0.951800
Distillation: Epoch : 17, Loss : 1.434415, Accuracy: 0.952000, Test accuracy: 0.953500
Distillation: Epoch : 18, Loss : 1.422629, Accuracy: 0.955000, Test accuracy: 0.954200
Distillation: Epoch : 19, Loss : 1.400291, Accuracy: 0.961000, Test accuracy: 0.954200
Distillation: Epoch : 20, Loss : 1.439445, Accuracy: 0.948000, Test accuracy: 0.956600
Distillation: Epoch : 21, Loss : 1.417887, Accuracy: 0.950000, Test accuracy: 0.956200
Distillation: Epoch : 22, Loss : 1.421937, Accuracy: 0.946000, Test accuracy: 0.957500
Distillation: Epoch : 23, Loss : 1.444781, Accuracy: 0.959000, Test accuracy: 0.958500
Distillation: Epoch : 24, Loss : 1.419932, Accuracy: 0.963000, Test accuracy: 0.959900
Distillation: Epoch : 25, Loss : 1.410233, Accuracy: 0.932000, Test accuracy: 0.960800
Distillation: Epoch : 26, Loss : 1.418868, Accuracy: 0.955000, Test accuracy: 0.960700
Distillation: Epoch : 27, Loss : 1.453895, Accuracy: 0.958000, Test accuracy: 0.961300
Distillation: Epoch : 28, Loss : 1.402873, Accuracy: 0.965000, Test accuracy: 0.962300
Distillation: Epoch : 29, Loss : 1.421318, Accuracy: 0.970000, Test accuracy: 0.962200
Distillation: Epoch : 30, Loss : 1.442436, Accuracy: 0.962000, Test accuracy: 0.962800
Distillation: Epoch : 31, Loss : 1.425088, Accuracy: 0.966000, Test accuracy: 0.962900
Distillation: Epoch : 32, Loss : 1.410919, Accuracy: 0.968000, Test accuracy: 0.964100
Distillation: Epoch : 33, Loss : 1.399377, Accuracy: 0.961000, Test accuracy: 0.963300
Distillation: Epoch : 34, Loss : 1.397684, Accuracy: 0.963000, Test accuracy: 0.964100
Distillation: Epoch : 35, Loss : 1.432553, Accuracy: 0.957000, Test accuracy: 0.965100
Distillation: Epoch : 36, Loss : 1.416703, Accuracy: 0.961000, Test accuracy: 0.965200
Distillation: Epoch : 37, Loss : 1.431453, Accuracy: 0.961000, Test accuracy: 0.965100
Distillation: Epoch : 38, Loss : 1.424478, Accuracy: 0.963000, Test accuracy: 0.965800
Distillation: Epoch : 39, Loss : 1.388035, Accuracy: 0.970000, Test accuracy: 0.965700
Distillation: Epoch : 40, Loss : 1.410460, Accuracy: 0.964000, Test accuracy: 0.966700
Distillation: Epoch : 41, Loss : 1.432653, Accuracy: 0.963000, Test accuracy: 0.967300
Distillation: Epoch : 42, Loss : 1.418231, Accuracy: 0.959000, Test accuracy: 0.967700
Distillation: Epoch : 43, Loss : 1.424025, Accuracy: 0.975000, Test accuracy: 0.968100
Distillation: Epoch : 44, Loss : 1.406722, Accuracy: 0.965000, Test accuracy: 0.967800
Distillation: Epoch : 45, Loss : 1.397970, Accuracy: 0.974000, Test accuracy: 0.967900
Distillation: Epoch : 46, Loss : 1.402524, Accuracy: 0.960000, Test accuracy: 0.968900
Distillation: Epoch : 47, Loss : 1.396149, Accuracy: 0.971000, Test accuracy: 0.969200
Distillation: Epoch : 48, Loss : 1.399254, Accuracy: 0.970000, Test accuracy: 0.968600
Distillation: Epoch : 49, Loss : 1.415211, Accuracy: 0.966000, Test accuracy: 0.969000
Distillation: Epoch : 50, Loss : 1.390294, Accuracy: 0.963000, Test accuracy: 0.969400
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9694
Generating confusion matrix for student4
[[ 965.    0.    3.    0.    0.    1.    4.    0.    6.    4.]
 [   0. 1118.   10.    0.    1.    0.    3.   13.    1.    7.]
 [   1.    2.  994.    4.    2.    1.    0.   13.    4.    0.]
 [   0.    2.    7.  986.    0.   19.    0.    5.    7.   10.]
 [   2.    0.    3.    0.  947.    0.    3.    1.    7.    8.]
 [   0.    0.    1.    8.    1.  858.    3.    0.    3.    8.]
 [   5.    5.    1.    0.    6.    3.  941.    0.    4.    1.]
 [   1.    0.    7.    9.    6.    1.    0.  990.    5.    7.]
 [   3.    8.    5.    3.    2.    3.    4.    0.  931.    0.]
 [   3.    0.    1.    0.   17.    6.    0.    6.    6.  964.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.992018, Accuracy: 0.724000, Test accuracy: 0.739100
Distillation: Epoch : 2, Loss : 1.849396, Accuracy: 0.841000, Test accuracy: 0.851700
Distillation: Epoch : 3, Loss : 1.819794, Accuracy: 0.869000, Test accuracy: 0.872400
Distillation: Epoch : 4, Loss : 1.788769, Accuracy: 0.869000, Test accuracy: 0.879300
Distillation: Epoch : 5, Loss : 1.820099, Accuracy: 0.873000, Test accuracy: 0.883300
Distillation: Epoch : 6, Loss : 1.790778, Accuracy: 0.892000, Test accuracy: 0.886400
Distillation: Epoch : 7, Loss : 1.788541, Accuracy: 0.894000, Test accuracy: 0.889800
Distillation: Epoch : 8, Loss : 1.768163, Accuracy: 0.894000, Test accuracy: 0.891800
Distillation: Epoch : 9, Loss : 1.786376, Accuracy: 0.884000, Test accuracy: 0.892700
Distillation: Epoch : 10, Loss : 1.796471, Accuracy: 0.882000, Test accuracy: 0.893800
Distillation: Epoch : 11, Loss : 1.783713, Accuracy: 0.904000, Test accuracy: 0.897000
Distillation: Epoch : 12, Loss : 1.787525, Accuracy: 0.900000, Test accuracy: 0.896200
Distillation: Epoch : 13, Loss : 1.788742, Accuracy: 0.885000, Test accuracy: 0.897600
Distillation: Epoch : 14, Loss : 1.772232, Accuracy: 0.905000, Test accuracy: 0.900200
Distillation: Epoch : 15, Loss : 1.784219, Accuracy: 0.878000, Test accuracy: 0.899700
Distillation: Epoch : 16, Loss : 1.768623, Accuracy: 0.908000, Test accuracy: 0.900200
Distillation: Epoch : 17, Loss : 1.778970, Accuracy: 0.897000, Test accuracy: 0.901800
Distillation: Epoch : 18, Loss : 1.766639, Accuracy: 0.890000, Test accuracy: 0.903600
Distillation: Epoch : 19, Loss : 1.781862, Accuracy: 0.888000, Test accuracy: 0.904300
Distillation: Epoch : 20, Loss : 1.799424, Accuracy: 0.883000, Test accuracy: 0.905400
Distillation: Epoch : 21, Loss : 1.768789, Accuracy: 0.909000, Test accuracy: 0.905300
Distillation: Epoch : 22, Loss : 1.771775, Accuracy: 0.901000, Test accuracy: 0.908000
Distillation: Epoch : 23, Loss : 1.788369, Accuracy: 0.891000, Test accuracy: 0.908800
Distillation: Epoch : 24, Loss : 1.758243, Accuracy: 0.912000, Test accuracy: 0.909100
Distillation: Epoch : 25, Loss : 1.753503, Accuracy: 0.912000, Test accuracy: 0.910300
Distillation: Epoch : 26, Loss : 1.781795, Accuracy: 0.907000, Test accuracy: 0.910800
Distillation: Epoch : 27, Loss : 1.765675, Accuracy: 0.885000, Test accuracy: 0.911900
Distillation: Epoch : 28, Loss : 1.777677, Accuracy: 0.891000, Test accuracy: 0.913000
Distillation: Epoch : 29, Loss : 1.763627, Accuracy: 0.898000, Test accuracy: 0.913500
Distillation: Epoch : 30, Loss : 1.746071, Accuracy: 0.901000, Test accuracy: 0.914400
Distillation: Epoch : 31, Loss : 1.763870, Accuracy: 0.897000, Test accuracy: 0.916500
Distillation: Epoch : 32, Loss : 1.748712, Accuracy: 0.905000, Test accuracy: 0.918400
Distillation: Epoch : 33, Loss : 1.766409, Accuracy: 0.899000, Test accuracy: 0.918000
Distillation: Epoch : 34, Loss : 1.746736, Accuracy: 0.916000, Test accuracy: 0.919500
Distillation: Epoch : 35, Loss : 1.740187, Accuracy: 0.918000, Test accuracy: 0.921300
Distillation: Epoch : 36, Loss : 1.760668, Accuracy: 0.900000, Test accuracy: 0.922100
Distillation: Epoch : 37, Loss : 1.741877, Accuracy: 0.922000, Test accuracy: 0.923500
Distillation: Epoch : 38, Loss : 1.761575, Accuracy: 0.898000, Test accuracy: 0.924400
Distillation: Epoch : 39, Loss : 1.767992, Accuracy: 0.924000, Test accuracy: 0.927100
Distillation: Epoch : 40, Loss : 1.726628, Accuracy: 0.918000, Test accuracy: 0.928300
Distillation: Epoch : 41, Loss : 1.770307, Accuracy: 0.920000, Test accuracy: 0.929000
Distillation: Epoch : 42, Loss : 1.743112, Accuracy: 0.928000, Test accuracy: 0.930500
Distillation: Epoch : 43, Loss : 1.738247, Accuracy: 0.920000, Test accuracy: 0.933100
Distillation: Epoch : 44, Loss : 1.755445, Accuracy: 0.918000, Test accuracy: 0.933800
Distillation: Epoch : 45, Loss : 1.756966, Accuracy: 0.920000, Test accuracy: 0.935500
Distillation: Epoch : 46, Loss : 1.752492, Accuracy: 0.936000, Test accuracy: 0.935800
Distillation: Epoch : 47, Loss : 1.739083, Accuracy: 0.929000, Test accuracy: 0.938000
Distillation: Epoch : 48, Loss : 1.734981, Accuracy: 0.935000, Test accuracy: 0.937800
Distillation: Epoch : 49, Loss : 1.733150, Accuracy: 0.931000, Test accuracy: 0.939500
Distillation: Epoch : 50, Loss : 1.738139, Accuracy: 0.941000, Test accuracy: 0.940900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9409
Generating confusion matrix for student4
[[ 955.    0.    3.    0.    1.    3.    6.    4.    5.    7.]
 [   0. 1106.   17.    1.    2.    3.    3.   11.    4.    7.]
 [   2.    4.  948.   14.    1.    2.    2.   19.   13.    2.]
 [   1.    8.   16.  963.    1.   30.    0.    9.   22.   19.]
 [   2.    0.   14.    0.  935.    4.    2.    5.    8.   43.]
 [   1.    1.    0.   17.    0.  836.   16.    2.    8.   11.]
 [  11.    3.    8.    0.   10.    7.  927.    1.   10.    0.]
 [   0.    0.   13.   11.    3.    4.    1.  951.    5.   22.]
 [   8.   13.   12.    2.    4.    0.    1.    0.  895.    5.]
 [   0.    0.    1.    2.   25.    3.    0.   26.    4.  893.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.206314, Accuracy: 0.539000, Test accuracy: 0.554300
Distillation: Epoch : 2, Loss : 2.054651, Accuracy: 0.841000, Test accuracy: 0.847700
Distillation: Epoch : 3, Loss : 2.035216, Accuracy: 0.864000, Test accuracy: 0.868300
Distillation: Epoch : 4, Loss : 2.026093, Accuracy: 0.875000, Test accuracy: 0.878400
Distillation: Epoch : 5, Loss : 2.036167, Accuracy: 0.872000, Test accuracy: 0.886900
Distillation: Epoch : 6, Loss : 2.018201, Accuracy: 0.872000, Test accuracy: 0.894900
Distillation: Epoch : 7, Loss : 2.027624, Accuracy: 0.894000, Test accuracy: 0.904100
Distillation: Epoch : 8, Loss : 2.010480, Accuracy: 0.910000, Test accuracy: 0.910900
Distillation: Epoch : 9, Loss : 1.999608, Accuracy: 0.905000, Test accuracy: 0.915200
Distillation: Epoch : 10, Loss : 2.004423, Accuracy: 0.912000, Test accuracy: 0.920200
Distillation: Epoch : 11, Loss : 2.000380, Accuracy: 0.930000, Test accuracy: 0.925900
Distillation: Epoch : 12, Loss : 1.990341, Accuracy: 0.927000, Test accuracy: 0.930400
Distillation: Epoch : 13, Loss : 1.998985, Accuracy: 0.930000, Test accuracy: 0.933900
Distillation: Epoch : 14, Loss : 2.000265, Accuracy: 0.927000, Test accuracy: 0.937000
Distillation: Epoch : 15, Loss : 1.989333, Accuracy: 0.932000, Test accuracy: 0.940000
Distillation: Epoch : 16, Loss : 1.981012, Accuracy: 0.925000, Test accuracy: 0.940700
Distillation: Epoch : 17, Loss : 1.996500, Accuracy: 0.949000, Test accuracy: 0.943200
Distillation: Epoch : 18, Loss : 1.978058, Accuracy: 0.927000, Test accuracy: 0.945500
Distillation: Epoch : 19, Loss : 1.979882, Accuracy: 0.938000, Test accuracy: 0.947000
Distillation: Epoch : 20, Loss : 1.987267, Accuracy: 0.941000, Test accuracy: 0.947300
Distillation: Epoch : 21, Loss : 1.991905, Accuracy: 0.931000, Test accuracy: 0.950200
Distillation: Epoch : 22, Loss : 1.987097, Accuracy: 0.955000, Test accuracy: 0.950800
Distillation: Epoch : 23, Loss : 1.977501, Accuracy: 0.933000, Test accuracy: 0.951500
Distillation: Epoch : 24, Loss : 1.991683, Accuracy: 0.936000, Test accuracy: 0.952300
Distillation: Epoch : 25, Loss : 1.980844, Accuracy: 0.945000, Test accuracy: 0.953100
Distillation: Epoch : 26, Loss : 1.993927, Accuracy: 0.945000, Test accuracy: 0.954200
Distillation: Epoch : 27, Loss : 1.990640, Accuracy: 0.957000, Test accuracy: 0.954200
Distillation: Epoch : 28, Loss : 1.972390, Accuracy: 0.961000, Test accuracy: 0.955200
Distillation: Epoch : 29, Loss : 1.990734, Accuracy: 0.957000, Test accuracy: 0.955300
Distillation: Epoch : 30, Loss : 1.991208, Accuracy: 0.956000, Test accuracy: 0.956400
Distillation: Epoch : 31, Loss : 1.973013, Accuracy: 0.943000, Test accuracy: 0.956500
Distillation: Epoch : 32, Loss : 1.985665, Accuracy: 0.943000, Test accuracy: 0.956200
Distillation: Epoch : 33, Loss : 1.974098, Accuracy: 0.966000, Test accuracy: 0.956700
Distillation: Epoch : 34, Loss : 1.988089, Accuracy: 0.947000, Test accuracy: 0.957300
Distillation: Epoch : 35, Loss : 1.982755, Accuracy: 0.955000, Test accuracy: 0.957200
Distillation: Epoch : 36, Loss : 1.975159, Accuracy: 0.950000, Test accuracy: 0.957100
Distillation: Epoch : 37, Loss : 1.983940, Accuracy: 0.960000, Test accuracy: 0.957300
Distillation: Epoch : 38, Loss : 1.993474, Accuracy: 0.948000, Test accuracy: 0.958500
Distillation: Epoch : 39, Loss : 1.980321, Accuracy: 0.959000, Test accuracy: 0.959000
Distillation: Epoch : 40, Loss : 1.970348, Accuracy: 0.962000, Test accuracy: 0.957900
Distillation: Epoch : 41, Loss : 1.964910, Accuracy: 0.968000, Test accuracy: 0.959000
Distillation: Epoch : 42, Loss : 1.974403, Accuracy: 0.955000, Test accuracy: 0.959800
Distillation: Epoch : 43, Loss : 1.972227, Accuracy: 0.959000, Test accuracy: 0.959600
Distillation: Epoch : 44, Loss : 1.982724, Accuracy: 0.944000, Test accuracy: 0.960700
Distillation: Epoch : 45, Loss : 1.954594, Accuracy: 0.957000, Test accuracy: 0.960900
Distillation: Epoch : 46, Loss : 1.981059, Accuracy: 0.951000, Test accuracy: 0.961200
Distillation: Epoch : 47, Loss : 1.966989, Accuracy: 0.953000, Test accuracy: 0.960800
Distillation: Epoch : 48, Loss : 1.978817, Accuracy: 0.965000, Test accuracy: 0.961400
Distillation: Epoch : 49, Loss : 1.979463, Accuracy: 0.952000, Test accuracy: 0.961900
Distillation: Epoch : 50, Loss : 1.977975, Accuracy: 0.960000, Test accuracy: 0.961900
Saving to student4/student4.ckpt
<confusion_matrix>
results for %s distillate with T = %d student4 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student4/student4.ckpt
Accuracy on the test set
0.9619
Generating confusion matrix for student4
[[ 967.    0.    1.    0.    0.    2.    5.    0.    7.    4.]
 [   0. 1111.    8.    0.    1.    1.    3.    9.    5.    7.]
 [   1.    1.  998.    6.    3.    1.    1.   19.    8.    2.]
 [   0.    4.    6.  973.    0.   21.    1.    4.    8.   12.]
 [   1.    0.    5.    1.  943.    0.    2.    2.    9.   20.]
 [   0.    0.    1.   11.    0.  850.    6.    0.    4.    7.]
 [   5.    6.    1.    0.    9.    4.  937.    0.    8.    2.]
 [   2.    0.    7.   13.    5.    3.    0.  983.    7.   11.]
 [   4.   13.    5.    6.    3.    4.    3.    0.  913.    0.]
 [   0.    0.    0.    0.   18.    6.    0.   11.    5.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.289350, Accuracy: 0.708000, Test accuracy: 0.729800
Distillation: Epoch : 2, Loss : 0.440286, Accuracy: 0.872000, Test accuracy: 0.881100
Distillation: Epoch : 3, Loss : 0.361584, Accuracy: 0.885000, Test accuracy: 0.904600
Distillation: Epoch : 4, Loss : 0.265585, Accuracy: 0.926000, Test accuracy: 0.913300
Distillation: Epoch : 5, Loss : 0.301518, Accuracy: 0.909000, Test accuracy: 0.918700
Distillation: Epoch : 6, Loss : 0.270985, Accuracy: 0.920000, Test accuracy: 0.925000
Distillation: Epoch : 7, Loss : 0.222202, Accuracy: 0.932000, Test accuracy: 0.930400
Distillation: Epoch : 8, Loss : 0.239656, Accuracy: 0.933000, Test accuracy: 0.932800
Distillation: Epoch : 9, Loss : 0.205081, Accuracy: 0.941000, Test accuracy: 0.936400
Distillation: Epoch : 10, Loss : 0.207632, Accuracy: 0.940000, Test accuracy: 0.939900
Distillation: Epoch : 11, Loss : 0.243369, Accuracy: 0.931000, Test accuracy: 0.942400
Distillation: Epoch : 12, Loss : 0.183430, Accuracy: 0.947000, Test accuracy: 0.945500
Distillation: Epoch : 13, Loss : 0.189956, Accuracy: 0.944000, Test accuracy: 0.945900
Distillation: Epoch : 14, Loss : 0.157179, Accuracy: 0.952000, Test accuracy: 0.948400
Distillation: Epoch : 15, Loss : 0.221708, Accuracy: 0.945000, Test accuracy: 0.950500
Distillation: Epoch : 16, Loss : 0.178256, Accuracy: 0.952000, Test accuracy: 0.951500
Distillation: Epoch : 17, Loss : 0.169689, Accuracy: 0.951000, Test accuracy: 0.951500
Distillation: Epoch : 18, Loss : 0.137619, Accuracy: 0.956000, Test accuracy: 0.954400
Distillation: Epoch : 19, Loss : 0.153104, Accuracy: 0.958000, Test accuracy: 0.953500
Distillation: Epoch : 20, Loss : 0.153123, Accuracy: 0.959000, Test accuracy: 0.955100
Distillation: Epoch : 21, Loss : 0.133030, Accuracy: 0.949000, Test accuracy: 0.954900
Distillation: Epoch : 22, Loss : 0.156404, Accuracy: 0.961000, Test accuracy: 0.956800
Distillation: Epoch : 23, Loss : 0.139739, Accuracy: 0.963000, Test accuracy: 0.958000
Distillation: Epoch : 24, Loss : 0.151409, Accuracy: 0.953000, Test accuracy: 0.959000
Distillation: Epoch : 25, Loss : 0.121469, Accuracy: 0.965000, Test accuracy: 0.959200
Distillation: Epoch : 26, Loss : 0.137727, Accuracy: 0.963000, Test accuracy: 0.960400
Distillation: Epoch : 27, Loss : 0.146313, Accuracy: 0.958000, Test accuracy: 0.960800
Distillation: Epoch : 28, Loss : 0.138016, Accuracy: 0.957000, Test accuracy: 0.961400
Distillation: Epoch : 29, Loss : 0.122501, Accuracy: 0.965000, Test accuracy: 0.961100
Distillation: Epoch : 30, Loss : 0.104974, Accuracy: 0.967000, Test accuracy: 0.961700
Distillation: Epoch : 31, Loss : 0.129735, Accuracy: 0.967000, Test accuracy: 0.962200
Distillation: Epoch : 32, Loss : 0.126332, Accuracy: 0.959000, Test accuracy: 0.962000
Distillation: Epoch : 33, Loss : 0.136988, Accuracy: 0.961000, Test accuracy: 0.962600
Distillation: Epoch : 34, Loss : 0.142448, Accuracy: 0.964000, Test accuracy: 0.964000
Distillation: Epoch : 35, Loss : 0.127840, Accuracy: 0.976000, Test accuracy: 0.964000
Distillation: Epoch : 36, Loss : 0.124865, Accuracy: 0.964000, Test accuracy: 0.963800
Distillation: Epoch : 37, Loss : 0.106210, Accuracy: 0.975000, Test accuracy: 0.964600
Distillation: Epoch : 38, Loss : 0.154270, Accuracy: 0.958000, Test accuracy: 0.964400
Distillation: Epoch : 39, Loss : 0.133291, Accuracy: 0.963000, Test accuracy: 0.965200
Distillation: Epoch : 40, Loss : 0.148598, Accuracy: 0.954000, Test accuracy: 0.965200
Distillation: Epoch : 41, Loss : 0.133220, Accuracy: 0.968000, Test accuracy: 0.965200
Distillation: Epoch : 42, Loss : 0.084940, Accuracy: 0.976000, Test accuracy: 0.965600
Distillation: Epoch : 43, Loss : 0.088623, Accuracy: 0.977000, Test accuracy: 0.965600
Distillation: Epoch : 44, Loss : 0.133654, Accuracy: 0.956000, Test accuracy: 0.965600
Distillation: Epoch : 45, Loss : 0.111182, Accuracy: 0.963000, Test accuracy: 0.965900
Distillation: Epoch : 46, Loss : 0.141374, Accuracy: 0.960000, Test accuracy: 0.966900
Distillation: Epoch : 47, Loss : 0.118895, Accuracy: 0.957000, Test accuracy: 0.967400
Distillation: Epoch : 48, Loss : 0.106082, Accuracy: 0.977000, Test accuracy: 0.966400
Distillation: Epoch : 49, Loss : 0.111711, Accuracy: 0.964000, Test accuracy: 0.967000
Distillation: Epoch : 50, Loss : 0.125089, Accuracy: 0.963000, Test accuracy: 0.966700
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9667
Generating confusion matrix for student5
[[ 965.    0.    3.    0.    2.    1.    8.    1.    5.    5.]
 [   0. 1118.    8.    0.    2.    1.    3.    5.    2.    5.]
 [   1.    3.  986.    3.    3.    0.    2.   14.    8.    1.]
 [   0.    3.   10.  988.    0.   15.    1.    9.   11.    8.]
 [   0.    0.    3.    0.  958.    0.    4.    3.    6.   13.]
 [   0.    0.    0.    5.    0.  856.    1.    0.    5.    1.]
 [   4.    1.    1.    0.    2.    8.  935.    0.    3.    0.]
 [   2.    1.    8.    3.    1.    2.    0.  980.   10.   11.]
 [   8.    9.   11.    7.    2.    3.    4.    3.  921.    5.]
 [   0.    0.    2.    4.   12.    6.    0.   13.    3.  960.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.074149, Accuracy: 0.564000, Test accuracy: 0.570600
Distillation: Epoch : 2, Loss : 1.591344, Accuracy: 0.786000, Test accuracy: 0.777500
Distillation: Epoch : 3, Loss : 1.160447, Accuracy: 0.812000, Test accuracy: 0.817100
Distillation: Epoch : 4, Loss : 0.912696, Accuracy: 0.822000, Test accuracy: 0.835500
Distillation: Epoch : 5, Loss : 0.698450, Accuracy: 0.849000, Test accuracy: 0.850800
Distillation: Epoch : 6, Loss : 0.610237, Accuracy: 0.847000, Test accuracy: 0.863800
Distillation: Epoch : 7, Loss : 0.497156, Accuracy: 0.878000, Test accuracy: 0.876900
Distillation: Epoch : 8, Loss : 0.453892, Accuracy: 0.873000, Test accuracy: 0.886800
Distillation: Epoch : 9, Loss : 0.398376, Accuracy: 0.896000, Test accuracy: 0.894500
Distillation: Epoch : 10, Loss : 0.373716, Accuracy: 0.903000, Test accuracy: 0.899700
Distillation: Epoch : 11, Loss : 0.393002, Accuracy: 0.888000, Test accuracy: 0.904700
Distillation: Epoch : 12, Loss : 0.327003, Accuracy: 0.905000, Test accuracy: 0.908800
Distillation: Epoch : 13, Loss : 0.338526, Accuracy: 0.898000, Test accuracy: 0.911200
Distillation: Epoch : 14, Loss : 0.287456, Accuracy: 0.917000, Test accuracy: 0.914100
Distillation: Epoch : 15, Loss : 0.307081, Accuracy: 0.917000, Test accuracy: 0.917500
Distillation: Epoch : 16, Loss : 0.330183, Accuracy: 0.906000, Test accuracy: 0.920900
Distillation: Epoch : 17, Loss : 0.374582, Accuracy: 0.902000, Test accuracy: 0.923200
Distillation: Epoch : 18, Loss : 0.317908, Accuracy: 0.911000, Test accuracy: 0.925800
Distillation: Epoch : 19, Loss : 0.313374, Accuracy: 0.914000, Test accuracy: 0.929200
Distillation: Epoch : 20, Loss : 0.289010, Accuracy: 0.917000, Test accuracy: 0.930800
Distillation: Epoch : 21, Loss : 0.297504, Accuracy: 0.914000, Test accuracy: 0.932700
Distillation: Epoch : 22, Loss : 0.238928, Accuracy: 0.928000, Test accuracy: 0.934000
Distillation: Epoch : 23, Loss : 0.241584, Accuracy: 0.929000, Test accuracy: 0.936100
Distillation: Epoch : 24, Loss : 0.246596, Accuracy: 0.926000, Test accuracy: 0.936800
Distillation: Epoch : 25, Loss : 0.199252, Accuracy: 0.941000, Test accuracy: 0.937900
Distillation: Epoch : 26, Loss : 0.243787, Accuracy: 0.924000, Test accuracy: 0.938400
Distillation: Epoch : 27, Loss : 0.218408, Accuracy: 0.951000, Test accuracy: 0.939100
Distillation: Epoch : 28, Loss : 0.223647, Accuracy: 0.932000, Test accuracy: 0.940600
Distillation: Epoch : 29, Loss : 0.209936, Accuracy: 0.938000, Test accuracy: 0.942600
Distillation: Epoch : 30, Loss : 0.212790, Accuracy: 0.938000, Test accuracy: 0.942800
Distillation: Epoch : 31, Loss : 0.215495, Accuracy: 0.942000, Test accuracy: 0.945100
Distillation: Epoch : 32, Loss : 0.253292, Accuracy: 0.926000, Test accuracy: 0.945300
Distillation: Epoch : 33, Loss : 0.191674, Accuracy: 0.951000, Test accuracy: 0.946000
Distillation: Epoch : 34, Loss : 0.218704, Accuracy: 0.945000, Test accuracy: 0.947400
Distillation: Epoch : 35, Loss : 0.263628, Accuracy: 0.927000, Test accuracy: 0.948700
Distillation: Epoch : 36, Loss : 0.162143, Accuracy: 0.958000, Test accuracy: 0.948600
Distillation: Epoch : 37, Loss : 0.190858, Accuracy: 0.954000, Test accuracy: 0.949500
Distillation: Epoch : 38, Loss : 0.196723, Accuracy: 0.956000, Test accuracy: 0.950400
Distillation: Epoch : 39, Loss : 0.225803, Accuracy: 0.945000, Test accuracy: 0.951300
Distillation: Epoch : 40, Loss : 0.169568, Accuracy: 0.956000, Test accuracy: 0.951900
Distillation: Epoch : 41, Loss : 0.236111, Accuracy: 0.936000, Test accuracy: 0.952000
Distillation: Epoch : 42, Loss : 0.179706, Accuracy: 0.949000, Test accuracy: 0.953300
Distillation: Epoch : 43, Loss : 0.226568, Accuracy: 0.937000, Test accuracy: 0.953300
Distillation: Epoch : 44, Loss : 0.194888, Accuracy: 0.950000, Test accuracy: 0.953700
Distillation: Epoch : 45, Loss : 0.183939, Accuracy: 0.951000, Test accuracy: 0.953700
Distillation: Epoch : 46, Loss : 0.175556, Accuracy: 0.955000, Test accuracy: 0.954100
Distillation: Epoch : 47, Loss : 0.158001, Accuracy: 0.957000, Test accuracy: 0.955300
Distillation: Epoch : 48, Loss : 0.167203, Accuracy: 0.962000, Test accuracy: 0.955100
Distillation: Epoch : 49, Loss : 0.179067, Accuracy: 0.951000, Test accuracy: 0.955700
Distillation: Epoch : 50, Loss : 0.165110, Accuracy: 0.960000, Test accuracy: 0.956500
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9565
Generating confusion matrix for student5
[[ 968.    0.    4.    0.    1.    3.   15.    2.    6.    8.]
 [   0. 1116.    7.    0.    0.    2.    3.    9.    0.    7.]
 [   2.    4.  969.   12.    4.    0.    2.   19.    3.    2.]
 [   0.    0.   12.  964.    0.   19.    0.    7.   12.    6.]
 [   0.    0.    7.    0.  952.    3.    6.    1.    7.   14.]
 [   1.    1.    1.   11.    0.  836.    4.    2.    3.    7.]
 [   4.    3.    2.    0.    4.    9.  924.    0.   10.    0.]
 [   2.    1.   12.   10.    1.    5.    0.  971.    3.   13.]
 [   3.   10.   12.   10.    4.    9.    4.    3.  921.    8.]
 [   0.    0.    6.    3.   16.    6.    0.   14.    9.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.480166, Accuracy: 0.726000, Test accuracy: 0.757100
Distillation: Epoch : 2, Loss : 0.838336, Accuracy: 0.832000, Test accuracy: 0.843000
Distillation: Epoch : 3, Loss : 0.735407, Accuracy: 0.874000, Test accuracy: 0.870800
Distillation: Epoch : 4, Loss : 0.716898, Accuracy: 0.864000, Test accuracy: 0.883200
Distillation: Epoch : 5, Loss : 0.713803, Accuracy: 0.887000, Test accuracy: 0.890800
Distillation: Epoch : 6, Loss : 0.662376, Accuracy: 0.902000, Test accuracy: 0.896200
Distillation: Epoch : 7, Loss : 0.671517, Accuracy: 0.890000, Test accuracy: 0.898800
Distillation: Epoch : 8, Loss : 0.686645, Accuracy: 0.880000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 0.651660, Accuracy: 0.894000, Test accuracy: 0.904800
Distillation: Epoch : 10, Loss : 0.603395, Accuracy: 0.920000, Test accuracy: 0.908900
Distillation: Epoch : 11, Loss : 0.638799, Accuracy: 0.897000, Test accuracy: 0.911500
Distillation: Epoch : 12, Loss : 0.620460, Accuracy: 0.907000, Test accuracy: 0.914400
Distillation: Epoch : 13, Loss : 0.642786, Accuracy: 0.904000, Test accuracy: 0.916300
Distillation: Epoch : 14, Loss : 0.637082, Accuracy: 0.919000, Test accuracy: 0.918400
Distillation: Epoch : 15, Loss : 0.602407, Accuracy: 0.919000, Test accuracy: 0.921400
Distillation: Epoch : 16, Loss : 0.618193, Accuracy: 0.907000, Test accuracy: 0.924100
Distillation: Epoch : 17, Loss : 0.593199, Accuracy: 0.922000, Test accuracy: 0.926200
Distillation: Epoch : 18, Loss : 0.567865, Accuracy: 0.922000, Test accuracy: 0.929800
Distillation: Epoch : 19, Loss : 0.586415, Accuracy: 0.931000, Test accuracy: 0.931600
Distillation: Epoch : 20, Loss : 0.596154, Accuracy: 0.910000, Test accuracy: 0.933400
Distillation: Epoch : 21, Loss : 0.585101, Accuracy: 0.919000, Test accuracy: 0.935100
Distillation: Epoch : 22, Loss : 0.535578, Accuracy: 0.936000, Test accuracy: 0.937400
Distillation: Epoch : 23, Loss : 0.558866, Accuracy: 0.938000, Test accuracy: 0.938100
Distillation: Epoch : 24, Loss : 0.547393, Accuracy: 0.936000, Test accuracy: 0.940700
Distillation: Epoch : 25, Loss : 0.570259, Accuracy: 0.922000, Test accuracy: 0.941600
Distillation: Epoch : 26, Loss : 0.582696, Accuracy: 0.919000, Test accuracy: 0.943600
Distillation: Epoch : 27, Loss : 0.506636, Accuracy: 0.947000, Test accuracy: 0.946200
Distillation: Epoch : 28, Loss : 0.528058, Accuracy: 0.942000, Test accuracy: 0.946700
Distillation: Epoch : 29, Loss : 0.525564, Accuracy: 0.935000, Test accuracy: 0.948300
Distillation: Epoch : 30, Loss : 0.557382, Accuracy: 0.942000, Test accuracy: 0.948800
Distillation: Epoch : 31, Loss : 0.523437, Accuracy: 0.949000, Test accuracy: 0.949700
Distillation: Epoch : 32, Loss : 0.506421, Accuracy: 0.936000, Test accuracy: 0.950800
Distillation: Epoch : 33, Loss : 0.483468, Accuracy: 0.955000, Test accuracy: 0.951200
Distillation: Epoch : 34, Loss : 0.525691, Accuracy: 0.936000, Test accuracy: 0.953300
Distillation: Epoch : 35, Loss : 0.511470, Accuracy: 0.941000, Test accuracy: 0.952800
Distillation: Epoch : 36, Loss : 0.520808, Accuracy: 0.939000, Test accuracy: 0.953700
Distillation: Epoch : 37, Loss : 0.505260, Accuracy: 0.950000, Test accuracy: 0.954700
Distillation: Epoch : 38, Loss : 0.492548, Accuracy: 0.965000, Test accuracy: 0.953500
Distillation: Epoch : 39, Loss : 0.497909, Accuracy: 0.953000, Test accuracy: 0.955500
Distillation: Epoch : 40, Loss : 0.506747, Accuracy: 0.948000, Test accuracy: 0.955500
Distillation: Epoch : 41, Loss : 0.513921, Accuracy: 0.941000, Test accuracy: 0.956700
Distillation: Epoch : 42, Loss : 0.502802, Accuracy: 0.943000, Test accuracy: 0.956500
Distillation: Epoch : 43, Loss : 0.513387, Accuracy: 0.947000, Test accuracy: 0.957000
Distillation: Epoch : 44, Loss : 0.471741, Accuracy: 0.957000, Test accuracy: 0.957300
Distillation: Epoch : 45, Loss : 0.523946, Accuracy: 0.951000, Test accuracy: 0.957500
Distillation: Epoch : 46, Loss : 0.463976, Accuracy: 0.967000, Test accuracy: 0.958600
Distillation: Epoch : 47, Loss : 0.492811, Accuracy: 0.952000, Test accuracy: 0.958300
Distillation: Epoch : 48, Loss : 0.480033, Accuracy: 0.963000, Test accuracy: 0.958400
Distillation: Epoch : 49, Loss : 0.459698, Accuracy: 0.966000, Test accuracy: 0.959000
Distillation: Epoch : 50, Loss : 0.509488, Accuracy: 0.949000, Test accuracy: 0.959300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9593
Generating confusion matrix for student5
[[ 962.    0.    2.    0.    1.    1.    6.    2.    4.    3.]
 [   0. 1115.    4.    0.    2.    0.    3.    7.    4.    7.]
 [   3.    4.  998.   10.    4.    1.    3.   22.    6.    2.]
 [   1.    2.    7.  966.    0.   20.    0.    5.   14.   16.]
 [   0.    0.    5.    1.  953.    2.    3.    2.    7.   19.]
 [   1.    0.    0.   15.    0.  851.    7.    1.    8.    9.]
 [   8.    2.    0.    0.    4.    6.  935.    0.    8.    1.]
 [   3.    0.    8.    8.    4.    4.    0.  973.    6.   17.]
 [   2.   12.    6.    8.    3.    2.    1.    2.  911.    6.]
 [   0.    0.    2.    2.   11.    5.    0.   14.    6.  929.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.679812, Accuracy: 0.736000, Test accuracy: 0.749500
Distillation: Epoch : 2, Loss : 0.992392, Accuracy: 0.834000, Test accuracy: 0.851700
Distillation: Epoch : 3, Loss : 0.925738, Accuracy: 0.861000, Test accuracy: 0.877600
Distillation: Epoch : 4, Loss : 0.869441, Accuracy: 0.874000, Test accuracy: 0.888700
Distillation: Epoch : 5, Loss : 0.823014, Accuracy: 0.896000, Test accuracy: 0.893100
Distillation: Epoch : 6, Loss : 0.820729, Accuracy: 0.890000, Test accuracy: 0.897600
Distillation: Epoch : 7, Loss : 0.856910, Accuracy: 0.877000, Test accuracy: 0.899900
Distillation: Epoch : 8, Loss : 0.856047, Accuracy: 0.873000, Test accuracy: 0.902500
Distillation: Epoch : 9, Loss : 0.852093, Accuracy: 0.885000, Test accuracy: 0.901300
Distillation: Epoch : 10, Loss : 0.812413, Accuracy: 0.897000, Test accuracy: 0.903600
Distillation: Epoch : 11, Loss : 0.840119, Accuracy: 0.890000, Test accuracy: 0.904800
Distillation: Epoch : 12, Loss : 0.806048, Accuracy: 0.904000, Test accuracy: 0.905800
Distillation: Epoch : 13, Loss : 0.819094, Accuracy: 0.887000, Test accuracy: 0.908800
Distillation: Epoch : 14, Loss : 0.854226, Accuracy: 0.883000, Test accuracy: 0.907800
Distillation: Epoch : 15, Loss : 0.787658, Accuracy: 0.905000, Test accuracy: 0.908200
Distillation: Epoch : 16, Loss : 0.799120, Accuracy: 0.901000, Test accuracy: 0.908600
Distillation: Epoch : 17, Loss : 0.799491, Accuracy: 0.889000, Test accuracy: 0.909800
Distillation: Epoch : 18, Loss : 0.821504, Accuracy: 0.896000, Test accuracy: 0.909600
Distillation: Epoch : 19, Loss : 0.797278, Accuracy: 0.901000, Test accuracy: 0.909700
Distillation: Epoch : 20, Loss : 0.820742, Accuracy: 0.893000, Test accuracy: 0.911300
Distillation: Epoch : 21, Loss : 0.806904, Accuracy: 0.896000, Test accuracy: 0.911200
Distillation: Epoch : 22, Loss : 0.804305, Accuracy: 0.905000, Test accuracy: 0.912000
Distillation: Epoch : 23, Loss : 0.784731, Accuracy: 0.908000, Test accuracy: 0.911500
Distillation: Epoch : 24, Loss : 0.817712, Accuracy: 0.910000, Test accuracy: 0.912800
Distillation: Epoch : 25, Loss : 0.795973, Accuracy: 0.906000, Test accuracy: 0.912900
Distillation: Epoch : 26, Loss : 0.784717, Accuracy: 0.904000, Test accuracy: 0.913100
Distillation: Epoch : 27, Loss : 0.787982, Accuracy: 0.903000, Test accuracy: 0.913000
Distillation: Epoch : 28, Loss : 0.781494, Accuracy: 0.918000, Test accuracy: 0.913300
Distillation: Epoch : 29, Loss : 0.785276, Accuracy: 0.902000, Test accuracy: 0.913400
Distillation: Epoch : 30, Loss : 0.778059, Accuracy: 0.908000, Test accuracy: 0.913400
Distillation: Epoch : 31, Loss : 0.824365, Accuracy: 0.898000, Test accuracy: 0.913900
Distillation: Epoch : 32, Loss : 0.764148, Accuracy: 0.914000, Test accuracy: 0.913200
Distillation: Epoch : 33, Loss : 0.792485, Accuracy: 0.907000, Test accuracy: 0.914000
Distillation: Epoch : 34, Loss : 0.768654, Accuracy: 0.921000, Test accuracy: 0.914100
Distillation: Epoch : 35, Loss : 0.809906, Accuracy: 0.908000, Test accuracy: 0.914400
Distillation: Epoch : 36, Loss : 0.777058, Accuracy: 0.929000, Test accuracy: 0.914400
Distillation: Epoch : 37, Loss : 0.771055, Accuracy: 0.913000, Test accuracy: 0.914200
Distillation: Epoch : 38, Loss : 0.764176, Accuracy: 0.920000, Test accuracy: 0.914900
Distillation: Epoch : 39, Loss : 0.754578, Accuracy: 0.928000, Test accuracy: 0.915100
Distillation: Epoch : 40, Loss : 0.762074, Accuracy: 0.922000, Test accuracy: 0.916500
Distillation: Epoch : 41, Loss : 0.764947, Accuracy: 0.912000, Test accuracy: 0.916700
Distillation: Epoch : 42, Loss : 0.751643, Accuracy: 0.918000, Test accuracy: 0.917400
Distillation: Epoch : 43, Loss : 0.735558, Accuracy: 0.922000, Test accuracy: 0.917400
Distillation: Epoch : 44, Loss : 0.792415, Accuracy: 0.914000, Test accuracy: 0.919000
Distillation: Epoch : 45, Loss : 0.799486, Accuracy: 0.922000, Test accuracy: 0.919800
Distillation: Epoch : 46, Loss : 0.772455, Accuracy: 0.910000, Test accuracy: 0.920500
Distillation: Epoch : 47, Loss : 0.782052, Accuracy: 0.918000, Test accuracy: 0.922400
Distillation: Epoch : 48, Loss : 0.746145, Accuracy: 0.919000, Test accuracy: 0.923300
Distillation: Epoch : 49, Loss : 0.751811, Accuracy: 0.923000, Test accuracy: 0.924500
Distillation: Epoch : 50, Loss : 0.755574, Accuracy: 0.930000, Test accuracy: 0.928300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9283
Generating confusion matrix for student5
[[ 952.    0.    5.    1.    1.    5.    5.    1.    5.    4.]
 [   0. 1107.    7.    2.    4.    3.    4.   16.    9.    5.]
 [   0.    3.  938.   16.    3.    2.    6.   18.    8.    1.]
 [   3.    2.   18.  952.    1.   51.    2.   10.   23.   19.]
 [   1.    0.    9.    2.  919.    2.    7.    7.   10.   32.]
 [   4.    2.    1.   16.    1.  793.   18.    0.   25.   11.]
 [  12.    4.   12.    3.   11.   15.  911.    0.   11.    1.]
 [   2.    0.    8.    7.    3.    1.    2.  944.   11.   29.]
 [   4.   17.   27.    8.    5.   17.    3.    2.  865.    5.]
 [   2.    0.    7.    3.   34.    3.    0.   30.    7.  902.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.904950, Accuracy: 0.559000, Test accuracy: 0.547200
Distillation: Epoch : 2, Loss : 1.163744, Accuracy: 0.817000, Test accuracy: 0.840000
Distillation: Epoch : 3, Loss : 1.066868, Accuracy: 0.859000, Test accuracy: 0.873400
Distillation: Epoch : 4, Loss : 1.052322, Accuracy: 0.869000, Test accuracy: 0.887100
Distillation: Epoch : 5, Loss : 1.003154, Accuracy: 0.898000, Test accuracy: 0.891000
Distillation: Epoch : 6, Loss : 0.994627, Accuracy: 0.888000, Test accuracy: 0.894700
Distillation: Epoch : 7, Loss : 1.019176, Accuracy: 0.871000, Test accuracy: 0.898800
Distillation: Epoch : 8, Loss : 0.949852, Accuracy: 0.913000, Test accuracy: 0.901500
Distillation: Epoch : 9, Loss : 0.975611, Accuracy: 0.888000, Test accuracy: 0.902500
Distillation: Epoch : 10, Loss : 0.990072, Accuracy: 0.894000, Test accuracy: 0.904600
Distillation: Epoch : 11, Loss : 0.939317, Accuracy: 0.913000, Test accuracy: 0.904900
Distillation: Epoch : 12, Loss : 0.974072, Accuracy: 0.899000, Test accuracy: 0.906700
Distillation: Epoch : 13, Loss : 0.986861, Accuracy: 0.892000, Test accuracy: 0.906800
Distillation: Epoch : 14, Loss : 0.973368, Accuracy: 0.900000, Test accuracy: 0.907300
Distillation: Epoch : 15, Loss : 0.943747, Accuracy: 0.901000, Test accuracy: 0.907900
Distillation: Epoch : 16, Loss : 0.968322, Accuracy: 0.895000, Test accuracy: 0.909600
Distillation: Epoch : 17, Loss : 0.950955, Accuracy: 0.913000, Test accuracy: 0.910000
Distillation: Epoch : 18, Loss : 0.974451, Accuracy: 0.885000, Test accuracy: 0.910200
Distillation: Epoch : 19, Loss : 0.974403, Accuracy: 0.882000, Test accuracy: 0.911000
Distillation: Epoch : 20, Loss : 0.939962, Accuracy: 0.895000, Test accuracy: 0.912200
Distillation: Epoch : 21, Loss : 0.926309, Accuracy: 0.910000, Test accuracy: 0.911900
Distillation: Epoch : 22, Loss : 0.982745, Accuracy: 0.896000, Test accuracy: 0.913100
Distillation: Epoch : 23, Loss : 0.927216, Accuracy: 0.924000, Test accuracy: 0.914200
Distillation: Epoch : 24, Loss : 0.971051, Accuracy: 0.902000, Test accuracy: 0.914600
Distillation: Epoch : 25, Loss : 0.913683, Accuracy: 0.911000, Test accuracy: 0.916400
Distillation: Epoch : 26, Loss : 0.921774, Accuracy: 0.913000, Test accuracy: 0.916000
Distillation: Epoch : 27, Loss : 0.942255, Accuracy: 0.910000, Test accuracy: 0.915600
Distillation: Epoch : 28, Loss : 0.949195, Accuracy: 0.910000, Test accuracy: 0.917300
Distillation: Epoch : 29, Loss : 0.927808, Accuracy: 0.907000, Test accuracy: 0.916500
Distillation: Epoch : 30, Loss : 0.943358, Accuracy: 0.909000, Test accuracy: 0.916200
Distillation: Epoch : 31, Loss : 0.915076, Accuracy: 0.908000, Test accuracy: 0.917300
Distillation: Epoch : 32, Loss : 0.942868, Accuracy: 0.908000, Test accuracy: 0.917300
Distillation: Epoch : 33, Loss : 0.920901, Accuracy: 0.920000, Test accuracy: 0.918600
Distillation: Epoch : 34, Loss : 0.947791, Accuracy: 0.904000, Test accuracy: 0.919200
Distillation: Epoch : 35, Loss : 0.978872, Accuracy: 0.893000, Test accuracy: 0.920200
Distillation: Epoch : 36, Loss : 0.927635, Accuracy: 0.912000, Test accuracy: 0.920000
Distillation: Epoch : 37, Loss : 0.940001, Accuracy: 0.918000, Test accuracy: 0.920600
Distillation: Epoch : 38, Loss : 0.902892, Accuracy: 0.918000, Test accuracy: 0.921400
Distillation: Epoch : 39, Loss : 0.911375, Accuracy: 0.925000, Test accuracy: 0.921300
Distillation: Epoch : 40, Loss : 0.967699, Accuracy: 0.895000, Test accuracy: 0.922600
Distillation: Epoch : 41, Loss : 0.893954, Accuracy: 0.919000, Test accuracy: 0.921900
Distillation: Epoch : 42, Loss : 0.912744, Accuracy: 0.923000, Test accuracy: 0.923100
Distillation: Epoch : 43, Loss : 0.890160, Accuracy: 0.923000, Test accuracy: 0.924600
Distillation: Epoch : 44, Loss : 0.929945, Accuracy: 0.920000, Test accuracy: 0.924700
Distillation: Epoch : 45, Loss : 0.895879, Accuracy: 0.937000, Test accuracy: 0.925500
Distillation: Epoch : 46, Loss : 0.896758, Accuracy: 0.928000, Test accuracy: 0.926100
Distillation: Epoch : 47, Loss : 0.927250, Accuracy: 0.923000, Test accuracy: 0.927100
Distillation: Epoch : 48, Loss : 0.917644, Accuracy: 0.922000, Test accuracy: 0.927900
Distillation: Epoch : 49, Loss : 0.909828, Accuracy: 0.920000, Test accuracy: 0.928800
Distillation: Epoch : 50, Loss : 0.904375, Accuracy: 0.932000, Test accuracy: 0.928600
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9286
Generating confusion matrix for student5
[[ 947.    0.    3.    2.    0.    6.    6.    1.    8.    5.]
 [   0. 1102.   11.    1.    3.    4.    3.   10.    5.    7.]
 [   1.    3.  927.   16.    6.    2.    5.   19.    5.    0.]
 [   3.    4.   21.  949.    1.   39.    0.   10.   22.   18.]
 [   1.    0.   10.    0.  912.    7.    6.    9.    8.   31.]
 [   4.    2.    2.   17.    2.  794.   16.    0.   20.   10.]
 [  13.    6.   10.    1.   15.   11.  917.    0.   11.    1.]
 [   2.    0.   13.   12.    2.    7.    2.  953.    6.   24.]
 [   6.   18.   28.    8.   10.   17.    3.    0.  881.    9.]
 [   3.    0.    7.    4.   31.    5.    0.   26.    8.  904.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.095183, Accuracy: 0.483000, Test accuracy: 0.506600
Distillation: Epoch : 2, Loss : 1.355994, Accuracy: 0.826000, Test accuracy: 0.826000
Distillation: Epoch : 3, Loss : 1.249772, Accuracy: 0.856000, Test accuracy: 0.863100
Distillation: Epoch : 4, Loss : 1.165519, Accuracy: 0.898000, Test accuracy: 0.882700
Distillation: Epoch : 5, Loss : 1.168759, Accuracy: 0.892000, Test accuracy: 0.894100
Distillation: Epoch : 6, Loss : 1.116316, Accuracy: 0.906000, Test accuracy: 0.904100
Distillation: Epoch : 7, Loss : 1.109345, Accuracy: 0.906000, Test accuracy: 0.910800
Distillation: Epoch : 8, Loss : 1.103074, Accuracy: 0.911000, Test accuracy: 0.917000
Distillation: Epoch : 9, Loss : 1.103216, Accuracy: 0.909000, Test accuracy: 0.921200
Distillation: Epoch : 10, Loss : 1.065711, Accuracy: 0.927000, Test accuracy: 0.926200
Distillation: Epoch : 11, Loss : 1.069583, Accuracy: 0.910000, Test accuracy: 0.928900
Distillation: Epoch : 12, Loss : 1.049065, Accuracy: 0.933000, Test accuracy: 0.933100
Distillation: Epoch : 13, Loss : 1.054615, Accuracy: 0.914000, Test accuracy: 0.936400
Distillation: Epoch : 14, Loss : 1.040092, Accuracy: 0.952000, Test accuracy: 0.939000
Distillation: Epoch : 15, Loss : 1.034913, Accuracy: 0.940000, Test accuracy: 0.940900
Distillation: Epoch : 16, Loss : 1.053531, Accuracy: 0.942000, Test accuracy: 0.943200
Distillation: Epoch : 17, Loss : 1.012570, Accuracy: 0.935000, Test accuracy: 0.943200
Distillation: Epoch : 18, Loss : 0.993039, Accuracy: 0.943000, Test accuracy: 0.945600
Distillation: Epoch : 19, Loss : 1.022517, Accuracy: 0.938000, Test accuracy: 0.947700
Distillation: Epoch : 20, Loss : 1.011644, Accuracy: 0.948000, Test accuracy: 0.948300
Distillation: Epoch : 21, Loss : 1.018826, Accuracy: 0.941000, Test accuracy: 0.950100
Distillation: Epoch : 22, Loss : 1.013807, Accuracy: 0.947000, Test accuracy: 0.951100
Distillation: Epoch : 23, Loss : 0.979614, Accuracy: 0.952000, Test accuracy: 0.951900
Distillation: Epoch : 24, Loss : 1.042804, Accuracy: 0.945000, Test accuracy: 0.953000
Distillation: Epoch : 25, Loss : 1.011886, Accuracy: 0.941000, Test accuracy: 0.953500
Distillation: Epoch : 26, Loss : 0.993358, Accuracy: 0.955000, Test accuracy: 0.953700
Distillation: Epoch : 27, Loss : 0.995095, Accuracy: 0.954000, Test accuracy: 0.954500
Distillation: Epoch : 28, Loss : 1.006541, Accuracy: 0.952000, Test accuracy: 0.955900
Distillation: Epoch : 29, Loss : 0.999049, Accuracy: 0.951000, Test accuracy: 0.956000
Distillation: Epoch : 30, Loss : 1.020152, Accuracy: 0.953000, Test accuracy: 0.955500
Distillation: Epoch : 31, Loss : 0.999700, Accuracy: 0.943000, Test accuracy: 0.956300
Distillation: Epoch : 32, Loss : 0.978741, Accuracy: 0.955000, Test accuracy: 0.955800
Distillation: Epoch : 33, Loss : 1.013579, Accuracy: 0.947000, Test accuracy: 0.957500
Distillation: Epoch : 34, Loss : 0.992458, Accuracy: 0.963000, Test accuracy: 0.957600
Distillation: Epoch : 35, Loss : 1.016170, Accuracy: 0.958000, Test accuracy: 0.958000
Distillation: Epoch : 36, Loss : 0.971737, Accuracy: 0.954000, Test accuracy: 0.958700
Distillation: Epoch : 37, Loss : 1.024993, Accuracy: 0.942000, Test accuracy: 0.959100
Distillation: Epoch : 38, Loss : 0.972498, Accuracy: 0.959000, Test accuracy: 0.958700
Distillation: Epoch : 39, Loss : 1.003183, Accuracy: 0.963000, Test accuracy: 0.960000
Distillation: Epoch : 40, Loss : 1.007476, Accuracy: 0.946000, Test accuracy: 0.960300
Distillation: Epoch : 41, Loss : 0.971699, Accuracy: 0.963000, Test accuracy: 0.959800
Distillation: Epoch : 42, Loss : 1.003709, Accuracy: 0.950000, Test accuracy: 0.961400
Distillation: Epoch : 43, Loss : 1.012724, Accuracy: 0.948000, Test accuracy: 0.960800
Distillation: Epoch : 44, Loss : 0.996139, Accuracy: 0.959000, Test accuracy: 0.961100
Distillation: Epoch : 45, Loss : 0.991202, Accuracy: 0.962000, Test accuracy: 0.960900
Distillation: Epoch : 46, Loss : 1.009945, Accuracy: 0.961000, Test accuracy: 0.960400
Distillation: Epoch : 47, Loss : 0.993856, Accuracy: 0.953000, Test accuracy: 0.961400
Distillation: Epoch : 48, Loss : 1.005295, Accuracy: 0.958000, Test accuracy: 0.961300
Distillation: Epoch : 49, Loss : 0.968737, Accuracy: 0.963000, Test accuracy: 0.961100
Distillation: Epoch : 50, Loss : 1.006496, Accuracy: 0.961000, Test accuracy: 0.962100
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9621
Generating confusion matrix for student5
[[ 968.    0.    1.    0.    1.    2.    6.    2.    6.    5.]
 [   0. 1114.    5.    0.    2.    0.    3.    8.    7.    7.]
 [   2.    4. 1000.   10.    3.    0.    1.   20.    8.    1.]
 [   0.    3.    5.  979.    0.   20.    1.    5.    9.   13.]
 [   0.    0.    3.    0.  951.    0.    3.    4.    6.   20.]
 [   0.    0.    0.    7.    0.  856.    5.    0.    4.    4.]
 [   7.    4.    2.    0.    5.    6.  936.    0.   11.    1.]
 [   0.    1.    8.    6.    3.    1.    0.  974.    9.   20.]
 [   2.    9.    7.    6.    4.    3.    3.    3.  908.    3.]
 [   1.    0.    1.    2.   13.    4.    0.   12.    6.  935.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.977829, Accuracy: 0.608000, Test accuracy: 0.610100
Distillation: Epoch : 2, Loss : 1.418559, Accuracy: 0.826000, Test accuracy: 0.846000
Distillation: Epoch : 3, Loss : 1.349508, Accuracy: 0.854000, Test accuracy: 0.872200
Distillation: Epoch : 4, Loss : 1.344420, Accuracy: 0.873000, Test accuracy: 0.880800
Distillation: Epoch : 5, Loss : 1.297062, Accuracy: 0.879000, Test accuracy: 0.887700
Distillation: Epoch : 6, Loss : 1.303915, Accuracy: 0.872000, Test accuracy: 0.890900
Distillation: Epoch : 7, Loss : 1.286331, Accuracy: 0.881000, Test accuracy: 0.892600
Distillation: Epoch : 8, Loss : 1.302037, Accuracy: 0.888000, Test accuracy: 0.894500
Distillation: Epoch : 9, Loss : 1.304539, Accuracy: 0.881000, Test accuracy: 0.895800
Distillation: Epoch : 10, Loss : 1.319688, Accuracy: 0.869000, Test accuracy: 0.896300
Distillation: Epoch : 11, Loss : 1.300990, Accuracy: 0.875000, Test accuracy: 0.897900
Distillation: Epoch : 12, Loss : 1.261534, Accuracy: 0.890000, Test accuracy: 0.898000
Distillation: Epoch : 13, Loss : 1.279977, Accuracy: 0.888000, Test accuracy: 0.899100
Distillation: Epoch : 14, Loss : 1.290492, Accuracy: 0.883000, Test accuracy: 0.899700
Distillation: Epoch : 15, Loss : 1.268151, Accuracy: 0.902000, Test accuracy: 0.900700
Distillation: Epoch : 16, Loss : 1.279345, Accuracy: 0.901000, Test accuracy: 0.900300
Distillation: Epoch : 17, Loss : 1.284869, Accuracy: 0.881000, Test accuracy: 0.901100
Distillation: Epoch : 18, Loss : 1.296467, Accuracy: 0.891000, Test accuracy: 0.902600
Distillation: Epoch : 19, Loss : 1.250489, Accuracy: 0.893000, Test accuracy: 0.901500
Distillation: Epoch : 20, Loss : 1.269207, Accuracy: 0.883000, Test accuracy: 0.902800
Distillation: Epoch : 21, Loss : 1.252460, Accuracy: 0.897000, Test accuracy: 0.904100
Distillation: Epoch : 22, Loss : 1.283648, Accuracy: 0.884000, Test accuracy: 0.905000
Distillation: Epoch : 23, Loss : 1.269832, Accuracy: 0.898000, Test accuracy: 0.902900
Distillation: Epoch : 24, Loss : 1.252832, Accuracy: 0.893000, Test accuracy: 0.905000
Distillation: Epoch : 25, Loss : 1.275121, Accuracy: 0.902000, Test accuracy: 0.905600
Distillation: Epoch : 26, Loss : 1.291172, Accuracy: 0.907000, Test accuracy: 0.906400
Distillation: Epoch : 27, Loss : 1.267899, Accuracy: 0.891000, Test accuracy: 0.904600
Distillation: Epoch : 28, Loss : 1.288004, Accuracy: 0.888000, Test accuracy: 0.906600
Distillation: Epoch : 29, Loss : 1.264808, Accuracy: 0.906000, Test accuracy: 0.906200
Distillation: Epoch : 30, Loss : 1.239837, Accuracy: 0.902000, Test accuracy: 0.906500
Distillation: Epoch : 31, Loss : 1.257199, Accuracy: 0.909000, Test accuracy: 0.906900
Distillation: Epoch : 32, Loss : 1.242356, Accuracy: 0.904000, Test accuracy: 0.907900
Distillation: Epoch : 33, Loss : 1.272115, Accuracy: 0.903000, Test accuracy: 0.907500
Distillation: Epoch : 34, Loss : 1.247983, Accuracy: 0.907000, Test accuracy: 0.908500
Distillation: Epoch : 35, Loss : 1.285110, Accuracy: 0.896000, Test accuracy: 0.909800
Distillation: Epoch : 36, Loss : 1.288167, Accuracy: 0.890000, Test accuracy: 0.907500
Distillation: Epoch : 37, Loss : 1.279199, Accuracy: 0.898000, Test accuracy: 0.909100
Distillation: Epoch : 38, Loss : 1.277443, Accuracy: 0.890000, Test accuracy: 0.909200
Distillation: Epoch : 39, Loss : 1.252252, Accuracy: 0.870000, Test accuracy: 0.908600
Distillation: Epoch : 40, Loss : 1.262119, Accuracy: 0.905000, Test accuracy: 0.908400
Distillation: Epoch : 41, Loss : 1.225864, Accuracy: 0.913000, Test accuracy: 0.908200
Distillation: Epoch : 42, Loss : 1.275698, Accuracy: 0.897000, Test accuracy: 0.909200
Distillation: Epoch : 43, Loss : 1.273601, Accuracy: 0.897000, Test accuracy: 0.908800
Distillation: Epoch : 44, Loss : 1.266229, Accuracy: 0.903000, Test accuracy: 0.909200
Distillation: Epoch : 45, Loss : 1.260242, Accuracy: 0.899000, Test accuracy: 0.909100
Distillation: Epoch : 46, Loss : 1.249522, Accuracy: 0.903000, Test accuracy: 0.909000
Distillation: Epoch : 47, Loss : 1.273427, Accuracy: 0.896000, Test accuracy: 0.908800
Distillation: Epoch : 48, Loss : 1.267946, Accuracy: 0.899000, Test accuracy: 0.908900
Distillation: Epoch : 49, Loss : 1.268194, Accuracy: 0.913000, Test accuracy: 0.908300
Distillation: Epoch : 50, Loss : 1.246368, Accuracy: 0.904000, Test accuracy: 0.908900
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9089
Generating confusion matrix for student5
[[ 934.    0.    5.    3.    0.    6.    5.    1.    6.    7.]
 [   0. 1103.   16.    2.    1.    3.    3.   20.   12.    7.]
 [   2.    2.  893.   20.    6.    3.    6.   16.    7.    2.]
 [   5.    4.   27.  933.    1.   45.    2.    7.   41.   20.]
 [   2.    1.   14.    1.  907.    7.    8.   10.   12.   34.]
 [   8.    6.    3.   21.    4.  771.   22.    2.   44.   10.]
 [  20.    4.   17.    3.   10.   18.  908.    1.   14.    1.]
 [   3.    0.   14.    9.    2.   10.    3.  933.    6.   32.]
 [   4.   15.   36.   13.   14.   22.    1.    1.  818.    7.]
 [   2.    0.    7.    5.   37.    7.    0.   37.   14.  889.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.003092, Accuracy: 0.667000, Test accuracy: 0.683300
Distillation: Epoch : 2, Loss : 1.513194, Accuracy: 0.851000, Test accuracy: 0.841900
Distillation: Epoch : 3, Loss : 1.486333, Accuracy: 0.871000, Test accuracy: 0.866000
Distillation: Epoch : 4, Loss : 1.426902, Accuracy: 0.874000, Test accuracy: 0.884000
Distillation: Epoch : 5, Loss : 1.449782, Accuracy: 0.874000, Test accuracy: 0.890600
Distillation: Epoch : 6, Loss : 1.416194, Accuracy: 0.888000, Test accuracy: 0.894400
Distillation: Epoch : 7, Loss : 1.409409, Accuracy: 0.891000, Test accuracy: 0.898200
Distillation: Epoch : 8, Loss : 1.355119, Accuracy: 0.911000, Test accuracy: 0.901800
Distillation: Epoch : 9, Loss : 1.419141, Accuracy: 0.900000, Test accuracy: 0.905300
Distillation: Epoch : 10, Loss : 1.412070, Accuracy: 0.904000, Test accuracy: 0.909800
Distillation: Epoch : 11, Loss : 1.379779, Accuracy: 0.901000, Test accuracy: 0.914000
Distillation: Epoch : 12, Loss : 1.354134, Accuracy: 0.930000, Test accuracy: 0.916000
Distillation: Epoch : 13, Loss : 1.388027, Accuracy: 0.896000, Test accuracy: 0.919300
Distillation: Epoch : 14, Loss : 1.372867, Accuracy: 0.910000, Test accuracy: 0.922200
Distillation: Epoch : 15, Loss : 1.359926, Accuracy: 0.914000, Test accuracy: 0.925300
Distillation: Epoch : 16, Loss : 1.369985, Accuracy: 0.920000, Test accuracy: 0.927000
Distillation: Epoch : 17, Loss : 1.366216, Accuracy: 0.917000, Test accuracy: 0.930200
Distillation: Epoch : 18, Loss : 1.374680, Accuracy: 0.914000, Test accuracy: 0.931600
Distillation: Epoch : 19, Loss : 1.352241, Accuracy: 0.922000, Test accuracy: 0.933700
Distillation: Epoch : 20, Loss : 1.366491, Accuracy: 0.925000, Test accuracy: 0.935600
Distillation: Epoch : 21, Loss : 1.346788, Accuracy: 0.922000, Test accuracy: 0.937700
Distillation: Epoch : 22, Loss : 1.343172, Accuracy: 0.933000, Test accuracy: 0.939200
Distillation: Epoch : 23, Loss : 1.351250, Accuracy: 0.922000, Test accuracy: 0.941400
Distillation: Epoch : 24, Loss : 1.351245, Accuracy: 0.946000, Test accuracy: 0.941000
Distillation: Epoch : 25, Loss : 1.350367, Accuracy: 0.935000, Test accuracy: 0.943000
Distillation: Epoch : 26, Loss : 1.323747, Accuracy: 0.943000, Test accuracy: 0.943900
Distillation: Epoch : 27, Loss : 1.320691, Accuracy: 0.940000, Test accuracy: 0.945500
Distillation: Epoch : 28, Loss : 1.332329, Accuracy: 0.942000, Test accuracy: 0.946000
Distillation: Epoch : 29, Loss : 1.334365, Accuracy: 0.954000, Test accuracy: 0.946700
Distillation: Epoch : 30, Loss : 1.328056, Accuracy: 0.938000, Test accuracy: 0.947800
Distillation: Epoch : 31, Loss : 1.324883, Accuracy: 0.943000, Test accuracy: 0.947500
Distillation: Epoch : 32, Loss : 1.325933, Accuracy: 0.942000, Test accuracy: 0.948900
Distillation: Epoch : 33, Loss : 1.311728, Accuracy: 0.948000, Test accuracy: 0.949700
Distillation: Epoch : 34, Loss : 1.282327, Accuracy: 0.946000, Test accuracy: 0.949200
Distillation: Epoch : 35, Loss : 1.330296, Accuracy: 0.940000, Test accuracy: 0.949600
Distillation: Epoch : 36, Loss : 1.306806, Accuracy: 0.942000, Test accuracy: 0.950300
Distillation: Epoch : 37, Loss : 1.324102, Accuracy: 0.940000, Test accuracy: 0.950700
Distillation: Epoch : 38, Loss : 1.312791, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 39, Loss : 1.333026, Accuracy: 0.948000, Test accuracy: 0.950600
Distillation: Epoch : 40, Loss : 1.325441, Accuracy: 0.946000, Test accuracy: 0.951200
Distillation: Epoch : 41, Loss : 1.335781, Accuracy: 0.935000, Test accuracy: 0.951200
Distillation: Epoch : 42, Loss : 1.301984, Accuracy: 0.957000, Test accuracy: 0.952500
Distillation: Epoch : 43, Loss : 1.297563, Accuracy: 0.956000, Test accuracy: 0.951600
Distillation: Epoch : 44, Loss : 1.290189, Accuracy: 0.960000, Test accuracy: 0.951600
Distillation: Epoch : 45, Loss : 1.308493, Accuracy: 0.953000, Test accuracy: 0.951900
Distillation: Epoch : 46, Loss : 1.333837, Accuracy: 0.944000, Test accuracy: 0.952900
Distillation: Epoch : 47, Loss : 1.306271, Accuracy: 0.948000, Test accuracy: 0.952300
Distillation: Epoch : 48, Loss : 1.316809, Accuracy: 0.957000, Test accuracy: 0.952300
Distillation: Epoch : 49, Loss : 1.320902, Accuracy: 0.938000, Test accuracy: 0.952000
Distillation: Epoch : 50, Loss : 1.327572, Accuracy: 0.948000, Test accuracy: 0.953400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9534
Generating confusion matrix for student5
[[ 957.    0.    5.    1.    1.    4.    4.    0.    6.    1.]
 [   0. 1109.    8.    2.    2.    0.    3.   11.    7.    5.]
 [   0.    2.  977.    9.    4.    1.    3.   19.    6.    1.]
 [   2.    5.   11.  954.    0.   15.    1.    6.   14.   11.]
 [   2.    0.   11.    0.  935.    1.    2.    9.    6.   18.]
 [   3.    0.    0.   23.    2.  846.    7.    0.    6.    9.]
 [   8.    7.    2.    1.   11.   12.  937.    1.    9.    3.]
 [   1.    0.    8.   13.    4.    3.    0.  970.    6.   12.]
 [   6.   12.    8.    7.    3.    7.    1.    1.  909.    9.]
 [   1.    0.    2.    0.   20.    3.    0.   11.    5.  940.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.113599, Accuracy: 0.518000, Test accuracy: 0.512300
Distillation: Epoch : 2, Loss : 1.661313, Accuracy: 0.804000, Test accuracy: 0.828500
Distillation: Epoch : 3, Loss : 1.565918, Accuracy: 0.854000, Test accuracy: 0.862100
Distillation: Epoch : 4, Loss : 1.555629, Accuracy: 0.876000, Test accuracy: 0.875600
Distillation: Epoch : 5, Loss : 1.562320, Accuracy: 0.879000, Test accuracy: 0.882700
Distillation: Epoch : 6, Loss : 1.542517, Accuracy: 0.880000, Test accuracy: 0.886900
Distillation: Epoch : 7, Loss : 1.531579, Accuracy: 0.871000, Test accuracy: 0.892700
Distillation: Epoch : 8, Loss : 1.546688, Accuracy: 0.890000, Test accuracy: 0.895700
Distillation: Epoch : 9, Loss : 1.551440, Accuracy: 0.870000, Test accuracy: 0.897900
Distillation: Epoch : 10, Loss : 1.535772, Accuracy: 0.894000, Test accuracy: 0.900900
Distillation: Epoch : 11, Loss : 1.549119, Accuracy: 0.879000, Test accuracy: 0.902400
Distillation: Epoch : 12, Loss : 1.516213, Accuracy: 0.909000, Test accuracy: 0.904600
Distillation: Epoch : 13, Loss : 1.536558, Accuracy: 0.893000, Test accuracy: 0.907500
Distillation: Epoch : 14, Loss : 1.527251, Accuracy: 0.888000, Test accuracy: 0.908500
Distillation: Epoch : 15, Loss : 1.505936, Accuracy: 0.908000, Test accuracy: 0.909500
Distillation: Epoch : 16, Loss : 1.509996, Accuracy: 0.912000, Test accuracy: 0.910700
Distillation: Epoch : 17, Loss : 1.485562, Accuracy: 0.917000, Test accuracy: 0.912400
Distillation: Epoch : 18, Loss : 1.519004, Accuracy: 0.892000, Test accuracy: 0.914400
Distillation: Epoch : 19, Loss : 1.478343, Accuracy: 0.905000, Test accuracy: 0.915000
Distillation: Epoch : 20, Loss : 1.488944, Accuracy: 0.913000, Test accuracy: 0.918200
Distillation: Epoch : 21, Loss : 1.500482, Accuracy: 0.932000, Test accuracy: 0.919400
Distillation: Epoch : 22, Loss : 1.476136, Accuracy: 0.926000, Test accuracy: 0.921400
Distillation: Epoch : 23, Loss : 1.479430, Accuracy: 0.917000, Test accuracy: 0.922200
Distillation: Epoch : 24, Loss : 1.480173, Accuracy: 0.922000, Test accuracy: 0.924000
Distillation: Epoch : 25, Loss : 1.467317, Accuracy: 0.922000, Test accuracy: 0.926300
Distillation: Epoch : 26, Loss : 1.491920, Accuracy: 0.913000, Test accuracy: 0.926400
Distillation: Epoch : 27, Loss : 1.457117, Accuracy: 0.937000, Test accuracy: 0.927100
Distillation: Epoch : 28, Loss : 1.475927, Accuracy: 0.928000, Test accuracy: 0.929200
Distillation: Epoch : 29, Loss : 1.464887, Accuracy: 0.927000, Test accuracy: 0.928800
Distillation: Epoch : 30, Loss : 1.449702, Accuracy: 0.930000, Test accuracy: 0.931000
Distillation: Epoch : 31, Loss : 1.453642, Accuracy: 0.942000, Test accuracy: 0.932300
Distillation: Epoch : 32, Loss : 1.472226, Accuracy: 0.929000, Test accuracy: 0.932300
Distillation: Epoch : 33, Loss : 1.465908, Accuracy: 0.933000, Test accuracy: 0.933400
Distillation: Epoch : 34, Loss : 1.466218, Accuracy: 0.925000, Test accuracy: 0.936500
Distillation: Epoch : 35, Loss : 1.474807, Accuracy: 0.931000, Test accuracy: 0.937000
Distillation: Epoch : 36, Loss : 1.477930, Accuracy: 0.933000, Test accuracy: 0.936500
Distillation: Epoch : 37, Loss : 1.458850, Accuracy: 0.950000, Test accuracy: 0.938100
Distillation: Epoch : 38, Loss : 1.449382, Accuracy: 0.926000, Test accuracy: 0.938800
Distillation: Epoch : 39, Loss : 1.442865, Accuracy: 0.939000, Test accuracy: 0.939200
Distillation: Epoch : 40, Loss : 1.469398, Accuracy: 0.932000, Test accuracy: 0.941100
Distillation: Epoch : 41, Loss : 1.472267, Accuracy: 0.941000, Test accuracy: 0.941800
Distillation: Epoch : 42, Loss : 1.449590, Accuracy: 0.928000, Test accuracy: 0.941900
Distillation: Epoch : 43, Loss : 1.453194, Accuracy: 0.927000, Test accuracy: 0.942000
Distillation: Epoch : 44, Loss : 1.454111, Accuracy: 0.939000, Test accuracy: 0.943200
Distillation: Epoch : 45, Loss : 1.474491, Accuracy: 0.927000, Test accuracy: 0.943900
Distillation: Epoch : 46, Loss : 1.436127, Accuracy: 0.949000, Test accuracy: 0.944800
Distillation: Epoch : 47, Loss : 1.453506, Accuracy: 0.947000, Test accuracy: 0.944200
Distillation: Epoch : 48, Loss : 1.443200, Accuracy: 0.935000, Test accuracy: 0.945200
Distillation: Epoch : 49, Loss : 1.464840, Accuracy: 0.934000, Test accuracy: 0.945600
Distillation: Epoch : 50, Loss : 1.454169, Accuracy: 0.942000, Test accuracy: 0.945300
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9453
Generating confusion matrix for student5
[[ 948.    0.    1.    0.    0.    5.    5.    0.    5.    2.]
 [   0. 1085.    1.    0.    0.    0.    2.   10.    3.    6.]
 [   4.    5.  974.   15.    4.    2.    1.   17.    9.    0.]
 [   1.    7.   17.  975.    1.   28.    0.    7.   35.   11.]
 [   4.    0.    6.    1.  935.    1.    3.   11.    5.   13.]
 [   5.    1.    1.    9.    1.  818.   10.    0.   16.    5.]
 [  10.    7.    5.    1.   16.   15.  935.    0.   10.    3.]
 [   2.    2.    6.    6.    2.    4.    0.  953.    3.   12.]
 [   5.   28.   21.    3.    3.   15.    2.    1.  882.    9.]
 [   1.    0.    0.    0.   20.    4.    0.   29.    6.  948.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.109551, Accuracy: 0.551000, Test accuracy: 0.577000
Distillation: Epoch : 2, Loss : 1.863174, Accuracy: 0.831000, Test accuracy: 0.836600
Distillation: Epoch : 3, Loss : 1.840127, Accuracy: 0.844000, Test accuracy: 0.862300
Distillation: Epoch : 4, Loss : 1.821283, Accuracy: 0.858000, Test accuracy: 0.873400
Distillation: Epoch : 5, Loss : 1.791900, Accuracy: 0.883000, Test accuracy: 0.879900
Distillation: Epoch : 6, Loss : 1.785049, Accuracy: 0.899000, Test accuracy: 0.884900
Distillation: Epoch : 7, Loss : 1.807077, Accuracy: 0.877000, Test accuracy: 0.888500
Distillation: Epoch : 8, Loss : 1.783764, Accuracy: 0.902000, Test accuracy: 0.889900
Distillation: Epoch : 9, Loss : 1.800797, Accuracy: 0.879000, Test accuracy: 0.890100
Distillation: Epoch : 10, Loss : 1.785087, Accuracy: 0.885000, Test accuracy: 0.893100
Distillation: Epoch : 11, Loss : 1.780094, Accuracy: 0.885000, Test accuracy: 0.894400
Distillation: Epoch : 12, Loss : 1.773952, Accuracy: 0.892000, Test accuracy: 0.895800
Distillation: Epoch : 13, Loss : 1.796346, Accuracy: 0.883000, Test accuracy: 0.897900
Distillation: Epoch : 14, Loss : 1.767068, Accuracy: 0.896000, Test accuracy: 0.898400
Distillation: Epoch : 15, Loss : 1.797898, Accuracy: 0.887000, Test accuracy: 0.900200
Distillation: Epoch : 16, Loss : 1.787517, Accuracy: 0.888000, Test accuracy: 0.900300
Distillation: Epoch : 17, Loss : 1.771140, Accuracy: 0.900000, Test accuracy: 0.901000
Distillation: Epoch : 18, Loss : 1.785448, Accuracy: 0.882000, Test accuracy: 0.900500
Distillation: Epoch : 19, Loss : 1.768840, Accuracy: 0.890000, Test accuracy: 0.901000
Distillation: Epoch : 20, Loss : 1.774893, Accuracy: 0.901000, Test accuracy: 0.901400
Distillation: Epoch : 21, Loss : 1.788097, Accuracy: 0.896000, Test accuracy: 0.902900
Distillation: Epoch : 22, Loss : 1.787078, Accuracy: 0.891000, Test accuracy: 0.903100
Distillation: Epoch : 23, Loss : 1.775524, Accuracy: 0.886000, Test accuracy: 0.903800
Distillation: Epoch : 24, Loss : 1.776957, Accuracy: 0.896000, Test accuracy: 0.903300
Distillation: Epoch : 25, Loss : 1.773363, Accuracy: 0.891000, Test accuracy: 0.905900
Distillation: Epoch : 26, Loss : 1.762530, Accuracy: 0.912000, Test accuracy: 0.906400
Distillation: Epoch : 27, Loss : 1.755770, Accuracy: 0.902000, Test accuracy: 0.906400
Distillation: Epoch : 28, Loss : 1.761861, Accuracy: 0.894000, Test accuracy: 0.908000
Distillation: Epoch : 29, Loss : 1.777659, Accuracy: 0.880000, Test accuracy: 0.907300
Distillation: Epoch : 30, Loss : 1.773757, Accuracy: 0.898000, Test accuracy: 0.908900
Distillation: Epoch : 31, Loss : 1.772073, Accuracy: 0.905000, Test accuracy: 0.907700
Distillation: Epoch : 32, Loss : 1.776520, Accuracy: 0.880000, Test accuracy: 0.909200
Distillation: Epoch : 33, Loss : 1.739401, Accuracy: 0.919000, Test accuracy: 0.909000
Distillation: Epoch : 34, Loss : 1.764908, Accuracy: 0.899000, Test accuracy: 0.909800
Distillation: Epoch : 35, Loss : 1.774339, Accuracy: 0.892000, Test accuracy: 0.909600
Distillation: Epoch : 36, Loss : 1.769646, Accuracy: 0.906000, Test accuracy: 0.910300
Distillation: Epoch : 37, Loss : 1.759778, Accuracy: 0.889000, Test accuracy: 0.910800
Distillation: Epoch : 38, Loss : 1.757223, Accuracy: 0.907000, Test accuracy: 0.911400
Distillation: Epoch : 39, Loss : 1.773380, Accuracy: 0.914000, Test accuracy: 0.913000
Distillation: Epoch : 40, Loss : 1.780655, Accuracy: 0.889000, Test accuracy: 0.912700
Distillation: Epoch : 41, Loss : 1.791564, Accuracy: 0.898000, Test accuracy: 0.913400
Distillation: Epoch : 42, Loss : 1.759323, Accuracy: 0.909000, Test accuracy: 0.914700
Distillation: Epoch : 43, Loss : 1.759196, Accuracy: 0.908000, Test accuracy: 0.914000
Distillation: Epoch : 44, Loss : 1.750757, Accuracy: 0.915000, Test accuracy: 0.915100
Distillation: Epoch : 45, Loss : 1.765466, Accuracy: 0.917000, Test accuracy: 0.916300
Distillation: Epoch : 46, Loss : 1.748947, Accuracy: 0.904000, Test accuracy: 0.914900
Distillation: Epoch : 47, Loss : 1.728731, Accuracy: 0.918000, Test accuracy: 0.917100
Distillation: Epoch : 48, Loss : 1.743723, Accuracy: 0.908000, Test accuracy: 0.915200
Distillation: Epoch : 49, Loss : 1.758423, Accuracy: 0.913000, Test accuracy: 0.917300
Distillation: Epoch : 50, Loss : 1.741738, Accuracy: 0.920000, Test accuracy: 0.917400
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.9174
Generating confusion matrix for student5
[[ 938.    0.    8.    1.    0.    5.    6.    1.   12.    4.]
 [   0. 1092.   12.    1.    0.    2.    4.   12.   14.    8.]
 [   6.    7.  903.   17.    2.    1.    4.   20.   11.    1.]
 [   6.    3.   25.  951.    1.   32.    1.   10.   27.   20.]
 [   2.    1.   24.    0.  896.    4.    7.   12.   12.   52.]
 [   3.    6.    1.   13.    3.  810.   19.    5.   16.    7.]
 [  11.    7.   14.    4.   13.   15.  914.    1.    8.    0.]
 [   3.    0.   17.   13.    5.    2.    2.  928.    5.   33.]
 [  10.   19.   25.    7.    8.   14.    1.    2.  866.    8.]
 [   1.    0.    3.    3.   54.    7.    0.   37.    3.  876.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.232622, Accuracy: 0.389000, Test accuracy: 0.383200
Distillation: Epoch : 2, Loss : 2.064259, Accuracy: 0.813000, Test accuracy: 0.827600
Distillation: Epoch : 3, Loss : 2.041257, Accuracy: 0.855000, Test accuracy: 0.847700
Distillation: Epoch : 4, Loss : 2.044360, Accuracy: 0.839000, Test accuracy: 0.860600
Distillation: Epoch : 5, Loss : 2.044164, Accuracy: 0.837000, Test accuracy: 0.868100
Distillation: Epoch : 6, Loss : 2.034805, Accuracy: 0.865000, Test accuracy: 0.872100
Distillation: Epoch : 7, Loss : 2.044315, Accuracy: 0.843000, Test accuracy: 0.871200
Distillation: Epoch : 8, Loss : 2.029134, Accuracy: 0.886000, Test accuracy: 0.875900
Distillation: Epoch : 9, Loss : 2.028057, Accuracy: 0.853000, Test accuracy: 0.878200
Distillation: Epoch : 10, Loss : 2.037698, Accuracy: 0.868000, Test accuracy: 0.878400
Distillation: Epoch : 11, Loss : 2.036056, Accuracy: 0.874000, Test accuracy: 0.880000
Distillation: Epoch : 12, Loss : 2.034101, Accuracy: 0.879000, Test accuracy: 0.881500
Distillation: Epoch : 13, Loss : 2.036596, Accuracy: 0.860000, Test accuracy: 0.879200
Distillation: Epoch : 14, Loss : 2.032643, Accuracy: 0.864000, Test accuracy: 0.881400
Distillation: Epoch : 15, Loss : 2.013866, Accuracy: 0.876000, Test accuracy: 0.880400
Distillation: Epoch : 16, Loss : 2.023463, Accuracy: 0.888000, Test accuracy: 0.882000
Distillation: Epoch : 17, Loss : 2.033019, Accuracy: 0.871000, Test accuracy: 0.883700
Distillation: Epoch : 18, Loss : 2.039795, Accuracy: 0.874000, Test accuracy: 0.884300
Distillation: Epoch : 19, Loss : 2.024891, Accuracy: 0.853000, Test accuracy: 0.884100
Distillation: Epoch : 20, Loss : 2.045490, Accuracy: 0.876000, Test accuracy: 0.882400
Distillation: Epoch : 21, Loss : 2.035448, Accuracy: 0.879000, Test accuracy: 0.883600
Distillation: Epoch : 22, Loss : 2.022681, Accuracy: 0.886000, Test accuracy: 0.886000
Distillation: Epoch : 23, Loss : 2.034458, Accuracy: 0.869000, Test accuracy: 0.884900
Distillation: Epoch : 24, Loss : 2.023345, Accuracy: 0.851000, Test accuracy: 0.886000
Distillation: Epoch : 25, Loss : 2.027897, Accuracy: 0.861000, Test accuracy: 0.884800
Distillation: Epoch : 26, Loss : 2.029625, Accuracy: 0.875000, Test accuracy: 0.887000
Distillation: Epoch : 27, Loss : 2.025665, Accuracy: 0.887000, Test accuracy: 0.887100
Distillation: Epoch : 28, Loss : 2.034873, Accuracy: 0.875000, Test accuracy: 0.886300
Distillation: Epoch : 29, Loss : 2.025040, Accuracy: 0.885000, Test accuracy: 0.888500
Distillation: Epoch : 30, Loss : 2.022629, Accuracy: 0.887000, Test accuracy: 0.889800
Distillation: Epoch : 31, Loss : 2.018516, Accuracy: 0.887000, Test accuracy: 0.887600
Distillation: Epoch : 32, Loss : 2.030235, Accuracy: 0.880000, Test accuracy: 0.889600
Distillation: Epoch : 33, Loss : 2.020265, Accuracy: 0.888000, Test accuracy: 0.889600
Distillation: Epoch : 34, Loss : 2.016541, Accuracy: 0.888000, Test accuracy: 0.887800
Distillation: Epoch : 35, Loss : 2.013975, Accuracy: 0.898000, Test accuracy: 0.887700
Distillation: Epoch : 36, Loss : 2.028188, Accuracy: 0.879000, Test accuracy: 0.890600
Distillation: Epoch : 37, Loss : 2.026796, Accuracy: 0.880000, Test accuracy: 0.885800
Distillation: Epoch : 38, Loss : 2.020581, Accuracy: 0.899000, Test accuracy: 0.890000
Distillation: Epoch : 39, Loss : 2.036347, Accuracy: 0.882000, Test accuracy: 0.890900
Distillation: Epoch : 40, Loss : 2.035598, Accuracy: 0.874000, Test accuracy: 0.888800
Distillation: Epoch : 41, Loss : 2.028865, Accuracy: 0.890000, Test accuracy: 0.891600
Distillation: Epoch : 42, Loss : 2.032935, Accuracy: 0.865000, Test accuracy: 0.891300
Distillation: Epoch : 43, Loss : 2.027475, Accuracy: 0.870000, Test accuracy: 0.888000
Distillation: Epoch : 44, Loss : 2.028418, Accuracy: 0.883000, Test accuracy: 0.889600
Distillation: Epoch : 45, Loss : 2.027328, Accuracy: 0.889000, Test accuracy: 0.891000
Distillation: Epoch : 46, Loss : 2.035210, Accuracy: 0.894000, Test accuracy: 0.889100
Distillation: Epoch : 47, Loss : 2.020489, Accuracy: 0.878000, Test accuracy: 0.890100
Distillation: Epoch : 48, Loss : 2.028575, Accuracy: 0.866000, Test accuracy: 0.890500
Distillation: Epoch : 49, Loss : 2.018486, Accuracy: 0.885000, Test accuracy: 0.890000
Distillation: Epoch : 50, Loss : 2.029608, Accuracy: 0.886000, Test accuracy: 0.889200
Saving to student5/student5.ckpt
<confusion_matrix>
results for %s distillate with T = %d student5 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student5/student5.ckpt
Accuracy on the test set
0.8892
Generating confusion matrix for student5
[[ 902.    0.    5.    3.    1.    5.    5.    1.    5.   11.]
 [   0. 1095.   23.    2.    1.    3.    3.   28.    7.    7.]
 [   6.    2.  864.   18.    5.    1.    4.   19.    8.    3.]
 [   8.    7.   31.  931.    2.   69.    1.    9.   69.   31.]
 [   4.    1.   21.    2.  904.   10.   12.   18.   13.   55.]
 [  19.    7.    1.   24.    5.  739.   22.    4.   39.   11.]
 [  32.    4.   35.    5.   15.   19.  909.    1.   18.    2.]
 [   1.    0.   13.   11.    1.   11.    2.  909.    5.   39.]
 [   6.   19.   36.   10.   15.   28.    0.    0.  801.   12.]
 [   2.    0.    3.    4.   33.    7.    0.   39.    9.  838.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.560233, Accuracy: 0.839000, Test accuracy: 0.845600
Distillation: Epoch : 2, Loss : 0.369372, Accuracy: 0.889000, Test accuracy: 0.904400
Distillation: Epoch : 3, Loss : 0.257230, Accuracy: 0.923000, Test accuracy: 0.922300
Distillation: Epoch : 4, Loss : 0.239262, Accuracy: 0.927000, Test accuracy: 0.932800
Distillation: Epoch : 5, Loss : 0.217197, Accuracy: 0.940000, Test accuracy: 0.941900
Distillation: Epoch : 6, Loss : 0.158736, Accuracy: 0.953000, Test accuracy: 0.946700
Distillation: Epoch : 7, Loss : 0.163143, Accuracy: 0.950000, Test accuracy: 0.949500
Distillation: Epoch : 8, Loss : 0.192830, Accuracy: 0.943000, Test accuracy: 0.955200
Distillation: Epoch : 9, Loss : 0.155047, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 10, Loss : 0.152211, Accuracy: 0.954000, Test accuracy: 0.958500
Distillation: Epoch : 11, Loss : 0.141939, Accuracy: 0.957000, Test accuracy: 0.962200
Distillation: Epoch : 12, Loss : 0.141050, Accuracy: 0.965000, Test accuracy: 0.964400
Distillation: Epoch : 13, Loss : 0.096602, Accuracy: 0.969000, Test accuracy: 0.965900
Distillation: Epoch : 14, Loss : 0.118347, Accuracy: 0.964000, Test accuracy: 0.967200
Distillation: Epoch : 15, Loss : 0.080348, Accuracy: 0.973000, Test accuracy: 0.967200
Distillation: Epoch : 16, Loss : 0.123535, Accuracy: 0.965000, Test accuracy: 0.967500
Distillation: Epoch : 17, Loss : 0.137451, Accuracy: 0.958000, Test accuracy: 0.970200
Distillation: Epoch : 18, Loss : 0.125836, Accuracy: 0.962000, Test accuracy: 0.971500
Distillation: Epoch : 19, Loss : 0.086946, Accuracy: 0.973000, Test accuracy: 0.972700
Distillation: Epoch : 20, Loss : 0.123015, Accuracy: 0.958000, Test accuracy: 0.973100
Distillation: Epoch : 21, Loss : 0.089762, Accuracy: 0.976000, Test accuracy: 0.971800
Distillation: Epoch : 22, Loss : 0.096109, Accuracy: 0.966000, Test accuracy: 0.973500
Distillation: Epoch : 23, Loss : 0.111250, Accuracy: 0.966000, Test accuracy: 0.974100
Distillation: Epoch : 24, Loss : 0.080962, Accuracy: 0.970000, Test accuracy: 0.973600
Distillation: Epoch : 25, Loss : 0.083085, Accuracy: 0.973000, Test accuracy: 0.975100
Distillation: Epoch : 26, Loss : 0.098970, Accuracy: 0.971000, Test accuracy: 0.976400
Distillation: Epoch : 27, Loss : 0.088548, Accuracy: 0.976000, Test accuracy: 0.975700
Distillation: Epoch : 28, Loss : 0.108176, Accuracy: 0.972000, Test accuracy: 0.976700
Distillation: Epoch : 29, Loss : 0.087722, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 30, Loss : 0.121575, Accuracy: 0.967000, Test accuracy: 0.978200
Distillation: Epoch : 31, Loss : 0.057221, Accuracy: 0.985000, Test accuracy: 0.978400
Distillation: Epoch : 32, Loss : 0.079101, Accuracy: 0.968000, Test accuracy: 0.978000
Distillation: Epoch : 33, Loss : 0.055455, Accuracy: 0.986000, Test accuracy: 0.979600
Distillation: Epoch : 34, Loss : 0.084474, Accuracy: 0.978000, Test accuracy: 0.979000
Distillation: Epoch : 35, Loss : 0.096025, Accuracy: 0.966000, Test accuracy: 0.979800
Distillation: Epoch : 36, Loss : 0.074940, Accuracy: 0.978000, Test accuracy: 0.979000
Distillation: Epoch : 37, Loss : 0.057444, Accuracy: 0.981000, Test accuracy: 0.979900
Distillation: Epoch : 38, Loss : 0.074622, Accuracy: 0.974000, Test accuracy: 0.979300
Distillation: Epoch : 39, Loss : 0.057912, Accuracy: 0.983000, Test accuracy: 0.980700
Distillation: Epoch : 40, Loss : 0.055375, Accuracy: 0.980000, Test accuracy: 0.980200
Distillation: Epoch : 41, Loss : 0.048694, Accuracy: 0.987000, Test accuracy: 0.980000
Distillation: Epoch : 42, Loss : 0.060732, Accuracy: 0.979000, Test accuracy: 0.980700
Distillation: Epoch : 43, Loss : 0.088838, Accuracy: 0.964000, Test accuracy: 0.980900
Distillation: Epoch : 44, Loss : 0.076114, Accuracy: 0.977000, Test accuracy: 0.981100
Distillation: Epoch : 45, Loss : 0.039598, Accuracy: 0.982000, Test accuracy: 0.980800
Distillation: Epoch : 46, Loss : 0.066888, Accuracy: 0.981000, Test accuracy: 0.980300
Distillation: Epoch : 47, Loss : 0.058830, Accuracy: 0.985000, Test accuracy: 0.981500
Distillation: Epoch : 48, Loss : 0.036495, Accuracy: 0.988000, Test accuracy: 0.981100
Distillation: Epoch : 49, Loss : 0.081550, Accuracy: 0.978000, Test accuracy: 0.982400
Distillation: Epoch : 50, Loss : 0.076739, Accuracy: 0.980000, Test accuracy: 0.981800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9818
Generating confusion matrix for student
[[ 975.    0.    2.    0.    1.    1.    4.    0.    5.    5.]
 [   0. 1126.    2.    0.    0.    1.    2.    4.    0.    5.]
 [   0.    2. 1010.    3.    2.    1.    0.    7.    4.    0.]
 [   0.    1.    2.  997.    0.    6.    0.    7.    4.    4.]
 [   0.    1.    2.    0.  971.    0.    6.    1.    4.    8.]
 [   0.    0.    0.    3.    0.  877.    3.    0.    1.    4.]
 [   1.    0.    0.    0.    2.    1.  940.    0.    1.    0.]
 [   2.    2.    8.    3.    2.    3.    0. 1004.    5.    6.]
 [   2.    3.    5.    4.    2.    2.    3.    1.  943.    2.]
 [   0.    0.    1.    0.    2.    0.    0.    4.    7.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.745974, Accuracy: 0.816000, Test accuracy: 0.828500
Distillation: Epoch : 2, Loss : 0.406658, Accuracy: 0.898000, Test accuracy: 0.889400
Distillation: Epoch : 3, Loss : 0.337151, Accuracy: 0.905000, Test accuracy: 0.911500
Distillation: Epoch : 4, Loss : 0.354899, Accuracy: 0.899000, Test accuracy: 0.922000
Distillation: Epoch : 5, Loss : 0.250965, Accuracy: 0.929000, Test accuracy: 0.930600
Distillation: Epoch : 6, Loss : 0.215336, Accuracy: 0.947000, Test accuracy: 0.937700
Distillation: Epoch : 7, Loss : 0.187894, Accuracy: 0.952000, Test accuracy: 0.942900
Distillation: Epoch : 8, Loss : 0.240919, Accuracy: 0.934000, Test accuracy: 0.947700
Distillation: Epoch : 9, Loss : 0.177365, Accuracy: 0.956000, Test accuracy: 0.952200
Distillation: Epoch : 10, Loss : 0.210408, Accuracy: 0.949000, Test accuracy: 0.955700
Distillation: Epoch : 11, Loss : 0.167655, Accuracy: 0.956000, Test accuracy: 0.957000
Distillation: Epoch : 12, Loss : 0.196795, Accuracy: 0.945000, Test accuracy: 0.960500
Distillation: Epoch : 13, Loss : 0.170868, Accuracy: 0.955000, Test accuracy: 0.960500
Distillation: Epoch : 14, Loss : 0.152932, Accuracy: 0.958000, Test accuracy: 0.963000
Distillation: Epoch : 15, Loss : 0.175098, Accuracy: 0.950000, Test accuracy: 0.965100
Distillation: Epoch : 16, Loss : 0.118223, Accuracy: 0.975000, Test accuracy: 0.965800
Distillation: Epoch : 17, Loss : 0.135031, Accuracy: 0.963000, Test accuracy: 0.966600
Distillation: Epoch : 18, Loss : 0.165005, Accuracy: 0.964000, Test accuracy: 0.967700
Distillation: Epoch : 19, Loss : 0.140762, Accuracy: 0.971000, Test accuracy: 0.968400
Distillation: Epoch : 20, Loss : 0.119039, Accuracy: 0.968000, Test accuracy: 0.969600
Distillation: Epoch : 21, Loss : 0.115596, Accuracy: 0.971000, Test accuracy: 0.970200
Distillation: Epoch : 22, Loss : 0.124846, Accuracy: 0.970000, Test accuracy: 0.971300
Distillation: Epoch : 23, Loss : 0.151561, Accuracy: 0.965000, Test accuracy: 0.971600
Distillation: Epoch : 24, Loss : 0.109015, Accuracy: 0.973000, Test accuracy: 0.972500
Distillation: Epoch : 25, Loss : 0.147460, Accuracy: 0.962000, Test accuracy: 0.973500
Distillation: Epoch : 26, Loss : 0.123419, Accuracy: 0.967000, Test accuracy: 0.972800
Distillation: Epoch : 27, Loss : 0.119602, Accuracy: 0.973000, Test accuracy: 0.974200
Distillation: Epoch : 28, Loss : 0.115880, Accuracy: 0.972000, Test accuracy: 0.973600
Distillation: Epoch : 29, Loss : 0.117510, Accuracy: 0.978000, Test accuracy: 0.975000
Distillation: Epoch : 30, Loss : 0.094236, Accuracy: 0.980000, Test accuracy: 0.976200
Distillation: Epoch : 31, Loss : 0.099529, Accuracy: 0.976000, Test accuracy: 0.974500
Distillation: Epoch : 32, Loss : 0.109604, Accuracy: 0.972000, Test accuracy: 0.976100
Distillation: Epoch : 33, Loss : 0.092044, Accuracy: 0.983000, Test accuracy: 0.976300
Distillation: Epoch : 34, Loss : 0.124322, Accuracy: 0.972000, Test accuracy: 0.977000
Distillation: Epoch : 35, Loss : 0.110916, Accuracy: 0.972000, Test accuracy: 0.975500
Distillation: Epoch : 36, Loss : 0.113768, Accuracy: 0.973000, Test accuracy: 0.976100
Distillation: Epoch : 37, Loss : 0.105228, Accuracy: 0.973000, Test accuracy: 0.976900
Distillation: Epoch : 38, Loss : 0.116993, Accuracy: 0.972000, Test accuracy: 0.975800
Distillation: Epoch : 39, Loss : 0.087888, Accuracy: 0.979000, Test accuracy: 0.976800
Distillation: Epoch : 40, Loss : 0.104173, Accuracy: 0.976000, Test accuracy: 0.977900
Distillation: Epoch : 41, Loss : 0.095160, Accuracy: 0.981000, Test accuracy: 0.978500
Distillation: Epoch : 42, Loss : 0.105118, Accuracy: 0.973000, Test accuracy: 0.979200
Distillation: Epoch : 43, Loss : 0.091660, Accuracy: 0.979000, Test accuracy: 0.978200
Distillation: Epoch : 44, Loss : 0.103975, Accuracy: 0.974000, Test accuracy: 0.979700
Distillation: Epoch : 45, Loss : 0.082093, Accuracy: 0.987000, Test accuracy: 0.977400
Distillation: Epoch : 46, Loss : 0.085464, Accuracy: 0.982000, Test accuracy: 0.979200
Distillation: Epoch : 47, Loss : 0.092116, Accuracy: 0.978000, Test accuracy: 0.978600
Distillation: Epoch : 48, Loss : 0.089310, Accuracy: 0.986000, Test accuracy: 0.979100
Distillation: Epoch : 49, Loss : 0.088613, Accuracy: 0.981000, Test accuracy: 0.979200
Distillation: Epoch : 50, Loss : 0.090719, Accuracy: 0.984000, Test accuracy: 0.979700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9797
Generating confusion matrix for student
[[ 970.    0.    2.    0.    1.    1.    4.    1.    4.    3.]
 [   0. 1125.    2.    0.    0.    0.    3.    4.    0.    3.]
 [   2.    4. 1013.    2.    2.    1.    0.   11.    9.    2.]
 [   0.    0.    1.  997.    0.    6.    0.    2.    7.    3.]
 [   0.    1.    1.    0.  961.    0.    5.    0.    1.    5.]
 [   1.    2.    0.    2.    0.  871.    2.    0.    5.    3.]
 [   2.    1.    0.    0.    3.    3.  939.    0.    1.    0.]
 [   1.    0.    4.    3.    2.    2.    0. 1005.    6.    8.]
 [   3.    2.    9.    5.    4.    6.    5.    2.  938.    4.]
 [   1.    0.    0.    1.    9.    2.    0.    3.    3.  978.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.126318, Accuracy: 0.753000, Test accuracy: 0.770600
Distillation: Epoch : 2, Loss : 0.763358, Accuracy: 0.849000, Test accuracy: 0.858300
Distillation: Epoch : 3, Loss : 0.695503, Accuracy: 0.876000, Test accuracy: 0.889300
Distillation: Epoch : 4, Loss : 0.658978, Accuracy: 0.901000, Test accuracy: 0.904400
Distillation: Epoch : 5, Loss : 0.649552, Accuracy: 0.907000, Test accuracy: 0.917400
Distillation: Epoch : 6, Loss : 0.602593, Accuracy: 0.919000, Test accuracy: 0.924300
Distillation: Epoch : 7, Loss : 0.585907, Accuracy: 0.932000, Test accuracy: 0.930500
Distillation: Epoch : 8, Loss : 0.551883, Accuracy: 0.943000, Test accuracy: 0.936300
Distillation: Epoch : 9, Loss : 0.561957, Accuracy: 0.929000, Test accuracy: 0.941200
Distillation: Epoch : 10, Loss : 0.556561, Accuracy: 0.933000, Test accuracy: 0.946600
Distillation: Epoch : 11, Loss : 0.515542, Accuracy: 0.943000, Test accuracy: 0.950100
Distillation: Epoch : 12, Loss : 0.511422, Accuracy: 0.948000, Test accuracy: 0.952400
Distillation: Epoch : 13, Loss : 0.510603, Accuracy: 0.941000, Test accuracy: 0.954400
Distillation: Epoch : 14, Loss : 0.518492, Accuracy: 0.951000, Test accuracy: 0.958000
Distillation: Epoch : 15, Loss : 0.508839, Accuracy: 0.944000, Test accuracy: 0.958600
Distillation: Epoch : 16, Loss : 0.467250, Accuracy: 0.954000, Test accuracy: 0.960800
Distillation: Epoch : 17, Loss : 0.498949, Accuracy: 0.947000, Test accuracy: 0.963800
Distillation: Epoch : 18, Loss : 0.487212, Accuracy: 0.966000, Test accuracy: 0.963500
Distillation: Epoch : 19, Loss : 0.508040, Accuracy: 0.947000, Test accuracy: 0.966200
Distillation: Epoch : 20, Loss : 0.486200, Accuracy: 0.961000, Test accuracy: 0.966000
Distillation: Epoch : 21, Loss : 0.461984, Accuracy: 0.970000, Test accuracy: 0.965700
Distillation: Epoch : 22, Loss : 0.463045, Accuracy: 0.968000, Test accuracy: 0.969700
Distillation: Epoch : 23, Loss : 0.483396, Accuracy: 0.957000, Test accuracy: 0.968500
Distillation: Epoch : 24, Loss : 0.465609, Accuracy: 0.964000, Test accuracy: 0.969700
Distillation: Epoch : 25, Loss : 0.453564, Accuracy: 0.978000, Test accuracy: 0.970300
Distillation: Epoch : 26, Loss : 0.436603, Accuracy: 0.971000, Test accuracy: 0.970800
Distillation: Epoch : 27, Loss : 0.459568, Accuracy: 0.968000, Test accuracy: 0.971400
Distillation: Epoch : 28, Loss : 0.453158, Accuracy: 0.966000, Test accuracy: 0.971400
Distillation: Epoch : 29, Loss : 0.460233, Accuracy: 0.969000, Test accuracy: 0.972400
Distillation: Epoch : 30, Loss : 0.437615, Accuracy: 0.970000, Test accuracy: 0.973400
Distillation: Epoch : 31, Loss : 0.429059, Accuracy: 0.977000, Test accuracy: 0.973800
Distillation: Epoch : 32, Loss : 0.447880, Accuracy: 0.963000, Test accuracy: 0.974700
Distillation: Epoch : 33, Loss : 0.433637, Accuracy: 0.975000, Test accuracy: 0.973300
Distillation: Epoch : 34, Loss : 0.440253, Accuracy: 0.967000, Test accuracy: 0.974100
Distillation: Epoch : 35, Loss : 0.451078, Accuracy: 0.962000, Test accuracy: 0.974700
Distillation: Epoch : 36, Loss : 0.422870, Accuracy: 0.981000, Test accuracy: 0.975700
Distillation: Epoch : 37, Loss : 0.435068, Accuracy: 0.975000, Test accuracy: 0.976200
Distillation: Epoch : 38, Loss : 0.443147, Accuracy: 0.975000, Test accuracy: 0.976300
Distillation: Epoch : 39, Loss : 0.458181, Accuracy: 0.972000, Test accuracy: 0.976800
Distillation: Epoch : 40, Loss : 0.419825, Accuracy: 0.984000, Test accuracy: 0.975900
Distillation: Epoch : 41, Loss : 0.444495, Accuracy: 0.974000, Test accuracy: 0.976700
Distillation: Epoch : 42, Loss : 0.434831, Accuracy: 0.975000, Test accuracy: 0.977700
Distillation: Epoch : 43, Loss : 0.431808, Accuracy: 0.984000, Test accuracy: 0.976700
Distillation: Epoch : 44, Loss : 0.455117, Accuracy: 0.963000, Test accuracy: 0.976500
Distillation: Epoch : 45, Loss : 0.442909, Accuracy: 0.971000, Test accuracy: 0.976500
Distillation: Epoch : 46, Loss : 0.434643, Accuracy: 0.970000, Test accuracy: 0.977000
Distillation: Epoch : 47, Loss : 0.449496, Accuracy: 0.969000, Test accuracy: 0.978000
Distillation: Epoch : 48, Loss : 0.423919, Accuracy: 0.978000, Test accuracy: 0.978200
Distillation: Epoch : 49, Loss : 0.436068, Accuracy: 0.972000, Test accuracy: 0.978100
Distillation: Epoch : 50, Loss : 0.435981, Accuracy: 0.983000, Test accuracy: 0.977900
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9779
Generating confusion matrix for student
[[ 968.    0.    2.    0.    1.    2.    4.    0.    7.    2.]
 [   0. 1123.    3.    0.    1.    0.    3.    3.    2.    6.]
 [   1.    2. 1015.    4.    1.    0.    0.   18.    4.    0.]
 [   0.    1.    2.  993.    0.   11.    0.    3.    7.   10.]
 [   0.    0.    1.    0.  956.    0.    2.    1.    2.    5.]
 [   0.    1.    0.    3.    0.  875.    5.    0.    9.    3.]
 [   3.    3.    2.    0.    4.    3.  944.    0.    2.    0.]
 [   3.    0.    2.    6.    2.    1.    0.  997.    3.    6.]
 [   4.    5.    4.    4.    2.    0.    0.    2.  934.    3.]
 [   1.    0.    1.    0.   15.    0.    0.    4.    4.  974.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.166286, Accuracy: 0.763000, Test accuracy: 0.800100
Distillation: Epoch : 2, Loss : 0.880778, Accuracy: 0.873000, Test accuracy: 0.878700
Distillation: Epoch : 3, Loss : 0.836034, Accuracy: 0.897000, Test accuracy: 0.898900
Distillation: Epoch : 4, Loss : 0.778905, Accuracy: 0.890000, Test accuracy: 0.910300
Distillation: Epoch : 5, Loss : 0.754969, Accuracy: 0.911000, Test accuracy: 0.917900
Distillation: Epoch : 6, Loss : 0.753950, Accuracy: 0.916000, Test accuracy: 0.926400
Distillation: Epoch : 7, Loss : 0.753337, Accuracy: 0.920000, Test accuracy: 0.932100
Distillation: Epoch : 8, Loss : 0.725141, Accuracy: 0.926000, Test accuracy: 0.938300
Distillation: Epoch : 9, Loss : 0.710157, Accuracy: 0.940000, Test accuracy: 0.945600
Distillation: Epoch : 10, Loss : 0.647979, Accuracy: 0.951000, Test accuracy: 0.950000
Distillation: Epoch : 11, Loss : 0.682599, Accuracy: 0.955000, Test accuracy: 0.953500
Distillation: Epoch : 12, Loss : 0.664334, Accuracy: 0.958000, Test accuracy: 0.956400
Distillation: Epoch : 13, Loss : 0.652381, Accuracy: 0.954000, Test accuracy: 0.959300
Distillation: Epoch : 14, Loss : 0.661321, Accuracy: 0.959000, Test accuracy: 0.960100
Distillation: Epoch : 15, Loss : 0.626828, Accuracy: 0.963000, Test accuracy: 0.964000
Distillation: Epoch : 16, Loss : 0.656099, Accuracy: 0.965000, Test accuracy: 0.965200
Distillation: Epoch : 17, Loss : 0.649392, Accuracy: 0.959000, Test accuracy: 0.965300
Distillation: Epoch : 18, Loss : 0.658537, Accuracy: 0.967000, Test accuracy: 0.968400
Distillation: Epoch : 19, Loss : 0.629542, Accuracy: 0.962000, Test accuracy: 0.969800
Distillation: Epoch : 20, Loss : 0.608003, Accuracy: 0.975000, Test accuracy: 0.970100
Distillation: Epoch : 21, Loss : 0.653563, Accuracy: 0.966000, Test accuracy: 0.970900
Distillation: Epoch : 22, Loss : 0.632585, Accuracy: 0.970000, Test accuracy: 0.971200
Distillation: Epoch : 23, Loss : 0.616660, Accuracy: 0.962000, Test accuracy: 0.970500
Distillation: Epoch : 24, Loss : 0.641266, Accuracy: 0.966000, Test accuracy: 0.971600
Distillation: Epoch : 25, Loss : 0.605322, Accuracy: 0.967000, Test accuracy: 0.971900
Distillation: Epoch : 26, Loss : 0.616456, Accuracy: 0.966000, Test accuracy: 0.972500
Distillation: Epoch : 27, Loss : 0.606237, Accuracy: 0.961000, Test accuracy: 0.972600
Distillation: Epoch : 28, Loss : 0.613009, Accuracy: 0.971000, Test accuracy: 0.973600
Distillation: Epoch : 29, Loss : 0.618472, Accuracy: 0.969000, Test accuracy: 0.973800
Distillation: Epoch : 30, Loss : 0.623171, Accuracy: 0.970000, Test accuracy: 0.974400
Distillation: Epoch : 31, Loss : 0.622388, Accuracy: 0.970000, Test accuracy: 0.974800
Distillation: Epoch : 32, Loss : 0.622194, Accuracy: 0.971000, Test accuracy: 0.974700
Distillation: Epoch : 33, Loss : 0.648999, Accuracy: 0.975000, Test accuracy: 0.975200
Distillation: Epoch : 34, Loss : 0.600888, Accuracy: 0.976000, Test accuracy: 0.974500
Distillation: Epoch : 35, Loss : 0.592057, Accuracy: 0.978000, Test accuracy: 0.976900
Distillation: Epoch : 36, Loss : 0.593243, Accuracy: 0.977000, Test accuracy: 0.975800
Distillation: Epoch : 37, Loss : 0.635098, Accuracy: 0.966000, Test accuracy: 0.975900
Distillation: Epoch : 38, Loss : 0.610348, Accuracy: 0.972000, Test accuracy: 0.976400
Distillation: Epoch : 39, Loss : 0.621993, Accuracy: 0.976000, Test accuracy: 0.976100
Distillation: Epoch : 40, Loss : 0.597700, Accuracy: 0.982000, Test accuracy: 0.977300
Distillation: Epoch : 41, Loss : 0.588827, Accuracy: 0.977000, Test accuracy: 0.976100
Distillation: Epoch : 42, Loss : 0.607485, Accuracy: 0.981000, Test accuracy: 0.977200
Distillation: Epoch : 43, Loss : 0.579384, Accuracy: 0.987000, Test accuracy: 0.977700
Distillation: Epoch : 44, Loss : 0.590589, Accuracy: 0.972000, Test accuracy: 0.978600
Distillation: Epoch : 45, Loss : 0.583080, Accuracy: 0.986000, Test accuracy: 0.977200
Distillation: Epoch : 46, Loss : 0.588383, Accuracy: 0.979000, Test accuracy: 0.977100
Distillation: Epoch : 47, Loss : 0.590597, Accuracy: 0.973000, Test accuracy: 0.978300
Distillation: Epoch : 48, Loss : 0.600329, Accuracy: 0.975000, Test accuracy: 0.977800
Distillation: Epoch : 49, Loss : 0.589109, Accuracy: 0.984000, Test accuracy: 0.977900
Distillation: Epoch : 50, Loss : 0.590971, Accuracy: 0.979000, Test accuracy: 0.978700
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9787
Generating confusion matrix for student
[[ 970.    0.    2.    1.    1.    1.    2.    0.    1.    5.]
 [   1. 1124.    1.    0.    0.    0.    2.    4.    0.    4.]
 [   1.    2. 1016.    1.    3.    0.    0.   17.    3.    1.]
 [   0.    2.    4.  994.    0.   12.    0.    3.    7.    5.]
 [   2.    0.    1.    0.  948.    0.    2.    1.    3.    4.]
 [   0.    1.    0.    2.    0.  874.    6.    0.    3.    1.]
 [   3.    2.    0.    0.    7.    4.  944.    0.    2.    0.]
 [   1.    1.    4.    6.    1.    0.    0.  995.    3.    5.]
 [   2.    3.    4.    3.    4.    0.    2.    1.  945.    7.]
 [   0.    0.    0.    3.   18.    1.    0.    7.    7.  977.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.390549, Accuracy: 0.769000, Test accuracy: 0.804400
Distillation: Epoch : 2, Loss : 1.070490, Accuracy: 0.855000, Test accuracy: 0.878000
Distillation: Epoch : 3, Loss : 0.992790, Accuracy: 0.895000, Test accuracy: 0.904300
Distillation: Epoch : 4, Loss : 0.937421, Accuracy: 0.910000, Test accuracy: 0.919000
Distillation: Epoch : 5, Loss : 0.921736, Accuracy: 0.912000, Test accuracy: 0.928100
Distillation: Epoch : 6, Loss : 0.895123, Accuracy: 0.935000, Test accuracy: 0.935900
Distillation: Epoch : 7, Loss : 0.886572, Accuracy: 0.942000, Test accuracy: 0.943700
Distillation: Epoch : 8, Loss : 0.865524, Accuracy: 0.946000, Test accuracy: 0.947800
Distillation: Epoch : 9, Loss : 0.848433, Accuracy: 0.953000, Test accuracy: 0.952700
Distillation: Epoch : 10, Loss : 0.831063, Accuracy: 0.954000, Test accuracy: 0.955500
Distillation: Epoch : 11, Loss : 0.846705, Accuracy: 0.961000, Test accuracy: 0.957700
Distillation: Epoch : 12, Loss : 0.837028, Accuracy: 0.945000, Test accuracy: 0.961900
Distillation: Epoch : 13, Loss : 0.820316, Accuracy: 0.957000, Test accuracy: 0.963500
Distillation: Epoch : 14, Loss : 0.839397, Accuracy: 0.955000, Test accuracy: 0.965300
Distillation: Epoch : 15, Loss : 0.829774, Accuracy: 0.971000, Test accuracy: 0.967300
Distillation: Epoch : 16, Loss : 0.794983, Accuracy: 0.961000, Test accuracy: 0.968200
Distillation: Epoch : 17, Loss : 0.823329, Accuracy: 0.962000, Test accuracy: 0.969900
Distillation: Epoch : 18, Loss : 0.814070, Accuracy: 0.970000, Test accuracy: 0.970900
Distillation: Epoch : 19, Loss : 0.789439, Accuracy: 0.969000, Test accuracy: 0.972400
Distillation: Epoch : 20, Loss : 0.778731, Accuracy: 0.979000, Test accuracy: 0.972400
Distillation: Epoch : 21, Loss : 0.830577, Accuracy: 0.956000, Test accuracy: 0.974300
Distillation: Epoch : 22, Loss : 0.793265, Accuracy: 0.967000, Test accuracy: 0.974900
Distillation: Epoch : 23, Loss : 0.783854, Accuracy: 0.977000, Test accuracy: 0.975400
Distillation: Epoch : 24, Loss : 0.812603, Accuracy: 0.963000, Test accuracy: 0.975000
Distillation: Epoch : 25, Loss : 0.816889, Accuracy: 0.972000, Test accuracy: 0.975400
Distillation: Epoch : 26, Loss : 0.798244, Accuracy: 0.968000, Test accuracy: 0.975000
Distillation: Epoch : 27, Loss : 0.788290, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 28, Loss : 0.811423, Accuracy: 0.973000, Test accuracy: 0.977100
Distillation: Epoch : 29, Loss : 0.784944, Accuracy: 0.977000, Test accuracy: 0.977700
Distillation: Epoch : 30, Loss : 0.787609, Accuracy: 0.976000, Test accuracy: 0.978100
Distillation: Epoch : 31, Loss : 0.793894, Accuracy: 0.974000, Test accuracy: 0.977500
Distillation: Epoch : 32, Loss : 0.781803, Accuracy: 0.969000, Test accuracy: 0.977600
Distillation: Epoch : 33, Loss : 0.775926, Accuracy: 0.975000, Test accuracy: 0.978400
Distillation: Epoch : 34, Loss : 0.790625, Accuracy: 0.971000, Test accuracy: 0.978100
Distillation: Epoch : 35, Loss : 0.776986, Accuracy: 0.975000, Test accuracy: 0.978500
Distillation: Epoch : 36, Loss : 0.781930, Accuracy: 0.973000, Test accuracy: 0.978600
Distillation: Epoch : 37, Loss : 0.766405, Accuracy: 0.973000, Test accuracy: 0.978900
Distillation: Epoch : 38, Loss : 0.803481, Accuracy: 0.978000, Test accuracy: 0.977900
Distillation: Epoch : 39, Loss : 0.769029, Accuracy: 0.974000, Test accuracy: 0.978000
Distillation: Epoch : 40, Loss : 0.781247, Accuracy: 0.972000, Test accuracy: 0.979000
Distillation: Epoch : 41, Loss : 0.799944, Accuracy: 0.971000, Test accuracy: 0.979200
Distillation: Epoch : 42, Loss : 0.776516, Accuracy: 0.976000, Test accuracy: 0.980200
Distillation: Epoch : 43, Loss : 0.776738, Accuracy: 0.975000, Test accuracy: 0.979200
Distillation: Epoch : 44, Loss : 0.823344, Accuracy: 0.969000, Test accuracy: 0.979600
Distillation: Epoch : 45, Loss : 0.771293, Accuracy: 0.978000, Test accuracy: 0.979600
Distillation: Epoch : 46, Loss : 0.758903, Accuracy: 0.981000, Test accuracy: 0.979700
Distillation: Epoch : 47, Loss : 0.775788, Accuracy: 0.984000, Test accuracy: 0.980000
Distillation: Epoch : 48, Loss : 0.771681, Accuracy: 0.981000, Test accuracy: 0.980500
Distillation: Epoch : 49, Loss : 0.792172, Accuracy: 0.987000, Test accuracy: 0.980300
Distillation: Epoch : 50, Loss : 0.765073, Accuracy: 0.981000, Test accuracy: 0.980800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9808
Generating confusion matrix for student
[[ 964.    0.    0.    0.    0.    1.    3.    0.    4.    3.]
 [   0. 1124.    2.    0.    0.    0.    2.    6.    1.    6.]
 [   2.    6. 1018.    0.    1.    1.    0.   14.    5.    0.]
 [   0.    0.    3.  994.    0.    9.    0.    3.    4.    8.]
 [   0.    1.    2.    0.  965.    0.    2.    0.    0.    8.]
 [   2.    1.    0.    5.    0.  875.    3.    0.    0.    4.]
 [   5.    2.    1.    0.    2.    3.  946.    0.    2.    0.]
 [   0.    0.    1.    6.    1.    0.    0. 1000.    0.    8.]
 [   5.    1.    5.    4.    2.    2.    2.    1.  955.    5.]
 [   2.    0.    0.    1.   11.    1.    0.    4.    3.  967.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.556759, Accuracy: 0.734000, Test accuracy: 0.756300
Distillation: Epoch : 2, Loss : 1.250630, Accuracy: 0.838000, Test accuracy: 0.857900
Distillation: Epoch : 3, Loss : 1.162122, Accuracy: 0.869000, Test accuracy: 0.887000
Distillation: Epoch : 4, Loss : 1.124090, Accuracy: 0.909000, Test accuracy: 0.906900
Distillation: Epoch : 5, Loss : 1.092030, Accuracy: 0.906000, Test accuracy: 0.919700
Distillation: Epoch : 6, Loss : 1.106117, Accuracy: 0.906000, Test accuracy: 0.927200
Distillation: Epoch : 7, Loss : 1.066208, Accuracy: 0.929000, Test accuracy: 0.936100
Distillation: Epoch : 8, Loss : 1.070554, Accuracy: 0.931000, Test accuracy: 0.943100
Distillation: Epoch : 9, Loss : 1.079858, Accuracy: 0.921000, Test accuracy: 0.948200
Distillation: Epoch : 10, Loss : 1.039787, Accuracy: 0.939000, Test accuracy: 0.951300
Distillation: Epoch : 11, Loss : 1.034938, Accuracy: 0.951000, Test accuracy: 0.955500
Distillation: Epoch : 12, Loss : 1.006090, Accuracy: 0.953000, Test accuracy: 0.957900
Distillation: Epoch : 13, Loss : 0.990284, Accuracy: 0.961000, Test accuracy: 0.959900
Distillation: Epoch : 14, Loss : 0.982787, Accuracy: 0.970000, Test accuracy: 0.961500
Distillation: Epoch : 15, Loss : 0.984794, Accuracy: 0.960000, Test accuracy: 0.963900
Distillation: Epoch : 16, Loss : 1.015587, Accuracy: 0.952000, Test accuracy: 0.965300
Distillation: Epoch : 17, Loss : 1.002174, Accuracy: 0.959000, Test accuracy: 0.964900
Distillation: Epoch : 18, Loss : 0.973528, Accuracy: 0.956000, Test accuracy: 0.968100
Distillation: Epoch : 19, Loss : 0.979772, Accuracy: 0.961000, Test accuracy: 0.968200
Distillation: Epoch : 20, Loss : 0.984128, Accuracy: 0.958000, Test accuracy: 0.969700
Distillation: Epoch : 21, Loss : 0.991273, Accuracy: 0.967000, Test accuracy: 0.970100
Distillation: Epoch : 22, Loss : 1.002907, Accuracy: 0.970000, Test accuracy: 0.971400
Distillation: Epoch : 23, Loss : 0.982514, Accuracy: 0.969000, Test accuracy: 0.970400
Distillation: Epoch : 24, Loss : 0.981020, Accuracy: 0.970000, Test accuracy: 0.971100
Distillation: Epoch : 25, Loss : 0.944074, Accuracy: 0.977000, Test accuracy: 0.972500
Distillation: Epoch : 26, Loss : 0.999653, Accuracy: 0.968000, Test accuracy: 0.972800
Distillation: Epoch : 27, Loss : 0.967406, Accuracy: 0.968000, Test accuracy: 0.973700
Distillation: Epoch : 28, Loss : 0.959089, Accuracy: 0.965000, Test accuracy: 0.973800
Distillation: Epoch : 29, Loss : 0.942486, Accuracy: 0.976000, Test accuracy: 0.974300
Distillation: Epoch : 30, Loss : 0.952546, Accuracy: 0.972000, Test accuracy: 0.974900
Distillation: Epoch : 31, Loss : 0.941185, Accuracy: 0.978000, Test accuracy: 0.975800
Distillation: Epoch : 32, Loss : 0.970713, Accuracy: 0.973000, Test accuracy: 0.975100
Distillation: Epoch : 33, Loss : 0.954768, Accuracy: 0.979000, Test accuracy: 0.976300
Distillation: Epoch : 34, Loss : 0.969030, Accuracy: 0.969000, Test accuracy: 0.976500
Distillation: Epoch : 35, Loss : 0.966645, Accuracy: 0.972000, Test accuracy: 0.976900
Distillation: Epoch : 36, Loss : 0.983339, Accuracy: 0.966000, Test accuracy: 0.976500
Distillation: Epoch : 37, Loss : 0.972946, Accuracy: 0.978000, Test accuracy: 0.976900
Distillation: Epoch : 38, Loss : 0.960549, Accuracy: 0.983000, Test accuracy: 0.977100
Distillation: Epoch : 39, Loss : 0.947016, Accuracy: 0.978000, Test accuracy: 0.977200
Distillation: Epoch : 40, Loss : 0.964874, Accuracy: 0.970000, Test accuracy: 0.976400
Distillation: Epoch : 41, Loss : 0.959271, Accuracy: 0.968000, Test accuracy: 0.978100
Distillation: Epoch : 42, Loss : 0.980154, Accuracy: 0.974000, Test accuracy: 0.978000
Distillation: Epoch : 43, Loss : 0.953534, Accuracy: 0.979000, Test accuracy: 0.978300
Distillation: Epoch : 44, Loss : 0.933001, Accuracy: 0.976000, Test accuracy: 0.978500
Distillation: Epoch : 45, Loss : 0.955168, Accuracy: 0.977000, Test accuracy: 0.979000
Distillation: Epoch : 46, Loss : 0.940344, Accuracy: 0.979000, Test accuracy: 0.979200
Distillation: Epoch : 47, Loss : 0.960780, Accuracy: 0.974000, Test accuracy: 0.979100
Distillation: Epoch : 48, Loss : 0.936333, Accuracy: 0.982000, Test accuracy: 0.979900
Distillation: Epoch : 49, Loss : 0.943014, Accuracy: 0.979000, Test accuracy: 0.979200
Distillation: Epoch : 50, Loss : 0.947930, Accuracy: 0.974000, Test accuracy: 0.980200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9802
Generating confusion matrix for student
[[ 968.    0.    1.    0.    0.    1.    4.    0.    2.    4.]
 [   0. 1127.    2.    0.    0.    0.    2.    4.    1.    7.]
 [   1.    3. 1022.    3.    2.    0.    0.   13.    4.    1.]
 [   0.    2.    1.  992.    0.    7.    0.    2.    7.    9.]
 [   0.    0.    0.    0.  964.    0.    1.    1.    3.   10.]
 [   1.    1.    0.    4.    0.  877.    3.    0.    5.    5.]
 [   3.    2.    1.    0.    2.    4.  946.    0.    3.    0.]
 [   1.    0.    3.    4.    2.    1.    0. 1002.    4.    5.]
 [   4.    0.    2.    5.    2.    2.    2.    0.  938.    2.]
 [   2.    0.    0.    2.   10.    0.    0.    6.    7.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.515852, Accuracy: 0.803000, Test accuracy: 0.790200
Distillation: Epoch : 2, Loss : 1.345985, Accuracy: 0.877000, Test accuracy: 0.872500
Distillation: Epoch : 3, Loss : 1.288931, Accuracy: 0.895000, Test accuracy: 0.897600
Distillation: Epoch : 4, Loss : 1.259659, Accuracy: 0.906000, Test accuracy: 0.911100
Distillation: Epoch : 5, Loss : 1.269379, Accuracy: 0.924000, Test accuracy: 0.923400
Distillation: Epoch : 6, Loss : 1.240039, Accuracy: 0.917000, Test accuracy: 0.931400
Distillation: Epoch : 7, Loss : 1.226003, Accuracy: 0.934000, Test accuracy: 0.936200
Distillation: Epoch : 8, Loss : 1.231720, Accuracy: 0.934000, Test accuracy: 0.940500
Distillation: Epoch : 9, Loss : 1.185936, Accuracy: 0.946000, Test accuracy: 0.944300
Distillation: Epoch : 10, Loss : 1.188229, Accuracy: 0.929000, Test accuracy: 0.949500
Distillation: Epoch : 11, Loss : 1.200728, Accuracy: 0.940000, Test accuracy: 0.950300
Distillation: Epoch : 12, Loss : 1.192731, Accuracy: 0.945000, Test accuracy: 0.953600
Distillation: Epoch : 13, Loss : 1.150112, Accuracy: 0.958000, Test accuracy: 0.958000
Distillation: Epoch : 14, Loss : 1.177896, Accuracy: 0.949000, Test accuracy: 0.959500
Distillation: Epoch : 15, Loss : 1.156887, Accuracy: 0.957000, Test accuracy: 0.961000
Distillation: Epoch : 16, Loss : 1.145864, Accuracy: 0.964000, Test accuracy: 0.963700
Distillation: Epoch : 17, Loss : 1.144482, Accuracy: 0.964000, Test accuracy: 0.964700
Distillation: Epoch : 18, Loss : 1.136334, Accuracy: 0.970000, Test accuracy: 0.965600
Distillation: Epoch : 19, Loss : 1.159093, Accuracy: 0.962000, Test accuracy: 0.967300
Distillation: Epoch : 20, Loss : 1.148642, Accuracy: 0.947000, Test accuracy: 0.967500
Distillation: Epoch : 21, Loss : 1.136357, Accuracy: 0.969000, Test accuracy: 0.967300
Distillation: Epoch : 22, Loss : 1.140882, Accuracy: 0.968000, Test accuracy: 0.969700
Distillation: Epoch : 23, Loss : 1.143732, Accuracy: 0.962000, Test accuracy: 0.968700
Distillation: Epoch : 24, Loss : 1.142824, Accuracy: 0.959000, Test accuracy: 0.970800
Distillation: Epoch : 25, Loss : 1.139458, Accuracy: 0.971000, Test accuracy: 0.970700
Distillation: Epoch : 26, Loss : 1.119071, Accuracy: 0.970000, Test accuracy: 0.971700
Distillation: Epoch : 27, Loss : 1.167417, Accuracy: 0.966000, Test accuracy: 0.972100
Distillation: Epoch : 28, Loss : 1.142733, Accuracy: 0.970000, Test accuracy: 0.971700
Distillation: Epoch : 29, Loss : 1.143845, Accuracy: 0.973000, Test accuracy: 0.971900
Distillation: Epoch : 30, Loss : 1.151531, Accuracy: 0.960000, Test accuracy: 0.973200
Distillation: Epoch : 31, Loss : 1.106365, Accuracy: 0.974000, Test accuracy: 0.972500
Distillation: Epoch : 32, Loss : 1.121594, Accuracy: 0.978000, Test accuracy: 0.972900
Distillation: Epoch : 33, Loss : 1.143551, Accuracy: 0.972000, Test accuracy: 0.973500
Distillation: Epoch : 34, Loss : 1.103083, Accuracy: 0.977000, Test accuracy: 0.974300
Distillation: Epoch : 35, Loss : 1.146119, Accuracy: 0.976000, Test accuracy: 0.974300
Distillation: Epoch : 36, Loss : 1.119415, Accuracy: 0.977000, Test accuracy: 0.973700
Distillation: Epoch : 37, Loss : 1.126496, Accuracy: 0.977000, Test accuracy: 0.973400
Distillation: Epoch : 38, Loss : 1.123161, Accuracy: 0.969000, Test accuracy: 0.974700
Distillation: Epoch : 39, Loss : 1.094420, Accuracy: 0.976000, Test accuracy: 0.974800
Distillation: Epoch : 40, Loss : 1.153237, Accuracy: 0.961000, Test accuracy: 0.974500
Distillation: Epoch : 41, Loss : 1.145573, Accuracy: 0.971000, Test accuracy: 0.976000
Distillation: Epoch : 42, Loss : 1.125685, Accuracy: 0.968000, Test accuracy: 0.976300
Distillation: Epoch : 43, Loss : 1.125386, Accuracy: 0.964000, Test accuracy: 0.975500
Distillation: Epoch : 44, Loss : 1.113374, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 45, Loss : 1.117796, Accuracy: 0.980000, Test accuracy: 0.976200
Distillation: Epoch : 46, Loss : 1.132079, Accuracy: 0.966000, Test accuracy: 0.976300
Distillation: Epoch : 47, Loss : 1.148521, Accuracy: 0.981000, Test accuracy: 0.976700
Distillation: Epoch : 48, Loss : 1.136205, Accuracy: 0.975000, Test accuracy: 0.977800
Distillation: Epoch : 49, Loss : 1.115567, Accuracy: 0.978000, Test accuracy: 0.978000
Distillation: Epoch : 50, Loss : 1.129742, Accuracy: 0.975000, Test accuracy: 0.978200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9782
Generating confusion matrix for student
[[ 966.    0.    1.    0.    1.    1.    6.    0.    2.    3.]
 [   1. 1125.    2.    0.    0.    0.    2.    5.    0.    5.]
 [   2.    4. 1006.    1.    3.    0.    0.   16.    4.    0.]
 [   0.    2.    5.  999.    0.   12.    0.    3.   10.    9.]
 [   0.    0.    2.    0.  955.    0.    1.    0.    3.    4.]
 [   2.    1.    0.    4.    0.  874.    5.    0.    5.    2.]
 [   6.    2.    3.    0.    3.    4.  943.    0.    3.    1.]
 [   1.    0.    3.    4.    3.    1.    0.  998.    3.    5.]
 [   2.    1.    9.    2.    4.    0.    1.    1.  939.    3.]
 [   0.    0.    1.    0.   13.    0.    0.    5.    5.  977.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.692930, Accuracy: 0.783000, Test accuracy: 0.784400
Distillation: Epoch : 2, Loss : 1.515190, Accuracy: 0.842000, Test accuracy: 0.857100
Distillation: Epoch : 3, Loss : 1.438763, Accuracy: 0.884000, Test accuracy: 0.887700
Distillation: Epoch : 4, Loss : 1.411361, Accuracy: 0.901000, Test accuracy: 0.906400
Distillation: Epoch : 5, Loss : 1.380210, Accuracy: 0.906000, Test accuracy: 0.923500
Distillation: Epoch : 6, Loss : 1.364116, Accuracy: 0.934000, Test accuracy: 0.934400
Distillation: Epoch : 7, Loss : 1.351432, Accuracy: 0.925000, Test accuracy: 0.942600
Distillation: Epoch : 8, Loss : 1.326310, Accuracy: 0.950000, Test accuracy: 0.948600
Distillation: Epoch : 9, Loss : 1.318947, Accuracy: 0.945000, Test accuracy: 0.953200
Distillation: Epoch : 10, Loss : 1.314796, Accuracy: 0.953000, Test accuracy: 0.957400
Distillation: Epoch : 11, Loss : 1.295187, Accuracy: 0.953000, Test accuracy: 0.959700
Distillation: Epoch : 12, Loss : 1.314142, Accuracy: 0.970000, Test accuracy: 0.961900
Distillation: Epoch : 13, Loss : 1.304511, Accuracy: 0.963000, Test accuracy: 0.964800
Distillation: Epoch : 14, Loss : 1.306829, Accuracy: 0.967000, Test accuracy: 0.966900
Distillation: Epoch : 15, Loss : 1.296654, Accuracy: 0.962000, Test accuracy: 0.967900
Distillation: Epoch : 16, Loss : 1.296880, Accuracy: 0.965000, Test accuracy: 0.970000
Distillation: Epoch : 17, Loss : 1.295562, Accuracy: 0.970000, Test accuracy: 0.970300
Distillation: Epoch : 18, Loss : 1.297847, Accuracy: 0.961000, Test accuracy: 0.971800
Distillation: Epoch : 19, Loss : 1.275130, Accuracy: 0.965000, Test accuracy: 0.972000
Distillation: Epoch : 20, Loss : 1.291411, Accuracy: 0.977000, Test accuracy: 0.972800
Distillation: Epoch : 21, Loss : 1.267214, Accuracy: 0.970000, Test accuracy: 0.973300
Distillation: Epoch : 22, Loss : 1.272730, Accuracy: 0.967000, Test accuracy: 0.973500
Distillation: Epoch : 23, Loss : 1.290523, Accuracy: 0.969000, Test accuracy: 0.975300
Distillation: Epoch : 24, Loss : 1.254595, Accuracy: 0.970000, Test accuracy: 0.975800
Distillation: Epoch : 25, Loss : 1.278390, Accuracy: 0.971000, Test accuracy: 0.975600
Distillation: Epoch : 26, Loss : 1.268432, Accuracy: 0.976000, Test accuracy: 0.977000
Distillation: Epoch : 27, Loss : 1.262831, Accuracy: 0.971000, Test accuracy: 0.977600
Distillation: Epoch : 28, Loss : 1.272815, Accuracy: 0.974000, Test accuracy: 0.977900
Distillation: Epoch : 29, Loss : 1.273278, Accuracy: 0.972000, Test accuracy: 0.978300
Distillation: Epoch : 30, Loss : 1.256342, Accuracy: 0.973000, Test accuracy: 0.978600
Distillation: Epoch : 31, Loss : 1.276182, Accuracy: 0.975000, Test accuracy: 0.979400
Distillation: Epoch : 32, Loss : 1.250608, Accuracy: 0.980000, Test accuracy: 0.979400
Distillation: Epoch : 33, Loss : 1.276259, Accuracy: 0.973000, Test accuracy: 0.979000
Distillation: Epoch : 34, Loss : 1.275119, Accuracy: 0.981000, Test accuracy: 0.979000
Distillation: Epoch : 35, Loss : 1.259696, Accuracy: 0.976000, Test accuracy: 0.979900
Distillation: Epoch : 36, Loss : 1.285174, Accuracy: 0.961000, Test accuracy: 0.980000
Distillation: Epoch : 37, Loss : 1.273644, Accuracy: 0.966000, Test accuracy: 0.981000
Distillation: Epoch : 38, Loss : 1.266191, Accuracy: 0.973000, Test accuracy: 0.980500
Distillation: Epoch : 39, Loss : 1.266341, Accuracy: 0.971000, Test accuracy: 0.980700
Distillation: Epoch : 40, Loss : 1.256080, Accuracy: 0.976000, Test accuracy: 0.981000
Distillation: Epoch : 41, Loss : 1.256029, Accuracy: 0.978000, Test accuracy: 0.980500
Distillation: Epoch : 42, Loss : 1.280327, Accuracy: 0.982000, Test accuracy: 0.981200
Distillation: Epoch : 43, Loss : 1.287224, Accuracy: 0.978000, Test accuracy: 0.980900
Distillation: Epoch : 44, Loss : 1.283805, Accuracy: 0.972000, Test accuracy: 0.981600
Distillation: Epoch : 45, Loss : 1.279046, Accuracy: 0.976000, Test accuracy: 0.980900
Distillation: Epoch : 46, Loss : 1.250706, Accuracy: 0.977000, Test accuracy: 0.981100
Distillation: Epoch : 47, Loss : 1.267454, Accuracy: 0.978000, Test accuracy: 0.981400
Distillation: Epoch : 48, Loss : 1.272577, Accuracy: 0.977000, Test accuracy: 0.981400
Distillation: Epoch : 49, Loss : 1.271385, Accuracy: 0.970000, Test accuracy: 0.981500
Distillation: Epoch : 50, Loss : 1.258776, Accuracy: 0.978000, Test accuracy: 0.981800
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9818
Generating confusion matrix for student
[[ 971.    0.    0.    0.    0.    2.    6.    0.    5.    2.]
 [   1. 1123.    4.    0.    0.    0.    3.    3.    2.    6.]
 [   0.    4. 1016.    1.    1.    0.    0.   14.    3.    0.]
 [   0.    3.    4.  998.    0.   10.    0.    1.    4.    7.]
 [   0.    0.    1.    0.  967.    0.    2.    0.    3.    5.]
 [   2.    1.    0.    5.    0.  873.    4.    0.    5.    6.]
 [   4.    3.    1.    0.    2.    3.  942.    0.    2.    0.]
 [   1.    1.    4.    3.    0.    1.    0. 1008.    2.    8.]
 [   0.    0.    2.    3.    2.    1.    1.    1.  945.    0.]
 [   1.    0.    0.    0.   10.    2.    0.    1.    3.  975.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.747403, Accuracy: 0.777000, Test accuracy: 0.791600
Distillation: Epoch : 2, Loss : 1.593858, Accuracy: 0.859000, Test accuracy: 0.857800
Distillation: Epoch : 3, Loss : 1.564854, Accuracy: 0.872000, Test accuracy: 0.874100
Distillation: Epoch : 4, Loss : 1.511473, Accuracy: 0.901000, Test accuracy: 0.888300
Distillation: Epoch : 5, Loss : 1.506502, Accuracy: 0.885000, Test accuracy: 0.900600
Distillation: Epoch : 6, Loss : 1.511831, Accuracy: 0.904000, Test accuracy: 0.910900
Distillation: Epoch : 7, Loss : 1.470176, Accuracy: 0.906000, Test accuracy: 0.914000
Distillation: Epoch : 8, Loss : 1.473370, Accuracy: 0.917000, Test accuracy: 0.925100
Distillation: Epoch : 9, Loss : 1.493747, Accuracy: 0.922000, Test accuracy: 0.930500
Distillation: Epoch : 10, Loss : 1.451848, Accuracy: 0.932000, Test accuracy: 0.938100
Distillation: Epoch : 11, Loss : 1.462686, Accuracy: 0.930000, Test accuracy: 0.944400
Distillation: Epoch : 12, Loss : 1.441299, Accuracy: 0.940000, Test accuracy: 0.949000
Distillation: Epoch : 13, Loss : 1.447917, Accuracy: 0.940000, Test accuracy: 0.952300
Distillation: Epoch : 14, Loss : 1.436855, Accuracy: 0.960000, Test accuracy: 0.955100
Distillation: Epoch : 15, Loss : 1.427297, Accuracy: 0.960000, Test accuracy: 0.956700
Distillation: Epoch : 16, Loss : 1.416346, Accuracy: 0.957000, Test accuracy: 0.959600
Distillation: Epoch : 17, Loss : 1.423350, Accuracy: 0.953000, Test accuracy: 0.963100
Distillation: Epoch : 18, Loss : 1.430045, Accuracy: 0.960000, Test accuracy: 0.964300
Distillation: Epoch : 19, Loss : 1.405897, Accuracy: 0.966000, Test accuracy: 0.966200
Distillation: Epoch : 20, Loss : 1.413513, Accuracy: 0.950000, Test accuracy: 0.967300
Distillation: Epoch : 21, Loss : 1.415120, Accuracy: 0.949000, Test accuracy: 0.968400
Distillation: Epoch : 22, Loss : 1.422408, Accuracy: 0.963000, Test accuracy: 0.969900
Distillation: Epoch : 23, Loss : 1.411231, Accuracy: 0.958000, Test accuracy: 0.969700
Distillation: Epoch : 24, Loss : 1.417113, Accuracy: 0.971000, Test accuracy: 0.971100
Distillation: Epoch : 25, Loss : 1.401815, Accuracy: 0.972000, Test accuracy: 0.971300
Distillation: Epoch : 26, Loss : 1.403930, Accuracy: 0.969000, Test accuracy: 0.971600
Distillation: Epoch : 27, Loss : 1.394068, Accuracy: 0.964000, Test accuracy: 0.972900
Distillation: Epoch : 28, Loss : 1.407259, Accuracy: 0.966000, Test accuracy: 0.973000
Distillation: Epoch : 29, Loss : 1.396186, Accuracy: 0.969000, Test accuracy: 0.973200
Distillation: Epoch : 30, Loss : 1.405655, Accuracy: 0.965000, Test accuracy: 0.973900
Distillation: Epoch : 31, Loss : 1.395875, Accuracy: 0.979000, Test accuracy: 0.973800
Distillation: Epoch : 32, Loss : 1.416667, Accuracy: 0.966000, Test accuracy: 0.974300
Distillation: Epoch : 33, Loss : 1.397363, Accuracy: 0.968000, Test accuracy: 0.975700
Distillation: Epoch : 34, Loss : 1.387481, Accuracy: 0.972000, Test accuracy: 0.976000
Distillation: Epoch : 35, Loss : 1.398551, Accuracy: 0.969000, Test accuracy: 0.975500
Distillation: Epoch : 36, Loss : 1.391815, Accuracy: 0.971000, Test accuracy: 0.975900
Distillation: Epoch : 37, Loss : 1.386561, Accuracy: 0.968000, Test accuracy: 0.977000
Distillation: Epoch : 38, Loss : 1.375872, Accuracy: 0.981000, Test accuracy: 0.976800
Distillation: Epoch : 39, Loss : 1.380010, Accuracy: 0.973000, Test accuracy: 0.977500
Distillation: Epoch : 40, Loss : 1.404235, Accuracy: 0.975000, Test accuracy: 0.978000
Distillation: Epoch : 41, Loss : 1.389272, Accuracy: 0.972000, Test accuracy: 0.978000
Distillation: Epoch : 42, Loss : 1.404072, Accuracy: 0.974000, Test accuracy: 0.978300
Distillation: Epoch : 43, Loss : 1.381150, Accuracy: 0.986000, Test accuracy: 0.978400
Distillation: Epoch : 44, Loss : 1.396606, Accuracy: 0.967000, Test accuracy: 0.978100
Distillation: Epoch : 45, Loss : 1.383637, Accuracy: 0.979000, Test accuracy: 0.978900
Distillation: Epoch : 46, Loss : 1.415723, Accuracy: 0.967000, Test accuracy: 0.979000
Distillation: Epoch : 47, Loss : 1.389176, Accuracy: 0.978000, Test accuracy: 0.978900
Distillation: Epoch : 48, Loss : 1.395780, Accuracy: 0.973000, Test accuracy: 0.979300
Distillation: Epoch : 49, Loss : 1.393061, Accuracy: 0.978000, Test accuracy: 0.979200
Distillation: Epoch : 50, Loss : 1.408569, Accuracy: 0.973000, Test accuracy: 0.979300
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9793
Generating confusion matrix for student
[[ 966.    0.    2.    0.    1.    1.    2.    0.    2.    2.]
 [   1. 1122.    3.    0.    1.    0.    2.    6.    0.    5.]
 [   0.    2. 1014.    2.    2.    0.    0.   15.    5.    1.]
 [   0.    1.    3.  995.    0.    7.    0.    2.    6.    9.]
 [   0.    0.    0.    0.  953.    0.    2.    0.    2.    6.]
 [   1.    1.    0.    3.    0.  880.    5.    1.    2.    4.]
 [   9.    5.    1.    0.    3.    2.  945.    0.    3.    1.]
 [   1.    0.    5.    5.    2.    0.    0.  998.    3.    6.]
 [   2.    4.    4.    2.    3.    2.    2.    1.  947.    2.]
 [   0.    0.    0.    3.   17.    0.    0.    5.    4.  973.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.951618, Accuracy: 0.740000, Test accuracy: 0.751100
Distillation: Epoch : 2, Loss : 1.870740, Accuracy: 0.821000, Test accuracy: 0.834000
Distillation: Epoch : 3, Loss : 1.822474, Accuracy: 0.862000, Test accuracy: 0.856000
Distillation: Epoch : 4, Loss : 1.794298, Accuracy: 0.883000, Test accuracy: 0.872800
Distillation: Epoch : 5, Loss : 1.781241, Accuracy: 0.890000, Test accuracy: 0.892800
Distillation: Epoch : 6, Loss : 1.799673, Accuracy: 0.888000, Test accuracy: 0.899100
Distillation: Epoch : 7, Loss : 1.787839, Accuracy: 0.878000, Test accuracy: 0.913900
Distillation: Epoch : 8, Loss : 1.742080, Accuracy: 0.923000, Test accuracy: 0.920800
Distillation: Epoch : 9, Loss : 1.751168, Accuracy: 0.922000, Test accuracy: 0.931300
Distillation: Epoch : 10, Loss : 1.741168, Accuracy: 0.934000, Test accuracy: 0.938000
Distillation: Epoch : 11, Loss : 1.729730, Accuracy: 0.931000, Test accuracy: 0.944300
Distillation: Epoch : 12, Loss : 1.734884, Accuracy: 0.953000, Test accuracy: 0.947500
Distillation: Epoch : 13, Loss : 1.722365, Accuracy: 0.959000, Test accuracy: 0.951500
Distillation: Epoch : 14, Loss : 1.713693, Accuracy: 0.946000, Test accuracy: 0.954800
Distillation: Epoch : 15, Loss : 1.725932, Accuracy: 0.947000, Test accuracy: 0.958200
Distillation: Epoch : 16, Loss : 1.694807, Accuracy: 0.956000, Test accuracy: 0.959600
Distillation: Epoch : 17, Loss : 1.713181, Accuracy: 0.959000, Test accuracy: 0.962000
Distillation: Epoch : 18, Loss : 1.719493, Accuracy: 0.959000, Test accuracy: 0.961800
Distillation: Epoch : 19, Loss : 1.703766, Accuracy: 0.956000, Test accuracy: 0.964600
Distillation: Epoch : 20, Loss : 1.704727, Accuracy: 0.970000, Test accuracy: 0.964100
Distillation: Epoch : 21, Loss : 1.701703, Accuracy: 0.960000, Test accuracy: 0.965600
Distillation: Epoch : 22, Loss : 1.702593, Accuracy: 0.964000, Test accuracy: 0.966000
Distillation: Epoch : 23, Loss : 1.695954, Accuracy: 0.962000, Test accuracy: 0.966600
Distillation: Epoch : 24, Loss : 1.707892, Accuracy: 0.953000, Test accuracy: 0.966700
Distillation: Epoch : 25, Loss : 1.695741, Accuracy: 0.965000, Test accuracy: 0.967200
Distillation: Epoch : 26, Loss : 1.706398, Accuracy: 0.966000, Test accuracy: 0.968400
Distillation: Epoch : 27, Loss : 1.682235, Accuracy: 0.972000, Test accuracy: 0.968600
Distillation: Epoch : 28, Loss : 1.705804, Accuracy: 0.960000, Test accuracy: 0.969800
Distillation: Epoch : 29, Loss : 1.704422, Accuracy: 0.946000, Test accuracy: 0.969700
Distillation: Epoch : 30, Loss : 1.715835, Accuracy: 0.957000, Test accuracy: 0.971200
Distillation: Epoch : 31, Loss : 1.702805, Accuracy: 0.962000, Test accuracy: 0.971300
Distillation: Epoch : 32, Loss : 1.697688, Accuracy: 0.966000, Test accuracy: 0.971000
Distillation: Epoch : 33, Loss : 1.694594, Accuracy: 0.971000, Test accuracy: 0.971300
Distillation: Epoch : 34, Loss : 1.697866, Accuracy: 0.965000, Test accuracy: 0.971700
Distillation: Epoch : 35, Loss : 1.686295, Accuracy: 0.973000, Test accuracy: 0.972600
Distillation: Epoch : 36, Loss : 1.689438, Accuracy: 0.977000, Test accuracy: 0.973100
Distillation: Epoch : 37, Loss : 1.687536, Accuracy: 0.969000, Test accuracy: 0.973500
Distillation: Epoch : 38, Loss : 1.715218, Accuracy: 0.959000, Test accuracy: 0.974000
Distillation: Epoch : 39, Loss : 1.720981, Accuracy: 0.970000, Test accuracy: 0.973300
Distillation: Epoch : 40, Loss : 1.708912, Accuracy: 0.965000, Test accuracy: 0.973500
Distillation: Epoch : 41, Loss : 1.692442, Accuracy: 0.967000, Test accuracy: 0.974200
Distillation: Epoch : 42, Loss : 1.702529, Accuracy: 0.983000, Test accuracy: 0.974900
Distillation: Epoch : 43, Loss : 1.702402, Accuracy: 0.974000, Test accuracy: 0.975000
Distillation: Epoch : 44, Loss : 1.703023, Accuracy: 0.963000, Test accuracy: 0.974900
Distillation: Epoch : 45, Loss : 1.702826, Accuracy: 0.966000, Test accuracy: 0.975200
Distillation: Epoch : 46, Loss : 1.677417, Accuracy: 0.973000, Test accuracy: 0.975700
Distillation: Epoch : 47, Loss : 1.678143, Accuracy: 0.978000, Test accuracy: 0.976000
Distillation: Epoch : 48, Loss : 1.687253, Accuracy: 0.973000, Test accuracy: 0.975900
Distillation: Epoch : 49, Loss : 1.697027, Accuracy: 0.976000, Test accuracy: 0.976400
Distillation: Epoch : 50, Loss : 1.705882, Accuracy: 0.971000, Test accuracy: 0.976200
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9762
Generating confusion matrix for student
[[ 965.    0.    1.    0.    0.    2.    3.    0.    4.    3.]
 [   0. 1125.    1.    0.    1.    0.    2.    4.    0.    6.]
 [   0.    3. 1015.    2.    1.    1.    0.   17.    5.    1.]
 [   0.    1.    6.  995.    0.    8.    1.    1.   13.   14.]
 [   1.    0.    2.    0.  952.    0.    4.    2.    3.    6.]
 [   2.    2.    0.    4.    0.  873.    6.    0.    5.    1.]
 [   7.    4.    0.    0.    6.    4.  942.    0.    3.    1.]
 [   1.    0.    4.    6.    1.    0.    0.  995.    1.    6.]
 [   4.    0.    3.    2.    3.    3.    0.    2.  934.    5.]
 [   0.    0.    0.    1.   18.    1.    0.    7.    6.  966.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.110946, Accuracy: 0.746000, Test accuracy: 0.761500
Distillation: Epoch : 2, Loss : 2.042616, Accuracy: 0.854000, Test accuracy: 0.855800
Distillation: Epoch : 3, Loss : 2.034605, Accuracy: 0.900000, Test accuracy: 0.883900
Distillation: Epoch : 4, Loss : 2.020380, Accuracy: 0.890000, Test accuracy: 0.901200
Distillation: Epoch : 5, Loss : 2.012858, Accuracy: 0.899000, Test accuracy: 0.917700
Distillation: Epoch : 6, Loss : 2.003538, Accuracy: 0.924000, Test accuracy: 0.930700
Distillation: Epoch : 7, Loss : 2.003057, Accuracy: 0.935000, Test accuracy: 0.940800
Distillation: Epoch : 8, Loss : 1.988754, Accuracy: 0.924000, Test accuracy: 0.946800
Distillation: Epoch : 9, Loss : 1.981091, Accuracy: 0.953000, Test accuracy: 0.948800
Distillation: Epoch : 10, Loss : 1.974897, Accuracy: 0.952000, Test accuracy: 0.955100
Distillation: Epoch : 11, Loss : 1.978307, Accuracy: 0.961000, Test accuracy: 0.957800
Distillation: Epoch : 12, Loss : 1.995213, Accuracy: 0.963000, Test accuracy: 0.959900
Distillation: Epoch : 13, Loss : 1.985554, Accuracy: 0.956000, Test accuracy: 0.961600
Distillation: Epoch : 14, Loss : 1.977789, Accuracy: 0.959000, Test accuracy: 0.963100
Distillation: Epoch : 15, Loss : 1.975216, Accuracy: 0.954000, Test accuracy: 0.964400
Distillation: Epoch : 16, Loss : 1.984117, Accuracy: 0.947000, Test accuracy: 0.965300
Distillation: Epoch : 17, Loss : 1.989550, Accuracy: 0.955000, Test accuracy: 0.966000
Distillation: Epoch : 18, Loss : 1.969058, Accuracy: 0.965000, Test accuracy: 0.966900
Distillation: Epoch : 19, Loss : 1.984743, Accuracy: 0.957000, Test accuracy: 0.968100
Distillation: Epoch : 20, Loss : 1.969637, Accuracy: 0.964000, Test accuracy: 0.968700
Distillation: Epoch : 21, Loss : 1.979788, Accuracy: 0.970000, Test accuracy: 0.969500
Distillation: Epoch : 22, Loss : 1.980905, Accuracy: 0.967000, Test accuracy: 0.969700
Distillation: Epoch : 23, Loss : 1.979066, Accuracy: 0.967000, Test accuracy: 0.970900
Distillation: Epoch : 24, Loss : 1.973618, Accuracy: 0.964000, Test accuracy: 0.971800
Distillation: Epoch : 25, Loss : 1.979967, Accuracy: 0.974000, Test accuracy: 0.971300
Distillation: Epoch : 26, Loss : 1.976526, Accuracy: 0.970000, Test accuracy: 0.972200
Distillation: Epoch : 27, Loss : 1.972252, Accuracy: 0.964000, Test accuracy: 0.972800
Distillation: Epoch : 28, Loss : 1.983391, Accuracy: 0.964000, Test accuracy: 0.973000
Distillation: Epoch : 29, Loss : 1.977473, Accuracy: 0.966000, Test accuracy: 0.972900
Distillation: Epoch : 30, Loss : 1.974117, Accuracy: 0.961000, Test accuracy: 0.973100
Distillation: Epoch : 31, Loss : 1.972619, Accuracy: 0.961000, Test accuracy: 0.973900
Distillation: Epoch : 32, Loss : 1.969352, Accuracy: 0.972000, Test accuracy: 0.974400
Distillation: Epoch : 33, Loss : 1.973196, Accuracy: 0.968000, Test accuracy: 0.974500
Distillation: Epoch : 34, Loss : 1.963687, Accuracy: 0.960000, Test accuracy: 0.974800
Distillation: Epoch : 35, Loss : 1.958410, Accuracy: 0.967000, Test accuracy: 0.974900
Distillation: Epoch : 36, Loss : 1.972574, Accuracy: 0.969000, Test accuracy: 0.975100
Distillation: Epoch : 37, Loss : 1.962003, Accuracy: 0.969000, Test accuracy: 0.975600
Distillation: Epoch : 38, Loss : 1.971810, Accuracy: 0.977000, Test accuracy: 0.974800
Distillation: Epoch : 39, Loss : 1.964414, Accuracy: 0.971000, Test accuracy: 0.975900
Distillation: Epoch : 40, Loss : 1.969129, Accuracy: 0.979000, Test accuracy: 0.975700
Distillation: Epoch : 41, Loss : 1.971845, Accuracy: 0.975000, Test accuracy: 0.976600
Distillation: Epoch : 42, Loss : 1.961849, Accuracy: 0.968000, Test accuracy: 0.977300
Distillation: Epoch : 43, Loss : 1.964216, Accuracy: 0.968000, Test accuracy: 0.976600
Distillation: Epoch : 44, Loss : 1.959319, Accuracy: 0.973000, Test accuracy: 0.977300
Distillation: Epoch : 45, Loss : 1.964315, Accuracy: 0.968000, Test accuracy: 0.977100
Distillation: Epoch : 46, Loss : 1.969119, Accuracy: 0.965000, Test accuracy: 0.977000
Distillation: Epoch : 47, Loss : 1.966495, Accuracy: 0.972000, Test accuracy: 0.977100
Distillation: Epoch : 48, Loss : 1.968242, Accuracy: 0.963000, Test accuracy: 0.978000
Distillation: Epoch : 49, Loss : 1.967558, Accuracy: 0.973000, Test accuracy: 0.978100
Distillation: Epoch : 50, Loss : 1.970326, Accuracy: 0.979000, Test accuracy: 0.978500
Saving to student/student.ckpt
<confusion_matrix>
results for %s distillate with T = %d student [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student/student.ckpt
Accuracy on the test set
0.9785
Generating confusion matrix for student
[[ 967.    0.    0.    0.    0.    1.    2.    0.    3.    2.]
 [   1. 1121.    1.    0.    0.    0.    2.    8.    1.    8.]
 [   1.    3. 1017.    1.    2.    0.    1.   12.    4.    1.]
 [   0.    0.    4.  999.    0.   14.    0.    4.    8.   13.]
 [   1.    0.    1.    0.  955.    0.    2.    1.    2.    8.]
 [   1.    0.    0.    3.    0.  871.    4.    0.    1.    1.]
 [   5.    7.    1.    0.    8.    4.  946.    0.    3.    1.]
 [   1.    1.    1.    2.    1.    0.    0.  998.    3.    6.]
 [   3.    3.    7.    5.    3.    2.    1.    1.  946.    4.]
 [   0.    0.    0.    0.   13.    0.    0.    4.    3.  965.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.860282, Accuracy: 0.828000, Test accuracy: 0.831400
Distillation: Epoch : 2, Loss : 0.452852, Accuracy: 0.888000, Test accuracy: 0.890900
Distillation: Epoch : 3, Loss : 0.331613, Accuracy: 0.899000, Test accuracy: 0.912700
Distillation: Epoch : 4, Loss : 0.299177, Accuracy: 0.910000, Test accuracy: 0.925400
Distillation: Epoch : 5, Loss : 0.236981, Accuracy: 0.932000, Test accuracy: 0.932200
Distillation: Epoch : 6, Loss : 0.243262, Accuracy: 0.936000, Test accuracy: 0.938300
Distillation: Epoch : 7, Loss : 0.182069, Accuracy: 0.947000, Test accuracy: 0.943100
Distillation: Epoch : 8, Loss : 0.215492, Accuracy: 0.936000, Test accuracy: 0.946600
Distillation: Epoch : 9, Loss : 0.190121, Accuracy: 0.944000, Test accuracy: 0.950300
Distillation: Epoch : 10, Loss : 0.178826, Accuracy: 0.952000, Test accuracy: 0.952600
Distillation: Epoch : 11, Loss : 0.166071, Accuracy: 0.954000, Test accuracy: 0.954000
Distillation: Epoch : 12, Loss : 0.142449, Accuracy: 0.954000, Test accuracy: 0.956000
Distillation: Epoch : 13, Loss : 0.135373, Accuracy: 0.968000, Test accuracy: 0.957200
Distillation: Epoch : 14, Loss : 0.140764, Accuracy: 0.962000, Test accuracy: 0.959500
Distillation: Epoch : 15, Loss : 0.151440, Accuracy: 0.953000, Test accuracy: 0.960500
Distillation: Epoch : 16, Loss : 0.130335, Accuracy: 0.970000, Test accuracy: 0.962200
Distillation: Epoch : 17, Loss : 0.129760, Accuracy: 0.960000, Test accuracy: 0.962900
Distillation: Epoch : 18, Loss : 0.144191, Accuracy: 0.965000, Test accuracy: 0.964300
Distillation: Epoch : 19, Loss : 0.115671, Accuracy: 0.968000, Test accuracy: 0.965400
Distillation: Epoch : 20, Loss : 0.095840, Accuracy: 0.970000, Test accuracy: 0.964600
Distillation: Epoch : 21, Loss : 0.116983, Accuracy: 0.964000, Test accuracy: 0.966500
Distillation: Epoch : 22, Loss : 0.128966, Accuracy: 0.957000, Test accuracy: 0.966900
Distillation: Epoch : 23, Loss : 0.090778, Accuracy: 0.975000, Test accuracy: 0.967700
Distillation: Epoch : 24, Loss : 0.111788, Accuracy: 0.963000, Test accuracy: 0.968100
Distillation: Epoch : 25, Loss : 0.128116, Accuracy: 0.956000, Test accuracy: 0.968100
Distillation: Epoch : 26, Loss : 0.092948, Accuracy: 0.972000, Test accuracy: 0.968800
Distillation: Epoch : 27, Loss : 0.099070, Accuracy: 0.980000, Test accuracy: 0.968700
Distillation: Epoch : 28, Loss : 0.099356, Accuracy: 0.975000, Test accuracy: 0.969200
Distillation: Epoch : 29, Loss : 0.077733, Accuracy: 0.980000, Test accuracy: 0.969400
Distillation: Epoch : 30, Loss : 0.071069, Accuracy: 0.979000, Test accuracy: 0.968700
Distillation: Epoch : 31, Loss : 0.103644, Accuracy: 0.972000, Test accuracy: 0.969800
Distillation: Epoch : 32, Loss : 0.116610, Accuracy: 0.964000, Test accuracy: 0.969200
Distillation: Epoch : 33, Loss : 0.091095, Accuracy: 0.971000, Test accuracy: 0.969900
Distillation: Epoch : 34, Loss : 0.073753, Accuracy: 0.984000, Test accuracy: 0.969800
Distillation: Epoch : 35, Loss : 0.070434, Accuracy: 0.979000, Test accuracy: 0.970200
Distillation: Epoch : 36, Loss : 0.113565, Accuracy: 0.966000, Test accuracy: 0.969700
Distillation: Epoch : 37, Loss : 0.104141, Accuracy: 0.969000, Test accuracy: 0.970500
Distillation: Epoch : 38, Loss : 0.115076, Accuracy: 0.965000, Test accuracy: 0.970300
Distillation: Epoch : 39, Loss : 0.106027, Accuracy: 0.967000, Test accuracy: 0.970100
Distillation: Epoch : 40, Loss : 0.087214, Accuracy: 0.978000, Test accuracy: 0.971400
Distillation: Epoch : 41, Loss : 0.104472, Accuracy: 0.969000, Test accuracy: 0.971900
Distillation: Epoch : 42, Loss : 0.090962, Accuracy: 0.977000, Test accuracy: 0.971800
Distillation: Epoch : 43, Loss : 0.103519, Accuracy: 0.972000, Test accuracy: 0.971100
Distillation: Epoch : 44, Loss : 0.064781, Accuracy: 0.982000, Test accuracy: 0.971200
Distillation: Epoch : 45, Loss : 0.064359, Accuracy: 0.982000, Test accuracy: 0.971800
Distillation: Epoch : 46, Loss : 0.075925, Accuracy: 0.980000, Test accuracy: 0.971600
Distillation: Epoch : 47, Loss : 0.090755, Accuracy: 0.975000, Test accuracy: 0.971400
Distillation: Epoch : 48, Loss : 0.085154, Accuracy: 0.978000, Test accuracy: 0.971900
Distillation: Epoch : 49, Loss : 0.087515, Accuracy: 0.972000, Test accuracy: 0.972100
Distillation: Epoch : 50, Loss : 0.085232, Accuracy: 0.975000, Test accuracy: 0.972400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9724
Generating confusion matrix for student2
[[ 971.    0.    3.    0.    1.    1.    7.    0.    5.    5.]
 [   1. 1121.    7.    1.    2.    0.    3.    5.    1.    6.]
 [   1.    5. 1000.    5.    3.    0.    0.   16.    6.    1.]
 [   1.    3.    8.  990.    0.    9.    1.    3.   13.    4.]
 [   0.    0.    3.    0.  959.    0.    4.    3.    2.    7.]
 [   3.    2.    0.    5.    0.  867.    5.    1.    4.    8.]
 [   1.    1.    1.    0.    3.    3.  934.    0.    2.    0.]
 [   1.    0.    5.    0.    0.    1.    0.  987.    5.    5.]
 [   1.    3.    3.    6.    1.    4.    4.    3.  927.    5.]
 [   0.    0.    2.    3.   13.    7.    0.   10.    9.  968.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.250180, Accuracy: 0.802000, Test accuracy: 0.800600
Distillation: Epoch : 2, Loss : 0.565004, Accuracy: 0.878000, Test accuracy: 0.875900
Distillation: Epoch : 3, Loss : 0.414034, Accuracy: 0.885000, Test accuracy: 0.903900
Distillation: Epoch : 4, Loss : 0.348097, Accuracy: 0.922000, Test accuracy: 0.914900
Distillation: Epoch : 5, Loss : 0.303469, Accuracy: 0.921000, Test accuracy: 0.923200
Distillation: Epoch : 6, Loss : 0.277133, Accuracy: 0.933000, Test accuracy: 0.928900
Distillation: Epoch : 7, Loss : 0.280778, Accuracy: 0.927000, Test accuracy: 0.933600
Distillation: Epoch : 8, Loss : 0.227219, Accuracy: 0.941000, Test accuracy: 0.936600
Distillation: Epoch : 9, Loss : 0.210743, Accuracy: 0.941000, Test accuracy: 0.940600
Distillation: Epoch : 10, Loss : 0.239325, Accuracy: 0.938000, Test accuracy: 0.943400
Distillation: Epoch : 11, Loss : 0.228955, Accuracy: 0.943000, Test accuracy: 0.946300
Distillation: Epoch : 12, Loss : 0.244957, Accuracy: 0.939000, Test accuracy: 0.948000
Distillation: Epoch : 13, Loss : 0.222655, Accuracy: 0.949000, Test accuracy: 0.950200
Distillation: Epoch : 14, Loss : 0.203444, Accuracy: 0.946000, Test accuracy: 0.950600
Distillation: Epoch : 15, Loss : 0.191643, Accuracy: 0.958000, Test accuracy: 0.952100
Distillation: Epoch : 16, Loss : 0.162582, Accuracy: 0.955000, Test accuracy: 0.954400
Distillation: Epoch : 17, Loss : 0.181633, Accuracy: 0.961000, Test accuracy: 0.955900
Distillation: Epoch : 18, Loss : 0.166887, Accuracy: 0.958000, Test accuracy: 0.956600
Distillation: Epoch : 19, Loss : 0.182363, Accuracy: 0.949000, Test accuracy: 0.956600
Distillation: Epoch : 20, Loss : 0.144621, Accuracy: 0.960000, Test accuracy: 0.957200
Distillation: Epoch : 21, Loss : 0.157902, Accuracy: 0.959000, Test accuracy: 0.958400
Distillation: Epoch : 22, Loss : 0.175873, Accuracy: 0.948000, Test accuracy: 0.959100
Distillation: Epoch : 23, Loss : 0.149726, Accuracy: 0.963000, Test accuracy: 0.961200
Distillation: Epoch : 24, Loss : 0.156862, Accuracy: 0.965000, Test accuracy: 0.961200
Distillation: Epoch : 25, Loss : 0.156738, Accuracy: 0.964000, Test accuracy: 0.960900
Distillation: Epoch : 26, Loss : 0.184838, Accuracy: 0.963000, Test accuracy: 0.962100
Distillation: Epoch : 27, Loss : 0.158990, Accuracy: 0.960000, Test accuracy: 0.961700
Distillation: Epoch : 28, Loss : 0.148908, Accuracy: 0.964000, Test accuracy: 0.962200
Distillation: Epoch : 29, Loss : 0.148151, Accuracy: 0.960000, Test accuracy: 0.963800
Distillation: Epoch : 30, Loss : 0.162752, Accuracy: 0.964000, Test accuracy: 0.963500
Distillation: Epoch : 31, Loss : 0.151368, Accuracy: 0.961000, Test accuracy: 0.963900
Distillation: Epoch : 32, Loss : 0.189537, Accuracy: 0.955000, Test accuracy: 0.965200
Distillation: Epoch : 33, Loss : 0.170164, Accuracy: 0.961000, Test accuracy: 0.965200
Distillation: Epoch : 34, Loss : 0.141751, Accuracy: 0.965000, Test accuracy: 0.965200
Distillation: Epoch : 35, Loss : 0.129170, Accuracy: 0.966000, Test accuracy: 0.965900
Distillation: Epoch : 36, Loss : 0.176214, Accuracy: 0.954000, Test accuracy: 0.966800
Distillation: Epoch : 37, Loss : 0.124082, Accuracy: 0.970000, Test accuracy: 0.966400
Distillation: Epoch : 38, Loss : 0.131782, Accuracy: 0.960000, Test accuracy: 0.966700
Distillation: Epoch : 39, Loss : 0.107142, Accuracy: 0.978000, Test accuracy: 0.967600
Distillation: Epoch : 40, Loss : 0.138993, Accuracy: 0.967000, Test accuracy: 0.967000
Distillation: Epoch : 41, Loss : 0.152642, Accuracy: 0.963000, Test accuracy: 0.968100
Distillation: Epoch : 42, Loss : 0.154447, Accuracy: 0.959000, Test accuracy: 0.967400
Distillation: Epoch : 43, Loss : 0.119496, Accuracy: 0.970000, Test accuracy: 0.968100
Distillation: Epoch : 44, Loss : 0.130228, Accuracy: 0.969000, Test accuracy: 0.968500
Distillation: Epoch : 45, Loss : 0.143434, Accuracy: 0.959000, Test accuracy: 0.968600
Distillation: Epoch : 46, Loss : 0.153606, Accuracy: 0.963000, Test accuracy: 0.968500
Distillation: Epoch : 47, Loss : 0.146081, Accuracy: 0.967000, Test accuracy: 0.969200
Distillation: Epoch : 48, Loss : 0.128912, Accuracy: 0.973000, Test accuracy: 0.968700
Distillation: Epoch : 49, Loss : 0.122256, Accuracy: 0.968000, Test accuracy: 0.968700
Distillation: Epoch : 50, Loss : 0.139877, Accuracy: 0.967000, Test accuracy: 0.969300
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9693
Generating confusion matrix for student2
[[ 967.    0.    1.    0.    1.    1.    4.    1.    5.    4.]
 [   0. 1123.    9.    0.    2.    0.    2.    5.    2.    6.]
 [   1.    3.  986.    8.    2.    0.    0.   18.    7.    1.]
 [   0.    2.    8.  979.    0.    8.    1.    3.    8.    6.]
 [   0.    0.    3.    0.  960.    0.    4.    2.    3.   13.]
 [   1.    1.    0.    6.    0.  870.    5.    1.    4.    2.]
 [   6.    2.    3.    0.    3.    5.  938.    0.    4.    0.]
 [   1.    0.    6.    5.    2.    1.    0.  979.    6.   12.]
 [   3.    4.   13.    9.    2.    5.    4.    3.  929.    3.]
 [   1.    0.    3.    3.   10.    2.    0.   16.    6.  962.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.500749, Accuracy: 0.782000, Test accuracy: 0.766800
Distillation: Epoch : 2, Loss : 0.882927, Accuracy: 0.851000, Test accuracy: 0.851900
Distillation: Epoch : 3, Loss : 0.754065, Accuracy: 0.873000, Test accuracy: 0.879000
Distillation: Epoch : 4, Loss : 0.678080, Accuracy: 0.894000, Test accuracy: 0.894100
Distillation: Epoch : 5, Loss : 0.637734, Accuracy: 0.909000, Test accuracy: 0.901400
Distillation: Epoch : 6, Loss : 0.678024, Accuracy: 0.898000, Test accuracy: 0.911600
Distillation: Epoch : 7, Loss : 0.590379, Accuracy: 0.915000, Test accuracy: 0.915200
Distillation: Epoch : 8, Loss : 0.621456, Accuracy: 0.915000, Test accuracy: 0.918400
Distillation: Epoch : 9, Loss : 0.606868, Accuracy: 0.914000, Test accuracy: 0.921400
Distillation: Epoch : 10, Loss : 0.591075, Accuracy: 0.907000, Test accuracy: 0.925700
Distillation: Epoch : 11, Loss : 0.553242, Accuracy: 0.931000, Test accuracy: 0.928000
Distillation: Epoch : 12, Loss : 0.579055, Accuracy: 0.924000, Test accuracy: 0.930400
Distillation: Epoch : 13, Loss : 0.603442, Accuracy: 0.913000, Test accuracy: 0.932900
Distillation: Epoch : 14, Loss : 0.581840, Accuracy: 0.931000, Test accuracy: 0.934400
Distillation: Epoch : 15, Loss : 0.544208, Accuracy: 0.941000, Test accuracy: 0.936200
Distillation: Epoch : 16, Loss : 0.516562, Accuracy: 0.944000, Test accuracy: 0.938000
Distillation: Epoch : 17, Loss : 0.538875, Accuracy: 0.940000, Test accuracy: 0.939500
Distillation: Epoch : 18, Loss : 0.546933, Accuracy: 0.931000, Test accuracy: 0.941800
Distillation: Epoch : 19, Loss : 0.541383, Accuracy: 0.939000, Test accuracy: 0.942800
Distillation: Epoch : 20, Loss : 0.521446, Accuracy: 0.949000, Test accuracy: 0.945200
Distillation: Epoch : 21, Loss : 0.526947, Accuracy: 0.942000, Test accuracy: 0.945400
Distillation: Epoch : 22, Loss : 0.536264, Accuracy: 0.941000, Test accuracy: 0.947900
Distillation: Epoch : 23, Loss : 0.529907, Accuracy: 0.947000, Test accuracy: 0.949300
Distillation: Epoch : 24, Loss : 0.489787, Accuracy: 0.955000, Test accuracy: 0.949700
Distillation: Epoch : 25, Loss : 0.480257, Accuracy: 0.959000, Test accuracy: 0.951400
Distillation: Epoch : 26, Loss : 0.510562, Accuracy: 0.947000, Test accuracy: 0.952000
Distillation: Epoch : 27, Loss : 0.503899, Accuracy: 0.944000, Test accuracy: 0.952600
Distillation: Epoch : 28, Loss : 0.479637, Accuracy: 0.965000, Test accuracy: 0.953800
Distillation: Epoch : 29, Loss : 0.488128, Accuracy: 0.948000, Test accuracy: 0.954700
Distillation: Epoch : 30, Loss : 0.484434, Accuracy: 0.963000, Test accuracy: 0.955500
Distillation: Epoch : 31, Loss : 0.499622, Accuracy: 0.949000, Test accuracy: 0.956600
Distillation: Epoch : 32, Loss : 0.467596, Accuracy: 0.961000, Test accuracy: 0.957000
Distillation: Epoch : 33, Loss : 0.510563, Accuracy: 0.945000, Test accuracy: 0.957300
Distillation: Epoch : 34, Loss : 0.491556, Accuracy: 0.963000, Test accuracy: 0.958100
Distillation: Epoch : 35, Loss : 0.526224, Accuracy: 0.952000, Test accuracy: 0.959000
Distillation: Epoch : 36, Loss : 0.506076, Accuracy: 0.945000, Test accuracy: 0.960000
Distillation: Epoch : 37, Loss : 0.508876, Accuracy: 0.938000, Test accuracy: 0.959300
Distillation: Epoch : 38, Loss : 0.460984, Accuracy: 0.958000, Test accuracy: 0.961100
Distillation: Epoch : 39, Loss : 0.476154, Accuracy: 0.967000, Test accuracy: 0.962000
Distillation: Epoch : 40, Loss : 0.479722, Accuracy: 0.952000, Test accuracy: 0.960900
Distillation: Epoch : 41, Loss : 0.478276, Accuracy: 0.956000, Test accuracy: 0.962500
Distillation: Epoch : 42, Loss : 0.464755, Accuracy: 0.953000, Test accuracy: 0.963000
Distillation: Epoch : 43, Loss : 0.468523, Accuracy: 0.957000, Test accuracy: 0.963000
Distillation: Epoch : 44, Loss : 0.486900, Accuracy: 0.955000, Test accuracy: 0.964400
Distillation: Epoch : 45, Loss : 0.458804, Accuracy: 0.969000, Test accuracy: 0.963500
Distillation: Epoch : 46, Loss : 0.469777, Accuracy: 0.962000, Test accuracy: 0.964700
Distillation: Epoch : 47, Loss : 0.490003, Accuracy: 0.959000, Test accuracy: 0.965100
Distillation: Epoch : 48, Loss : 0.474078, Accuracy: 0.965000, Test accuracy: 0.966000
Distillation: Epoch : 49, Loss : 0.464632, Accuracy: 0.970000, Test accuracy: 0.966400
Distillation: Epoch : 50, Loss : 0.468427, Accuracy: 0.963000, Test accuracy: 0.966500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9665
Generating confusion matrix for student2
[[ 967.    0.    2.    0.    1.    2.    3.    1.    7.    4.]
 [   0. 1119.    7.    0.    1.    1.    2.    6.    3.    6.]
 [   1.    4.  991.    7.    3.    1.    2.   17.   10.    1.]
 [   0.    0.    9.  985.    0.   14.    1.    4.   10.    9.]
 [   0.    0.    3.    0.  953.    0.    4.    3.    6.   12.]
 [   2.    1.    0.    7.    0.  859.    3.    0.    4.    3.]
 [   4.    5.    2.    0.    7.    5.  941.    0.    6.    1.]
 [   1.    0.    9.    4.    2.    2.    0.  980.    8.   16.]
 [   5.    6.    7.    5.    4.    5.    2.    2.  913.    0.]
 [   0.    0.    2.    2.   11.    3.    0.   15.    7.  957.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.889546, Accuracy: 0.691000, Test accuracy: 0.721600
Distillation: Epoch : 2, Loss : 1.144562, Accuracy: 0.842000, Test accuracy: 0.833100
Distillation: Epoch : 3, Loss : 0.931916, Accuracy: 0.854000, Test accuracy: 0.870200
Distillation: Epoch : 4, Loss : 0.893454, Accuracy: 0.870000, Test accuracy: 0.887400
Distillation: Epoch : 5, Loss : 0.822968, Accuracy: 0.893000, Test accuracy: 0.901600
Distillation: Epoch : 6, Loss : 0.817708, Accuracy: 0.893000, Test accuracy: 0.908800
Distillation: Epoch : 7, Loss : 0.750321, Accuracy: 0.916000, Test accuracy: 0.915500
Distillation: Epoch : 8, Loss : 0.787080, Accuracy: 0.908000, Test accuracy: 0.919900
Distillation: Epoch : 9, Loss : 0.765943, Accuracy: 0.917000, Test accuracy: 0.924800
Distillation: Epoch : 10, Loss : 0.745541, Accuracy: 0.935000, Test accuracy: 0.928600
Distillation: Epoch : 11, Loss : 0.738825, Accuracy: 0.915000, Test accuracy: 0.931600
Distillation: Epoch : 12, Loss : 0.716856, Accuracy: 0.926000, Test accuracy: 0.933100
Distillation: Epoch : 13, Loss : 0.696825, Accuracy: 0.934000, Test accuracy: 0.935600
Distillation: Epoch : 14, Loss : 0.682336, Accuracy: 0.946000, Test accuracy: 0.938100
Distillation: Epoch : 15, Loss : 0.704298, Accuracy: 0.940000, Test accuracy: 0.940100
Distillation: Epoch : 16, Loss : 0.700627, Accuracy: 0.936000, Test accuracy: 0.941100
Distillation: Epoch : 17, Loss : 0.672781, Accuracy: 0.947000, Test accuracy: 0.943300
Distillation: Epoch : 18, Loss : 0.662405, Accuracy: 0.961000, Test accuracy: 0.945100
Distillation: Epoch : 19, Loss : 0.673970, Accuracy: 0.943000, Test accuracy: 0.946800
Distillation: Epoch : 20, Loss : 0.690494, Accuracy: 0.952000, Test accuracy: 0.948400
Distillation: Epoch : 21, Loss : 0.689635, Accuracy: 0.941000, Test accuracy: 0.949000
Distillation: Epoch : 22, Loss : 0.667848, Accuracy: 0.949000, Test accuracy: 0.949900
Distillation: Epoch : 23, Loss : 0.659388, Accuracy: 0.948000, Test accuracy: 0.951300
Distillation: Epoch : 24, Loss : 0.661750, Accuracy: 0.942000, Test accuracy: 0.951700
Distillation: Epoch : 25, Loss : 0.676500, Accuracy: 0.949000, Test accuracy: 0.953600
Distillation: Epoch : 26, Loss : 0.654659, Accuracy: 0.946000, Test accuracy: 0.954600
Distillation: Epoch : 27, Loss : 0.668061, Accuracy: 0.957000, Test accuracy: 0.955000
Distillation: Epoch : 28, Loss : 0.700795, Accuracy: 0.950000, Test accuracy: 0.955300
Distillation: Epoch : 29, Loss : 0.648195, Accuracy: 0.952000, Test accuracy: 0.958000
Distillation: Epoch : 30, Loss : 0.631294, Accuracy: 0.956000, Test accuracy: 0.958400
Distillation: Epoch : 31, Loss : 0.626324, Accuracy: 0.964000, Test accuracy: 0.959100
Distillation: Epoch : 32, Loss : 0.650005, Accuracy: 0.962000, Test accuracy: 0.960200
Distillation: Epoch : 33, Loss : 0.622094, Accuracy: 0.968000, Test accuracy: 0.960900
Distillation: Epoch : 34, Loss : 0.644431, Accuracy: 0.968000, Test accuracy: 0.961200
Distillation: Epoch : 35, Loss : 0.644214, Accuracy: 0.961000, Test accuracy: 0.960800
Distillation: Epoch : 36, Loss : 0.656774, Accuracy: 0.959000, Test accuracy: 0.961500
Distillation: Epoch : 37, Loss : 0.672431, Accuracy: 0.961000, Test accuracy: 0.962500
Distillation: Epoch : 38, Loss : 0.638167, Accuracy: 0.963000, Test accuracy: 0.962600
Distillation: Epoch : 39, Loss : 0.665198, Accuracy: 0.946000, Test accuracy: 0.963600
Distillation: Epoch : 40, Loss : 0.646749, Accuracy: 0.953000, Test accuracy: 0.964500
Distillation: Epoch : 41, Loss : 0.655873, Accuracy: 0.957000, Test accuracy: 0.963500
Distillation: Epoch : 42, Loss : 0.615810, Accuracy: 0.966000, Test accuracy: 0.964500
Distillation: Epoch : 43, Loss : 0.627680, Accuracy: 0.968000, Test accuracy: 0.963800
Distillation: Epoch : 44, Loss : 0.617921, Accuracy: 0.962000, Test accuracy: 0.964600
Distillation: Epoch : 45, Loss : 0.619781, Accuracy: 0.960000, Test accuracy: 0.964900
Distillation: Epoch : 46, Loss : 0.610103, Accuracy: 0.965000, Test accuracy: 0.965500
Distillation: Epoch : 47, Loss : 0.637862, Accuracy: 0.960000, Test accuracy: 0.966000
Distillation: Epoch : 48, Loss : 0.686978, Accuracy: 0.948000, Test accuracy: 0.965800
Distillation: Epoch : 49, Loss : 0.625455, Accuracy: 0.966000, Test accuracy: 0.966200
Distillation: Epoch : 50, Loss : 0.646504, Accuracy: 0.959000, Test accuracy: 0.966500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9665
Generating confusion matrix for student2
[[ 968.    0.    1.    0.    1.    1.    4.    0.    7.    3.]
 [   1. 1117.    4.    0.    0.    1.    3.    4.    3.    5.]
 [   1.    2.  999.    6.    2.    1.    1.   19.    7.    1.]
 [   0.    1.   11.  988.    0.   22.    1.    5.   13.   13.]
 [   0.    0.    0.    0.  947.    0.    6.    1.    6.    9.]
 [   1.    0.    1.    7.    0.  850.    4.    0.    3.    7.]
 [   3.    7.    2.    0.   10.    4.  937.    0.    7.    2.]
 [   2.    1.    4.    2.    2.    4.    0.  988.    7.    8.]
 [   4.    7.    8.    5.    4.    6.    2.    1.  911.    1.]
 [   0.    0.    2.    2.   16.    3.    0.   10.   10.  960.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.554153, Accuracy: 0.772000, Test accuracy: 0.765500
Distillation: Epoch : 2, Loss : 1.157363, Accuracy: 0.831000, Test accuracy: 0.837300
Distillation: Epoch : 3, Loss : 1.115211, Accuracy: 0.842000, Test accuracy: 0.869200
Distillation: Epoch : 4, Loss : 1.033170, Accuracy: 0.870000, Test accuracy: 0.880400
Distillation: Epoch : 5, Loss : 1.010647, Accuracy: 0.894000, Test accuracy: 0.888300
Distillation: Epoch : 6, Loss : 1.054254, Accuracy: 0.857000, Test accuracy: 0.892200
Distillation: Epoch : 7, Loss : 1.001964, Accuracy: 0.889000, Test accuracy: 0.896500
Distillation: Epoch : 8, Loss : 0.985824, Accuracy: 0.887000, Test accuracy: 0.898700
Distillation: Epoch : 9, Loss : 1.017983, Accuracy: 0.882000, Test accuracy: 0.901100
Distillation: Epoch : 10, Loss : 0.981327, Accuracy: 0.897000, Test accuracy: 0.901200
Distillation: Epoch : 11, Loss : 0.955961, Accuracy: 0.901000, Test accuracy: 0.901300
Distillation: Epoch : 12, Loss : 0.991067, Accuracy: 0.894000, Test accuracy: 0.904600
Distillation: Epoch : 13, Loss : 0.960097, Accuracy: 0.883000, Test accuracy: 0.906000
Distillation: Epoch : 14, Loss : 0.972285, Accuracy: 0.902000, Test accuracy: 0.907000
Distillation: Epoch : 15, Loss : 0.975310, Accuracy: 0.893000, Test accuracy: 0.907900
Distillation: Epoch : 16, Loss : 0.968502, Accuracy: 0.897000, Test accuracy: 0.908400
Distillation: Epoch : 17, Loss : 0.925934, Accuracy: 0.912000, Test accuracy: 0.908600
Distillation: Epoch : 18, Loss : 0.976312, Accuracy: 0.904000, Test accuracy: 0.909800
Distillation: Epoch : 19, Loss : 0.981369, Accuracy: 0.906000, Test accuracy: 0.909700
Distillation: Epoch : 20, Loss : 0.936743, Accuracy: 0.912000, Test accuracy: 0.910300
Distillation: Epoch : 21, Loss : 0.975963, Accuracy: 0.910000, Test accuracy: 0.911400
Distillation: Epoch : 22, Loss : 0.961684, Accuracy: 0.892000, Test accuracy: 0.911800
Distillation: Epoch : 23, Loss : 0.933913, Accuracy: 0.930000, Test accuracy: 0.913500
Distillation: Epoch : 24, Loss : 0.972308, Accuracy: 0.896000, Test accuracy: 0.912800
Distillation: Epoch : 25, Loss : 0.936555, Accuracy: 0.900000, Test accuracy: 0.914700
Distillation: Epoch : 26, Loss : 0.924133, Accuracy: 0.910000, Test accuracy: 0.916000
Distillation: Epoch : 27, Loss : 0.925843, Accuracy: 0.917000, Test accuracy: 0.918500
Distillation: Epoch : 28, Loss : 0.952430, Accuracy: 0.905000, Test accuracy: 0.918200
Distillation: Epoch : 29, Loss : 0.941305, Accuracy: 0.907000, Test accuracy: 0.920000
Distillation: Epoch : 30, Loss : 0.941843, Accuracy: 0.916000, Test accuracy: 0.921200
Distillation: Epoch : 31, Loss : 0.942803, Accuracy: 0.913000, Test accuracy: 0.921800
Distillation: Epoch : 32, Loss : 0.896395, Accuracy: 0.926000, Test accuracy: 0.923500
Distillation: Epoch : 33, Loss : 0.916975, Accuracy: 0.929000, Test accuracy: 0.925200
Distillation: Epoch : 34, Loss : 0.925549, Accuracy: 0.906000, Test accuracy: 0.926900
Distillation: Epoch : 35, Loss : 0.892834, Accuracy: 0.925000, Test accuracy: 0.928500
Distillation: Epoch : 36, Loss : 0.906128, Accuracy: 0.909000, Test accuracy: 0.929700
Distillation: Epoch : 37, Loss : 0.883744, Accuracy: 0.933000, Test accuracy: 0.930600
Distillation: Epoch : 38, Loss : 0.932434, Accuracy: 0.921000, Test accuracy: 0.932000
Distillation: Epoch : 39, Loss : 0.883489, Accuracy: 0.925000, Test accuracy: 0.933200
Distillation: Epoch : 40, Loss : 0.900642, Accuracy: 0.925000, Test accuracy: 0.934700
Distillation: Epoch : 41, Loss : 0.894770, Accuracy: 0.935000, Test accuracy: 0.935400
Distillation: Epoch : 42, Loss : 0.883657, Accuracy: 0.938000, Test accuracy: 0.936800
Distillation: Epoch : 43, Loss : 0.901527, Accuracy: 0.936000, Test accuracy: 0.937400
Distillation: Epoch : 44, Loss : 0.862117, Accuracy: 0.926000, Test accuracy: 0.938900
Distillation: Epoch : 45, Loss : 0.860416, Accuracy: 0.942000, Test accuracy: 0.941300
Distillation: Epoch : 46, Loss : 0.871320, Accuracy: 0.930000, Test accuracy: 0.942500
Distillation: Epoch : 47, Loss : 0.857622, Accuracy: 0.938000, Test accuracy: 0.942700
Distillation: Epoch : 48, Loss : 0.901608, Accuracy: 0.932000, Test accuracy: 0.943400
Distillation: Epoch : 49, Loss : 0.841321, Accuracy: 0.951000, Test accuracy: 0.946200
Distillation: Epoch : 50, Loss : 0.864734, Accuracy: 0.942000, Test accuracy: 0.946800
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9468
Generating confusion matrix for student2
[[ 958.    0.    5.    3.    0.    4.    9.    0.    7.    5.]
 [   0. 1115.    3.    0.    1.    2.    3.   12.    4.    4.]
 [   0.    2.  954.   12.    7.    2.    3.   16.   11.    2.]
 [   0.    2.   12.  969.    1.   30.    1.    8.   12.   19.]
 [   1.    1.    5.    1.  924.    1.    6.    8.    9.   22.]
 [   2.    2.    0.    5.    1.  824.    8.    2.    6.   10.]
 [  12.    6.   11.    2.    7.   10.  927.    0.    7.    1.]
 [   1.    0.   12.    5.    3.    2.    0.  962.    7.   13.]
 [   6.    7.   25.    9.    7.   12.    1.    2.  905.    3.]
 [   0.    0.    5.    4.   31.    5.    0.   18.    6.  930.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.700442, Accuracy: 0.738000, Test accuracy: 0.765900
Distillation: Epoch : 2, Loss : 1.300800, Accuracy: 0.802000, Test accuracy: 0.835800
Distillation: Epoch : 3, Loss : 1.207380, Accuracy: 0.854000, Test accuracy: 0.866900
Distillation: Epoch : 4, Loss : 1.186824, Accuracy: 0.881000, Test accuracy: 0.880900
Distillation: Epoch : 5, Loss : 1.173529, Accuracy: 0.865000, Test accuracy: 0.890400
Distillation: Epoch : 6, Loss : 1.119298, Accuracy: 0.888000, Test accuracy: 0.896200
Distillation: Epoch : 7, Loss : 1.150091, Accuracy: 0.884000, Test accuracy: 0.898400
Distillation: Epoch : 8, Loss : 1.136229, Accuracy: 0.886000, Test accuracy: 0.901500
Distillation: Epoch : 9, Loss : 1.126682, Accuracy: 0.902000, Test accuracy: 0.906000
Distillation: Epoch : 10, Loss : 1.136490, Accuracy: 0.882000, Test accuracy: 0.908500
Distillation: Epoch : 11, Loss : 1.110044, Accuracy: 0.909000, Test accuracy: 0.911700
Distillation: Epoch : 12, Loss : 1.075543, Accuracy: 0.908000, Test accuracy: 0.913800
Distillation: Epoch : 13, Loss : 1.103889, Accuracy: 0.905000, Test accuracy: 0.917600
Distillation: Epoch : 14, Loss : 1.082663, Accuracy: 0.916000, Test accuracy: 0.920700
Distillation: Epoch : 15, Loss : 1.085421, Accuracy: 0.904000, Test accuracy: 0.921800
Distillation: Epoch : 16, Loss : 1.076206, Accuracy: 0.919000, Test accuracy: 0.926100
Distillation: Epoch : 17, Loss : 1.084707, Accuracy: 0.920000, Test accuracy: 0.929200
Distillation: Epoch : 18, Loss : 1.044454, Accuracy: 0.922000, Test accuracy: 0.932800
Distillation: Epoch : 19, Loss : 1.029357, Accuracy: 0.938000, Test accuracy: 0.934100
Distillation: Epoch : 20, Loss : 1.024429, Accuracy: 0.944000, Test accuracy: 0.937500
Distillation: Epoch : 21, Loss : 1.031882, Accuracy: 0.948000, Test accuracy: 0.939000
Distillation: Epoch : 22, Loss : 1.019098, Accuracy: 0.941000, Test accuracy: 0.941900
Distillation: Epoch : 23, Loss : 1.018199, Accuracy: 0.940000, Test accuracy: 0.943900
Distillation: Epoch : 24, Loss : 1.038975, Accuracy: 0.935000, Test accuracy: 0.946600
Distillation: Epoch : 25, Loss : 1.016518, Accuracy: 0.955000, Test accuracy: 0.948300
Distillation: Epoch : 26, Loss : 1.002717, Accuracy: 0.954000, Test accuracy: 0.949300
Distillation: Epoch : 27, Loss : 1.058697, Accuracy: 0.937000, Test accuracy: 0.950900
Distillation: Epoch : 28, Loss : 1.042598, Accuracy: 0.935000, Test accuracy: 0.951600
Distillation: Epoch : 29, Loss : 1.034615, Accuracy: 0.955000, Test accuracy: 0.953200
Distillation: Epoch : 30, Loss : 1.010520, Accuracy: 0.951000, Test accuracy: 0.955400
Distillation: Epoch : 31, Loss : 0.988926, Accuracy: 0.952000, Test accuracy: 0.957200
Distillation: Epoch : 32, Loss : 0.996746, Accuracy: 0.958000, Test accuracy: 0.958400
Distillation: Epoch : 33, Loss : 1.016073, Accuracy: 0.955000, Test accuracy: 0.959900
Distillation: Epoch : 34, Loss : 1.004030, Accuracy: 0.958000, Test accuracy: 0.960700
Distillation: Epoch : 35, Loss : 0.993450, Accuracy: 0.965000, Test accuracy: 0.962200
Distillation: Epoch : 36, Loss : 0.965880, Accuracy: 0.967000, Test accuracy: 0.963300
Distillation: Epoch : 37, Loss : 1.008825, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 38, Loss : 0.991776, Accuracy: 0.962000, Test accuracy: 0.964800
Distillation: Epoch : 39, Loss : 0.972871, Accuracy: 0.957000, Test accuracy: 0.965400
Distillation: Epoch : 40, Loss : 0.973467, Accuracy: 0.973000, Test accuracy: 0.965300
Distillation: Epoch : 41, Loss : 0.988551, Accuracy: 0.957000, Test accuracy: 0.966200
Distillation: Epoch : 42, Loss : 0.956275, Accuracy: 0.968000, Test accuracy: 0.967100
Distillation: Epoch : 43, Loss : 0.989235, Accuracy: 0.954000, Test accuracy: 0.967100
Distillation: Epoch : 44, Loss : 0.993730, Accuracy: 0.965000, Test accuracy: 0.967900
Distillation: Epoch : 45, Loss : 0.977304, Accuracy: 0.964000, Test accuracy: 0.968200
Distillation: Epoch : 46, Loss : 1.007502, Accuracy: 0.964000, Test accuracy: 0.968700
Distillation: Epoch : 47, Loss : 1.016361, Accuracy: 0.954000, Test accuracy: 0.968200
Distillation: Epoch : 48, Loss : 0.986392, Accuracy: 0.968000, Test accuracy: 0.969300
Distillation: Epoch : 49, Loss : 0.959522, Accuracy: 0.978000, Test accuracy: 0.969300
Distillation: Epoch : 50, Loss : 0.969089, Accuracy: 0.974000, Test accuracy: 0.969500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9695
Generating confusion matrix for student2
[[ 965.    0.    2.    0.    0.    1.    5.    1.    5.    4.]
 [   0. 1124.    4.    0.    1.    1.    2.    5.    4.    6.]
 [   3.    1.  999.    5.    5.    1.    0.   19.    7.    1.]
 [   1.    3.    8.  994.    0.    7.    0.    8.   12.   12.]
 [   1.    0.    3.    0.  947.    1.    5.    0.    6.   14.]
 [   2.    0.    0.    4.    0.  872.    6.    1.    4.    6.]
 [   5.    5.    2.    0.    5.    4.  938.    0.    4.    1.]
 [   1.    0.    5.    4.    2.    2.    0.  984.    6.    8.]
 [   2.    2.    9.    2.    3.    2.    2.    2.  917.    2.]
 [   0.    0.    0.    1.   19.    1.    0.    8.    9.  955.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.812330, Accuracy: 0.725000, Test accuracy: 0.734900
Distillation: Epoch : 2, Loss : 1.443968, Accuracy: 0.830000, Test accuracy: 0.837100
Distillation: Epoch : 3, Loss : 1.363251, Accuracy: 0.863000, Test accuracy: 0.868300
Distillation: Epoch : 4, Loss : 1.297582, Accuracy: 0.865000, Test accuracy: 0.883600
Distillation: Epoch : 5, Loss : 1.282022, Accuracy: 0.885000, Test accuracy: 0.890300
Distillation: Epoch : 6, Loss : 1.288475, Accuracy: 0.888000, Test accuracy: 0.897800
Distillation: Epoch : 7, Loss : 1.282553, Accuracy: 0.877000, Test accuracy: 0.901900
Distillation: Epoch : 8, Loss : 1.274906, Accuracy: 0.894000, Test accuracy: 0.906200
Distillation: Epoch : 9, Loss : 1.268260, Accuracy: 0.896000, Test accuracy: 0.911500
Distillation: Epoch : 10, Loss : 1.228525, Accuracy: 0.893000, Test accuracy: 0.914500
Distillation: Epoch : 11, Loss : 1.238054, Accuracy: 0.910000, Test accuracy: 0.917700
Distillation: Epoch : 12, Loss : 1.262415, Accuracy: 0.902000, Test accuracy: 0.921100
Distillation: Epoch : 13, Loss : 1.235033, Accuracy: 0.911000, Test accuracy: 0.922800
Distillation: Epoch : 14, Loss : 1.239881, Accuracy: 0.907000, Test accuracy: 0.924900
Distillation: Epoch : 15, Loss : 1.224761, Accuracy: 0.918000, Test accuracy: 0.926700
Distillation: Epoch : 16, Loss : 1.219967, Accuracy: 0.930000, Test accuracy: 0.929700
Distillation: Epoch : 17, Loss : 1.204426, Accuracy: 0.932000, Test accuracy: 0.932100
Distillation: Epoch : 18, Loss : 1.191957, Accuracy: 0.931000, Test accuracy: 0.934200
Distillation: Epoch : 19, Loss : 1.223259, Accuracy: 0.931000, Test accuracy: 0.936300
Distillation: Epoch : 20, Loss : 1.198696, Accuracy: 0.931000, Test accuracy: 0.939200
Distillation: Epoch : 21, Loss : 1.195009, Accuracy: 0.930000, Test accuracy: 0.940000
Distillation: Epoch : 22, Loss : 1.190082, Accuracy: 0.928000, Test accuracy: 0.942400
Distillation: Epoch : 23, Loss : 1.187524, Accuracy: 0.945000, Test accuracy: 0.945600
Distillation: Epoch : 24, Loss : 1.160685, Accuracy: 0.953000, Test accuracy: 0.947100
Distillation: Epoch : 25, Loss : 1.179060, Accuracy: 0.931000, Test accuracy: 0.948400
Distillation: Epoch : 26, Loss : 1.156419, Accuracy: 0.955000, Test accuracy: 0.951600
Distillation: Epoch : 27, Loss : 1.156351, Accuracy: 0.956000, Test accuracy: 0.952300
Distillation: Epoch : 28, Loss : 1.169221, Accuracy: 0.947000, Test accuracy: 0.953100
Distillation: Epoch : 29, Loss : 1.164814, Accuracy: 0.959000, Test accuracy: 0.954300
Distillation: Epoch : 30, Loss : 1.158673, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 31, Loss : 1.168360, Accuracy: 0.953000, Test accuracy: 0.956400
Distillation: Epoch : 32, Loss : 1.153135, Accuracy: 0.954000, Test accuracy: 0.957200
Distillation: Epoch : 33, Loss : 1.158973, Accuracy: 0.966000, Test accuracy: 0.957700
Distillation: Epoch : 34, Loss : 1.158860, Accuracy: 0.958000, Test accuracy: 0.958300
Distillation: Epoch : 35, Loss : 1.151424, Accuracy: 0.949000, Test accuracy: 0.959500
Distillation: Epoch : 36, Loss : 1.164870, Accuracy: 0.955000, Test accuracy: 0.959700
Distillation: Epoch : 37, Loss : 1.160377, Accuracy: 0.955000, Test accuracy: 0.961000
Distillation: Epoch : 38, Loss : 1.165626, Accuracy: 0.951000, Test accuracy: 0.962100
Distillation: Epoch : 39, Loss : 1.156077, Accuracy: 0.943000, Test accuracy: 0.961600
Distillation: Epoch : 40, Loss : 1.161286, Accuracy: 0.955000, Test accuracy: 0.961800
Distillation: Epoch : 41, Loss : 1.167314, Accuracy: 0.956000, Test accuracy: 0.962300
Distillation: Epoch : 42, Loss : 1.156532, Accuracy: 0.951000, Test accuracy: 0.963500
Distillation: Epoch : 43, Loss : 1.153177, Accuracy: 0.959000, Test accuracy: 0.963700
Distillation: Epoch : 44, Loss : 1.151065, Accuracy: 0.961000, Test accuracy: 0.964100
Distillation: Epoch : 45, Loss : 1.141958, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 46, Loss : 1.147293, Accuracy: 0.965000, Test accuracy: 0.965100
Distillation: Epoch : 47, Loss : 1.124234, Accuracy: 0.971000, Test accuracy: 0.965100
Distillation: Epoch : 48, Loss : 1.137683, Accuracy: 0.969000, Test accuracy: 0.965500
Distillation: Epoch : 49, Loss : 1.142241, Accuracy: 0.959000, Test accuracy: 0.966200
Distillation: Epoch : 50, Loss : 1.137718, Accuracy: 0.964000, Test accuracy: 0.965900
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9659
Generating confusion matrix for student2
[[ 962.    0.    2.    0.    1.    1.    5.    0.    6.    6.]
 [   1. 1120.    5.    0.    1.    0.    2.    6.    2.    5.]
 [   3.    3. 1000.    3.    2.    0.    0.   20.    9.    1.]
 [   0.    1.    5.  993.    0.   11.    1.    7.    9.   17.]
 [   0.    0.    1.    1.  944.    0.    4.    3.    6.   15.]
 [   3.    1.    0.    4.    0.  868.   10.    1.    7.    5.]
 [   8.    5.    2.    0.   11.    3.  935.    0.    6.    1.]
 [   1.    0.    4.    4.    1.    2.    0.  974.    5.   12.]
 [   2.    5.   11.    3.    1.    5.    1.    3.  918.    2.]
 [   0.    0.    2.    2.   21.    2.    0.   14.    6.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.900934, Accuracy: 0.752000, Test accuracy: 0.744000
Distillation: Epoch : 2, Loss : 1.590279, Accuracy: 0.803000, Test accuracy: 0.827800
Distillation: Epoch : 3, Loss : 1.453653, Accuracy: 0.874000, Test accuracy: 0.861500
Distillation: Epoch : 4, Loss : 1.428811, Accuracy: 0.875000, Test accuracy: 0.879900
Distillation: Epoch : 5, Loss : 1.448140, Accuracy: 0.871000, Test accuracy: 0.888500
Distillation: Epoch : 6, Loss : 1.434412, Accuracy: 0.884000, Test accuracy: 0.894900
Distillation: Epoch : 7, Loss : 1.380418, Accuracy: 0.890000, Test accuracy: 0.901100
Distillation: Epoch : 8, Loss : 1.403215, Accuracy: 0.874000, Test accuracy: 0.907100
Distillation: Epoch : 9, Loss : 1.395558, Accuracy: 0.907000, Test accuracy: 0.913000
Distillation: Epoch : 10, Loss : 1.375919, Accuracy: 0.921000, Test accuracy: 0.917800
Distillation: Epoch : 11, Loss : 1.374690, Accuracy: 0.911000, Test accuracy: 0.921600
Distillation: Epoch : 12, Loss : 1.361182, Accuracy: 0.928000, Test accuracy: 0.925600
Distillation: Epoch : 13, Loss : 1.360085, Accuracy: 0.920000, Test accuracy: 0.929200
Distillation: Epoch : 14, Loss : 1.359734, Accuracy: 0.921000, Test accuracy: 0.932600
Distillation: Epoch : 15, Loss : 1.340525, Accuracy: 0.923000, Test accuracy: 0.935700
Distillation: Epoch : 16, Loss : 1.355022, Accuracy: 0.930000, Test accuracy: 0.937400
Distillation: Epoch : 17, Loss : 1.340039, Accuracy: 0.937000, Test accuracy: 0.940200
Distillation: Epoch : 18, Loss : 1.352558, Accuracy: 0.924000, Test accuracy: 0.942500
Distillation: Epoch : 19, Loss : 1.298114, Accuracy: 0.936000, Test accuracy: 0.944200
Distillation: Epoch : 20, Loss : 1.334474, Accuracy: 0.949000, Test accuracy: 0.945800
Distillation: Epoch : 21, Loss : 1.320699, Accuracy: 0.954000, Test accuracy: 0.947200
Distillation: Epoch : 22, Loss : 1.324982, Accuracy: 0.937000, Test accuracy: 0.947900
Distillation: Epoch : 23, Loss : 1.333845, Accuracy: 0.950000, Test accuracy: 0.949300
Distillation: Epoch : 24, Loss : 1.284917, Accuracy: 0.949000, Test accuracy: 0.951600
Distillation: Epoch : 25, Loss : 1.286520, Accuracy: 0.938000, Test accuracy: 0.952300
Distillation: Epoch : 26, Loss : 1.304052, Accuracy: 0.954000, Test accuracy: 0.952900
Distillation: Epoch : 27, Loss : 1.288625, Accuracy: 0.951000, Test accuracy: 0.953800
Distillation: Epoch : 28, Loss : 1.316316, Accuracy: 0.949000, Test accuracy: 0.954500
Distillation: Epoch : 29, Loss : 1.301733, Accuracy: 0.956000, Test accuracy: 0.955400
Distillation: Epoch : 30, Loss : 1.278871, Accuracy: 0.965000, Test accuracy: 0.956300
Distillation: Epoch : 31, Loss : 1.303864, Accuracy: 0.956000, Test accuracy: 0.956800
Distillation: Epoch : 32, Loss : 1.305888, Accuracy: 0.964000, Test accuracy: 0.957600
Distillation: Epoch : 33, Loss : 1.294465, Accuracy: 0.952000, Test accuracy: 0.958000
Distillation: Epoch : 34, Loss : 1.294553, Accuracy: 0.941000, Test accuracy: 0.958100
Distillation: Epoch : 35, Loss : 1.286426, Accuracy: 0.953000, Test accuracy: 0.958600
Distillation: Epoch : 36, Loss : 1.294658, Accuracy: 0.958000, Test accuracy: 0.958500
Distillation: Epoch : 37, Loss : 1.313724, Accuracy: 0.946000, Test accuracy: 0.958900
Distillation: Epoch : 38, Loss : 1.296177, Accuracy: 0.957000, Test accuracy: 0.959900
Distillation: Epoch : 39, Loss : 1.290343, Accuracy: 0.961000, Test accuracy: 0.959200
Distillation: Epoch : 40, Loss : 1.307323, Accuracy: 0.944000, Test accuracy: 0.960600
Distillation: Epoch : 41, Loss : 1.297733, Accuracy: 0.959000, Test accuracy: 0.960800
Distillation: Epoch : 42, Loss : 1.298451, Accuracy: 0.968000, Test accuracy: 0.961100
Distillation: Epoch : 43, Loss : 1.267114, Accuracy: 0.961000, Test accuracy: 0.961400
Distillation: Epoch : 44, Loss : 1.301636, Accuracy: 0.956000, Test accuracy: 0.961800
Distillation: Epoch : 45, Loss : 1.306087, Accuracy: 0.958000, Test accuracy: 0.961600
Distillation: Epoch : 46, Loss : 1.308778, Accuracy: 0.960000, Test accuracy: 0.963200
Distillation: Epoch : 47, Loss : 1.306854, Accuracy: 0.951000, Test accuracy: 0.962700
Distillation: Epoch : 48, Loss : 1.284673, Accuracy: 0.956000, Test accuracy: 0.963700
Distillation: Epoch : 49, Loss : 1.297495, Accuracy: 0.966000, Test accuracy: 0.963900
Distillation: Epoch : 50, Loss : 1.282134, Accuracy: 0.973000, Test accuracy: 0.965400
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9654
Generating confusion matrix for student2
[[ 965.    0.    0.    0.    1.    1.    7.    0.    3.    6.]
 [   1. 1124.    7.    1.    1.    1.    2.    6.    3.    6.]
 [   2.    2.  994.    5.    3.    1.    0.   17.   11.    1.]
 [   0.    2.    5.  983.    0.    6.    0.    8.   11.   16.]
 [   2.    0.    2.    1.  945.    0.    5.    1.    9.   13.]
 [   1.    0.    0.    5.    0.  874.    8.    1.    4.    7.]
 [   4.    4.    2.    0.    8.    3.  935.    0.    6.    1.]
 [   2.    0.    6.    5.    0.    1.    0.  976.    8.   12.]
 [   3.    3.   15.    7.    5.    4.    1.    1.  912.    1.]
 [   0.    0.    1.    3.   19.    1.    0.   18.    7.  946.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.984801, Accuracy: 0.696000, Test accuracy: 0.726400
Distillation: Epoch : 2, Loss : 1.653081, Accuracy: 0.804000, Test accuracy: 0.821500
Distillation: Epoch : 3, Loss : 1.614320, Accuracy: 0.820000, Test accuracy: 0.855000
Distillation: Epoch : 4, Loss : 1.543830, Accuracy: 0.875000, Test accuracy: 0.871900
Distillation: Epoch : 5, Loss : 1.552113, Accuracy: 0.881000, Test accuracy: 0.881400
Distillation: Epoch : 6, Loss : 1.541567, Accuracy: 0.885000, Test accuracy: 0.888600
Distillation: Epoch : 7, Loss : 1.513089, Accuracy: 0.894000, Test accuracy: 0.895000
Distillation: Epoch : 8, Loss : 1.508355, Accuracy: 0.908000, Test accuracy: 0.900300
Distillation: Epoch : 9, Loss : 1.514894, Accuracy: 0.918000, Test accuracy: 0.906200
Distillation: Epoch : 10, Loss : 1.487971, Accuracy: 0.900000, Test accuracy: 0.909100
Distillation: Epoch : 11, Loss : 1.491076, Accuracy: 0.911000, Test accuracy: 0.912300
Distillation: Epoch : 12, Loss : 1.483590, Accuracy: 0.916000, Test accuracy: 0.916600
Distillation: Epoch : 13, Loss : 1.472530, Accuracy: 0.914000, Test accuracy: 0.920400
Distillation: Epoch : 14, Loss : 1.494105, Accuracy: 0.909000, Test accuracy: 0.924900
Distillation: Epoch : 15, Loss : 1.483949, Accuracy: 0.918000, Test accuracy: 0.927400
Distillation: Epoch : 16, Loss : 1.475931, Accuracy: 0.944000, Test accuracy: 0.930600
Distillation: Epoch : 17, Loss : 1.464468, Accuracy: 0.922000, Test accuracy: 0.933000
Distillation: Epoch : 18, Loss : 1.481528, Accuracy: 0.915000, Test accuracy: 0.936000
Distillation: Epoch : 19, Loss : 1.437342, Accuracy: 0.934000, Test accuracy: 0.938000
Distillation: Epoch : 20, Loss : 1.487135, Accuracy: 0.934000, Test accuracy: 0.939400
Distillation: Epoch : 21, Loss : 1.458781, Accuracy: 0.936000, Test accuracy: 0.941000
Distillation: Epoch : 22, Loss : 1.476415, Accuracy: 0.921000, Test accuracy: 0.943400
Distillation: Epoch : 23, Loss : 1.439840, Accuracy: 0.949000, Test accuracy: 0.944200
Distillation: Epoch : 24, Loss : 1.440753, Accuracy: 0.936000, Test accuracy: 0.946900
Distillation: Epoch : 25, Loss : 1.458142, Accuracy: 0.932000, Test accuracy: 0.947200
Distillation: Epoch : 26, Loss : 1.444560, Accuracy: 0.939000, Test accuracy: 0.947800
Distillation: Epoch : 27, Loss : 1.447390, Accuracy: 0.940000, Test accuracy: 0.950000
Distillation: Epoch : 28, Loss : 1.436075, Accuracy: 0.944000, Test accuracy: 0.950600
Distillation: Epoch : 29, Loss : 1.442790, Accuracy: 0.956000, Test accuracy: 0.951200
Distillation: Epoch : 30, Loss : 1.431436, Accuracy: 0.957000, Test accuracy: 0.950800
Distillation: Epoch : 31, Loss : 1.445584, Accuracy: 0.945000, Test accuracy: 0.952400
Distillation: Epoch : 32, Loss : 1.419305, Accuracy: 0.957000, Test accuracy: 0.953400
Distillation: Epoch : 33, Loss : 1.448881, Accuracy: 0.954000, Test accuracy: 0.954100
Distillation: Epoch : 34, Loss : 1.415584, Accuracy: 0.955000, Test accuracy: 0.954200
Distillation: Epoch : 35, Loss : 1.408740, Accuracy: 0.961000, Test accuracy: 0.955000
Distillation: Epoch : 36, Loss : 1.444449, Accuracy: 0.948000, Test accuracy: 0.954300
Distillation: Epoch : 37, Loss : 1.451856, Accuracy: 0.947000, Test accuracy: 0.955700
Distillation: Epoch : 38, Loss : 1.439486, Accuracy: 0.944000, Test accuracy: 0.955700
Distillation: Epoch : 39, Loss : 1.437099, Accuracy: 0.945000, Test accuracy: 0.957300
Distillation: Epoch : 40, Loss : 1.404373, Accuracy: 0.953000, Test accuracy: 0.957300
Distillation: Epoch : 41, Loss : 1.433668, Accuracy: 0.962000, Test accuracy: 0.956900
Distillation: Epoch : 42, Loss : 1.447922, Accuracy: 0.945000, Test accuracy: 0.957600
Distillation: Epoch : 43, Loss : 1.427523, Accuracy: 0.970000, Test accuracy: 0.957800
Distillation: Epoch : 44, Loss : 1.431846, Accuracy: 0.951000, Test accuracy: 0.958400
Distillation: Epoch : 45, Loss : 1.436474, Accuracy: 0.955000, Test accuracy: 0.958200
Distillation: Epoch : 46, Loss : 1.425423, Accuracy: 0.963000, Test accuracy: 0.959500
Distillation: Epoch : 47, Loss : 1.426729, Accuracy: 0.947000, Test accuracy: 0.959900
Distillation: Epoch : 48, Loss : 1.425996, Accuracy: 0.954000, Test accuracy: 0.961100
Distillation: Epoch : 49, Loss : 1.442582, Accuracy: 0.941000, Test accuracy: 0.961800
Distillation: Epoch : 50, Loss : 1.423010, Accuracy: 0.956000, Test accuracy: 0.961500
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9615
Generating confusion matrix for student2
[[ 963.    0.    1.    0.    1.    2.    8.    2.    6.    4.]
 [   0. 1120.    3.    0.    1.    0.    2.   11.    4.    6.]
 [   2.    4.  989.    7.    4.    1.    0.   19.    7.    1.]
 [   1.    1.   10.  988.    1.   15.    0.    7.   14.   15.]
 [   0.    0.    5.    1.  946.    0.    7.    3.    7.   15.]
 [   0.    0.    0.    5.    1.  861.    5.    1.    7.    7.]
 [   9.    4.    2.    0.    6.    3.  934.    0.    8.    2.]
 [   1.    0.    8.    6.    4.    2.    0.  967.    9.   14.]
 [   4.    6.   13.    2.    4.    5.    2.    3.  906.    4.]
 [   0.    0.    1.    1.   14.    3.    0.   15.    6.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.119931, Accuracy: 0.626000, Test accuracy: 0.638000
Distillation: Epoch : 2, Loss : 1.886225, Accuracy: 0.815000, Test accuracy: 0.819900
Distillation: Epoch : 3, Loss : 1.829011, Accuracy: 0.840000, Test accuracy: 0.853000
Distillation: Epoch : 4, Loss : 1.813117, Accuracy: 0.855000, Test accuracy: 0.871000
Distillation: Epoch : 5, Loss : 1.809172, Accuracy: 0.860000, Test accuracy: 0.882300
Distillation: Epoch : 6, Loss : 1.791260, Accuracy: 0.893000, Test accuracy: 0.887800
Distillation: Epoch : 7, Loss : 1.784620, Accuracy: 0.890000, Test accuracy: 0.895700
Distillation: Epoch : 8, Loss : 1.794102, Accuracy: 0.884000, Test accuracy: 0.899500
Distillation: Epoch : 9, Loss : 1.767894, Accuracy: 0.896000, Test accuracy: 0.905500
Distillation: Epoch : 10, Loss : 1.763740, Accuracy: 0.905000, Test accuracy: 0.909200
Distillation: Epoch : 11, Loss : 1.749650, Accuracy: 0.907000, Test accuracy: 0.913200
Distillation: Epoch : 12, Loss : 1.753497, Accuracy: 0.911000, Test accuracy: 0.917700
Distillation: Epoch : 13, Loss : 1.749366, Accuracy: 0.915000, Test accuracy: 0.922100
Distillation: Epoch : 14, Loss : 1.750041, Accuracy: 0.910000, Test accuracy: 0.926600
Distillation: Epoch : 15, Loss : 1.751779, Accuracy: 0.913000, Test accuracy: 0.929500
Distillation: Epoch : 16, Loss : 1.743606, Accuracy: 0.924000, Test accuracy: 0.930900
Distillation: Epoch : 17, Loss : 1.742910, Accuracy: 0.921000, Test accuracy: 0.932800
Distillation: Epoch : 18, Loss : 1.757392, Accuracy: 0.931000, Test accuracy: 0.934600
Distillation: Epoch : 19, Loss : 1.727043, Accuracy: 0.935000, Test accuracy: 0.937400
Distillation: Epoch : 20, Loss : 1.745546, Accuracy: 0.936000, Test accuracy: 0.938900
Distillation: Epoch : 21, Loss : 1.731462, Accuracy: 0.930000, Test accuracy: 0.941000
Distillation: Epoch : 22, Loss : 1.728333, Accuracy: 0.936000, Test accuracy: 0.942100
Distillation: Epoch : 23, Loss : 1.737550, Accuracy: 0.930000, Test accuracy: 0.943100
Distillation: Epoch : 24, Loss : 1.730729, Accuracy: 0.929000, Test accuracy: 0.944500
Distillation: Epoch : 25, Loss : 1.729435, Accuracy: 0.942000, Test accuracy: 0.945100
Distillation: Epoch : 26, Loss : 1.732180, Accuracy: 0.933000, Test accuracy: 0.947300
Distillation: Epoch : 27, Loss : 1.711447, Accuracy: 0.952000, Test accuracy: 0.948400
Distillation: Epoch : 28, Loss : 1.721493, Accuracy: 0.945000, Test accuracy: 0.949700
Distillation: Epoch : 29, Loss : 1.730297, Accuracy: 0.946000, Test accuracy: 0.950600
Distillation: Epoch : 30, Loss : 1.703232, Accuracy: 0.947000, Test accuracy: 0.951100
Distillation: Epoch : 31, Loss : 1.708419, Accuracy: 0.945000, Test accuracy: 0.951800
Distillation: Epoch : 32, Loss : 1.725858, Accuracy: 0.947000, Test accuracy: 0.952300
Distillation: Epoch : 33, Loss : 1.729849, Accuracy: 0.945000, Test accuracy: 0.953000
Distillation: Epoch : 34, Loss : 1.726985, Accuracy: 0.948000, Test accuracy: 0.954600
Distillation: Epoch : 35, Loss : 1.727478, Accuracy: 0.944000, Test accuracy: 0.955700
Distillation: Epoch : 36, Loss : 1.723643, Accuracy: 0.954000, Test accuracy: 0.955700
Distillation: Epoch : 37, Loss : 1.714574, Accuracy: 0.953000, Test accuracy: 0.956500
Distillation: Epoch : 38, Loss : 1.740101, Accuracy: 0.943000, Test accuracy: 0.956900
Distillation: Epoch : 39, Loss : 1.717449, Accuracy: 0.954000, Test accuracy: 0.958100
Distillation: Epoch : 40, Loss : 1.712143, Accuracy: 0.956000, Test accuracy: 0.958900
Distillation: Epoch : 41, Loss : 1.689013, Accuracy: 0.964000, Test accuracy: 0.958600
Distillation: Epoch : 42, Loss : 1.718206, Accuracy: 0.949000, Test accuracy: 0.959500
Distillation: Epoch : 43, Loss : 1.701446, Accuracy: 0.951000, Test accuracy: 0.959400
Distillation: Epoch : 44, Loss : 1.713515, Accuracy: 0.951000, Test accuracy: 0.959500
Distillation: Epoch : 45, Loss : 1.698268, Accuracy: 0.963000, Test accuracy: 0.960600
Distillation: Epoch : 46, Loss : 1.701089, Accuracy: 0.965000, Test accuracy: 0.959800
Distillation: Epoch : 47, Loss : 1.700476, Accuracy: 0.957000, Test accuracy: 0.960600
Distillation: Epoch : 48, Loss : 1.708827, Accuracy: 0.965000, Test accuracy: 0.960800
Distillation: Epoch : 49, Loss : 1.706515, Accuracy: 0.958000, Test accuracy: 0.961300
Distillation: Epoch : 50, Loss : 1.720765, Accuracy: 0.957000, Test accuracy: 0.961600
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.9616
Generating confusion matrix for student2
[[ 965.    0.    1.    0.    2.    2.    1.    0.    3.    4.]
 [   0. 1112.    3.    0.    0.    0.    2.    5.    2.    5.]
 [   4.    2.  990.    8.    5.    0.    1.   19.   13.    2.]
 [   0.    1.   12.  980.    0.   16.    0.   11.   18.   13.]
 [   0.    1.    3.    0.  936.    0.    3.    1.    4.    4.]
 [   3.    1.    0.    9.    0.  859.   15.    2.    5.    9.]
 [   6.    9.    4.    0.    7.    6.  935.    0.    5.    2.]
 [   1.    0.    5.    7.    3.    0.    0.  982.    4.   17.]
 [   1.    9.   14.    6.    4.    7.    1.    2.  912.    8.]
 [   0.    0.    0.    0.   25.    2.    0.    6.    8.  945.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.173868, Accuracy: 0.703000, Test accuracy: 0.703300
Distillation: Epoch : 2, Loss : 2.070123, Accuracy: 0.814000, Test accuracy: 0.825400
Distillation: Epoch : 3, Loss : 2.048915, Accuracy: 0.829000, Test accuracy: 0.853100
Distillation: Epoch : 4, Loss : 2.050114, Accuracy: 0.855000, Test accuracy: 0.861800
Distillation: Epoch : 5, Loss : 2.040034, Accuracy: 0.869000, Test accuracy: 0.869600
Distillation: Epoch : 6, Loss : 2.032594, Accuracy: 0.867000, Test accuracy: 0.877700
Distillation: Epoch : 7, Loss : 2.026743, Accuracy: 0.886000, Test accuracy: 0.883300
Distillation: Epoch : 8, Loss : 2.025044, Accuracy: 0.858000, Test accuracy: 0.888900
Distillation: Epoch : 9, Loss : 2.020422, Accuracy: 0.866000, Test accuracy: 0.893500
Distillation: Epoch : 10, Loss : 2.037026, Accuracy: 0.876000, Test accuracy: 0.897700
Distillation: Epoch : 11, Loss : 2.017660, Accuracy: 0.887000, Test accuracy: 0.902100
Distillation: Epoch : 12, Loss : 2.024441, Accuracy: 0.902000, Test accuracy: 0.906400
Distillation: Epoch : 13, Loss : 2.010844, Accuracy: 0.903000, Test accuracy: 0.911700
Distillation: Epoch : 14, Loss : 2.002282, Accuracy: 0.913000, Test accuracy: 0.915100
Distillation: Epoch : 15, Loss : 2.005500, Accuracy: 0.902000, Test accuracy: 0.918800
Distillation: Epoch : 16, Loss : 2.010500, Accuracy: 0.909000, Test accuracy: 0.922700
Distillation: Epoch : 17, Loss : 2.001535, Accuracy: 0.928000, Test accuracy: 0.925600
Distillation: Epoch : 18, Loss : 2.002954, Accuracy: 0.917000, Test accuracy: 0.929200
Distillation: Epoch : 19, Loss : 1.995431, Accuracy: 0.938000, Test accuracy: 0.932600
Distillation: Epoch : 20, Loss : 1.996378, Accuracy: 0.933000, Test accuracy: 0.937200
Distillation: Epoch : 21, Loss : 1.987238, Accuracy: 0.935000, Test accuracy: 0.939000
Distillation: Epoch : 22, Loss : 1.995274, Accuracy: 0.932000, Test accuracy: 0.940600
Distillation: Epoch : 23, Loss : 1.987573, Accuracy: 0.931000, Test accuracy: 0.943000
Distillation: Epoch : 24, Loss : 1.983228, Accuracy: 0.934000, Test accuracy: 0.944600
Distillation: Epoch : 25, Loss : 1.995255, Accuracy: 0.940000, Test accuracy: 0.946700
Distillation: Epoch : 26, Loss : 1.979200, Accuracy: 0.950000, Test accuracy: 0.950000
Distillation: Epoch : 27, Loss : 1.980854, Accuracy: 0.947000, Test accuracy: 0.950900
Distillation: Epoch : 28, Loss : 1.973848, Accuracy: 0.940000, Test accuracy: 0.953100
Distillation: Epoch : 29, Loss : 1.983057, Accuracy: 0.953000, Test accuracy: 0.954200
Distillation: Epoch : 30, Loss : 1.988744, Accuracy: 0.953000, Test accuracy: 0.954800
Distillation: Epoch : 31, Loss : 1.967586, Accuracy: 0.959000, Test accuracy: 0.956000
Distillation: Epoch : 32, Loss : 1.975785, Accuracy: 0.954000, Test accuracy: 0.956700
Distillation: Epoch : 33, Loss : 1.985405, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 34, Loss : 1.972817, Accuracy: 0.949000, Test accuracy: 0.958000
Distillation: Epoch : 35, Loss : 1.981969, Accuracy: 0.955000, Test accuracy: 0.959600
Distillation: Epoch : 36, Loss : 1.984911, Accuracy: 0.961000, Test accuracy: 0.960100
Distillation: Epoch : 37, Loss : 1.967247, Accuracy: 0.960000, Test accuracy: 0.960700
Distillation: Epoch : 38, Loss : 1.974896, Accuracy: 0.955000, Test accuracy: 0.961700
Distillation: Epoch : 39, Loss : 1.969608, Accuracy: 0.949000, Test accuracy: 0.962100
Distillation: Epoch : 40, Loss : 1.974987, Accuracy: 0.960000, Test accuracy: 0.962600
Distillation: Epoch : 41, Loss : 1.966427, Accuracy: 0.961000, Test accuracy: 0.962700
Distillation: Epoch : 42, Loss : 1.965433, Accuracy: 0.965000, Test accuracy: 0.962900
Distillation: Epoch : 43, Loss : 1.982863, Accuracy: 0.954000, Test accuracy: 0.964100
Distillation: Epoch : 44, Loss : 1.980430, Accuracy: 0.961000, Test accuracy: 0.963600
Distillation: Epoch : 45, Loss : 1.976318, Accuracy: 0.960000, Test accuracy: 0.964400
Distillation: Epoch : 46, Loss : 1.967252, Accuracy: 0.956000, Test accuracy: 0.964300
Distillation: Epoch : 47, Loss : 1.963605, Accuracy: 0.971000, Test accuracy: 0.964700
Distillation: Epoch : 48, Loss : 1.973323, Accuracy: 0.963000, Test accuracy: 0.964800
Distillation: Epoch : 49, Loss : 1.971319, Accuracy: 0.966000, Test accuracy: 0.965400
Distillation: Epoch : 50, Loss : 1.975177, Accuracy: 0.960000, Test accuracy: 0.965000
Saving to student2/student2.ckpt
<confusion_matrix>
results for %s distillate with T = %d student2 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student2/student2.ckpt
Accuracy on the test set
0.965
Generating confusion matrix for student2
[[ 964.    0.    1.    0.    0.    1.    5.    0.    6.    4.]
 [   0. 1124.    6.    1.    0.    0.    2.   12.    3.    6.]
 [   0.    1.  993.    3.    2.    1.    0.   23.   11.    1.]
 [   1.    3.    4.  991.    0.   12.    0.    6.   15.    9.]
 [   0.    0.    4.    0.  941.    0.    2.    2.    4.   13.]
 [   2.    0.    0.    5.    0.  865.    8.    1.    6.    6.]
 [   7.    4.    2.    0.   13.    5.  940.    0.    6.    1.]
 [   1.    1.    6.    7.    4.    2.    0.  967.    4.    8.]
 [   5.    2.   15.    2.    4.    5.    1.    2.  909.    5.]
 [   0.    0.    1.    1.   18.    1.    0.   15.   10.  956.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 0.805579, Accuracy: 0.804000, Test accuracy: 0.809700
Distillation: Epoch : 2, Loss : 0.437839, Accuracy: 0.894000, Test accuracy: 0.874700
Distillation: Epoch : 3, Loss : 0.365257, Accuracy: 0.899000, Test accuracy: 0.892000
Distillation: Epoch : 4, Loss : 0.388029, Accuracy: 0.886000, Test accuracy: 0.901900
Distillation: Epoch : 5, Loss : 0.339337, Accuracy: 0.895000, Test accuracy: 0.907900
Distillation: Epoch : 6, Loss : 0.368200, Accuracy: 0.880000, Test accuracy: 0.912900
Distillation: Epoch : 7, Loss : 0.291863, Accuracy: 0.908000, Test accuracy: 0.917400
Distillation: Epoch : 8, Loss : 0.276802, Accuracy: 0.914000, Test accuracy: 0.919900
Distillation: Epoch : 9, Loss : 0.278331, Accuracy: 0.923000, Test accuracy: 0.923000
Distillation: Epoch : 10, Loss : 0.236019, Accuracy: 0.928000, Test accuracy: 0.924700
Distillation: Epoch : 11, Loss : 0.328681, Accuracy: 0.913000, Test accuracy: 0.926600
Distillation: Epoch : 12, Loss : 0.242509, Accuracy: 0.928000, Test accuracy: 0.929900
Distillation: Epoch : 13, Loss : 0.265410, Accuracy: 0.921000, Test accuracy: 0.931300
Distillation: Epoch : 14, Loss : 0.229670, Accuracy: 0.933000, Test accuracy: 0.933200
Distillation: Epoch : 15, Loss : 0.210120, Accuracy: 0.940000, Test accuracy: 0.935700
Distillation: Epoch : 16, Loss : 0.202792, Accuracy: 0.935000, Test accuracy: 0.936800
Distillation: Epoch : 17, Loss : 0.195514, Accuracy: 0.940000, Test accuracy: 0.938200
Distillation: Epoch : 18, Loss : 0.220631, Accuracy: 0.938000, Test accuracy: 0.940000
Distillation: Epoch : 19, Loss : 0.209150, Accuracy: 0.949000, Test accuracy: 0.941200
Distillation: Epoch : 20, Loss : 0.202052, Accuracy: 0.943000, Test accuracy: 0.942600
Distillation: Epoch : 21, Loss : 0.173317, Accuracy: 0.943000, Test accuracy: 0.944500
Distillation: Epoch : 22, Loss : 0.163540, Accuracy: 0.956000, Test accuracy: 0.944800
Distillation: Epoch : 23, Loss : 0.162018, Accuracy: 0.958000, Test accuracy: 0.946500
Distillation: Epoch : 24, Loss : 0.172078, Accuracy: 0.944000, Test accuracy: 0.947900
Distillation: Epoch : 25, Loss : 0.166525, Accuracy: 0.950000, Test accuracy: 0.948500
Distillation: Epoch : 26, Loss : 0.180577, Accuracy: 0.948000, Test accuracy: 0.949600
Distillation: Epoch : 27, Loss : 0.183693, Accuracy: 0.955000, Test accuracy: 0.950000
Distillation: Epoch : 28, Loss : 0.181960, Accuracy: 0.953000, Test accuracy: 0.950200
Distillation: Epoch : 29, Loss : 0.153892, Accuracy: 0.961000, Test accuracy: 0.951100
Distillation: Epoch : 30, Loss : 0.208672, Accuracy: 0.951000, Test accuracy: 0.952300
Distillation: Epoch : 31, Loss : 0.149913, Accuracy: 0.959000, Test accuracy: 0.952500
Distillation: Epoch : 32, Loss : 0.155991, Accuracy: 0.948000, Test accuracy: 0.953300
Distillation: Epoch : 33, Loss : 0.149940, Accuracy: 0.953000, Test accuracy: 0.952700
Distillation: Epoch : 34, Loss : 0.155886, Accuracy: 0.954000, Test accuracy: 0.954700
Distillation: Epoch : 35, Loss : 0.151547, Accuracy: 0.952000, Test accuracy: 0.954100
Distillation: Epoch : 36, Loss : 0.150151, Accuracy: 0.960000, Test accuracy: 0.955200
Distillation: Epoch : 37, Loss : 0.154849, Accuracy: 0.958000, Test accuracy: 0.955100
Distillation: Epoch : 38, Loss : 0.130962, Accuracy: 0.960000, Test accuracy: 0.955600
Distillation: Epoch : 39, Loss : 0.180398, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 40, Loss : 0.122889, Accuracy: 0.966000, Test accuracy: 0.955900
Distillation: Epoch : 41, Loss : 0.127932, Accuracy: 0.964000, Test accuracy: 0.956800
Distillation: Epoch : 42, Loss : 0.173341, Accuracy: 0.950000, Test accuracy: 0.956900
Distillation: Epoch : 43, Loss : 0.120520, Accuracy: 0.966000, Test accuracy: 0.958100
Distillation: Epoch : 44, Loss : 0.114758, Accuracy: 0.963000, Test accuracy: 0.958700
Distillation: Epoch : 45, Loss : 0.126781, Accuracy: 0.962000, Test accuracy: 0.957800
Distillation: Epoch : 46, Loss : 0.160323, Accuracy: 0.948000, Test accuracy: 0.958700
Distillation: Epoch : 47, Loss : 0.127593, Accuracy: 0.964000, Test accuracy: 0.957600
Distillation: Epoch : 48, Loss : 0.138527, Accuracy: 0.957000, Test accuracy: 0.959100
Distillation: Epoch : 49, Loss : 0.145460, Accuracy: 0.959000, Test accuracy: 0.959700
Distillation: Epoch : 50, Loss : 0.150165, Accuracy: 0.966000, Test accuracy: 0.960200
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9602
Generating confusion matrix for student3
[[ 970.    0.    3.    2.    1.    5.    6.    3.    8.    3.]
 [   0. 1116.    2.    0.    1.    1.    3.    4.    2.    5.]
 [   1.    3.  996.   11.    4.    1.    4.   21.    7.    1.]
 [   1.    3.    6.  966.    0.    7.    1.    4.   13.    4.]
 [   0.    0.    6.    0.  956.    0.    6.    6.    5.   25.]
 [   3.    1.    0.   10.    0.  856.    7.    1.    6.   13.]
 [   2.    2.    1.    0.    5.    8.  925.    0.    4.    1.]
 [   2.    0.    8.    7.    5.    4.    1.  970.   10.   15.]
 [   1.   10.    9.    9.    2.    9.    5.    3.  916.   11.]
 [   0.    0.    1.    5.    8.    1.    0.   16.    3.  931.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.479909, Accuracy: 0.768000, Test accuracy: 0.771000
Distillation: Epoch : 2, Loss : 0.725815, Accuracy: 0.847000, Test accuracy: 0.852200
Distillation: Epoch : 3, Loss : 0.534399, Accuracy: 0.867000, Test accuracy: 0.879400
Distillation: Epoch : 4, Loss : 0.448530, Accuracy: 0.877000, Test accuracy: 0.895200
Distillation: Epoch : 5, Loss : 0.379634, Accuracy: 0.883000, Test accuracy: 0.903600
Distillation: Epoch : 6, Loss : 0.350526, Accuracy: 0.904000, Test accuracy: 0.908900
Distillation: Epoch : 7, Loss : 0.358507, Accuracy: 0.898000, Test accuracy: 0.913100
Distillation: Epoch : 8, Loss : 0.294570, Accuracy: 0.917000, Test accuracy: 0.919400
Distillation: Epoch : 9, Loss : 0.299070, Accuracy: 0.913000, Test accuracy: 0.924100
Distillation: Epoch : 10, Loss : 0.269381, Accuracy: 0.925000, Test accuracy: 0.927200
Distillation: Epoch : 11, Loss : 0.260978, Accuracy: 0.927000, Test accuracy: 0.931400
Distillation: Epoch : 12, Loss : 0.276508, Accuracy: 0.927000, Test accuracy: 0.934700
Distillation: Epoch : 13, Loss : 0.248108, Accuracy: 0.934000, Test accuracy: 0.937000
Distillation: Epoch : 14, Loss : 0.240502, Accuracy: 0.932000, Test accuracy: 0.939600
Distillation: Epoch : 15, Loss : 0.234450, Accuracy: 0.934000, Test accuracy: 0.941700
Distillation: Epoch : 16, Loss : 0.249162, Accuracy: 0.930000, Test accuracy: 0.944100
Distillation: Epoch : 17, Loss : 0.228178, Accuracy: 0.945000, Test accuracy: 0.945800
Distillation: Epoch : 18, Loss : 0.217976, Accuracy: 0.943000, Test accuracy: 0.947200
Distillation: Epoch : 19, Loss : 0.254929, Accuracy: 0.930000, Test accuracy: 0.948500
Distillation: Epoch : 20, Loss : 0.233445, Accuracy: 0.935000, Test accuracy: 0.950600
Distillation: Epoch : 21, Loss : 0.191428, Accuracy: 0.955000, Test accuracy: 0.950400
Distillation: Epoch : 22, Loss : 0.226159, Accuracy: 0.937000, Test accuracy: 0.952200
Distillation: Epoch : 23, Loss : 0.223051, Accuracy: 0.938000, Test accuracy: 0.952800
Distillation: Epoch : 24, Loss : 0.215131, Accuracy: 0.933000, Test accuracy: 0.953700
Distillation: Epoch : 25, Loss : 0.179597, Accuracy: 0.960000, Test accuracy: 0.954100
Distillation: Epoch : 26, Loss : 0.200784, Accuracy: 0.948000, Test accuracy: 0.954700
Distillation: Epoch : 27, Loss : 0.217326, Accuracy: 0.945000, Test accuracy: 0.954800
Distillation: Epoch : 28, Loss : 0.191309, Accuracy: 0.949000, Test accuracy: 0.956000
Distillation: Epoch : 29, Loss : 0.188455, Accuracy: 0.948000, Test accuracy: 0.956400
Distillation: Epoch : 30, Loss : 0.154657, Accuracy: 0.961000, Test accuracy: 0.956900
Distillation: Epoch : 31, Loss : 0.179529, Accuracy: 0.947000, Test accuracy: 0.957700
Distillation: Epoch : 32, Loss : 0.180026, Accuracy: 0.950000, Test accuracy: 0.958100
Distillation: Epoch : 33, Loss : 0.205992, Accuracy: 0.950000, Test accuracy: 0.957800
Distillation: Epoch : 34, Loss : 0.190462, Accuracy: 0.948000, Test accuracy: 0.958700
Distillation: Epoch : 35, Loss : 0.162540, Accuracy: 0.954000, Test accuracy: 0.959100
Distillation: Epoch : 36, Loss : 0.188399, Accuracy: 0.954000, Test accuracy: 0.958200
Distillation: Epoch : 37, Loss : 0.204546, Accuracy: 0.949000, Test accuracy: 0.958900
Distillation: Epoch : 38, Loss : 0.156060, Accuracy: 0.959000, Test accuracy: 0.959000
Distillation: Epoch : 39, Loss : 0.164404, Accuracy: 0.963000, Test accuracy: 0.959600
Distillation: Epoch : 40, Loss : 0.165075, Accuracy: 0.957000, Test accuracy: 0.960600
Distillation: Epoch : 41, Loss : 0.167161, Accuracy: 0.961000, Test accuracy: 0.960300
Distillation: Epoch : 42, Loss : 0.200903, Accuracy: 0.946000, Test accuracy: 0.960100
Distillation: Epoch : 43, Loss : 0.166224, Accuracy: 0.964000, Test accuracy: 0.960200
Distillation: Epoch : 44, Loss : 0.188365, Accuracy: 0.954000, Test accuracy: 0.960900
Distillation: Epoch : 45, Loss : 0.159889, Accuracy: 0.955000, Test accuracy: 0.960800
Distillation: Epoch : 46, Loss : 0.170421, Accuracy: 0.955000, Test accuracy: 0.961500
Distillation: Epoch : 47, Loss : 0.160804, Accuracy: 0.956000, Test accuracy: 0.961800
Distillation: Epoch : 48, Loss : 0.153213, Accuracy: 0.963000, Test accuracy: 0.962300
Distillation: Epoch : 49, Loss : 0.155803, Accuracy: 0.960000, Test accuracy: 0.961600
Distillation: Epoch : 50, Loss : 0.183227, Accuracy: 0.956000, Test accuracy: 0.961500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9615
Generating confusion matrix for student3
[[ 969.    0.    1.    1.    2.    5.    9.    1.    7.    6.]
 [   0. 1121.    5.    0.    1.    1.    3.    5.    5.    8.]
 [   1.    3.  986.    8.    3.    0.    1.   19.   12.    2.]
 [   0.    1.    5.  979.    2.   17.    0.    8.   10.   11.]
 [   0.    0.    4.    1.  952.    1.    2.    1.    7.   15.]
 [   0.    1.    1.   10.    0.  848.    8.    1.    7.    8.]
 [   5.    3.    5.    0.    3.    7.  934.    0.    4.    1.]
 [   3.    0.    8.    6.    2.    2.    0.  973.    6.    8.]
 [   2.    6.   15.    4.    3.    7.    1.    4.  909.    6.]
 [   0.    0.    2.    1.   14.    4.    0.   16.    7.  944.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.573296, Accuracy: 0.747000, Test accuracy: 0.758400
Distillation: Epoch : 2, Loss : 1.009217, Accuracy: 0.798000, Test accuracy: 0.831900
Distillation: Epoch : 3, Loss : 0.823831, Accuracy: 0.844000, Test accuracy: 0.863800
Distillation: Epoch : 4, Loss : 0.722317, Accuracy: 0.878000, Test accuracy: 0.880400
Distillation: Epoch : 5, Loss : 0.703483, Accuracy: 0.874000, Test accuracy: 0.886700
Distillation: Epoch : 6, Loss : 0.675509, Accuracy: 0.891000, Test accuracy: 0.894600
Distillation: Epoch : 7, Loss : 0.693942, Accuracy: 0.890000, Test accuracy: 0.900800
Distillation: Epoch : 8, Loss : 0.677686, Accuracy: 0.894000, Test accuracy: 0.904200
Distillation: Epoch : 9, Loss : 0.673291, Accuracy: 0.895000, Test accuracy: 0.908500
Distillation: Epoch : 10, Loss : 0.647716, Accuracy: 0.895000, Test accuracy: 0.909100
Distillation: Epoch : 11, Loss : 0.667861, Accuracy: 0.881000, Test accuracy: 0.911200
Distillation: Epoch : 12, Loss : 0.626914, Accuracy: 0.892000, Test accuracy: 0.913200
Distillation: Epoch : 13, Loss : 0.644820, Accuracy: 0.901000, Test accuracy: 0.913100
Distillation: Epoch : 14, Loss : 0.643160, Accuracy: 0.897000, Test accuracy: 0.913200
Distillation: Epoch : 15, Loss : 0.617743, Accuracy: 0.911000, Test accuracy: 0.915400
Distillation: Epoch : 16, Loss : 0.647112, Accuracy: 0.901000, Test accuracy: 0.916700
Distillation: Epoch : 17, Loss : 0.604873, Accuracy: 0.907000, Test accuracy: 0.916400
Distillation: Epoch : 18, Loss : 0.611532, Accuracy: 0.916000, Test accuracy: 0.917600
Distillation: Epoch : 19, Loss : 0.594664, Accuracy: 0.920000, Test accuracy: 0.919200
Distillation: Epoch : 20, Loss : 0.610577, Accuracy: 0.923000, Test accuracy: 0.919300
Distillation: Epoch : 21, Loss : 0.590738, Accuracy: 0.917000, Test accuracy: 0.920700
Distillation: Epoch : 22, Loss : 0.640343, Accuracy: 0.907000, Test accuracy: 0.921400
Distillation: Epoch : 23, Loss : 0.578176, Accuracy: 0.917000, Test accuracy: 0.922700
Distillation: Epoch : 24, Loss : 0.607783, Accuracy: 0.921000, Test accuracy: 0.923100
Distillation: Epoch : 25, Loss : 0.573442, Accuracy: 0.920000, Test accuracy: 0.925300
Distillation: Epoch : 26, Loss : 0.557980, Accuracy: 0.930000, Test accuracy: 0.924900
Distillation: Epoch : 27, Loss : 0.603269, Accuracy: 0.916000, Test accuracy: 0.926300
Distillation: Epoch : 28, Loss : 0.597582, Accuracy: 0.917000, Test accuracy: 0.927400
Distillation: Epoch : 29, Loss : 0.578665, Accuracy: 0.923000, Test accuracy: 0.928200
Distillation: Epoch : 30, Loss : 0.602003, Accuracy: 0.915000, Test accuracy: 0.928400
Distillation: Epoch : 31, Loss : 0.583960, Accuracy: 0.931000, Test accuracy: 0.929400
Distillation: Epoch : 32, Loss : 0.567993, Accuracy: 0.925000, Test accuracy: 0.929800
Distillation: Epoch : 33, Loss : 0.571770, Accuracy: 0.913000, Test accuracy: 0.931100
Distillation: Epoch : 34, Loss : 0.564162, Accuracy: 0.932000, Test accuracy: 0.931600
Distillation: Epoch : 35, Loss : 0.592854, Accuracy: 0.916000, Test accuracy: 0.933300
Distillation: Epoch : 36, Loss : 0.563757, Accuracy: 0.929000, Test accuracy: 0.932200
Distillation: Epoch : 37, Loss : 0.554474, Accuracy: 0.927000, Test accuracy: 0.934600
Distillation: Epoch : 38, Loss : 0.589965, Accuracy: 0.926000, Test accuracy: 0.934900
Distillation: Epoch : 39, Loss : 0.559865, Accuracy: 0.932000, Test accuracy: 0.936900
Distillation: Epoch : 40, Loss : 0.552175, Accuracy: 0.933000, Test accuracy: 0.936200
Distillation: Epoch : 41, Loss : 0.525481, Accuracy: 0.946000, Test accuracy: 0.937000
Distillation: Epoch : 42, Loss : 0.563409, Accuracy: 0.929000, Test accuracy: 0.938000
Distillation: Epoch : 43, Loss : 0.555945, Accuracy: 0.936000, Test accuracy: 0.939000
Distillation: Epoch : 44, Loss : 0.528402, Accuracy: 0.942000, Test accuracy: 0.938100
Distillation: Epoch : 45, Loss : 0.545073, Accuracy: 0.935000, Test accuracy: 0.939100
Distillation: Epoch : 46, Loss : 0.531226, Accuracy: 0.934000, Test accuracy: 0.940200
Distillation: Epoch : 47, Loss : 0.587225, Accuracy: 0.914000, Test accuracy: 0.940800
Distillation: Epoch : 48, Loss : 0.530014, Accuracy: 0.932000, Test accuracy: 0.942400
Distillation: Epoch : 49, Loss : 0.527189, Accuracy: 0.938000, Test accuracy: 0.941700
Distillation: Epoch : 50, Loss : 0.534086, Accuracy: 0.936000, Test accuracy: 0.942500
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9425
Generating confusion matrix for student3
[[ 957.    0.    4.    0.    0.    6.    3.    0.    6.    6.]
 [   0. 1109.    4.    0.    3.    2.    3.   13.    6.    6.]
 [   1.    3.  965.    8.    8.    1.    5.   22.    4.    1.]
 [   4.    3.   12.  968.    0.   23.    4.    7.   21.   13.]
 [   0.    0.    5.    2.  919.    4.    7.    6.    9.   28.]
 [   2.    2.    0.   10.    1.  820.   13.    0.   10.    5.]
 [  13.    4.    9.    3.   10.   14.  920.    0.    8.    1.]
 [   1.    2.    7.    6.    3.    1.    1.  949.    5.   20.]
 [   1.   12.   22.   11.    7.   18.    2.    0.  899.   10.]
 [   1.    0.    4.    2.   31.    3.    0.   31.    6.  919.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.666264, Accuracy: 0.731000, Test accuracy: 0.748400
Distillation: Epoch : 2, Loss : 1.090776, Accuracy: 0.803000, Test accuracy: 0.822400
Distillation: Epoch : 3, Loss : 0.974849, Accuracy: 0.850000, Test accuracy: 0.858400
Distillation: Epoch : 4, Loss : 0.918425, Accuracy: 0.863000, Test accuracy: 0.875600
Distillation: Epoch : 5, Loss : 0.863477, Accuracy: 0.889000, Test accuracy: 0.885500
Distillation: Epoch : 6, Loss : 0.901600, Accuracy: 0.870000, Test accuracy: 0.890800
Distillation: Epoch : 7, Loss : 0.831711, Accuracy: 0.894000, Test accuracy: 0.894100
Distillation: Epoch : 8, Loss : 0.859305, Accuracy: 0.874000, Test accuracy: 0.898500
Distillation: Epoch : 9, Loss : 0.828699, Accuracy: 0.884000, Test accuracy: 0.899200
Distillation: Epoch : 10, Loss : 0.848921, Accuracy: 0.871000, Test accuracy: 0.902300
Distillation: Epoch : 11, Loss : 0.831404, Accuracy: 0.882000, Test accuracy: 0.902500
Distillation: Epoch : 12, Loss : 0.765787, Accuracy: 0.909000, Test accuracy: 0.904900
Distillation: Epoch : 13, Loss : 0.789874, Accuracy: 0.899000, Test accuracy: 0.905900
Distillation: Epoch : 14, Loss : 0.843586, Accuracy: 0.888000, Test accuracy: 0.908800
Distillation: Epoch : 15, Loss : 0.783313, Accuracy: 0.906000, Test accuracy: 0.907700
Distillation: Epoch : 16, Loss : 0.827052, Accuracy: 0.896000, Test accuracy: 0.910000
Distillation: Epoch : 17, Loss : 0.786681, Accuracy: 0.920000, Test accuracy: 0.909900
Distillation: Epoch : 18, Loss : 0.769845, Accuracy: 0.904000, Test accuracy: 0.912400
Distillation: Epoch : 19, Loss : 0.758841, Accuracy: 0.912000, Test accuracy: 0.912500
Distillation: Epoch : 20, Loss : 0.787174, Accuracy: 0.903000, Test accuracy: 0.913200
Distillation: Epoch : 21, Loss : 0.802068, Accuracy: 0.906000, Test accuracy: 0.913200
Distillation: Epoch : 22, Loss : 0.764403, Accuracy: 0.905000, Test accuracy: 0.914800
Distillation: Epoch : 23, Loss : 0.756413, Accuracy: 0.904000, Test accuracy: 0.917200
Distillation: Epoch : 24, Loss : 0.770413, Accuracy: 0.907000, Test accuracy: 0.916800
Distillation: Epoch : 25, Loss : 0.758977, Accuracy: 0.916000, Test accuracy: 0.917800
Distillation: Epoch : 26, Loss : 0.744078, Accuracy: 0.927000, Test accuracy: 0.919500
Distillation: Epoch : 27, Loss : 0.742123, Accuracy: 0.935000, Test accuracy: 0.918700
Distillation: Epoch : 28, Loss : 0.770141, Accuracy: 0.923000, Test accuracy: 0.919400
Distillation: Epoch : 29, Loss : 0.774662, Accuracy: 0.920000, Test accuracy: 0.921300
Distillation: Epoch : 30, Loss : 0.793491, Accuracy: 0.901000, Test accuracy: 0.922500
Distillation: Epoch : 31, Loss : 0.768781, Accuracy: 0.916000, Test accuracy: 0.923000
Distillation: Epoch : 32, Loss : 0.734835, Accuracy: 0.927000, Test accuracy: 0.921800
Distillation: Epoch : 33, Loss : 0.732385, Accuracy: 0.937000, Test accuracy: 0.923400
Distillation: Epoch : 34, Loss : 0.769501, Accuracy: 0.896000, Test accuracy: 0.924800
Distillation: Epoch : 35, Loss : 0.745999, Accuracy: 0.915000, Test accuracy: 0.925800
Distillation: Epoch : 36, Loss : 0.740451, Accuracy: 0.913000, Test accuracy: 0.926600
Distillation: Epoch : 37, Loss : 0.740742, Accuracy: 0.934000, Test accuracy: 0.926700
Distillation: Epoch : 38, Loss : 0.730241, Accuracy: 0.932000, Test accuracy: 0.927600
Distillation: Epoch : 39, Loss : 0.735854, Accuracy: 0.933000, Test accuracy: 0.928500
Distillation: Epoch : 40, Loss : 0.721731, Accuracy: 0.925000, Test accuracy: 0.929100
Distillation: Epoch : 41, Loss : 0.748766, Accuracy: 0.911000, Test accuracy: 0.930700
Distillation: Epoch : 42, Loss : 0.729042, Accuracy: 0.926000, Test accuracy: 0.931800
Distillation: Epoch : 43, Loss : 0.751155, Accuracy: 0.933000, Test accuracy: 0.933800
Distillation: Epoch : 44, Loss : 0.717414, Accuracy: 0.926000, Test accuracy: 0.933600
Distillation: Epoch : 45, Loss : 0.731809, Accuracy: 0.926000, Test accuracy: 0.935200
Distillation: Epoch : 46, Loss : 0.698774, Accuracy: 0.934000, Test accuracy: 0.936100
Distillation: Epoch : 47, Loss : 0.768306, Accuracy: 0.910000, Test accuracy: 0.937300
Distillation: Epoch : 48, Loss : 0.700705, Accuracy: 0.940000, Test accuracy: 0.937400
Distillation: Epoch : 49, Loss : 0.706129, Accuracy: 0.935000, Test accuracy: 0.938000
Distillation: Epoch : 50, Loss : 0.667332, Accuracy: 0.943000, Test accuracy: 0.938600
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9386
Generating confusion matrix for student3
[[ 952.    0.    5.    3.    0.    6.    3.    0.    4.    6.]
 [   0. 1109.    8.    1.    4.    2.    3.   13.    4.    4.]
 [   1.    3.  943.   17.    8.    1.    4.   21.    8.    2.]
 [   3.    3.   14.  954.    0.   30.    1.    6.   21.   13.]
 [   1.    1.   14.    2.  920.    4.    6.    7.    9.   20.]
 [   2.    2.    1.   11.    0.  804.   12.    0.   16.    6.]
 [  13.    7.    7.    3.   12.   19.  927.    0.    7.    0.]
 [   2.    2.   14.    8.    2.    5.    1.  951.    4.   18.]
 [   5.    8.   21.    9.    6.   17.    1.    1.  894.    8.]
 [   1.    0.    5.    2.   30.    4.    0.   29.    7.  932.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.786511, Accuracy: 0.715000, Test accuracy: 0.722600
Distillation: Epoch : 2, Loss : 1.273138, Accuracy: 0.797000, Test accuracy: 0.813700
Distillation: Epoch : 3, Loss : 1.108541, Accuracy: 0.852000, Test accuracy: 0.855500
Distillation: Epoch : 4, Loss : 1.087698, Accuracy: 0.852000, Test accuracy: 0.871900
Distillation: Epoch : 5, Loss : 1.023308, Accuracy: 0.876000, Test accuracy: 0.884300
Distillation: Epoch : 6, Loss : 1.029188, Accuracy: 0.868000, Test accuracy: 0.889500
Distillation: Epoch : 7, Loss : 1.018617, Accuracy: 0.867000, Test accuracy: 0.894900
Distillation: Epoch : 8, Loss : 0.992089, Accuracy: 0.884000, Test accuracy: 0.896900
Distillation: Epoch : 9, Loss : 0.996956, Accuracy: 0.894000, Test accuracy: 0.899700
Distillation: Epoch : 10, Loss : 0.956885, Accuracy: 0.904000, Test accuracy: 0.902700
Distillation: Epoch : 11, Loss : 0.949298, Accuracy: 0.917000, Test accuracy: 0.902700
Distillation: Epoch : 12, Loss : 0.963444, Accuracy: 0.895000, Test accuracy: 0.905900
Distillation: Epoch : 13, Loss : 0.952598, Accuracy: 0.900000, Test accuracy: 0.907500
Distillation: Epoch : 14, Loss : 0.941738, Accuracy: 0.908000, Test accuracy: 0.909100
Distillation: Epoch : 15, Loss : 0.975116, Accuracy: 0.891000, Test accuracy: 0.910200
Distillation: Epoch : 16, Loss : 0.937233, Accuracy: 0.899000, Test accuracy: 0.912400
Distillation: Epoch : 17, Loss : 0.931539, Accuracy: 0.922000, Test accuracy: 0.912800
Distillation: Epoch : 18, Loss : 0.955409, Accuracy: 0.917000, Test accuracy: 0.915800
Distillation: Epoch : 19, Loss : 0.924997, Accuracy: 0.916000, Test accuracy: 0.914700
Distillation: Epoch : 20, Loss : 0.946547, Accuracy: 0.916000, Test accuracy: 0.917600
Distillation: Epoch : 21, Loss : 0.940237, Accuracy: 0.915000, Test accuracy: 0.919300
Distillation: Epoch : 22, Loss : 0.926850, Accuracy: 0.924000, Test accuracy: 0.921300
Distillation: Epoch : 23, Loss : 0.926285, Accuracy: 0.924000, Test accuracy: 0.922200
Distillation: Epoch : 24, Loss : 0.935664, Accuracy: 0.907000, Test accuracy: 0.924800
Distillation: Epoch : 25, Loss : 0.857500, Accuracy: 0.933000, Test accuracy: 0.926300
Distillation: Epoch : 26, Loss : 0.923739, Accuracy: 0.918000, Test accuracy: 0.928200
Distillation: Epoch : 27, Loss : 0.886468, Accuracy: 0.919000, Test accuracy: 0.930200
Distillation: Epoch : 28, Loss : 0.900995, Accuracy: 0.908000, Test accuracy: 0.931300
Distillation: Epoch : 29, Loss : 0.912054, Accuracy: 0.912000, Test accuracy: 0.932900
Distillation: Epoch : 30, Loss : 0.888770, Accuracy: 0.932000, Test accuracy: 0.934700
Distillation: Epoch : 31, Loss : 0.872716, Accuracy: 0.935000, Test accuracy: 0.936400
Distillation: Epoch : 32, Loss : 0.897697, Accuracy: 0.934000, Test accuracy: 0.939100
Distillation: Epoch : 33, Loss : 0.867988, Accuracy: 0.940000, Test accuracy: 0.939700
Distillation: Epoch : 34, Loss : 0.893152, Accuracy: 0.941000, Test accuracy: 0.941000
Distillation: Epoch : 35, Loss : 0.882296, Accuracy: 0.935000, Test accuracy: 0.942900
Distillation: Epoch : 36, Loss : 0.878163, Accuracy: 0.933000, Test accuracy: 0.944000
Distillation: Epoch : 37, Loss : 0.881176, Accuracy: 0.940000, Test accuracy: 0.945300
Distillation: Epoch : 38, Loss : 0.857268, Accuracy: 0.943000, Test accuracy: 0.947200
Distillation: Epoch : 39, Loss : 0.834340, Accuracy: 0.953000, Test accuracy: 0.948100
Distillation: Epoch : 40, Loss : 0.886734, Accuracy: 0.939000, Test accuracy: 0.948700
Distillation: Epoch : 41, Loss : 0.870778, Accuracy: 0.936000, Test accuracy: 0.949500
Distillation: Epoch : 42, Loss : 0.837530, Accuracy: 0.944000, Test accuracy: 0.950200
Distillation: Epoch : 43, Loss : 0.826717, Accuracy: 0.954000, Test accuracy: 0.950600
Distillation: Epoch : 44, Loss : 0.835623, Accuracy: 0.952000, Test accuracy: 0.951200
Distillation: Epoch : 45, Loss : 0.854466, Accuracy: 0.952000, Test accuracy: 0.951900
Distillation: Epoch : 46, Loss : 0.871668, Accuracy: 0.941000, Test accuracy: 0.952500
Distillation: Epoch : 47, Loss : 0.821336, Accuracy: 0.957000, Test accuracy: 0.953600
Distillation: Epoch : 48, Loss : 0.820134, Accuracy: 0.942000, Test accuracy: 0.953900
Distillation: Epoch : 49, Loss : 0.854730, Accuracy: 0.955000, Test accuracy: 0.954700
Distillation: Epoch : 50, Loss : 0.863761, Accuracy: 0.944000, Test accuracy: 0.955000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.955
Generating confusion matrix for student3
[[ 957.    0.    3.    0.    1.    1.    6.    3.    2.    4.]
 [   0. 1120.    4.    0.    2.    1.    2.    6.    6.    6.]
 [   3.    3.  975.    9.    3.    1.    1.   23.    9.    2.]
 [   0.    2.   11.  977.    0.   22.    0.    6.   17.   17.]
 [   1.    1.    4.    1.  942.    0.    6.    2.    7.   16.]
 [   1.    1.    1.    5.    0.  845.   10.    0.   12.    9.]
 [  11.    4.    3.    0.    8.    7.  932.    0.    6.    1.]
 [   2.    0.    5.    3.    4.    1.    0.  964.    6.   14.]
 [   4.    4.   22.   11.    4.   10.    1.    3.  900.    2.]
 [   1.    0.    4.    4.   18.    4.    0.   21.    9.  938.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.903597, Accuracy: 0.739000, Test accuracy: 0.726900
Distillation: Epoch : 2, Loss : 1.391610, Accuracy: 0.799000, Test accuracy: 0.817700
Distillation: Epoch : 3, Loss : 1.260049, Accuracy: 0.835000, Test accuracy: 0.853400
Distillation: Epoch : 4, Loss : 1.190219, Accuracy: 0.864000, Test accuracy: 0.873500
Distillation: Epoch : 5, Loss : 1.131079, Accuracy: 0.906000, Test accuracy: 0.884900
Distillation: Epoch : 6, Loss : 1.112466, Accuracy: 0.899000, Test accuracy: 0.893300
Distillation: Epoch : 7, Loss : 1.150675, Accuracy: 0.898000, Test accuracy: 0.897400
Distillation: Epoch : 8, Loss : 1.121001, Accuracy: 0.902000, Test accuracy: 0.899900
Distillation: Epoch : 9, Loss : 1.123659, Accuracy: 0.898000, Test accuracy: 0.905600
Distillation: Epoch : 10, Loss : 1.144734, Accuracy: 0.897000, Test accuracy: 0.909000
Distillation: Epoch : 11, Loss : 1.111647, Accuracy: 0.898000, Test accuracy: 0.912800
Distillation: Epoch : 12, Loss : 1.103962, Accuracy: 0.893000, Test accuracy: 0.916000
Distillation: Epoch : 13, Loss : 1.109177, Accuracy: 0.907000, Test accuracy: 0.918000
Distillation: Epoch : 14, Loss : 1.094798, Accuracy: 0.908000, Test accuracy: 0.920700
Distillation: Epoch : 15, Loss : 1.119297, Accuracy: 0.920000, Test accuracy: 0.923500
Distillation: Epoch : 16, Loss : 1.097527, Accuracy: 0.931000, Test accuracy: 0.925100
Distillation: Epoch : 17, Loss : 1.078817, Accuracy: 0.919000, Test accuracy: 0.928200
Distillation: Epoch : 18, Loss : 1.093422, Accuracy: 0.923000, Test accuracy: 0.930600
Distillation: Epoch : 19, Loss : 1.041911, Accuracy: 0.948000, Test accuracy: 0.932300
Distillation: Epoch : 20, Loss : 1.029953, Accuracy: 0.931000, Test accuracy: 0.934400
Distillation: Epoch : 21, Loss : 1.028672, Accuracy: 0.935000, Test accuracy: 0.935300
Distillation: Epoch : 22, Loss : 1.035657, Accuracy: 0.930000, Test accuracy: 0.936900
Distillation: Epoch : 23, Loss : 1.010342, Accuracy: 0.938000, Test accuracy: 0.938300
Distillation: Epoch : 24, Loss : 1.025642, Accuracy: 0.945000, Test accuracy: 0.939600
Distillation: Epoch : 25, Loss : 1.036205, Accuracy: 0.944000, Test accuracy: 0.941100
Distillation: Epoch : 26, Loss : 1.019668, Accuracy: 0.943000, Test accuracy: 0.942200
Distillation: Epoch : 27, Loss : 1.027127, Accuracy: 0.950000, Test accuracy: 0.945200
Distillation: Epoch : 28, Loss : 1.046205, Accuracy: 0.937000, Test accuracy: 0.945300
Distillation: Epoch : 29, Loss : 1.028600, Accuracy: 0.949000, Test accuracy: 0.946200
Distillation: Epoch : 30, Loss : 1.013541, Accuracy: 0.941000, Test accuracy: 0.947700
Distillation: Epoch : 31, Loss : 1.020122, Accuracy: 0.946000, Test accuracy: 0.949000
Distillation: Epoch : 32, Loss : 1.030898, Accuracy: 0.948000, Test accuracy: 0.948700
Distillation: Epoch : 33, Loss : 1.001552, Accuracy: 0.954000, Test accuracy: 0.950500
Distillation: Epoch : 34, Loss : 0.996531, Accuracy: 0.954000, Test accuracy: 0.951400
Distillation: Epoch : 35, Loss : 0.977348, Accuracy: 0.960000, Test accuracy: 0.951900
Distillation: Epoch : 36, Loss : 1.026124, Accuracy: 0.942000, Test accuracy: 0.952800
Distillation: Epoch : 37, Loss : 1.023828, Accuracy: 0.944000, Test accuracy: 0.952600
Distillation: Epoch : 38, Loss : 1.028802, Accuracy: 0.952000, Test accuracy: 0.954100
Distillation: Epoch : 39, Loss : 0.997817, Accuracy: 0.950000, Test accuracy: 0.954400
Distillation: Epoch : 40, Loss : 1.013607, Accuracy: 0.946000, Test accuracy: 0.954200
Distillation: Epoch : 41, Loss : 1.013767, Accuracy: 0.953000, Test accuracy: 0.955300
Distillation: Epoch : 42, Loss : 1.014003, Accuracy: 0.943000, Test accuracy: 0.955000
Distillation: Epoch : 43, Loss : 0.976860, Accuracy: 0.948000, Test accuracy: 0.956000
Distillation: Epoch : 44, Loss : 1.042677, Accuracy: 0.950000, Test accuracy: 0.956400
Distillation: Epoch : 45, Loss : 0.995614, Accuracy: 0.941000, Test accuracy: 0.955600
Distillation: Epoch : 46, Loss : 0.972569, Accuracy: 0.951000, Test accuracy: 0.956400
Distillation: Epoch : 47, Loss : 1.053352, Accuracy: 0.950000, Test accuracy: 0.957200
Distillation: Epoch : 48, Loss : 1.029081, Accuracy: 0.947000, Test accuracy: 0.957500
Distillation: Epoch : 49, Loss : 0.988884, Accuracy: 0.960000, Test accuracy: 0.957800
Distillation: Epoch : 50, Loss : 0.995890, Accuracy: 0.957000, Test accuracy: 0.957800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9578
Generating confusion matrix for student3
[[ 959.    0.    2.    0.    1.    2.    2.    2.    3.    3.]
 [   1. 1118.    6.    2.    2.    0.    2.   13.    4.    5.]
 [   3.    4.  981.    6.    1.    1.    2.   23.    8.    1.]
 [   1.    1.   12.  984.    0.   18.    0.    8.   15.   16.]
 [   1.    1.    6.    0.  943.    0.    6.    2.    7.   14.]
 [   1.    0.    0.    7.    1.  851.   10.    0.   10.    8.]
 [   9.    4.    2.    0.    9.    5.  935.    0.    7.    3.]
 [   1.    0.    6.    4.    4.    2.    0.  962.    7.   18.]
 [   4.    7.   14.    5.    4.    8.    1.    3.  908.    4.]
 [   0.    0.    3.    2.   17.    5.    0.   15.    5.  937.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.980774, Accuracy: 0.673000, Test accuracy: 0.688600
Distillation: Epoch : 2, Loss : 1.557477, Accuracy: 0.786000, Test accuracy: 0.828300
Distillation: Epoch : 3, Loss : 1.368599, Accuracy: 0.861000, Test accuracy: 0.861200
Distillation: Epoch : 4, Loss : 1.311581, Accuracy: 0.858000, Test accuracy: 0.880100
Distillation: Epoch : 5, Loss : 1.278626, Accuracy: 0.893000, Test accuracy: 0.893900
Distillation: Epoch : 6, Loss : 1.271688, Accuracy: 0.896000, Test accuracy: 0.905200
Distillation: Epoch : 7, Loss : 1.295648, Accuracy: 0.880000, Test accuracy: 0.911000
Distillation: Epoch : 8, Loss : 1.275339, Accuracy: 0.907000, Test accuracy: 0.915100
Distillation: Epoch : 9, Loss : 1.262290, Accuracy: 0.922000, Test accuracy: 0.918200
Distillation: Epoch : 10, Loss : 1.228503, Accuracy: 0.918000, Test accuracy: 0.922000
Distillation: Epoch : 11, Loss : 1.233132, Accuracy: 0.924000, Test accuracy: 0.924900
Distillation: Epoch : 12, Loss : 1.221598, Accuracy: 0.915000, Test accuracy: 0.927000
Distillation: Epoch : 13, Loss : 1.232730, Accuracy: 0.935000, Test accuracy: 0.929000
Distillation: Epoch : 14, Loss : 1.204267, Accuracy: 0.939000, Test accuracy: 0.932100
Distillation: Epoch : 15, Loss : 1.218855, Accuracy: 0.917000, Test accuracy: 0.934500
Distillation: Epoch : 16, Loss : 1.185445, Accuracy: 0.924000, Test accuracy: 0.936600
Distillation: Epoch : 17, Loss : 1.231282, Accuracy: 0.934000, Test accuracy: 0.938200
Distillation: Epoch : 18, Loss : 1.204857, Accuracy: 0.928000, Test accuracy: 0.940000
Distillation: Epoch : 19, Loss : 1.210965, Accuracy: 0.934000, Test accuracy: 0.941200
Distillation: Epoch : 20, Loss : 1.186966, Accuracy: 0.937000, Test accuracy: 0.942300
Distillation: Epoch : 21, Loss : 1.201260, Accuracy: 0.941000, Test accuracy: 0.943700
Distillation: Epoch : 22, Loss : 1.181907, Accuracy: 0.945000, Test accuracy: 0.945700
Distillation: Epoch : 23, Loss : 1.174707, Accuracy: 0.951000, Test accuracy: 0.946800
Distillation: Epoch : 24, Loss : 1.183547, Accuracy: 0.935000, Test accuracy: 0.946500
Distillation: Epoch : 25, Loss : 1.172309, Accuracy: 0.942000, Test accuracy: 0.947800
Distillation: Epoch : 26, Loss : 1.189668, Accuracy: 0.936000, Test accuracy: 0.947400
Distillation: Epoch : 27, Loss : 1.175083, Accuracy: 0.940000, Test accuracy: 0.949100
Distillation: Epoch : 28, Loss : 1.175605, Accuracy: 0.946000, Test accuracy: 0.949000
Distillation: Epoch : 29, Loss : 1.156319, Accuracy: 0.946000, Test accuracy: 0.949600
Distillation: Epoch : 30, Loss : 1.157588, Accuracy: 0.954000, Test accuracy: 0.950500
Distillation: Epoch : 31, Loss : 1.176177, Accuracy: 0.942000, Test accuracy: 0.951000
Distillation: Epoch : 32, Loss : 1.187630, Accuracy: 0.938000, Test accuracy: 0.951500
Distillation: Epoch : 33, Loss : 1.150912, Accuracy: 0.945000, Test accuracy: 0.952400
Distillation: Epoch : 34, Loss : 1.173906, Accuracy: 0.935000, Test accuracy: 0.952600
Distillation: Epoch : 35, Loss : 1.146678, Accuracy: 0.952000, Test accuracy: 0.953700
Distillation: Epoch : 36, Loss : 1.180304, Accuracy: 0.951000, Test accuracy: 0.953900
Distillation: Epoch : 37, Loss : 1.161371, Accuracy: 0.953000, Test accuracy: 0.954500
Distillation: Epoch : 38, Loss : 1.167776, Accuracy: 0.952000, Test accuracy: 0.954700
Distillation: Epoch : 39, Loss : 1.171434, Accuracy: 0.954000, Test accuracy: 0.954600
Distillation: Epoch : 40, Loss : 1.172982, Accuracy: 0.950000, Test accuracy: 0.955500
Distillation: Epoch : 41, Loss : 1.144711, Accuracy: 0.954000, Test accuracy: 0.956000
Distillation: Epoch : 42, Loss : 1.166809, Accuracy: 0.952000, Test accuracy: 0.956500
Distillation: Epoch : 43, Loss : 1.158440, Accuracy: 0.951000, Test accuracy: 0.956700
Distillation: Epoch : 44, Loss : 1.169842, Accuracy: 0.935000, Test accuracy: 0.957000
Distillation: Epoch : 45, Loss : 1.173862, Accuracy: 0.949000, Test accuracy: 0.957300
Distillation: Epoch : 46, Loss : 1.172112, Accuracy: 0.940000, Test accuracy: 0.957100
Distillation: Epoch : 47, Loss : 1.166151, Accuracy: 0.951000, Test accuracy: 0.957400
Distillation: Epoch : 48, Loss : 1.155158, Accuracy: 0.959000, Test accuracy: 0.958000
Distillation: Epoch : 49, Loss : 1.167459, Accuracy: 0.949000, Test accuracy: 0.957700
Distillation: Epoch : 50, Loss : 1.189785, Accuracy: 0.947000, Test accuracy: 0.958300
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9583
Generating confusion matrix for student3
[[ 958.    0.    2.    0.    1.    1.    5.    1.    6.    4.]
 [   0. 1118.    6.    1.    1.    1.    3.    7.    4.    6.]
 [   1.    3.  987.    9.    2.    0.    0.   22.    9.    1.]
 [   1.    2.    5.  980.    0.   17.    0.   12.   14.   16.]
 [   1.    0.    5.    2.  940.    0.    5.    3.    7.   17.]
 [   2.    0.    0.    7.    0.  857.   12.    1.    6.    9.]
 [  10.    6.    2.    0.    8.    5.  932.    0.    3.    2.]
 [   2.    0.    8.    5.    7.    2.    0.  962.    7.   12.]
 [   5.    6.   14.    4.    4.    5.    1.    3.  908.    1.]
 [   0.    0.    3.    2.   19.    4.    0.   17.   10.  941.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 1.995952, Accuracy: 0.640000, Test accuracy: 0.624600
Distillation: Epoch : 2, Loss : 1.602140, Accuracy: 0.774000, Test accuracy: 0.802900
Distillation: Epoch : 3, Loss : 1.511803, Accuracy: 0.820000, Test accuracy: 0.841900
Distillation: Epoch : 4, Loss : 1.502675, Accuracy: 0.827000, Test accuracy: 0.856800
Distillation: Epoch : 5, Loss : 1.471286, Accuracy: 0.847000, Test accuracy: 0.869400
Distillation: Epoch : 6, Loss : 1.465273, Accuracy: 0.871000, Test accuracy: 0.876200
Distillation: Epoch : 7, Loss : 1.427452, Accuracy: 0.874000, Test accuracy: 0.880500
Distillation: Epoch : 8, Loss : 1.430252, Accuracy: 0.875000, Test accuracy: 0.881000
Distillation: Epoch : 9, Loss : 1.422750, Accuracy: 0.891000, Test accuracy: 0.885400
Distillation: Epoch : 10, Loss : 1.401733, Accuracy: 0.899000, Test accuracy: 0.889500
Distillation: Epoch : 11, Loss : 1.431025, Accuracy: 0.881000, Test accuracy: 0.890200
Distillation: Epoch : 12, Loss : 1.417916, Accuracy: 0.889000, Test accuracy: 0.892700
Distillation: Epoch : 13, Loss : 1.422988, Accuracy: 0.891000, Test accuracy: 0.894100
Distillation: Epoch : 14, Loss : 1.419183, Accuracy: 0.893000, Test accuracy: 0.895300
Distillation: Epoch : 15, Loss : 1.425575, Accuracy: 0.892000, Test accuracy: 0.896300
Distillation: Epoch : 16, Loss : 1.392345, Accuracy: 0.881000, Test accuracy: 0.897000
Distillation: Epoch : 17, Loss : 1.406345, Accuracy: 0.887000, Test accuracy: 0.896700
Distillation: Epoch : 18, Loss : 1.412505, Accuracy: 0.882000, Test accuracy: 0.899600
Distillation: Epoch : 19, Loss : 1.406745, Accuracy: 0.891000, Test accuracy: 0.900200
Distillation: Epoch : 20, Loss : 1.393338, Accuracy: 0.892000, Test accuracy: 0.900100
Distillation: Epoch : 21, Loss : 1.417618, Accuracy: 0.895000, Test accuracy: 0.901900
Distillation: Epoch : 22, Loss : 1.401137, Accuracy: 0.891000, Test accuracy: 0.901400
Distillation: Epoch : 23, Loss : 1.411516, Accuracy: 0.893000, Test accuracy: 0.903300
Distillation: Epoch : 24, Loss : 1.386688, Accuracy: 0.922000, Test accuracy: 0.902500
Distillation: Epoch : 25, Loss : 1.415551, Accuracy: 0.893000, Test accuracy: 0.903200
Distillation: Epoch : 26, Loss : 1.406547, Accuracy: 0.900000, Test accuracy: 0.904900
Distillation: Epoch : 27, Loss : 1.405212, Accuracy: 0.889000, Test accuracy: 0.904900
Distillation: Epoch : 28, Loss : 1.382631, Accuracy: 0.903000, Test accuracy: 0.906400
Distillation: Epoch : 29, Loss : 1.411483, Accuracy: 0.909000, Test accuracy: 0.907300
Distillation: Epoch : 30, Loss : 1.397255, Accuracy: 0.896000, Test accuracy: 0.906300
Distillation: Epoch : 31, Loss : 1.399333, Accuracy: 0.891000, Test accuracy: 0.907900
Distillation: Epoch : 32, Loss : 1.390806, Accuracy: 0.907000, Test accuracy: 0.908000
Distillation: Epoch : 33, Loss : 1.360452, Accuracy: 0.910000, Test accuracy: 0.907700
Distillation: Epoch : 34, Loss : 1.417002, Accuracy: 0.884000, Test accuracy: 0.907700
Distillation: Epoch : 35, Loss : 1.388655, Accuracy: 0.905000, Test accuracy: 0.909000
Distillation: Epoch : 36, Loss : 1.403422, Accuracy: 0.899000, Test accuracy: 0.910100
Distillation: Epoch : 37, Loss : 1.377827, Accuracy: 0.910000, Test accuracy: 0.910900
Distillation: Epoch : 38, Loss : 1.380676, Accuracy: 0.907000, Test accuracy: 0.911800
Distillation: Epoch : 39, Loss : 1.385611, Accuracy: 0.905000, Test accuracy: 0.912600
Distillation: Epoch : 40, Loss : 1.354168, Accuracy: 0.922000, Test accuracy: 0.913200
Distillation: Epoch : 41, Loss : 1.361114, Accuracy: 0.914000, Test accuracy: 0.914100
Distillation: Epoch : 42, Loss : 1.388690, Accuracy: 0.908000, Test accuracy: 0.913900
Distillation: Epoch : 43, Loss : 1.397946, Accuracy: 0.898000, Test accuracy: 0.915000
Distillation: Epoch : 44, Loss : 1.359023, Accuracy: 0.906000, Test accuracy: 0.915800
Distillation: Epoch : 45, Loss : 1.376675, Accuracy: 0.903000, Test accuracy: 0.917700
Distillation: Epoch : 46, Loss : 1.383697, Accuracy: 0.907000, Test accuracy: 0.916900
Distillation: Epoch : 47, Loss : 1.360801, Accuracy: 0.906000, Test accuracy: 0.918500
Distillation: Epoch : 48, Loss : 1.376812, Accuracy: 0.901000, Test accuracy: 0.918100
Distillation: Epoch : 49, Loss : 1.364000, Accuracy: 0.913000, Test accuracy: 0.919200
Distillation: Epoch : 50, Loss : 1.359123, Accuracy: 0.912000, Test accuracy: 0.920800
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9208
Generating confusion matrix for student3
[[ 938.    0.    5.    2.    0.    5.    4.    1.    5.    7.]
 [   0. 1101.    9.    1.    3.    3.    4.   16.    6.    8.]
 [   2.    3.  914.   16.    5.    2.    4.   19.    7.    3.]
 [   5.    6.   20.  947.    2.   51.    0.    7.   35.   19.]
 [   3.    1.   13.    1.  922.    5.    9.   10.    9.   31.]
 [   6.    4.    0.   14.    1.  771.   18.    1.   23.    7.]
 [  17.    6.   13.    3.    6.   17.  917.    1.   13.    1.]
 [   1.    0.   14.   10.    3.    5.    1.  940.    4.   29.]
 [   5.   14.   38.   12.   15.   27.    1.    1.  861.    7.]
 [   3.    0.    6.    4.   25.    6.    0.   32.   11.  897.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.083852, Accuracy: 0.563000, Test accuracy: 0.570600
Distillation: Epoch : 2, Loss : 1.709953, Accuracy: 0.848000, Test accuracy: 0.837100
Distillation: Epoch : 3, Loss : 1.598498, Accuracy: 0.862000, Test accuracy: 0.872600
Distillation: Epoch : 4, Loss : 1.564807, Accuracy: 0.872000, Test accuracy: 0.893000
Distillation: Epoch : 5, Loss : 1.537842, Accuracy: 0.893000, Test accuracy: 0.903100
Distillation: Epoch : 6, Loss : 1.522928, Accuracy: 0.904000, Test accuracy: 0.911000
Distillation: Epoch : 7, Loss : 1.516223, Accuracy: 0.922000, Test accuracy: 0.917000
Distillation: Epoch : 8, Loss : 1.486209, Accuracy: 0.915000, Test accuracy: 0.920900
Distillation: Epoch : 9, Loss : 1.503176, Accuracy: 0.918000, Test accuracy: 0.925100
Distillation: Epoch : 10, Loss : 1.480773, Accuracy: 0.922000, Test accuracy: 0.928500
Distillation: Epoch : 11, Loss : 1.476901, Accuracy: 0.917000, Test accuracy: 0.931500
Distillation: Epoch : 12, Loss : 1.486099, Accuracy: 0.932000, Test accuracy: 0.934200
Distillation: Epoch : 13, Loss : 1.469652, Accuracy: 0.922000, Test accuracy: 0.936000
Distillation: Epoch : 14, Loss : 1.463136, Accuracy: 0.918000, Test accuracy: 0.936800
Distillation: Epoch : 15, Loss : 1.447037, Accuracy: 0.927000, Test accuracy: 0.939400
Distillation: Epoch : 16, Loss : 1.473853, Accuracy: 0.926000, Test accuracy: 0.940800
Distillation: Epoch : 17, Loss : 1.470107, Accuracy: 0.928000, Test accuracy: 0.942400
Distillation: Epoch : 18, Loss : 1.472661, Accuracy: 0.929000, Test accuracy: 0.944100
Distillation: Epoch : 19, Loss : 1.454755, Accuracy: 0.942000, Test accuracy: 0.944600
Distillation: Epoch : 20, Loss : 1.456657, Accuracy: 0.937000, Test accuracy: 0.945700
Distillation: Epoch : 21, Loss : 1.469858, Accuracy: 0.937000, Test accuracy: 0.946700
Distillation: Epoch : 22, Loss : 1.454529, Accuracy: 0.936000, Test accuracy: 0.947600
Distillation: Epoch : 23, Loss : 1.453408, Accuracy: 0.955000, Test accuracy: 0.948800
Distillation: Epoch : 24, Loss : 1.459558, Accuracy: 0.953000, Test accuracy: 0.949300
Distillation: Epoch : 25, Loss : 1.460534, Accuracy: 0.944000, Test accuracy: 0.949500
Distillation: Epoch : 26, Loss : 1.420528, Accuracy: 0.946000, Test accuracy: 0.950300
Distillation: Epoch : 27, Loss : 1.453356, Accuracy: 0.951000, Test accuracy: 0.950600
Distillation: Epoch : 28, Loss : 1.418541, Accuracy: 0.957000, Test accuracy: 0.950500
Distillation: Epoch : 29, Loss : 1.451982, Accuracy: 0.952000, Test accuracy: 0.951900
Distillation: Epoch : 30, Loss : 1.422796, Accuracy: 0.951000, Test accuracy: 0.951800
Distillation: Epoch : 31, Loss : 1.438997, Accuracy: 0.953000, Test accuracy: 0.951600
Distillation: Epoch : 32, Loss : 1.455508, Accuracy: 0.947000, Test accuracy: 0.952000
Distillation: Epoch : 33, Loss : 1.445540, Accuracy: 0.951000, Test accuracy: 0.952600
Distillation: Epoch : 34, Loss : 1.434350, Accuracy: 0.949000, Test accuracy: 0.953300
Distillation: Epoch : 35, Loss : 1.436201, Accuracy: 0.946000, Test accuracy: 0.953600
Distillation: Epoch : 36, Loss : 1.424984, Accuracy: 0.939000, Test accuracy: 0.953900
Distillation: Epoch : 37, Loss : 1.425659, Accuracy: 0.953000, Test accuracy: 0.953900
Distillation: Epoch : 38, Loss : 1.434410, Accuracy: 0.940000, Test accuracy: 0.954600
Distillation: Epoch : 39, Loss : 1.417528, Accuracy: 0.950000, Test accuracy: 0.954800
Distillation: Epoch : 40, Loss : 1.423560, Accuracy: 0.952000, Test accuracy: 0.954800
Distillation: Epoch : 41, Loss : 1.425406, Accuracy: 0.952000, Test accuracy: 0.955100
Distillation: Epoch : 42, Loss : 1.443213, Accuracy: 0.948000, Test accuracy: 0.953900
Distillation: Epoch : 43, Loss : 1.425630, Accuracy: 0.956000, Test accuracy: 0.955100
Distillation: Epoch : 44, Loss : 1.430535, Accuracy: 0.952000, Test accuracy: 0.954900
Distillation: Epoch : 45, Loss : 1.449659, Accuracy: 0.955000, Test accuracy: 0.955300
Distillation: Epoch : 46, Loss : 1.425391, Accuracy: 0.951000, Test accuracy: 0.955100
Distillation: Epoch : 47, Loss : 1.411363, Accuracy: 0.961000, Test accuracy: 0.956100
Distillation: Epoch : 48, Loss : 1.439034, Accuracy: 0.953000, Test accuracy: 0.955700
Distillation: Epoch : 49, Loss : 1.433075, Accuracy: 0.938000, Test accuracy: 0.955900
Distillation: Epoch : 50, Loss : 1.410577, Accuracy: 0.944000, Test accuracy: 0.956000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.956
Generating confusion matrix for student3
[[ 957.    0.    2.    0.    1.    2.    9.    2.    7.    5.]
 [   1. 1113.    3.    1.    3.    1.    3.   10.    5.    6.]
 [   3.    4.  978.    7.    1.    1.    0.   24.   10.    1.]
 [   1.    2.    6.  983.    0.   13.    0.    7.   14.   15.]
 [   1.    0.    7.    1.  943.    0.    6.    5.    5.   15.]
 [   1.    0.    1.    7.    1.  861.   12.    1.    8.    7.]
 [  11.    5.    4.    0.    7.    5.  927.    0.    7.    2.]
 [   1.    0.    7.    4.    5.    1.    0.  961.    7.   16.]
 [   4.   11.   23.    5.    4.    5.    1.    2.  900.    5.]
 [   0.    0.    1.    2.   17.    3.    0.   16.   11.  937.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.122545, Accuracy: 0.649000, Test accuracy: 0.670600
Distillation: Epoch : 2, Loss : 1.886437, Accuracy: 0.790000, Test accuracy: 0.799600
Distillation: Epoch : 3, Loss : 1.844583, Accuracy: 0.836000, Test accuracy: 0.835400
Distillation: Epoch : 4, Loss : 1.844118, Accuracy: 0.847000, Test accuracy: 0.857300
Distillation: Epoch : 5, Loss : 1.809155, Accuracy: 0.863000, Test accuracy: 0.866200
Distillation: Epoch : 6, Loss : 1.800517, Accuracy: 0.860000, Test accuracy: 0.875800
Distillation: Epoch : 7, Loss : 1.785225, Accuracy: 0.877000, Test accuracy: 0.879400
Distillation: Epoch : 8, Loss : 1.789843, Accuracy: 0.878000, Test accuracy: 0.884500
Distillation: Epoch : 9, Loss : 1.805487, Accuracy: 0.876000, Test accuracy: 0.887200
Distillation: Epoch : 10, Loss : 1.815196, Accuracy: 0.885000, Test accuracy: 0.892000
Distillation: Epoch : 11, Loss : 1.786678, Accuracy: 0.888000, Test accuracy: 0.895300
Distillation: Epoch : 12, Loss : 1.774089, Accuracy: 0.895000, Test accuracy: 0.899100
Distillation: Epoch : 13, Loss : 1.812968, Accuracy: 0.895000, Test accuracy: 0.899300
Distillation: Epoch : 14, Loss : 1.763502, Accuracy: 0.877000, Test accuracy: 0.904500
Distillation: Epoch : 15, Loss : 1.787535, Accuracy: 0.896000, Test accuracy: 0.905800
Distillation: Epoch : 16, Loss : 1.773057, Accuracy: 0.875000, Test accuracy: 0.905500
Distillation: Epoch : 17, Loss : 1.765303, Accuracy: 0.898000, Test accuracy: 0.906100
Distillation: Epoch : 18, Loss : 1.776827, Accuracy: 0.883000, Test accuracy: 0.908200
Distillation: Epoch : 19, Loss : 1.758651, Accuracy: 0.901000, Test accuracy: 0.909300
Distillation: Epoch : 20, Loss : 1.771618, Accuracy: 0.891000, Test accuracy: 0.911700
Distillation: Epoch : 21, Loss : 1.766681, Accuracy: 0.893000, Test accuracy: 0.913200
Distillation: Epoch : 22, Loss : 1.764287, Accuracy: 0.905000, Test accuracy: 0.914300
Distillation: Epoch : 23, Loss : 1.773742, Accuracy: 0.911000, Test accuracy: 0.916200
Distillation: Epoch : 24, Loss : 1.762636, Accuracy: 0.913000, Test accuracy: 0.917400
Distillation: Epoch : 25, Loss : 1.748831, Accuracy: 0.916000, Test accuracy: 0.917900
Distillation: Epoch : 26, Loss : 1.763081, Accuracy: 0.909000, Test accuracy: 0.920000
Distillation: Epoch : 27, Loss : 1.752351, Accuracy: 0.924000, Test accuracy: 0.922000
Distillation: Epoch : 28, Loss : 1.747185, Accuracy: 0.910000, Test accuracy: 0.924100
Distillation: Epoch : 29, Loss : 1.763195, Accuracy: 0.909000, Test accuracy: 0.924900
Distillation: Epoch : 30, Loss : 1.754714, Accuracy: 0.918000, Test accuracy: 0.926900
Distillation: Epoch : 31, Loss : 1.727375, Accuracy: 0.943000, Test accuracy: 0.927800
Distillation: Epoch : 32, Loss : 1.726489, Accuracy: 0.930000, Test accuracy: 0.929500
Distillation: Epoch : 33, Loss : 1.756249, Accuracy: 0.913000, Test accuracy: 0.930700
Distillation: Epoch : 34, Loss : 1.751323, Accuracy: 0.924000, Test accuracy: 0.931700
Distillation: Epoch : 35, Loss : 1.758399, Accuracy: 0.919000, Test accuracy: 0.932700
Distillation: Epoch : 36, Loss : 1.741650, Accuracy: 0.923000, Test accuracy: 0.934400
Distillation: Epoch : 37, Loss : 1.723432, Accuracy: 0.939000, Test accuracy: 0.934800
Distillation: Epoch : 38, Loss : 1.748768, Accuracy: 0.926000, Test accuracy: 0.936600
Distillation: Epoch : 39, Loss : 1.735787, Accuracy: 0.933000, Test accuracy: 0.937200
Distillation: Epoch : 40, Loss : 1.747609, Accuracy: 0.921000, Test accuracy: 0.938600
Distillation: Epoch : 41, Loss : 1.719172, Accuracy: 0.931000, Test accuracy: 0.939500
Distillation: Epoch : 42, Loss : 1.732607, Accuracy: 0.928000, Test accuracy: 0.938700
Distillation: Epoch : 43, Loss : 1.724189, Accuracy: 0.934000, Test accuracy: 0.940100
Distillation: Epoch : 44, Loss : 1.746555, Accuracy: 0.921000, Test accuracy: 0.940800
Distillation: Epoch : 45, Loss : 1.738525, Accuracy: 0.940000, Test accuracy: 0.941700
Distillation: Epoch : 46, Loss : 1.720060, Accuracy: 0.939000, Test accuracy: 0.943000
Distillation: Epoch : 47, Loss : 1.729770, Accuracy: 0.954000, Test accuracy: 0.942800
Distillation: Epoch : 48, Loss : 1.740478, Accuracy: 0.929000, Test accuracy: 0.943600
Distillation: Epoch : 49, Loss : 1.724111, Accuracy: 0.942000, Test accuracy: 0.944200
Distillation: Epoch : 50, Loss : 1.731917, Accuracy: 0.940000, Test accuracy: 0.944000
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.944
Generating confusion matrix for student3
[[ 948.    0.    4.    0.    0.    3.    3.    1.    5.    6.]
 [   1. 1094.    8.    0.    2.    1.    2.   15.    3.    6.]
 [   5.    6.  968.    6.    6.    1.    0.   18.   10.    2.]
 [   2.    4.    4.  978.    0.   22.    0.    8.   34.   21.]
 [   3.    1.    9.    2.  932.    0.    6.    4.    7.   22.]
 [   3.    2.    0.    7.    0.  840.   21.    2.   11.    5.]
 [  11.    7.    6.    2.   12.    9.  925.    0.    3.    1.]
 [   3.    0.   12.    8.    3.    2.    0.  946.    5.   20.]
 [   4.   21.   18.    6.    5.   13.    1.    3.  886.    3.]
 [   0.    0.    3.    1.   22.    1.    0.   31.   10.  923.]]
</confusion_matrix>
Distillation: Epoch : 1, Loss : 2.229543, Accuracy: 0.510000, Test accuracy: 0.483300
Distillation: Epoch : 2, Loss : 2.112816, Accuracy: 0.739000, Test accuracy: 0.762800
Distillation: Epoch : 3, Loss : 2.071918, Accuracy: 0.800000, Test accuracy: 0.818300
Distillation: Epoch : 4, Loss : 2.061559, Accuracy: 0.811000, Test accuracy: 0.840600
Distillation: Epoch : 5, Loss : 2.045506, Accuracy: 0.850000, Test accuracy: 0.853700
Distillation: Epoch : 6, Loss : 2.039013, Accuracy: 0.866000, Test accuracy: 0.861800
Distillation: Epoch : 7, Loss : 2.037541, Accuracy: 0.856000, Test accuracy: 0.867500
Distillation: Epoch : 8, Loss : 2.029657, Accuracy: 0.870000, Test accuracy: 0.873400
Distillation: Epoch : 9, Loss : 2.027833, Accuracy: 0.877000, Test accuracy: 0.878200
Distillation: Epoch : 10, Loss : 2.032566, Accuracy: 0.864000, Test accuracy: 0.881500
Distillation: Epoch : 11, Loss : 2.046276, Accuracy: 0.842000, Test accuracy: 0.884000
Distillation: Epoch : 12, Loss : 2.028060, Accuracy: 0.872000, Test accuracy: 0.887000
Distillation: Epoch : 13, Loss : 2.019819, Accuracy: 0.880000, Test accuracy: 0.889900
Distillation: Epoch : 14, Loss : 2.022782, Accuracy: 0.890000, Test accuracy: 0.893200
Distillation: Epoch : 15, Loss : 2.017122, Accuracy: 0.901000, Test accuracy: 0.893800
Distillation: Epoch : 16, Loss : 2.016569, Accuracy: 0.895000, Test accuracy: 0.897400
Distillation: Epoch : 17, Loss : 2.018668, Accuracy: 0.903000, Test accuracy: 0.898900
Distillation: Epoch : 18, Loss : 2.018800, Accuracy: 0.896000, Test accuracy: 0.901100
Distillation: Epoch : 19, Loss : 2.012910, Accuracy: 0.895000, Test accuracy: 0.903000
Distillation: Epoch : 20, Loss : 2.018296, Accuracy: 0.903000, Test accuracy: 0.906300
Distillation: Epoch : 21, Loss : 2.003810, Accuracy: 0.895000, Test accuracy: 0.906600
Distillation: Epoch : 22, Loss : 2.003889, Accuracy: 0.896000, Test accuracy: 0.910500
Distillation: Epoch : 23, Loss : 2.005503, Accuracy: 0.907000, Test accuracy: 0.913100
Distillation: Epoch : 24, Loss : 2.014444, Accuracy: 0.908000, Test accuracy: 0.913900
Distillation: Epoch : 25, Loss : 2.000023, Accuracy: 0.906000, Test accuracy: 0.916300
Distillation: Epoch : 26, Loss : 1.997617, Accuracy: 0.910000, Test accuracy: 0.918400
Distillation: Epoch : 27, Loss : 2.011453, Accuracy: 0.911000, Test accuracy: 0.919800
Distillation: Epoch : 28, Loss : 2.000399, Accuracy: 0.918000, Test accuracy: 0.922500
Distillation: Epoch : 29, Loss : 1.995005, Accuracy: 0.921000, Test accuracy: 0.923000
Distillation: Epoch : 30, Loss : 2.003206, Accuracy: 0.922000, Test accuracy: 0.923400
Distillation: Epoch : 31, Loss : 1.995383, Accuracy: 0.932000, Test accuracy: 0.924000
Distillation: Epoch : 32, Loss : 1.983784, Accuracy: 0.945000, Test accuracy: 0.924000
Distillation: Epoch : 33, Loss : 1.991819, Accuracy: 0.931000, Test accuracy: 0.925600
Distillation: Epoch : 34, Loss : 1.999892, Accuracy: 0.911000, Test accuracy: 0.926400
Distillation: Epoch : 35, Loss : 2.000506, Accuracy: 0.917000, Test accuracy: 0.928500
Distillation: Epoch : 36, Loss : 2.000582, Accuracy: 0.923000, Test accuracy: 0.931300
Distillation: Epoch : 37, Loss : 2.001428, Accuracy: 0.931000, Test accuracy: 0.931200
Distillation: Epoch : 38, Loss : 2.001596, Accuracy: 0.929000, Test accuracy: 0.931700
Distillation: Epoch : 39, Loss : 2.007586, Accuracy: 0.922000, Test accuracy: 0.933100
Distillation: Epoch : 40, Loss : 1.989411, Accuracy: 0.934000, Test accuracy: 0.934000
Distillation: Epoch : 41, Loss : 1.993415, Accuracy: 0.927000, Test accuracy: 0.935600
Distillation: Epoch : 42, Loss : 1.994702, Accuracy: 0.925000, Test accuracy: 0.935200
Distillation: Epoch : 43, Loss : 1.986577, Accuracy: 0.923000, Test accuracy: 0.937000
Distillation: Epoch : 44, Loss : 2.007655, Accuracy: 0.916000, Test accuracy: 0.937000
Distillation: Epoch : 45, Loss : 2.000393, Accuracy: 0.931000, Test accuracy: 0.937800
Distillation: Epoch : 46, Loss : 1.993368, Accuracy: 0.912000, Test accuracy: 0.938500
Distillation: Epoch : 47, Loss : 1.991803, Accuracy: 0.942000, Test accuracy: 0.939300
Distillation: Epoch : 48, Loss : 1.991286, Accuracy: 0.929000, Test accuracy: 0.940000
Distillation: Epoch : 49, Loss : 1.989600, Accuracy: 0.937000, Test accuracy: 0.939500
Distillation: Epoch : 50, Loss : 1.991097, Accuracy: 0.940000, Test accuracy: 0.941700
Saving to student3/student3.ckpt
<confusion_matrix>
results for %s distillate with T = %d student3 [1, 3, 6, 7, 8, 9, 10, 11, 12, 15, 20]
Loading from student3/student3.ckpt
Accuracy on the test set
0.9417
Generating confusion matrix for student3
[[ 952.    0.    2.    0.    0.    3.    6.    0.    8.    4.]
 [   0. 1103.    8.    0.    1.    3.    3.    5.    9.    4.]
 [   1.    3.  952.    7.    4.    1.    1.   20.   10.    1.]
 [   1.    4.   20.  980.    6.   40.    1.   10.   20.   20.]
 [   6.    1.    4.    0.  929.    0.    3.    2.    6.   11.]
 [   2.    6.    2.    7.    4.  813.   13.    1.   26.   10.]
 [  12.    6.   11.    0.    9.   10.  929.    0.    9.    0.]
 [   1.    0.   10.    9.    2.    2.    0.  957.    6.   17.]
 [   3.   12.   23.    5.    4.   14.    2.    3.  869.    9.]
 [   2.    0.    0.    2.   23.    6.    0.   30.   11.  933.]]
</confusion_matrix>
